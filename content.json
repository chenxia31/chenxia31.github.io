{"meta":{"title":"Chenxia's blog","subtitle":"","description":"","author":"chenxia","url":"https://blog.tjdata.site","root":"/"},"pages":[{"title":"","date":"2023-03-02T15:41:44.250Z","updated":"2022-10-17T06:51:03.692Z","comments":false,"path":"baidu_verify_code-C4OM5jwAkw.html","permalink":"https://blog.tjdata.site/baidu_verify_code-C4OM5jwAkw.html","excerpt":"","text":"07ca04d26b4bb28f9b4db5f6f4d416b3"},{"title":"404 Not Found：该页无法显示","date":"2023-03-02T15:41:44.242Z","updated":"2022-03-20T16:18:46.000Z","comments":false,"path":"/404.html","permalink":"https://blog.tjdata.site/404.html","excerpt":"","text":""},{"title":"分类","date":"2023-03-02T15:41:44.250Z","updated":"2022-03-20T16:18:46.000Z","comments":false,"path":"categories/index.html","permalink":"https://blog.tjdata.site/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-03-02T15:41:44.251Z","updated":"2022-03-20T16:18:46.000Z","comments":false,"path":"repository/index.html","permalink":"https://blog.tjdata.site/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-03-02T15:41:44.251Z","updated":"2022-03-20T16:18:46.000Z","comments":false,"path":"tags/index.html","permalink":"https://blog.tjdata.site/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2023-08-12T07:41:54.185Z","updated":"2023-08-12T07:33:59.346Z","comments":false,"path":"links/index.html","permalink":"https://blog.tjdata.site/links/index.html","excerpt":"","text":"Test for links"},{"title":"书单","date":"2023-03-02T15:41:44.250Z","updated":"2022-03-20T16:18:46.000Z","comments":false,"path":"books/index.html","permalink":"https://blog.tjdata.site/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2023-03-02T15:41:44.250Z","updated":"2022-10-16T15:53:43.064Z","comments":false,"path":"about/index.html","permalink":"https://blog.tjdata.site/about/index.html","excerpt":"关于为什么我希望拥有一个自己的博客？并承诺会将这份博客写下去","text":"关于为什么我希望拥有一个自己的博客？并承诺会将这份博客写下去 0x01 关于blog 博客本身便有着其自身作为互联网的浪漫！（这里不谈web3）互联网作为其诞生之初便是让每个人都平等的链接起来并可以分享和发表自己的观点，但是随着商业和政府的融入，互联网逐渐显示出其工具性的特点，个人在其中的作用逐渐被垄断性的互联网公司所抹除，仿佛互联网公司便是互联网中的实际执法者。但回顾在互联网最开始的愿景中，是希望每个人可以通过互联网连接在一起，博客有着一台服务器、一个域名便可以发不出自己的生活点滴、自由思想等，可以让自己的声音在互联网的一角中的留有回响 0x02 关于自己 本人的专业是交通运输行业中的交通信息方向的大四学生（2022年），作为一名综合性的应用学科，交通本科中学习的方向很多，但是同样也有学的不精细的特点 （基础类）高等数学、线性代数、概率论、复变函数、理论力学、C++ （专业基础类）模电数电、电路分析、交通信号基础、自动控制原理、信号与系统、信息传输原理 （专业进阶）嵌入式系统、交通信息检测与处理、交通数据分析、车站与区间信号控制、列车运行控制系统 在计算机技术加持在传统行业中，以数据来说话的思想推动着数据化、信息化、智能化、自动化的发展，这可能也是本人研究生之后的方向。所以作为一个非计算机科学、非数学科学出生的人来说，交通行业对于数据处理的方式可能最多是在于模型应用场景的人为区分，但是本人还是希望可以学习一些计算机、数学、编程等比较有趣的知识来武装自己，并在接触新鲜事物中保持着自己的前进的动力。 正如Jobs所述：stay hungry，stay foolish！ 0x03 关于自己的blog 对于一个系统的设计自然要从需求的角度出发，自己的blog体系也不意外，因此建立自己博客的目的是我希望将自己的学习知识用比较个性化的语言总结出来发布到网上 记录：并总结自己的所学，可能会走弯路，但是要尝试去做 督促：自己学习，同样是为了自己后续的进步 因此希望从大四开始，从今天开始，至少保证一个月一篇，正常尽可能的保持一个星期一篇来认真写出一份文章。 同时post的分类可能会有： base，比如Linux的简单使用、python环境的配置等 lives，自己杂谈的所思所想 CS，比如web开发、数据结构之类的知识 DS，比如一些数据的笔记、算法的推导"}],"posts":[{"title":"Python学习_matplotlib指南","slug":"Python学习-matplotlib指南","date":"2023-08-29T12:03:02.000Z","updated":"2023-08-29T12:04:04.839Z","comments":true,"path":"posts/5fd26a11.html","link":"","permalink":"https://blog.tjdata.site/posts/5fd26a11.html","excerpt":"阅读Python的matplotlib的","text":"阅读Python的matplotlib的 Python 绘图教程 0x00 Basic setting What is matplotlib? Matplotlib is a comprehensive library for creating static, animated, interactive visualization in Python. We can as follows: 创建高质量的图片 创建可以交互的、放大、拖动、更新的图片 定制化风格和尺寸 导出为不同的格式 在Jupyter notebook或其他应用中使用 丰富的第三方库 在使用中图片可以按照A4比例来进行设置，同时设置对应的字体和颜色 1234567mm = 1/25.4# plt.figure(figsize=(10*mm,20*mm)plt.rcParams[&#x27;font.family&#x27;]= &quot;Times New Roman&quot;mpl.rcParams[&#x27;xtick.labelsize&#x27;] = 10mpl.rcParams[&#x27;ytick.labelsize&#x27;] = 10plt.rcParams[&#x27;mathtext.fontset&#x27;]=&#x27;cm&#x27;plt.style.use(&#x27;tableau-colorblind10&#x27;) 0x01 Intro to Matplotlib pyplot 1.1 两种绘图方式 面向对象（Objetc- oriented style）的绘图方式将图片的fig和axis区分开来，使用plt.subplots( )来创建figure对象 函数编程，直接使用封装好的plt.figure() plt.plot()来创建figure和绘图对象 1.2 图片对象包括哪些属性 12345678910111213141516171819202122232425262728293031323334353637383940fig,ax = plt.subplots(figsize=(150*mm,100*mm))ax.set_title(&#x27;The title stays&#x27;,fontsize=10)ax.set_xlabel(&#x27;xlabel stays&#x27;,fontsize=10)ax.set_ylabel(&#x27;ylabel stays&#x27;,fontsize=10)ax.xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter(&#x27;%.1f&#x27;))ax.yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter(&#x27;%.1f&#x27;))ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(1))ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(1))ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.5))ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.5))ax.set_xscale(&#x27;linear&#x27;)ax.set_yscale(&#x27;linear&#x27;)ax.set_xticks(np.linspace(0,10,11))ax.set_yticks(np.linspace(0,10,11))ax.plot(np.linspace(0,10,100),np.linspace(0,10,100),label=&#x27;1:1&#x27;,color=&#x27;k&#x27;,linestyle=&#x27;--&#x27;)ax.scatter(np.linspace(0,10,20),np.sin(np.linspace(0,10,20)+1),label=&#x27;1:2&#x27;,color=&#x27;g&#x27;,marker=&#x27;o&#x27;)ax.legend(loc=&#x27;upper left&#x27;,fontsize=10,frameon=False)ax.grid(&#x27;major&#x27;,color=&#x27;k&#x27;,linestyle=&#x27;--&#x27;,linewidth=0.1)ax.spines[&#x27;right&#x27;].set_color(&#x27;None&#x27;)ax.spines[&#x27;top&#x27;].set_color(&#x27;None&#x27;)ax.spines[&#x27;bottom&#x27;].set_position((&#x27;data&#x27;,1)) #将x轴移到y=0处ax.spines[&#x27;left&#x27;].set_position((&#x27;data&#x27;,1)) #将x轴移到x=0处ax.text(6,9,&quot;function:y=x&quot;,size=15,color=&#x27;r&#x27;,style=&#x27;italic&#x27;,weight=&#x27;light&#x27;,bbox=dict(facecolor=&#x27;w&#x27;,alpha=0.5))for coord in np.linspace(3,7,10): ax.text(coord,coord+1,&#x27;%.0f&#x27;%coord,ha=&#x27;center&#x27;,va=&#x27;bottom&#x27;)ax.annotate(&#x27;annotate&#x27;,xy=(9,9),xytext=(7,6),arrowprops=dict(arrowstyle=&#x27;-&gt;&#x27;,connectionstyle=&#x27;arc3,rad=0.2&#x27;))ax2 = ax.twinx()ax2.set_ylabel(&#x27;ylabel stays&#x27;,fontsize=10)ax2.set_yscale(&#x27;linear&#x27;)ax2.set_yticks(np.linspace(0,10,11))ax2.set_ylim(0,10)X,Y = np.meshgrid(np.linspace(0,10,11),np.linspace(0,10,11))Z = np.sin(X)+np.cos(Y)pc = ax2.pcolormesh(X,Y,Z,cmap=&#x27;RdBu_r&#x27;,vmin=-1, vmax=1,alpha=0.3)fig.colorbar(pc,ax=ax2,shrink=0.8,pad=0.1)ax2.set_ylabel(&#x27;colorbar&#x27;,fontsize=10) 1.3 Pyplot 设置 上面的图形选项很多，从学习的角度可以全而广的了解，从实际使用的角度可能只会用到其中的几个。 color：pink。lightblue； 1ax.set_prop_cycle(color=[&#x27;#1f77b4&#x27;, &#x27;#aec7e8&#x27;, &#x27;#ff7f0e&#x27;, &#x27;#ffbb78&#x27;, &#x27;#2ca02c&#x27;, &#x27;#98df8a&#x27;,&#x27;#d62728&#x27;, &#x27;#ff9896&#x27;, &#x27;#9467bd&#x27;, &#x27;#c5b0d5&#x27;, &#x27;#8c564b&#x27;, &#x27;#c49c94&#x27;,&#x27;#e377c2&#x27;, &#x27;#f7b6d2&#x27;, &#x27;#7f7f7f&#x27;, &#x27;#c7c7c7&#x27;, &#x27;#bcbd22&#x27;, &#x27;#dbdb8d&#x27;,&#x27;#17becf&#x27;, &#x27;#9edae5&#x27;]) colormap：RdBu linestyle：https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html# marker：https://matplotlib.org/stable/gallery/lines_bars_and_markers/marker_reference.html 等等，除此之外还需要设置针对不同的图增加不同的表达方式。这个就需要从图的种类开始学习。 1.4 Image展示设置 可以通过PIL的Image.open实现图像转换为numpy.array，之后使用imshow方式来可视化图片。同时可以图像进行通道遮盖、色彩映射、添加colorbar等展示，并计算色彩范围，重塑图片大小、插值等操作 0x02 Figure from the Matplotlib 选择官方https://matplotlib.org/stable/gallery/index.html 中一些比较有意思的作为参考 2.1 直线（Lines）、条形图（Bar）、标记（Markers） ax.bar_label 给bar添加标签 ax.bar(…,xerr=error,…) 添加误差线 通过添加upperlimits来设置误差线的箭头 fill_between 填充，可以设置where参数 dash style的设置。set_dash间隔 steps 和 stair设计 2.2 图片（Images），轮廓（Contours）和平面（Filed） 添加水印 fig.figimage 绘制轮廓 matshow显示二维数组 2.3 子图（Subplot），坐标轴（Axes）和图（Figures） 在axes中增加add_axes() 创建多张axes之间的链接 放大效果，axins插入一个框，同时设置set_xlim和set_ylim 2.4 统计（Statistics） 箱图boxplot，可以选择vert垂直标记，path_artist是否填充颜色，labels 箱型图hist，可以返回cumulative的数据 2.5 饼图（Pie）和极坐标图（Polar charts） 有pie绘制图，用bar绘制堆叠图，之后使用connectionPatch来进行两者的链接 2.6 文本（Text）、标签（Label）和标记（Annotation） 不玩花的 2.7 pyplot module 辅助线 axhlines，axvhline 2.8 颜色（Color） colormap，https://matplotlib.org/stable/gallery/color/colormap_reference.html#sphx-glr-gallery-color-colormap-reference-py colors，https://matplotlib.org/stable/gallery/color/named_colors.html#sphx-glr-gallery-color-named-colors-py 2.9 形状和（Shapes）和集合（Collections） 不玩花的 通常在matplotlib patch中的形状或者路径https://blog.csdn.net/qq_27825451/article/details/82967904 2.10 风格指南（Style sheet） 集合 https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html#sphx-glr-gallery-style-sheets-style-sheets-reference-py 选择多了很难呀 2.11 坐标轴网格 略 2.12 坐标轴设计 略 2.13 特殊例子 Show case xkcd非常好玩 好看的颜色 2.14 动画 Animation 调用animation.FuncAnimation就可以实现动图 不玩花的 2.15 事件句柄 （Event handling） 动态交互，不玩花的 2.16 混杂的（Miscellaneous） 给图添加table，可以使用plt.table对象 2.17 3D绘图（3D plotting） 2.18 缩放（Scales） 2.19 特殊绘图（Specialty plots） 2.20 坐标框（Splines） 2.21 标签（Ticks） 坐标 https://matplotlib.org/stable/gallery/ticks/tick-formatters.html#sphx-glr-gallery-ticks-tick-formatters-py 2.22 单位（Units） 我超！可以从basic_unit中导入cm 2.23 嵌入（Embedding into GUI） 略 2.24 组件（Widgets） 指针 cursor添加一些操作，tracking position 按钮 button 确认 check 选择 selector 选择器 menu 鼠标 mouse 区间选择 rangeslider 似乎没这个必要哈哈哈 ![Untitled](/Users/chenxia/Program/js_chenxia31-blog/source/_posts/Python 绘图教程 68e6ac8c6cc64e4db95c2da1686d65dd/Untitled 17.png) 2.25 用户例子（Userdemo） 别人使用的例子","categories":[{"name":"baseline","slug":"baseline","permalink":"https://blog.tjdata.site/categories/baseline/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://blog.tjdata.site/tags/wiki/"}]},{"title":"行为流派02_从gymnasium开始自己的环境","slug":"行为流派02-从gymnasium开始自己的环境","date":"2023-08-25T08:23:26.000Z","updated":"2023-08-25T11:21:49.962Z","comments":true,"path":"posts/a4f3c685.html","link":"","permalink":"https://blog.tjdata.site/posts/a4f3c685.html","excerpt":"openAI的gym中提供了很多封装好的环境，在此基础上我们可以使用其来跑通深度强化学习的代码，但是更多的时候我们希望调用算法来解决一个实际问题，因此尝试为定制化的问题转换成为MDP六元组《变量、状态、动作、奖励、状态转移、终止条件》后编程为可以交互的环境即可。本文介绍学习gymnasium和stable- baseline3的学习思路并手动实现一个MyCar的环境。","text":"openAI的gym中提供了很多封装好的环境，在此基础上我们可以使用其来跑通深度强化学习的代码，但是更多的时候我们希望调用算法来解决一个实际问题，因此尝试为定制化的问题转换成为MDP六元组《变量、状态、动作、奖励、状态转移、终止条件》后编程为可以交互的环境即可。本文介绍学习gymnasium和stable- baseline3的学习思路并手动实现一个MyCar的环境。 0x01 巨人的肩膀 ：调库 根据MDP过程，环境和智能体两个抽象类主要需要包括几个API操作： 环境：参数设置（init），初始化环境（reset），状态更新（step），关闭（closed），显示（render） 智能体：深度学习参数（net），学习行为（learn），生成行为（predict） 所以抽象来看 1234567891011121314import gymnasium as gymimport stable_baselines3 as sb3env = gym.make(&#x27;[env_name]&#x27;,render_mode=&#x27;human&#x27;)# 定义好参数，已经学习agent = sb3.load(&#x27;[saved_model_dir]&#x27;) observation,info = env.reset(seed=42)terminated = falsewhile not terminated: action = agent.predict(observation) observation,reward,terminated,truncated,info = env.step(action) if truncated: env.reset()env.closed 1.1 环境库 gymnasium.env 目前主流的强化学习环境主要是基于openai-gym，主要介绍为 Gym is an open source Python library for developing and comparing reinforcement learning algorithms by providing a standard API to communicate between learning algorithms and environments, as well as a standard set of environments compliant with that API. Since its release, Gym’s API has become the field standard for doing this. Gym是一个开源的Python库，通过提供标准API在学习算法和环境之间进行通信，以及一组符合该API的标准环境，来开发和比较强化学习算法。自发布以来，Gym的API已成为这样做的现场标准。 但是代码安装有点太屎山了，现有另外的一个fork版本gymnasium更加的简单和包容 Gymnasium is a maintained fork of OpenAI’s Gym library. The Gymnasium interface is simple, pythonic, and capable of representing general RL problems, and has a compatibility wrapper for old Gym environments Gymasium是OpenAI gym library的一个维护分支。Gymnasium界面简单，pythonic，能够表示一般的RL问题，并具有旧gym环境的兼容性warp器 1pip install gymnasium 1.2 强化学习算法库 stable_baselines3 Stable_baseline3是基于OpenAI baselines改进的实现，类似gymnasium和gym的关系，主要实现的修改为： 统一算法结构 实现PEP8兼容 文档化函数和类 更多的测试和代码覆盖 1pip install stable_baseline3 另外在stable_baseline3的基础上包括预训练好的智能体平台RL Baseline zoo，同时也提供训练、评估智能体行为、微调超参数和录屏的功能，具体的使用可以参考官方文档。 12apt-get install swig cmake libopenmpi-dev zlib1g-dev ffmpegpip install stable-baselines box2d box2d-kengz pyyaml pybullet optuna pytablewriter PS: 如果不习惯用conda管理环境，或者有迁移环境的需求可以参考使用docker创建镜像 另外还有一些其他优秀的RL库，比如蘑菇书-joyrl、Tensorforce 0x02 优秀环境欣赏 在gymnasium的官网环境中给出一些典型的环境，可以分类为： 经典控制（Classic control），比如杂技演员（Acrobat）、单臂摆（Cart pole）、小车上山（Mountain car）、钟摆（Pendulum） 二维环境（Box2D），双足行走（Bipedal walker）、赛车（Car racing）、登月（Lunar lander） 文本游戏（Toy Text），二十一点（Blackjack）、悬崖寻路（Cliff walking）、冰湖（Frozen lake）、出租车（Taxi） 多关节接触动力学（Multi Joint Dynamics with Contact，MoJoCo） 雅达利（Atari），是的就是被任天堂打败的“雅达利大崩溃”的雅达利 第三方环境，flappy-bird-env，highway-env，sumo-rl，等等 0x03 gymnasium.env 详细介绍 关于基类的介绍，在gymnasium.env中很清楚，但是一堆英文可能看着有点累，这里主要介绍作为一个抽象类它的外部接口和基本常见属性： 方法： Step() ，根据agent的action更新state，同时返回五元组(更新状态obs，奖励信号reward，是否结束terminated，是否中断truncated，信息info)，注意这里对gym.env中的done更加细致 reset()，重置环境到初始状态 Render() 图形引擎，用于可视化过程，不要也可以 close（） 关闭环境 属性 actions_space 定义动作环境 observation_space 定义状态环境 Reward_range 奖励范围 spec metadata np.random Stable_baseline3也提供一些教程给出自定义类的属性并且提供了一个colab-GoLeftEnv 12345678910111213141516171819202122232425262728293031323334import gymnasium as gymimport numpy as npfrom gymnasium import spacesclass CustomEnv(gym.Env): &quot;&quot;&quot;Custom Environment that follows gym interface.&quot;&quot;&quot; metadata = &#123;&quot;render_modes&quot;: [&quot;human&quot;], &quot;render_fps&quot;: 30&#125; def __init__(self, arg1, arg2, ...): super().__init__() # Define action and observation space # They must be gym.spaces objects # Example when using discrete actions: self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS) # Example for using image as input (channel-first; channel-last also works): self.observation_space = spaces.Box(low=0, high=255, shape=(N_CHANNELS, HEIGHT, WIDTH), dtype=np.uint8) def step(self, action): ... return observation, reward, terminated, truncated, info def reset(self, seed=None, options=None): ... return observation, info def render(self): ... def close(self): ... 0x04 从零开始的MyCar 假设我们现在希望训练一个智能体，可以在出现下列的网格中出现时都会向原点前进，在定义的环境时可以使用gymnaisum.env定义自己的环境类MyCar，之后使用stable_baselines3中的check_env对环境的输入和输出做检查： 由此分析环境中的属性： 状态空间：二维的空间和问题的size有关 动作空间：离散的五种动作，暂停和上下左右 是否结束：到达原点 是否中止：跑到环境之外 奖励：当前状态距离原点的距离 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117import gymnasiumfrom gymnasium import spacesimport numpy as np# Path: modelTimetable/DRL/myEnv.ipynb# Implementing the environment# Reproduction of the cartpole environment# # Discription: # Create a car in a two-dimensional plane with a width of 20, and the coordinates of # the center point are the destination of the car to reach.## State:# The state of the car is represented by the coordinates of the center point of the car.(x,y)# Action:# The action of the car is represented by the speed of the car.(vx,vy)# Reward:# The reward is the distance between the car and the destination.# Termination:# The car reaches the destination.(0,0)# truncation:# The car is out of the screen.&#x27;&#x27;&#x27;gymnasium is the main class that we will use to create our environment.The gymnasium class has the following methods:__init__(): This method is used to initialize the environment. It takes the following parameters:step(): This method is used to take an action and return the next state, reward, and whether the episode is over. Physical engine- input: action- output: observation, reward,terminated,truncated,inforeset(): This method is used to reset the environment to its initial state.- input: None- output: observationrender(): This method is used to render the environment:Image engine- input: mode(default=&#x27;human&#x27;,&#x27;human&#x27;,&#x27;rgb_array&#x27;,&#x27;ansi&#x27;,&#x27;rgb_array_list)- output: Noneeg:gymnasium.make(&#x27;CartPole-v0&#x27;,render_mode=&#x27;human&#x27;)close(): This method is used to close the environment.&#x27;&#x27;&#x27;class MyCar(gymnasium.Env): metadata = &#123; &#x27;render.modes&#x27;: [&#x27;human&#x27;, &#x27;rgb_array&#x27;], &#x27;video.frames_per_second&#x27;: 2 &#125; def __init__(self): self.target_x = 0 self.target_y = 0 self.size = 10 self.action_space = spaces.Discrete(5) # 0:stop, 1:up, 2:down, 3:left, 4:right self.observation_space = spaces.Box(np.array([-self.size,-self.size]), np.array([self.size,self.size])) self.state = None self.info = &#123;&#125; def step(self, action): assert self.action_space.contains(action), &quot;%r (%s) invalid&quot;%(action, type(action)) # update the state by the action x,y = self.state if action == 0: x += 0 y += 0 elif action == 1: x += 0 y += 1 elif action == 2: x += 0 y += -1 elif action == 3: x += -1 y += 0 elif action == 4: x += 1 y += 0 # the next state self.state = np.array([x,y]) self.state = self.state.astype(np.float32) reward = self._get_reward() terminated = self._get_terminated() terminated = bool(terminated) truncated = self._get_truncated() truncated = bool(truncated) info = &#123;&#125; return self.state, reward, terminated,truncated, info def reset(self,seed=None): self.state = np.ceil(np.random.rand(2)*2*self.size)-self.size self.state = self.state.astype(np.float32) self.counts = 0 self.info = &#123;&#125; return self.state,self.info def render(self, mode=&#x27;human&#x27;): print(self.state) def close(self): return super().close() def _get_reward(self): return -np.sqrt(self.state[0]**2+self.state[1]**2) def _get_terminated(self): x,y = self.state return x==self.target_x and y==self.target_y def _get_truncated(self): x,y = self.state return x&lt;-self.size or x&gt;self.size or y&lt;-self.size or y&gt;self.sizefrom stable_baselines3.common.env_checker import check_envenv = MyCar()check_env(env, warn=True) 测试它的输出输出 12345678910env = MyCar()env.reset()state,reward,terminated,truncated,info = env.step(env.action_space.sample())log = 0while not terminated: env.render() state,reward,terminated,truncated,info = env.step(env.action_space.sample()) if truncated: env.reset() log += 1 0x05 开始训练 这里只是调用stable_baselines的最简单的DQN库，没有调整参数和网络结构 12345678910111213141516from stable_baselines3 import DQNfrom stable_baselines3.common import logger# Train the agent by the stable_baselines3import osmodels_dir = &#x27;./models/DQN&#x27;logdir = &#x27;./logs&#x27;if not os.path.exists(models_dir): os.makedirs(models_dir)if not os.path.exists(logdir): os.makedirs(logdir)env = MyCar()agent = DQN(&#x27;MlpPolicy&#x27;, env, verbose=1,tensorboard_log=logdir)agent.learn(total_timesteps=100000, log_interval=100,tb_log_name=&#x27;DQN&#x27;)agent.save(&quot;DQN_MyCar&quot;) 之后可以通过保存的环境来测试结果 12345678env = MyCar()obs = env.reset()agent = DQN.load(&#x27;deepq_cartpole.zip&#x27;,env=env)terminated = Falsewhile not terminated: action,_state = agent.predict(obs) obs,rew,terminated,truncated,info = env.step(action) print(env.state) 并使用 1tensorboard --logdir = logs 0x06 总结 最感动的是stable_baselines3提供的custom_gym_env.ipynb中最后给出的be creative！ 建立环境又何尝不是一种创造。 参考链接很多，感谢互联网～","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS188","slug":"CS188","permalink":"https://blog.tjdata.site/tags/CS188/"}]},{"title":"行为流派01_智能体与搜索","slug":"行为流派01-智能体与搜索","date":"2023-08-22T12:12:57.000Z","updated":"2023-08-22T12:26:21.371Z","comments":true,"path":"posts/9c6b1465.html","link":"","permalink":"https://blog.tjdata.site/posts/9c6b1465.html","excerpt":"根据CS188《Intro to AI》来对搜索策略进行一定的总结","text":"根据CS188《Intro to AI》来对搜索策略进行一定的总结 0x01 智能体 在人工智能中，核心问题是创建一个理性的智能体(Rational agent)，是一个实体通过一些系列的动作(Actions)来实现目标或者是喜好(Goal or perferences),它存在于环境中（Environment），智能体通过传感器（sensors）获取信息并驱动自己的动作（Actuators）。 Reflex agent：仅仅根据现有来选择动作 Planning agent：根据一系列的动作来确定现有状态下的动作 定义一个任务通常会用到PEAS（评价指标，环境，动作，传感器） Performance Measure：指的是智能体需要提高的衡量指标 Environment：总结影响智能体的因素 Actions and Sensors：说明智能体如何对环境造成改变，同时如何获取信息 特定的我们确定几类不同特征的任务： 部分观察的任务(Partially observable environments) 或者 完全观察(Fully observation) 随机过程(Stochastic) 或者 确定过程（Deterministic） 多智能体环境（multi-agent） 静态环境（static）或者动态环境（Dynamic） 0x02 搜索问题定义 搜索问题包括以下几个部分： State 在所给案例中的所有状态 Action 在每个状态可取动作的集合 Transition 在某一状态下采用动作得到的下一个状态 Cost 从一个状态到另外一个状态的成本 Start state 初始状态 Goal test 判断是否到达最终的状态 例如吃豆人Pathing和吃掉所有豆子Eat-all-dots问题之间的区别： 常见的表现形式为状态空间图和搜索树 state space graphs and search trees 状态空间图：用不同状态之间的转移关系来表示 搜索树：以状态为节点，动作作为边，但是每个状态和节点不仅编码状态本身，还编码路径 getNextState get Action get Action Cost 我们只存储立即处理的state，并计算最新的状态 0x03 基本搜索（normal search） 一个标准的方式来寻找到轨迹（Plan），是从初始状态开始(getStartState)来到达最终状态（Goal state），同时维护可能的过程（Frontier），同时拓展我们的当前过程通过删除节点state为state- action- state。（称作strategy），当我们删除缩手的frontiers，我们得到最终的路径（path） 这些搜索中具有一些基本属性： 搜索的完整性 completeness 搜索的最优性 optimality 分枝因素 最大深度 最浅解的深度 常见的无信息搜索包括：DFS、BFS、UCS 常见的信息搜索包括；Greedy search and A star search 后者相比较前者主要增加代价，代价的含义包括两个方面 Estimation of distance to goal state，as the cost function may be the lower bound for the problem, the heuristics are typically solutions to relaxed problem(where some of the constraint of the original problem have been removed) 比如利用启发式的方法可以让PACMAN更加倾向于到达最终的目的地 Estimation of the empirical cost function 0x04 约束问题（Constraint satisfied problem）和回溯（Backtracking search）和local search 之前的文章中介绍什么是规划问题（Planing problem），可以使用搜索策略（Search strategy）进行求解。对于另外一种问题可以描述为约束满足问题（Constraint satisfaction problems，CSP）是一类识别（Identification problem） 识别问题（Identification problem）：我们必须简单的识别最终的结果是否为目标状态 这个术语通常指在机器学习和人工智能中,系统需要从一组潜在的候选项中识别出正确的项目的任务。这类问题通常涉及模式识别,即从输入的数据中提取有意义的信息模式。 一些常见的识别问题示例包括: 图像识别:从图片中识别出特定对象或场景 语音识别:从语音输入中识别出说话内容 面部识别:从图片或视频中识别出特定人脸 手写识别:识别手写输入的文字内容 生物识别:通过指纹、声纹等生物特征识别个体身份 文档分类:将文本文档分类到预定义的类别中 识别问题通常需要构建合适的机器学习模型,然后使用大量带标签的训练数据对模型进行训练,使其能够对新输入进行可靠的识别与分类。同时还需要处理各种困难情况,如光线、角度、遮挡等对图像识别的影响,以提高模型的鲁棒性。 三元组： variables，一系列的变量集合 domain，不同变量可能存在的取值范围 constraints，不同变量之间的约束关系 例如：八皇后问题 约束编程问题的求解方式是NP-hard问题，随着问题规模的扩大时间呈现指数型增加。我们可以将约束满足问题转换成为搜索问题： state 为部分赋值（对CSP的可变赋值，其中一些变量被分配了值，而另一些变量没有）。 successor function 输出所有状态，并分配一个新变量，目标测试验证所有变量都被分配，并在其测试的状态中满足所有约束。 约束问题比之前的搜索问题具有更复杂的框架，因此可以尝试将上述公示和合适的启发式方法结合起来 之前的文章中介绍什么是规划问题（Planing problem），可以使用搜索策略（Search strategy）进行求解。对于另外一种问题可以描述为约束满足问题（Constraint satisfaction problems，CSP）是一类识别（Identification problem） 识别问题（Identification problem）：我们必须简单的识别最终的结果是否为目标状态 这个术语通常指在机器学习和人工智能中,系统需要从一组潜在的候选项中识别出正确的项目的任务。这类问题通常涉及模式识别,即从输入的数据中提取有意义的信息模式。 一些常见的识别问题示例包括: 图像识别:从图片中识别出特定对象或场景 语音识别:从语音输入中识别出说话内容 面部识别:从图片或视频中识别出特定人脸 手写识别:识别手写输入的文字内容 生物识别:通过指纹、声纹等生物特征识别个体身份 文档分类:将文本文档分类到预定义的类别中 识别问题通常需要构建合适的机器学习模型,然后使用大量带标签的训练数据对模型进行训练,使其能够对新输入进行可靠的识别与分类。同时还需要处理各种困难情况,如光线、角度、遮挡等对图像识别的影响,以提高模型的鲁棒性。 三元组： variables，一系列的变量集合 domain，不同变量可能存在的取值范围 constraints，不同变量之间的约束关系 例如：八皇后问题 约束编程问题的求解方式是NP-hard问题，随着问题规模的扩大时间呈现指数型增加。我们可以将约束满足问题转换成为搜索问题： state 为部分赋值（对CSP的可变赋值，其中一些变量被分配了值，而另一些变量没有）。 successor function 输出所有状态，并分配一个新变量，目标测试验证所有变量都被分配，并在其测试的状态中满足所有约束。 约束问题比之前的搜索问题具有更复杂的框架，因此可以尝试将上述公示和合适的启发式方法结合起来 map coloring problem : 给定一堆颜色，要求相邻的地区之间的颜色不能相等 通常我们可以对约束进行分类： unary constraints 专有约束，在约束图中表示 点 binary constraint：两个变量，在约束图中表示 边 higher-order constraint：非常规 另一方面，回溯搜索仅在变量值不违反任何约束的情况下为变量分配值，从而显著减少回溯。虽然回溯搜索是比深度优先搜索的野蛮强化的巨大改进，但通过过滤、变量/值排序和结构拓宽的进一步改进，我们仍然可以获得更多的速度收益。 变量的取值范围已经是一个较大的进步 Tricks1: 过滤（Filter）： Tricks2:变量排序（Variable or value ordering） minimum remaining values，选择分配有效剩余值最少的变量 least constraining value，从剩余未份配值的domain中选择prunes最少的值 Tricks3: 结构拓宽（Structural exploration） 另外一种方法：本地搜索通过迭代的改进对一些值的随机分配开始，然后迭代的选择一个随机冲突变量，并对变量重新分配给违反约束最小的变量，直到不再存在约束违规，称为一种具有最小冲突启发式的策略 爬山搜索 Hill-Climbing Search 模拟退火搜索 Simulate annealing search 遗传搜索 generic algorithm 0x05 游戏（Game） 和对抗搜索（Adversarial search problem） 在之前的搜索问题中，我们尝试解决他们高效并且最优的，利用不同的搜索方式。以及更加具有启发式的强大的搜索算法。但是在面临一些问题中搜索算法中会遇到对方的阻碍，这种情况下单纯的利用搜索策略。这一类新的问题通常可以被称为adversarial search problem，或者叫做游戏games。 不同于传统搜索问题返回直接的答案，对抗搜索由于problem一直在发生变化，这样复杂的场景中往往要求我们返回一个策略（Strategy or policy），一个简单的对抗搜索问题包括一下策略： Initial state players ：每一轮属于谁的player actions，player可以实现的动作 transition model 状态转移的结果 terminal test terminal values 可以使用 Min-max搜索 Alpha-beta搜索 evaluation function 0x06 动态决策过程（MDP）和强化学习（Reinforcement learning） ～ to be continued 参考链接： OI wiki：搜索部分简介 《CS188: Intro to atrificial intelligent》 伯克利人工智能入门课按经典教材章节顺序授课,内容涵盖各主要领域;课程笔记通俗易懂,作业可在Gradescope平台完成实时测评,项目复现经典游戏,运用所学知识实现算法,使吃豆人在迷宫自由行动。","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS188","slug":"CS188","permalink":"https://blog.tjdata.site/tags/CS188/"}]},{"title":"datawhale_NLP任务二","slug":"datawhale-NLP任务二","date":"2023-08-21T06:33:47.000Z","updated":"2023-08-21T08:01:12.709Z","comments":true,"path":"posts/12d9621e.html","link":"","permalink":"https://blog.tjdata.site/posts/12d9621e.html","excerpt":"比赛的基本信息在之前的任务一中已经有所介绍，属于文本领域（Natural language processing，NLP）的分类任务，之前的方法是采用的是“抽取特征+分类器”的方式来实现的。这样的方法范式通常需要手动构造许多特征，并且需要较适应的分类器来训练，其中主要的困难点在于（1）手工构造的特征是否有效 （2）如何保证机器学习模型训练中的偏差-方差权衡。但是随着Attention范式的爆火，自动抽取文本特征成为困难，所以在Baseline中我们可以尝试使用BERT（Bidirectional encoder representations from transformers）来自动构造特征，但是和计算机视觉（Computer vision，CV）类似端到端（End-to-end）的思维总是很诱人，所以尝试利用“input+prompt”对训练集进行修改，同时对训练好的大模型进行微调（Fine-tuning）成为一种新的范式。 本文将借助本次项目中提供的Topline代码（深度学习）进行解读。","text":"比赛的基本信息在之前的任务一中已经有所介绍，属于文本领域（Natural language processing，NLP）的分类任务，之前的方法是采用的是“抽取特征+分类器”的方式来实现的。这样的方法范式通常需要手动构造许多特征，并且需要较适应的分类器来训练，其中主要的困难点在于（1）手工构造的特征是否有效 （2）如何保证机器学习模型训练中的偏差-方差权衡。但是随着Attention范式的爆火，自动抽取文本特征成为困难，所以在Baseline中我们可以尝试使用BERT（Bidirectional encoder representations from transformers）来自动构造特征，但是和计算机视觉（Computer vision，CV）类似端到端（End-to-end）的思维总是很诱人，所以尝试利用“input+prompt”对训练集进行修改，同时对训练好的大模型进行微调（Fine-tuning）成为一种新的范式。 本文将借助本次项目中提供的Topline代码（深度学习）进行解读。 目录设计 Kaggle大神开源了一本 《approaching any machine learning problem》其中并不是介绍机器学习的各种数学原理，而更多的是从开发的角度、代码文件设计来介绍常见配置。感觉很像是Project profile，在讨论如何将Dirty work更好的组织起来。本次项目代码的路径设计中包括 1234567891011- checkpoints 模型训练的权重- dataset 存放数据集- evaluate_predictions 评估文件- models_input_files 存放模型输入文件- model_predictions 存放推理概率文件- premodels 预训练模型权重，config.json文件# 以及各种src(.py)- data_process.py- models_training.py- evaluate_models.py- ensemble_and_submit.py 虽然之前的学习的过程中我们将深度学习总结为八股：data process、dataset and dataloader、models、loss function、optimizer、hyper-parameters、model train、model eval。但是从调库的角度，可以将其中的第二步～第七步看作一部分，通常可以从hugging face获取。 数据预处理 这一部分是将数据集划分为 ：训练集、验证集、测试集。不同数据集之间的区别是 训练集 train dataset：直接对于模型的参数进行调整的数据，直接影响梯度下降的结果 验证集 validation dataset：可以通过在训练集和训练得到的模型在验证集中结果对比，来调整模型的超参数，直接影响超参数，间接影响模型结果 测试集 test dataset：模型完全没有见过的数据，属于公平评价模型泛化能力的结果 难点在于将原始文本（Raw documentation）通过分词器（transformer.AutoTokenizer)转换成为 （输入id，注意力掩码，标记类型）（inputs_ids_list,attention_mask_list,token_tyope_ids_list）重点在于如何将文本表示成为向量形式。参考之前阅读李沐的RNN教程中从零构建文本处理的代码，这一段的核心代码参考hugging face为： 123456789101112131415161718192021222324252627282930313233343536373839from transformers import AutoTokenizer # 导入AutoTokenizer类，用于文本分词model_name = &#x27;roberta-base&#x27;# 从模型实例中得到分词器tokenizer = AutoTokenizer.from_pretrained(model_name, max_length=MAX_LENGTH, cache_dir=&#x27;./premodels/&#123;model_name&#125;_saved&#x27;)# 根据分词器构建标签input_ids_list, attention_mask_list, token_type_ids_list = [], [], []for i in tqdm(range(len(train[&#x27;content&#x27;]))): sample = train[&#x27;content&#x27;][i] # 分词处理，使用最长优先方式截断 tokenized = tokenizer(sample, truncation=&#x27;longest_first&#x27;) # 获取输入id，注意力掩码，标注类型并转换为torch对象 input_ids, attention_mask = tokenized[&#x27;input_ids&#x27;], tokenized[&#x27;attention_mask&#x27;] input_ids, attention_mask = torch.tensor(input_ids), torch.tensor(attention_mask) # 可能有的没有id，所以需要加一个try- except try: token_type_ids = tokenized[&#x27;token_type_ids&#x27;] # 获取标记类型ID token_type_ids = torch.tensor(token_type_ids) # 转换为PyTorch张量 except: token_type_ids = torch.zeros_like(input_ids) input_ids_list.append(input_ids) # 将输入ID添加到列表中 attention_mask_list.append(attention_mask) # 将注意力掩码添加到列表中 token_type_ids_list.append(token_type_ids) # 将标记类型ID添加到列表中 # 得到训练数据标签 y_train.append(train[&#x27;label&#x27;][i]) # 将训练数据的标签添加到列表中# 同时为了保证向量维度大小一致，使用torch pad_sequence input_ids_tensor = pad_sequence(input_ids_list, batch_first=True, padding_value=0) attention_mask_tensor = pad_sequence(attention_mask_list, batch_first=True, padding_value=0) token_type_ids_tensor = pad_sequence(token_type_ids_list, batch_first=True, padding_value=0) # 建立数据集x_train = torch.stack([input_ids_tensor, attention_mask_tensor, token_type_ids_tensor], dim=1) x_train = x_train.numpy() # 最后保存数据，这里转换成为numpy，不知道有没有其他格式np.save(f&#x27;./models_input_files/x_train&#123;model_index&#125;.npy&#x27;, x_train) # 保存训练数据 模型训练 这里的操作主要是加载数据、确定超参数、定义模型（从预训练）、模型训练。其中的核心在于加载数据、如何定义模型和如何从pretrain权重训练模型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class opt: seed = 42 ...class Model(nn.Module): def __init__(self,model_name): super().__init__() # 下载权重 self.model = AutoModel.from_pretrained(model_name,cahe_dir=&#x27;../premodels/&#x27;+model_name+&#x27;_saved&#x27;) # 获取现有模型的纬度 config = AutoConfig.from_pretrained(model_name,cahe_dir=&#x27;../premodels/&#x27;+model_name+&#x27;_saved&#x27;) last_dim = config.hidden_size # 最后一层的维度 # 基于最后的纬度开始一些参数的额设计 if opt.use_BCE:out_size = 1 # 损失函数如果使用BCE,则输出大小为1 else :out_size = 2 # 否则则使用CE,输出大小为2 feature_size = 128 # 设置特征的维度大小 self.fc1 = nn.Linear(last_dim, feature_size) # 全连接层1 self.fc2 = nn.Linear(last_dim, feature_size) # 全连接层2 self.classifier = nn.Linear(feature_size, out_size) # 分类器 self.dropout = nn.Dropout(0.3) # Dropout层 def forward(self,x): input_ids, attention_mask, token_type_ids = x[:,0],x[:,1],x[:,2] # 获取输入 x = self.model(input_ids, attention_mask) # 通过模型 all_token = x[0] # 全部序列分词的表征向量 pooled_output = x[1] # [CLS]的表征向量+一个全连接层+Tanh激活函数 # 对于大模型的输出进行特征融合 feature1 = all_token.mean(dim=1) # 对全部序列分词的表征向量取均值 feature1 = self.fc1(feature1) # 再输入进全连接层，得到feature1 feature2 = pooled_output # [CLS]的表征向量+一个全连接层+Tanh激活函数 feature2 = self.fc2(feature2) # 再输入进全连接层，得到feature2 feature = 0.5*feature1 + 0.5*feature2 # 加权融合特征 feature = self.dropout(feature) # Dropout x = self.classifier(feature) # 分类 return x def load_data(): 返回datasetdef model_pretrain(): # 定义超参数 model_save_dir = device = 等 # 模型初始化 model = MODEL(model_name).to(device) # 优化器初始化 opt = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay=weight_decay) # 损失函数 loss_func = nn.CrossEntropy() # 训练过程 for epoch in range(epoches): model.train() train_loss = 0 train_acc = 0 for X,y in train_loader: y_hat = model(X) loss = loss_func(y_hat,y) train_loss += loss.item() opt.zero_grad() loss.backward() opt.step() # 计算acc 每间隔一定轮次开始现实验证过程 f1 recall # 保存最好的模型 torch.save(model.module.state_dict(),&#x27;&#x27;) 另外一种方式：Lora微调 这里更多的是对数据中增加一种prompt,核心代码如下 123456789101112131415161718192021222324252627# 构建包括instruction、input、output的数据集for i in range(len(train_df)): # 获取当前行的数据 paper_item = train_df.loc[i] # 创建一个字典，包含指令、输入和输出信息 tmp = &#123; &quot;instruction&quot;: &quot;Please judge whether it is a medical field paper according to the given paper title and abstract, output 1 or 0, the following is the paper title and abstract --&gt;&quot;, &quot;input&quot;: f&quot;title:&#123;paper_item[1]&#125;,abstract:&#123;paper_item[3]&#125;&quot;, &quot;output&quot;: str(paper_item[5]) &#125; # 将字典添加到结果列表中 res.append(tmp) 导入所需的库和模块from peft import PeftModelfrom transformers import AutoTokenizer, AutoModel, GenerationConfig, AutoModelForCausalLM# 定义预训练模型的路径model_path = &quot;../chatglm2-6b&quot;model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda()tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)# 加载 label lora权重model = PeftModel.from_pretrained(model, &#x27;./output/label_xfg&#x27;).half()model = model.eval()# 使用加载的模型和分词器进行聊天，生成回复response, history = model.chat(tokenizer, &quot;你好&quot;, history=[])response One more thing 为什么是Attention？ 这里借助自己笔记的理解，所以attention是啥，如果利用QKV的角度来看比较复杂，如果从简单的回归问题角度来看它只是另外一种计算权重方式的函数。 但是！attention的作用不仅局限于回归问题，它从seq问题中而来，解决的就是CNN或者RNN对于距离的敏感性。 就像CNN的感受野，对于单层感受野可能是固定好的（与kernel size、padding、step有关），但是多层累积中感受野是可以逐渐扩大的。但是CNN适用于图像的可能解释是一，图像的维度是固定size的（像素无论多大都是有限的）而 RNN的感受野，借鉴被人的说法是取决于词元模型和hidden layer，但是由于hidden layer也是具有顺序的特征，它的感受野也不会传递的太远。 attention利用attention socre对不同的key进行筛选，来得到一个足够远但是量不大的感受野。选择重要的数据。 警惕大模型？ 调用别人的模型可能很舒服，但要是完全端到端那么也太无力了，这里给出hugging face常见使用的代码片段 Pipeline: 需要良好的网络连接 123from transformers import pipelineclassifier = pipeline(&#x27;sentiment-analysis&#x27;)classfifier = (&#x27;I have waiting for a hugging face course my whole life&#x27;) 模型特征提取：Tokenizer、Model、Pretrain 1234567from transformers import AutoTokenizer,AutoModel# tokenizertokenizer = AutoTokenizer.from_pretrained(model_name)input = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=&quot;pt&quot;)# modelmodel = AutoModel.from_pretrained(checkpoint)# 增加自己的操作 post- process Model除了Automodel还包括*Model (retrieve the hidden states)*ForCausalLM *ForMaskedLM ForMultipleChoice *ForQuestionAnswering *ForSequenceClassification *ForTokenClassification 大模型Finetune 大尺寸预训练：在这个阶段，模型在大规模的文本数据集上进行预训练。这是一个非监督学习的过程，模型需要预测在给定的文本序列中下一个词是什么。预训练的目标是让模型学会理解和生成人类语言的基本模式。 指令微调：在预训练之后，模型会在一个更小但专门针对特定任务的数据集上进行微调。这个数据集通常由人工生成，包含了模型需要学会的任务的特定指令。例如，如果我们想要让模型学会如何进行数学计算，我们就需要提供一些包含数学问题和对应解答的数据。 RLHF（Reinforcement Learning from Human Feedback）：这是一个强化学习过程，模型会根据人类提供的反馈进行学习和优化。首先，我们会收集一些模型的预测结果，并让人类评估这些结果的好坏。然后，我们会使用这些评估结果作为奖励，训练模型优化其预测性能。通过这种方式，模型可以学会生成更符合人类期望的结果。","categories":[{"name":"memo","slug":"memo","permalink":"https://blog.tjdata.site/categories/memo/"}],"tags":[{"name":"datawhale","slug":"datawhale","permalink":"https://blog.tjdata.site/tags/datawhale/"}]},{"title":"datawhale_NLP任务一","slug":"datawhale-NLP任务一","date":"2023-08-18T02:45:43.000Z","updated":"2023-08-18T02:48:30.698Z","comments":true,"path":"posts/29594cb7.html","link":"","permalink":"https://blog.tjdata.site/posts/29594cb7.html","excerpt":"摘要","text":"摘要 0x01 问题描述 通过机器学习的方式对论文摘要等信息的理解，来判断该论文是否属于医学领域的文献。 数据集中包括publicdata-train,publicdata-test,trainB,数据集中包含标题、作者、摘要和关键词 模型：可以采用task1基于文本提取的TF-IDF+LR分类的机器学习方式；也可以task2采用基于Bert大模型微调的方式 评价：最终的评价标准采用F1-score来进行分析 123456789101112# input：Inflammatory Breast Cancer: What to Know About This Unique, Aggressive Breast Cancer.，[Arjun Menta, Tamer M Fouad, Anthony Lucci, Huong Le-Petross, Michael C Stauder, Wendy A Woodward, Naoto T Ueno, Bora Lim]，Inflammatory breast cancer (IBC) is a rare form of breast cancer that accounts for only 2% to 4% of all breast cancer cases. Despite its low incidence, IBC contributes to 7% to 10% of breast cancer caused mortality. Despite ongoing international efforts to formulate better diagnosis, treatment, and research, the survival of patients with IBC has not been significantly improved, and there are no therapeutic agents that specifically target IBC to date. The authors present a comprehensive overview that aims to assess the present and new management strategies of IBC.，Breast changes; Clinical trials; Inflammatory breast cancer; Trimodality care.# output:1 for yes and 0 for no 0x02 Baseline 可以使用CV或者TF来对原始文本进行分析 之后利用分类器比如LR或者lightGBM进行分类处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import pandas as pd import numpy as npfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizerfrom sklearn.linear_model import LogisticRegressionimport warningswarnings.filterwarnings(&quot;ignore&quot;)# Read the datasetdf_train = pd.read_csv(&#x27;../data/train.csv&#x27;)df_valid = pd.read_csv(&#x27;../data/test.csv&#x27;)df_test = pd.read_csv(&#x27;../data/testB.csv&#x27;)df_train = df_train.fillna(&#x27;&#x27;)df_valid.fillna(&#x27;&#x27;)df_test = df_test.fillna(&#x27;&#x27;)# Featuresdf_train[&#x27;text&#x27;] = df_train.apply(lambda x:&#x27; &#x27;.join(x.drop(&#x27;uuid&#x27;).astype(str)),axis=1)df_valid[&#x27;text&#x27;] = df_valid.apply(lambda x:&#x27; &#x27;.join(x.drop(&#x27;uuid&#x27;).astype(str)),axis=1)df_test[&#x27;text&#x27;] = df_test.apply(lambda x:&#x27; &#x27;.join(x.drop(&#x27;uuid&#x27;).astype(str)),axis=1)# df_train[&#x27;text&#x27;]vector = TfidfVectorizer().fit(df_train[&#x27;text&#x27;].tolist())vocab = vector.vocabulary_train_vector = vector.transform(df_train[&#x27;text&#x27;])valid_vector = vector.transform(df_valid[&#x27;text&#x27;])test_vector = vector.transform(df_test[&#x27;text&#x27;])df_trainv = pd.DataFrame(train_vector.toarray(),columns=vocab)df_validv = pd.DataFrame(valid_vector.toarray(),columns=vocab)df_testv = pd.DataFrame(test_vector.toarray(),columns=vocab)df_train.describe()# lightGBM modelimport lightgbm as lgb data = lgb.Dataset(df_trainv,df_train[&#x27;label&#x27;])# data_val = lgb.Dataset(df_validv,df_valid[&#x27;label&#x27;])params = &#123; &#x27;boosting_type&#x27;: &#x27;gbdt&#x27;, &#x27;objective&#x27;: &#x27;binary&#x27;, &#x27;metric&#x27;: &#x27;binary_logloss&#x27;, &#x27;num_leaves&#x27;: 31, &#x27;learning_rate&#x27;: 0.05, &#x27;feature_fraction&#x27;: 0.9, &#x27;bagging_fraction&#x27;: 0.8, &#x27;bagging_freq&#x27;: 5, &#x27;verbose&#x27;: 0&#125;model = lgb.train(params, data)y_pred = model.predict(test_vector)y_pred = np.where(y_pred&gt;=0.5,1,0)df_test[&#x27;label&#x27;] = y_preddf_test[&#x27;Keywords&#x27;] = df_test[&#x27;title&#x27;].fillna(&#x27;&#x27;)df_test[[&#x27;uuid&#x27;, &#x27;Keywords&#x27;, &#x27;label&#x27;]].to_csv(&#x27;../data/task1_lightGBM.csv&#x27;, index=None) 0x03 结果 最终的提交结果为","categories":[{"name":"memo","slug":"memo","permalink":"https://blog.tjdata.site/categories/memo/"}],"tags":[{"name":"datawhale","slug":"datawhale","permalink":"https://blog.tjdata.site/tags/datawhale/"}]},{"title":"工科生研1的MacbookPro14深度使用感受","slug":"工科生研1的MacbookPro14深度使用感受","date":"2023-08-07T07:04:17.000Z","updated":"2023-08-07T10:58:15.084Z","comments":true,"path":"posts/f57a89c.html","link":"","permalink":"https://blog.tjdata.site/posts/f57a89c.html","excerpt":"在研究生使用半年的Macbook Air（2020M1）之后由于存储、屏幕等原因，转向具有诸多优点的MacbookPro14（2021），在深度磨合半年之后介绍这台设备的优点。从工业设计、外部接口、硬件配置、屏幕素质介绍使用感受，并从文件处理、知识管理、系统工具、娱乐角度介绍软件资源，最后给出文件管理和待办管理的工作流。 本文主要介绍2021款MacBook Pro 14inch, 具体的参数规格","text":"在研究生使用半年的Macbook Air（2020M1）之后由于存储、屏幕等原因，转向具有诸多优点的MacbookPro14（2021），在深度磨合半年之后介绍这台设备的优点。从工业设计、外部接口、硬件配置、屏幕素质介绍使用感受，并从文件处理、知识管理、系统工具、娱乐角度介绍软件资源，最后给出文件管理和待办管理的工作流。 本文主要介绍2021款MacBook Pro 14inch, 具体的参数规格 0x01 使用感受 一下从工业设计、外部接口、硬件配置、屏幕素质角度介绍使用感受。 从工业设计角度，外观上虽然失去了Macbook Air楔形设计的优美，但是坚实的底座和方正的设计会让人觉得它很踏实。但是真的很重，相比Air的重真的需要加一个档次的心理准备。另外这次的键盘相比air更重，按键也更大，特别是非常大的esc键，非常舒服。 从外部接口来看尤其是 3thunderbolt4+MagSafe3+headphone jack +HDMI+SDXC 真是非常实用，所以直接抛弃贝尔金七合一的拓展坞。HDMI在外出接投影仪的时候真的非常好用，SD卡在导出相机照片的时候非常方便。美中不足的有两点：一是没有USB-A接口，在日常使用移动硬盘和连接安卓手机不方便 二是HDMI和SD卡的速度有一定的限制。 观点1：外设永远没有自带方便 从硬件配置角度，后续我会详细结合软件操作来介绍。这里总的体验感受是M1pro相比M1从速度上真的会快很多，但是功耗也会快很多。但是菜狗很少会遇到性能瓶颈（doge），日常使用的续航大概只有6～12小时不等（之前的Air大概有12～18小时）。另外对于电脑来说，256G还是太小了，虽然我有一台4T的windows台式机，但还是感觉移动办公的电脑存储也不能太低（点名微信）。同时虽然移动硬盘很便宜，但是使用建议参考观点1。外放的感觉超级赞！远超iPhone 13pro，略超iPad pro12.9inch。 从屏幕素质角度，3024*1964的254ppi的屏幕日常使用非常的惊艳，同时基于miniLED观看HDR视频可以高达1600nit。但是总感觉屏幕太亮很刺眼，看时间长了屏幕有点头晕。但是理论上基于miniLED的LCD面板频闪很低，具体原因未知。将其显示从XDR调整为Display，同时开启True Tone和Night shift会稍微好一点。刘海没有Face ID很让人失望，但是刘海正好处于菜单栏和状态栏之间的交界处，这样的设计可以正好将显示上移，在屏下技术不完善的今天，日常使用的关注点还是很少的。 0x02 软件资源库 这里主要介绍具有GUI的应用程序，通常可以分为以下，推荐下载软件的网站： macyy、xclient、AppNee以及相关telegram群聊 2.1 文件处理 Office 365三件套：Word、Excel、PowerPoint macOS自带：Keynote、iMovie Typora：markdown的最佳工具 PDF expert和预览：PDF处理工具 Tex Studio：不会用VScode来编辑Latex，还是用这个 nPlayer：相比IINA打开HDR视频会更有优势 VS code：最强的文本编辑器，sublime text有点麻烦的。 GifSki：压缩视频生成Gif SVG view：查看SVG R studio：处理R文件 2.2 知识管理 Notion：all in one的笔记软件 Zotero7: 文献管理软件 Marginnote3: 桌面级的读书笔记摘要工具 微信读书：macOS可以直接下载！ xmind：生成思维导图很好看，但是现在逐渐转向PPT One drive：拼车的Office365非常香，iCloud太贵了！ Dash：API管理 Cubox：真的知识管理软件，稍后读。 Note+Reminder+Calendar：系统自带的GTD管理系统 2.3 系统功能 iStat Menus Status，状态栏系统状态检测，可以显示现有功率！ Alfred，相比spotlight而言功能更多，但是文件检索的效率略低。有的时候one drive文件搜索不到 Bob：翻译软件，配合自带的翻译使用非常流畅，同时可以下载插件 Clash X：网络增强 Terminus：终端增强 Oh-My-Zsh：终端增强 Barender4：状态栏增强 Rectangle：窗口管理 iShot pro：截图 Better zip：解压缩 cheetsheet：快捷键提醒 超级右键：右键增强，但是有的时候增强也并不是好事 Monitor Control：管理显示器亮度 观点2：局部便捷化会破坏系统一致性，而产生更大的混乱。 2.4 娱乐 微信、telegram：即时通讯 Chrome、Safari、Arc：浏览器，通往互联网的窗口 Steam：有一部分Mac可以玩的，比如人类一败涂地、胡闹厨房等等 Music：自带的yyds 百度网盘+阿里云盘 0x03 工作流分享 在上述的软件基础上，我们给出自己的工作流，主要包括3.1文件管理、3.2待办管理（GTD）、3.3 同步管理等等 3.1 文件管理 经过长时间的摸索，给出结合领域知识+标签的Finder文件管理方式。 树状的文件资源管理器在Linux、macOS、Windows中几乎达成共识。但是macOS依旧保留“标签”这个重要属性，标签可以将文件之间的关系从树的节点转换成为平权的图的节点，这样带来的好处是自由行的增加，坏处是管理的困难。通常在最终管理只会记住度比较大的节点。我们会面临的困境是，树状分类的文件夹不足以代表内部文件的所有特征，而标签的文件系统管理困难。所以我们需要在**合理文件夹分类和恰当的标签管理中做权衡。**给出的解决方案是： 领域知识鲜明的设置领域文件夹，否则按照格式管理 标签仅表示状态，和额外的一次性的元信息 首先对于第一点，感觉Flomo标签软件传授的笔记理念（虽然我不用flomo），其倡导的卡片分类我发现也适用于文件管理。系统默认会将用户文件分为：文档、音乐、视频、照片这样的格式。如果我们只按照格式来存储这样的文件，我们会发现我们的Project1需要的文档、代码、图片等等文件散落在不同的文件夹，不利于整理。因此我们可以设计另外一个专放领域知识的文件夹，里面可以存储课程1、课程2、项目1、项目2,…的领域文件夹，对于小型文件不易区分的文件存储在不同格式的文件夹，pdf文件存储在文档、png存储在图片文件夹。充分利用不同文件的强关系 对于第二点，受益于spotlight、everything这样的文件，我们可以用哈希的方式来搜索我们的文件。因此我设计标签并不是对文件属性的强分类，而是对文件的信息补充，包括状态信息、所属成员、以及独一无二的meta信息，标签可以加的足够多来保证后续可以搜索到。 3.2 待办管理（GTD） 《Get thing done》参考这本书可以给对于日常任务管理提升一个级别。在研究生之前的任务可能就是简单的复习，写题等等。回想生活那么简单就是因为自己是个单线程生物。但是研究生中不同任务的并行，有的需要跑代码，有的时候需要写文档，还会有偶发的中断任务去处理，由于我们并不是机器，任务也是死板的输入输出。因此在混乱的任务中找到自己的工作流是GTD需要做的事情。 之前尝试过滴答清单，最好发现还是多端同步的苹果自带的日历Calendar、提醒事项Reminder、笔记Note好用。 首先我们可以对任务分为三类：Event、Todo、DDL。这里的命名和书里面的可能不一样～ Event：通常放在Calendar中，指的是有确定时间发生的，不需要check是否完成的。比如上课（不去也没关系）、比如演唱会抢票（抢不到也没关系）、比如开组会（是否完成也不需要确认）等等； Todo：通常放在Reminder中，可能叫Task比较好，指的是需要check完成的，但是一般没有时间。比如买袜子、看一本书等等。这一类任务通常需要根据优先级来排序； DDL：放在Reminder中，指的是需要check完成的，一般有截止日期。比如6月1号之前提交论文，比如下一月十号之前完成一项汇报。这一类任务需要根据截止日期来排序。 分类好之后我们需要包括输入，通常即时可以用Siri、Alfred收集自己的任务，或者以周或月为单位整理自己的任务（用备忘录），之后再整理送入自己的系统。 观点3: 友好的系统设计可以保证它易用，但是维护一个系统是需要持之以恒的用下去，并从中得到正反馈。 3.3 知识管理 基于Notion实现All in one并不现实，不同的软件具有应对不同场景的优势。Cubox用于稍后阅读、Notion适用于笔记梳理、Note适用于即刻笔记、Marginnote适用于文档阅读等等，自己路需要自己去摸索！ Mermaid使用教程 知识管理流程 网络代理使用 预览工具使用 更多的参考 工科生研0的Macbook Air M1 13inch（16+256）深度使用感受 One more thing Mac终究只是连接到网络世界的工具，屏幕背后的人是最重要的！ 在使用Mac的过程中，我可能陷入追求机器性能极致迷茫，似乎M1pro的H.264编码很厉害，似乎视频剪辑很厉害。但是如果你不需要这些功能，你不需要用这些功能来证明你确实需要M1pro，而是要在实现自己本身目的的前提下最大化的利用它并判断是否合适！ 希望能启发你的一些思考和讨论！","categories":[{"name":"memo","slug":"memo","permalink":"https://blog.tjdata.site/categories/memo/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"https://blog.tjdata.site/tags/Mac/"}]},{"title":"EM算法HMM和CRF","slug":"EM算法HMM和CRF","date":"2023-07-27T08:56:45.000Z","updated":"2023-08-12T07:34:14.252Z","comments":true,"path":"posts/a77ab19e.html","link":"","permalink":"https://blog.tjdata.site/posts/a77ab19e.html","excerpt":"摘要","text":"摘要 正文","categories":[],"tags":[]},{"title":"有意思的两道二叉树的题目","slug":"有意思的两道二叉树的题目","date":"2023-07-12T13:16:48.000Z","updated":"2023-07-27T11:09:23.910Z","comments":true,"path":"posts/67653c3b.html","link":"","permalink":"https://blog.tjdata.site/posts/67653c3b.html","excerpt":"摘要","text":"摘要 正文","categories":[],"tags":[]},{"title":"关于tensorboard介绍的翻译","slug":"关于tensorboard介绍的翻译","date":"2023-07-05T01:49:45.000Z","updated":"2023-07-05T02:18:18.507Z","comments":true,"path":"posts/5ddcb6b8.html","link":"","permalink":"https://blog.tjdata.site/posts/5ddcb6b8.html","excerpt":"原文地址《Introducing Tensor Board.dev: a new way to share your ML experiment results》","text":"原文地址《Introducing Tensor Board.dev: a new way to share your ML experiment results》 Tensorboard作为tensorflow的可视化组件，通常为研究者和工程师提供可视化和理解机器学习的实验结果。它可以被用来 Tracking experiment metrics(记录实验指标) Visualizing models(可视化模型) Profiling ML programs(分析机器学习运行过程) Visualizing hyperparameter tuning experiments(可视化超参数调节实验) 除了可以简单的可视化模型，Tensorboard也可以多端合作。你可能想分享超参变动对结果的影响、解释一个复杂的训练过程和从失败中获取帮助 我们之前加过人们尝试分享TensorBoard的截图来实现，但是截图并不是可交互的并且没有展示所有的细节。在Google，研究人员和工程师往往通过tensorboard 可视化结果给团队成员来讨论观点。我们的目标是为更广泛的社区提供这个能力 这也是为什么我们开发tensorboard.dev：一项托管服务（目前正在预览中），使您能够轻松地免费托管、跟踪和共享您的ML实验。只需上传您的TensorBoard日志，即可收到一个每个人都可以查看的链接，无需安装或设置。 If a picture is worth a thousand words, we believe an interactive TensorBoard can be even more valuable. 使用逻辑 通过SummaryWriter()类来实现数据保存和展示 1234567891011121314151617from torch.utils.tensorborad import SummaryWriterwrite = SummaryWrite(&#x27;../logs&#x27;) # 指定log保存的位置# 常用方法add_scalar(tag, scalar_value, global_step=None, walltime=None, new_style=False, double_precision=False)add_scalars(main_tag, tag_scalar_dict, global_step=None, walltime=None)add_histogram(tag, values, global_step=None, bins=&#x27;tensorflow&#x27;, walltime=None, max_bins=None)add_image(tag, img_tensor, global_step=None, walltime=None, dataformats=&#x27;CHW&#x27;)add_images(tag, img_tensor, global_step=None, walltime=None, dataformats=&#x27;NCHW&#x27;)add_figure(tag, figure, global_step=None, close=True, walltime=None)add_video(tag, vid_tensor, global_step=None, fps=4, walltime=None)add_audio(tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None)add_text(tag, text_string, global_step=None, walltime=None)add_graph(model, input_to_model=None, verbose=False, use_strict_trace=True)add_embedding(mat, metadata=None, label_img=None, global_step=None, tag=&#x27;default&#x27;, metadata_header=None) 实际应用 12345678910111213from torch.utils.tensorboard import SummaryWriterimport torch.nn as nnimport torchimport numpy as npinput = torch.zeros(1,20)net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))writer = SummaryWriter(&#x27;./logs&#x27;)for epoch in range(100): writer.add_scalar(&#x27;Loss/train&#x27;,np.random.random(),epoch) writer.add_scalar(&#x27;Loss/test&#x27;,np.random.random(),epoch) writer.add_scalar(&#x27;Accuarcy/train&#x27;,np.random.random(),epoch) writer.add_graph(net,input_to_model=input)","categories":[{"name":"memo","slug":"memo","permalink":"https://blog.tjdata.site/categories/memo/"}],"tags":[{"name":"torch","slug":"torch","permalink":"https://blog.tjdata.site/tags/torch/"}]},{"title":"Kaggle竞赛手写问题识别","slug":"Kaggle竞赛手写问题识别","date":"2023-06-05T10:17:10.000Z","updated":"2023-06-05T10:44:00.698Z","comments":true,"path":"posts/eeffea24.html","link":"","permalink":"https://blog.tjdata.site/posts/eeffea24.html","excerpt":"最近看了Python的PEP8，其中对于代码规范的要求是注释主要选择英文，本次项目的进行中也在竭力的进行，但是发现效果并不是很好，如果为了别人的代码可读性的标准而导致自己的代码低效，这个显然是不可取的。never mind，本章主要介绍CNN届的Hello world————手写数字识别。自己从无到有的敲一下。","text":"最近看了Python的PEP8，其中对于代码规范的要求是注释主要选择英文，本次项目的进行中也在竭力的进行，但是发现效果并不是很好，如果为了别人的代码可读性的标准而导致自己的代码低效，这个显然是不可取的。never mind，本章主要介绍CNN届的Hello world————手写数字识别。自己从无到有的敲一下。 项目介绍 MNIST(modifed national institute of standard and technology) is the “Hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classficiation algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for resource for researchers and leaaners alike. In this competition, your goal is to correctly identify digits from a dataset from a dataset of tens of thousands of handwritten images. We have curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand works well and how techique compare. 12345678910import numpy as np # 线性代数import pandas as pd # 数据预处理import matplotlib.pyplot as plt # 绘图import torchimport torch.nn as nnfrom torch.utils.data import DataLoaderfrom sklearn.model_selection import train_test_splitimport torchvision.transforms as transformsfrom torch.utils.data import Datasetdevice = torch.device(&#x27;mps&#x27;) # mps需要torch&gt;=1.13 数据集 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# csv -&gt; pd.DataFrametrainDF = pd.read_csv(&#x27;../DigitRecongnier/data/train.csv&#x27;)# pd.DataFrame -&gt; numpy.arraylabels = trainDF[&#x27;label&#x27;].valuestrain = trainDF.drop([&#x27;label&#x27;],axis=1)features = train.values# 划分数据集和测试集features_train,features_test,targets_train,targets_test = train_test_split(features,labels,test_size=0.2,random_state=42)# def split_data(features,labels,per):# &#x27;&#x27;&#x27;按照per划分数据集&#x27;&#x27;&#x27;# split_len=int(per*len(labels))# trainFeatures = features[:split_len]# trainLabels = labels[:split_len]# valFeatures = features[split_len:]# valLabels = labels[split_len:]# return trainFeatures,trainLabels,valFeatures,valLabels# trainFeatures,trainLabels,valFeatures,valLabels = split_data(features,labels,0.8)# numpy.array -&gt; tensorfeaturesTrain = torch.from_numpy(features_train)/255targetsTrain = torch.from_numpy(targets_train)featuresTest = torch.from_numpy(features_test)/255targetsTest = torch.from_numpy(targets_test)# trainF = torch.tensor(trainFeatures)# trainFS = trainF.reshape((-1,28,28))# # 证明前后是一样的# trainF[0] == trainFS[0].reshape(1,-1)# # tensor -&gt; dataset(using tensordataset) # # 缺点是不能使用transform# train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)# test = torch.utils.data.TensorDataset(featuresTest,targetsTest)# tensor -&gt; data (using super the dataset)class TensorDatasetSelf(Dataset): &#x27;&#x27;&#x27; tensor dataset 继承 dataset 只需要重载len和getitem就可以&#x27;&#x27;&#x27; def __init__(self,features,target,transform=None) -&gt; None: super().__init__() self.datatensor = features self.labeltensor = target self.transform = transform def __len__(self): return self.datatensor.size(0) def __getitem__(self, index): cur = self.datatensor[index] X = cur.reshape((1,28,28)) return X,self.labeltensor[index]# 定义一个变换，将数据缩放到 0 到 1 的范围内# 坑：Resize返回一个image# transform = transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor()])train = TensorDatasetSelf(featuresTrain,targetsTrain)test = TensorDatasetSelf(featuresTest,targetsTest) Hint01 : torch构建dataset的几种方式 自定义Dataset类，可以通过继承torch.utils.data.Dataset来实现，需要重写__len__(),getitem()类 使用tensorDataset类，是一个包装器类，实现从tensor到dataset的直接的转变 Hint02 Dataset中添加数据预处理 我们输入features、labels进入dataset类之后，在输出的时候我们可能希望对其进行一些预处理 比如图像增强常用的预处理、增强、旋转等等 from torchvision import transforms transforms.compose()类似pipeline，来实现一系列的transform操作，常见的transform操作有： transforms.ToTensor() 自定义transforms 数据迭代器 123456789101112131415# 构建数据集的超参数设置batchsize = 128epoches = 20# dataset -&gt; dataloadertrain_iter = DataLoader(train,batch_size=batchsize,shuffle=False)test_iter = DataLoader(test,batch_size=batchsize,shuffle=False)# tensor 也可以 plt！for X,y in train_iter: print(X.shape) cur = X[0][0] plt.imshow(cur) plt.show() break 模型 经典的CNN方面的论文，无论他最后需要实现的有多复杂，在深度学习的pipeline中，只是占据着模型构建的角色。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 使用经典的CNN模型class LeNet(nn.Module): def __init__(self): &#x27;&#x27;&#x27;input :28*28,output:10&#x27;&#x27;&#x27; super().__init__() # Convolution 1 self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0) self.relu1 = nn.ReLU() # Max pool 1 self.maxpool1 = nn.MaxPool2d(kernel_size=2) # Convolution 2 self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0) self.relu2 = nn.ReLU() # Max pool 2 self.maxpool2 = nn.MaxPool2d(kernel_size=2) # Fully connected 1 self.fc1 = nn.Linear(32 * 16, 10) def forward(self, x): # Convolution 1 out = self.cnn1(x) out = self.relu1(out) # Max pool 1 out = self.maxpool1(out) # Convolution 2 out = self.cnn2(out) out = self.relu2(out) # Max pool 2 out = self.maxpool2(out) # flatten # out = out.view(1, -1) out = out.view(out.size(0), -1) # Linear function (readout) out = self.fc1(out) return outmodel = LeNet()# testTensor = torch.randint(0,255,(1,28,28),dtype=torch.float)# model (testTensor) 损失函数 1loss = nn.CrossEntropyLoss() 优化器 12learning_rate = 0.03opt = torch.optim.SGD(model.parameters(),lr=learning_rate) 训练 123456789101112131415161718# trian with(data_iter,model,loss,optimizer)# 将模型添加到device中model =model.to(device)# 训练多个epochfor epoch in range(epoches): # 训练多个iter for X,y in train_iter: # X,y = X.to(device),y.to(device) model.train() opt.zero_grad() l = loss(model(X),y) l.mean().backward() opt.step()# to choice a better model，this should be train ata 测试 12345678910valDF = pd.read_csv(&#x27;../DigitRecongnier/data/test.csv&#x27;)valtensor = torch.tensor(valDF.values,dtype=torch.float,device=device)valtensor = valtensor.view((-1,1,28,28))result = model(valtensor)res = torch.argmax(result,dim=1)index =pd.Series(np.arange(1,28001))res =res.to(&#x27;cpu&#x27;)label = pd.Series(res)df = pd.DataFrame(&#123;&#x27;ImageId&#x27;:index,&#x27;Label&#x27;:label&#125;)df.to_csv(&#x27;../DigitRecongnier/data/sample_submission.csv&#x27;,index=False)","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"Kaggle","slug":"Kaggle","permalink":"https://blog.tjdata.site/tags/Kaggle/"}]},{"title":"CS229局部线性回归review和实现","slug":"CS229局部线性回归review和实现","date":"2023-05-31T10:29:14.000Z","updated":"2023-05-31T10:40:35.938Z","comments":true,"path":"posts/994c246.html","link":"","permalink":"https://blog.tjdata.site/posts/994c246.html","excerpt":"在学习Torch之际，正好结合沐神的《动手学深度学习》和CS229中的局部线性回归讲义实践一下！终于跑通了第一个属于自己的代码！！","text":"在学习Torch之际，正好结合沐神的《动手学深度学习》和CS229中的局部线性回归讲义实践一下！终于跑通了第一个属于自己的代码！！ 0x01 什么是线性回归？ 在之前的CS229中，线性回归（Linear regression）作为机器学习的Hello world，让我们了解到学习模型（supervised learning algorithm）会包括几个部分： 数据集（dataset） 假设（hypothesis） 损失函数（loss function） 优化方法（optimization method） 详细可见 cs229-01线性模型 0x02 什么是局部线性回归？ 也就是给梯度一个权重 0x03 从零开始的代码实现 在了解算法的基础上，如何使用代码构建出来是另外一个方面。两者可以是互补的！ 参照Tensorflow2.0 八股文的描述，我们将深度学习网络构建的过程也可以分为几个典型的步骤： 构建dataset 根据dataset生成不同的dataloader，方便后续批量梯度下降(batch gradient descent) 建立Model（根据hypothesis） 选择损失函数 loss function 优化器选择 超参数的设置 lr、epoch、batchsize 学习过程，批量梯度下降 评价指标，对于regression的分析常见的包括MSE、MAPE等等 3.1 定义数据集 1234567891011121314import torchimport matplotlib.pyplot as pltdef gen_data(w,b,num_examples): &quot;&quot;&quot;生成y=Xw+b的噪声&quot;&quot;&quot; # dtype=float X = torch.normal(0,1,(num_examples,len(w)),dtype=float) y = torch.matmul(X,w) y += torch.normal(0,0.01,y.shape,dtype=float) # reshape的意义在于将vector变成为matrix，vector应该是N，而matrix是N*1 return X,y.reshape((-1,1))true_w=torch.tensor([2,-3.4],dtype=float)true_b=4.2features,labels=gen_data(true_w,true_b,1000)plt.scatter(features[:,1],labels,1) 3.2 定义数据迭代 基于Python原生生成的迭代器虽然可以连续的获取不同的小批量，但是执行效率很低，因为此****要求将所有数据加载到内存中，并执行大量的随机内存访问****，所以通常深度学习框架会内置迭代器，用于处理存储在文件中的数据和数据流提供的数据 1234567891011121314151617import randomdef data_iter(batch_size,features,labels): num_examples = len(features) indices = list(range(num_examples)) # 样本随机读取，没有特定的顺序 random.shuffle(indices) for i in range(0,num_examples,batch_size): batch_indices = torch.tensor( indices[i:min(i+batch_size,num_examples)] ) yield features[batch_indices],labels[batch_indices]# batchsize=10# for X,y in data_iter(batch_size=batchsize,features=features,labels=labels):# &#x27;&#x27;&#x27;仅作为测试使用&#x27;&#x27;&#x27;# print(X,&#x27;\\n&#x27;,y)# break 3.3 定义模型 同时也能够返回对应参数的parameters的size，这里和教科书不一样，我们使用class的方式来建立新的模型。 123456789101112class network: def __init__(self) -&gt; None: self.w=torch.normal(0,0.01,size=(2,1),requires_grad=True,dtype=float) self.b=torch.zeros(1,requires_grad=True,dtype=float) def predict(self,X): return torch.matmul(X,self.w)+self.b def parameters(self): &#x27;&#x27;&#x27;返回对应参数的size&#x27;&#x27;&#x27; return [self.w,self.b]model=network() 3.4 定义损失函数 Local loss是局部损失函数 12345678910111213def get_weight(X,features): &#x27;&#x27;&#x27;权重分析&#x27;&#x27;&#x27; diff = X.unsqueeze(-2).unsqueeze(-2)- features.unsqueeze(-2) w = torch.exp(-diff**2/0.000002).squeeze(-2).sum(axis=(1,2)) return wdef square_loss(y_hat,y): return (y_hat-y.reshape(y_hat.shape))**2/2# y_hat=model.predict(X)# res=square_loss(y_hat,y)# res.mean()def local_loss(y_hat,y,X): new_w=get_weight(X,features) return new_w.reshape(shape=(-1,1))*(y_hat-y.reshape(y_hat.shape))**2/2 3.5 定义优化算法 在计算机求解优化算法的过程中，我们可以先想一下我们需要什么东西？ 按照梯度下降的方式来进行神经网络的优化过程中，必然需要知道parameters的size，之后是对参数更新之后的长度learning rate，依旧每次下降的batch-size 12345678910def sgd(params,lr,batchsize): &#x27;&#x27;&#x27;小批量随机梯度下降&#x27;&#x27;&#x27; # model.eval() 和 with torch.node_grad()区别是什么 # model.eval()主要用于model的validation过程中，通知dropout和batchnorm层在train # val模式之间切换 # with torch.no_grad()主要是停止autograd模块的工作，起到加速和节省显存的作用 with torch.no_grad(): #??这是做什么的 for param in params: param -= lr*param.grad/batchsize param.grad.zero_() 3.6 定义超参数 12345lr = 0.05batchsize=10num_epoches = 4net = network()loss = square_loss 3.7 开始训练 123456789for epoch in range(num_epoches): for X,y in data_iter(batch_size=batchsize,features=features,labels=labels): # l = loss(net.predict(X),y) l = local_loss(net.predict(X),y,X) l.sum().backward() sgd(net.parameters(),lr,batchsize) with torch.no_grad(): train_l=loss(net.predict(features),labels).mean() print(train_l) 3.8 评估模型 1print(net.w) 0x04 几个注意的点 数据dtype最好设置float 注意vector和matrix甚至tensor之间的区别 在weight计算中的维度的变化来保证broadcasting with torch.no_grad( )和model.eval( )的区别 令人惊喜的torch的broadcasting的功能！！","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"LSR","slug":"LSR","permalink":"https://blog.tjdata.site/tags/LSR/"}]},{"title":"QuantumultX使用教程记录","slug":"QuantumultX使用教程记录","date":"2023-05-24T00:47:34.000Z","updated":"2023-05-24T02:01:51.464Z","comments":true,"path":"posts/cc1a6fba.html","link":"","permalink":"https://blog.tjdata.site/posts/cc1a6fba.html","excerpt":"一直使用圈x作为我的代理软件，但是出现了一些问题，现在想总结一些圈x使用的方法。","text":"一直使用圈x作为我的代理软件，但是出现了一些问题，现在想总结一些圈x使用的方法。 0x01 Overview 圈X的功能有哪些？ Proxy server，导入订阅连接，可以使用代理访问网站 [server local] [server remote] Filter rules,设置对应的策略组和分流规则，对应[proxy] [filter_remote] [filter_local] Rewriter rule，重写规则和MITM解密，主要用来去广告和重定向[rewrite] [mitm] 0x02 Proxy server使用 添加节点和订阅链接的方式有三种，一般使用2就足够了～ 通过Quantumult X 界面添加节点。setting-&gt;external proxy-&gt;add 通过Quantumult X 界面添加订阅。setting-&gt;external proxy-&gt;resources 手动修改配置文件添加节点，在配置文件中的[server_local]部分，setting-&gt;proxy file–&gt; edit 1234# trojan 节点写法trojan=example.com:443, password=pwd, over-tls=true, tls-verification=false, fast-open=false, udp-relay=false, tag=节点名称# vmess 节点写法vmess=example.com:443, method=chacha20-ietf-poly1305, password=pwd, obfs-host=example.com, obfs=wss, obfs-uri=/ws, tls-verification=true, fast-open=false, udp-relay=false, tag=节点名称 在实际使用中可以分为all proxy、all direct、based on filter等 All proxy：所有的网络请求都通过Proxy下选中的节点进行 All direct：所有的网络请求都不使用代理进行 Based on filter: 根据分流规则将网络请求进行分流，并通过策略组将分流规则传递来的网络请求进行转发 0x03 Filter rules 使用 graph Q[request] P1[Based on filter] J[Filter=filter_local+filter_remote] P2[Direct] P3[Proxy1] P4[Proxy2] P5[Reject] Q--&gt;P1 P1--&gt;J J--&gt;P2 J--&gt;P3 J--&gt;P4 J--&gt;P5 当我们发送请求的时候，确定请求代理之后，根据Filter rules，来判断走哪些策略组。首先策略组分为static、available、robin和SSID，常见的Proxy设置在配置文件中的[proxy]中，对应的分流规则在[filter_local] 和 [filter_remote] 首先分流规则是根据匹配来选择对应的策略组的，这一点和clash等类似，比如通过域名来判断，添加的方式主要有： 导入远程分流规则订阅，这里默认在proxyfile的[filter_remote] 自己本地撰写分流规则，这里默认在proxyfile的[filter_local] 利用抓包的方式来确定选择对应的策略组（因为我们通常不知道域名是什么qwq）activity–&gt;one row–&gt;filter–&gt;new filter–&gt;proxy 这里当然可以去寻找一些现有的filter 0x04 Rewrite rules 上述其实实现了代理软件的基本功能，但是QuantumultX还提供了重写的过程，个人理解是将软件的请求重写调整，而不是简单的换一个服务器访问。 一个简单的例子就是你访问www.baidu.com之后，它必然会返回一个网页，我们可以通过正则匹配的方式挑选出其中img的路径，并重定向到你自己的网址，这样就可以更换logo 因此这里需要MITM解密和设置[rewrite] 还是看大佬的配置比较好","categories":[{"name":"memo","slug":"memo","permalink":"https://blog.tjdata.site/categories/memo/"}],"tags":[{"name":"proxyApp","slug":"proxyApp","permalink":"https://blog.tjdata.site/tags/proxyApp/"}]},{"title":"Torch文档阅读","slug":"Torch文档阅读","date":"2023-05-23T14:25:41.000Z","updated":"2023-05-23T14:31:49.485Z","comments":true,"path":"posts/5ef17af5.html","link":"","permalink":"https://blog.tjdata.site/posts/5ef17af5.html","excerpt":"Torch官方文档中最关键的类torch.tensor，最重要的机制autograd，这里对常见的API进行总结","text":"Torch官方文档中最关键的类torch.tensor，最重要的机制autograd，这里对常见的API进行总结 Pytorch 基本教程 从组成元素上来看学习Torch主要需要熟悉以下几个概念，个人总结以下几个概念 什么是Tensor？这个是深度学习框架计算的源泉，参考NumPy的array和Pandas的Dataframe。我们对于基本变量的操作主要分为如何创建？如何生成？如何复制？如何运算？如何索引？如何删除？等等操作 数据的预处理，如何通过读取数据来构建自己的dataset、dataloader，并对数据进行一定的transform、随机抽取等等 深度的八股：网路结构Net、优化器选择Optim、损失函数的选择Loss等等 训练函数和测试函数。如何在epoch训练、如何打印loss、如何计算summary等等 123456789101112131415161718import torchimport numpy as np# 生成torch通常可以包括以下几点# 1. 利用内置的函数 empty.ones.rand.randn.randint randperm linspace等等# 2. 利用现有的数据，list、numpy.array、tensor等# 3. 通过运算broadcasting,cat,join等x =torch.empty(5,3)x_numpy=np.zeros((5,3))# Torch 生成随机数的种类torch.rand(1,2) # 均匀分布torch.randint(2,3,(2,2)) #整数分布torch.randn(2,3) # 标准正态分布torch.randperm(10) # 不重复随机数torch.linspace(0,10,1) # 线性间距torch.arange(12)torch.poisson(torch.rand(3,5)*5) # poisson分布 12import matplotlib.pyplot as pltplt.plot(torch.linspace(1,5,steps=50),torch.poisson(torch.linspace(1,10,steps=50))) 12345x=torch.randn(5,4,dtype=torch.float32)x = torch.tensor([1,2,3,4])x = torch.tensor(np.arange(10))x = torch.randn(3,4)y = torch.rand_like(x) 1234567891011121314151617181920212223242526272829303132333435363738# Torch之间的运算# torch默认的操作是elements和broadcasting的X = torch.randn(3,4)y= torch.rand(1,4)# torch.tensor之间的可能会有三种方式：运算符号，运算函数，内在的函数torch.add(X,y)X.add_(y)X+y# 对于tensor的操作x=torch.rand(3,4,5)x[:,:,-1]y=x.view(60)z=x.view(5,12)zx[0,0,0].item()# 对于tensor的reshape操作通常可以分为:名字name、维度shape和类型type# view和reshape是在改变形状# squeeze unsqueeze 增加维度和删减维度# transpose permute 是变换维度# expand repeat 维度拓展images=torch.randn(4,1,28,28) # 4张通道数为1的28*28的图片images_batch=images.view(4,28*28)# 在0维度拓展维度unsqueeze，相当于将tensor放入包装盒种images_batch.unsqueeze(0).shape# Tensor 的合并和分割主要包括# concatenate 连接，作用是将2个tensor按照特定的维度连接起来，其他维度必须相同# stack 对接起来# split 根据长度拆分tensor# chunk 均等分的splita=torch.randn(3,4)b=torch.rand(2,4)torch.cat([a,b],dim=0)a.split([1,2],dim=0) 0x02 自动微分 Autograd 上述虽然给tensor的创建、索引、运算和形状改变，但其实更重要的是Torch基于此实现的自动微分机制。可能需要一些前向推理和反向传播的知识，这里需要结合tensor和gradient来介绍一些基础的知识。初步的需要了解 tensor中grad的激活、分割、计算等等 运算 torch.Tensor是package的核心类，如果将其属性 .require_grad设置为true，则会开始跟踪tensor的所有操作，在完成计算之后，可以调用 .backward()来自动就按所有的梯度，累积到 .grad属性之中 .detach() 可以停止跟踪历史记录和内存，或者在with torch.no_grad() 123456789101112x = torch.randn(2,2,requires_grad=True)y=x+2z=y*y*3out=z.sum()out.backward()x.grad # 这里想当于 d(out)/d(x)x=torch.randn(10,3,requires_grad=True)b=torch.randn(3,1,requires_grad=True)y=torch.matmul(x,b).sum()y.backward()b 0x03 神经网络的搭建 网络内部需要考虑 input 和 output，内部需要考虑layer和forward 迭代整个输入 通过神经网络处理输入 计算损失 loss 反向传播计算梯度 更新网络的参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445import torch.nn as nn import torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super().__init__() # 假设图片的输入是 1channel,5*5,6channel 输出 self.conv1=nn.Conv2d(1,6,5) self.conv2=nn.Conv2d(6,16,5) # 这里的16*5*5可以推理应该需要的size self.fc1=nn.Linear(16*5*5,120) self.fc2=nn.Linear(120,84) self.fc3=nn.Linear(84,10) def forward(self,x): x=F.max_pool2d(F.relu(self.conv1(x)),(2,2)) # If the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_featuresnet=Net()# Question: 这里必须要加上一个梯度input=torch.randn(1,1,32,32,requires_grad=True)output=net(input)# dummy targettarget=torch.rand(10)target=target.unsqueeze(0)criterion=nn.MSELoss()loss=criterion(target,output)import torch.optim as optimoptimizer=optim.SGD(net.parameters(),lr=0.01) 123456789print(&#x27;conv1.bias.grad before backward&#x27;)print(net.conv1.bias.grad)optimizer.zero_grad()out=net(input)loss=criterion(output,target)loss.backward()optimizer.step()print(&#x27;conv1.bias.grad after backward&#x27;)print(net.conv1.bias.grad) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#用net来训练CIFA10import torchvisionimport torchvision.transforms as transformstransform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset=torchvision.datasets.CIFAR10(root=&#x27;../data&#x27;,train=True,download=False,transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)import matplotlib.pyplot as pltimport numpy as npclasses = (&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;)def imshow(img): img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0)))# get some random training imagesdataiter = iter(trainloader)images, labels = next(dataiter)# show imagesimshow(torchvision.utils.make_grid(images))# print labelsprint(&#x27; &#x27;.join(&#x27;%5s&#x27; % classes[labels[j]] for j in range(4)))class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return xnet = Net()criterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print(&#x27;[%d, %5d] loss: %.3f&#x27; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0print(&#x27;Finished Training&#x27;) One more thing: cheetsheet 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# creating tensorsx =torch.empty(3,4)torch.zeros(2,3)torch.ones(2,3)torch.manual_seed(1998)torch.rand(4,4)torch.rand_like(x)torch.tensro([3,4])torch.one((2,3),dtype=torch.int16)torch.zeros(2,2)+1torch.ones(2,2)*3torch.rand(3,4)**4# broadcastingtorch.rand(3,4)*(torch.rand(3,4)*2)# more math with tensorstorch.abs(a)torch.ceil(a)torch.floor(a)torch.clamp(a,0.5,0.5)torch.sin(a)torch.asin(a)torch.bitwise_and(a,x)torch.max()torch.mean()torch.std()torch.prod()v1 = torch.tensor([1., 0., 0.]) # x unit vectorv2 = torch.tensor([0., 1., 0.]) # y unit vectortorch.cross(v2,v1)torch.matmul(a,x)torch.mv(a,v2)torch.svd(x)# creating tensorsx =torch.empty(3,4)torch.zeros(2,3)torch.ones(2,3)torch.manual_seed(1998)torch.rand(4,4)torch.rand_like(x)torch.tensro([3,4])torch.one((2,3),dtype=torch.int16)torch.zeros(2,2)+1torch.ones(2,2)*3torch.rand(3,4)**4# broadcastingtorch.rand(3,4)*(torch.rand(3,4)*2)# more math with tensorstorch.abs(a)torch.ceil(a)torch.floor(a)torch.clamp(a,0.5,0.5)torch.sin(a)torch.asin(a)torch.bitwise_and(a,x)torch.max()torch.mean()torch.std()torch.prod()v1 = torch.tensor([1., 0., 0.]) # x unit vectorv2 = torch.tensor([0., 1., 0.]) # y unit vectortorch.cross(v2,v1)torch.matmul(a,x)torch.mv(a,v2)torch.svd(x)x=torch.rand(3,4,requires_grad=True)y=x+2y.sum().backward()plt.plot(x.detach(),y.detach())with torch.no_grad(): y=x+2","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"document","slug":"document","permalink":"https://blog.tjdata.site/tags/document/"}]},{"title":"知识管理的一些想法","slug":"知识管理的一些想法","date":"2023-05-17T05:55:36.000Z","updated":"2023-05-17T06:52:43.516Z","comments":true,"path":"posts/d49191c7.html","link":"","permalink":"https://blog.tjdata.site/posts/d49191c7.html","excerpt":"作为一枚INFJ，经常会对效率工具进行反思。今天看了一本和知识管理联系不大的《如何有效阅读一本书》，然后对自己现有的知识管理系统中备忘录+日历+提醒事项，配合ShortCut快速输入、Cubox聚集、Notion整理的一套系统进行整理和反思。给出三个核心的观点。","text":"作为一枚INFJ，经常会对效率工具进行反思。今天看了一本和知识管理联系不大的《如何有效阅读一本书》，然后对自己现有的知识管理系统中备忘录+日历+提醒事项，配合ShortCut快速输入、Cubox聚集、Notion整理的一套系统进行整理和反思。给出三个核心的观点。 0x01 现有工具使用流程 对于现代互联网的工具的感受是，它无处不在，但是在光鲜亮丽的覆盖率之下反而更加暴露了各种信息交换不流畅的问题。你在Apple日历中设置的事项很难在安卓手机上看到，你在推特发的推文很难被同步到你的备忘录，你在豆瓣收藏的书籍也不会出现在亚马逊的购物中，你在PDF中做出的批注也难导出到你的Notion中… 为了解决这些信息交流的问题，我们往往需要确定自己的工作流Workflow。通过自身的控制来更好的使用工具。当然当一个高效的工具出现的时候你也会开心的，比如看到Warp代替iTerm，时代毕竟是在发展的。电子工具的用途主要有三个：1. GTD日程管理、2. 信息收集、3. 信息处理 graph classDef someclass fill:#f96 A[GTD : Get thing done]:::someclass C(Calendar:Event) R(Reminder:ToDo Schedule) N(Notes) C--&gt;A R--&gt;A N--&gt;A N--&gt;C N--&gt;R B[知识收集 Cubox]:::someclass W(Wechat Helper) API(Cubox API) ALF(Alfred) S(Short Cut) W--&gt;B API--&gt;B ALF--&gt;B S--&gt;B NO[知识整理 Notion]:::someclass DB(Database) BD(Database2) DB--&gt;NO BD--&gt;NO OUTPUT(Blog):::someclass A--&gt;B--&gt;NO--&gt;OUTPUT 接下来介绍一些原则： 一元化原则：如果在这个地方找不到，那么其他地方也找不到 避免无穷原则：收藏很简单，但是清空很难 多思考，多输出：一件事情只有我们给别人能够讲清楚的时候，我们自己才能明白 0x02 一元化原则 – GTD系统的可靠性 GTD是在一本书中提出的概念，用于个人的任务管理的一种方法论。同样这里还会有其他很多的任务管理的方法。最核心的要素是Get thing done。那么如何知道自己做什么？什么时候去做呢？原书给出作者思考的过程，这里介绍我目前摸索的对于日常事务的分类方法和实践规则。 首先事项根据主观和客观可以分为Calendar和Reminder，这也是两者之间的区别： Calendar：日历中发生的往往是一件Events（这也是macOS中的英文），它应该是一种不随个人意志发生的事情。比如国庆节、比如朋友的生日、比如上课、比如上课的DDL。这些事情的最大特点是发生完就结束了，不会有主动拖延这个概念。所以这个通常需要确定一个时间点 Reminder：这个发生的是我们主观想去做的事情（Item），这些事项可以是“去买个便利贴”“完成某一件作业”“在DDL之前做完PPT” 但是对于不同的提醒事项也可以进行分类，经过可以经验可以分为 Schedule：按照时间排序。规划好时间的事情，比如“明天早上9点新建一个论文文件夹”。在之前建立系统的时候，假如schedule设置太多，往往会导致自己完不成而逐渐拖延，所以这里建议计划一个星期会比较好 To Do List：按照优先级排序。这里是想做的，但是没有规划好时间的事情，比如说“看《奥本海默》”，这类事情往往需要构建一个优先级，当自己的Schedule做完的时候，可以从TODO中做起优先级高的事情 Deadline：按照时间排序。这里往往是一件事情的结束。代表的是一个过程。比如“下周一交作业”，这个时候需要我们在“下周一”这个时间点完成作业，并提交，我们不可能等到下周一再去完成作业。所以这个建议设置Flag 到此为止我们的GTD系统已经可以建立起来了，但是这个系统往往会受到冲击： 不可靠性，收集在Calendar和Reminder中的事项并不完全。导致我们对系统的信任度不高，经常还会依靠自己的大脑来回忆事情。 懒惰性，假如Schedule的东西太多，而自己不去完成，会导致系统的任务越来越多而崩溃 缺乏激励性，没有办法给自己正反馈，导致系统维护困难。 这里给出一个建议：在实践中我们要坚持一元化的原则，也就是在微信或者口头上获取一个事件，可以立马将其添加到自己的inbox，然后再对其分类整理。我们要充分信任自己的系统，因为GTD不仅是记录我们做了什么，还是一个帮助我们大脑记忆的系统。如果我们陷入回忆自己需要做什么的魔咒中，往往会消耗大量的精力和时间。 graph cal[Calendar] re[Reminder] E(Event sorted by time) S(Schedule sorted by time) T(To Do List sorted by priority) D(DeadLine sorted by time) cal --&gt; E re--&gt;S re--&gt;T re--&gt;D 0x03 避免无穷收藏：Cubox 互联网将知识串联在一起的后果是我们可以无限的滑动，我们永远看不完Google搜索的结果、看不完微博的帖子、看不完商品的简介…在知识管理也是这样。互联网带来的有用的知识也越来越多，当我们看到一个有意思的微信文章、或者诱人的博客、或者是B站大学的课程，往往会丢到自己的收藏夹中，然后不同软件中的收藏夹并不会互相沟通，唯一的共同点是逐渐增加但是从不清空。 所以将收集箱填满只是起点，终点是让收集箱回归空的状态。同样为了遵循“一元化”原则，希望可以将所有的知识和自己的想法收集到一个地方。并不想发生在微信收藏看文章、在B站看视频、在微信读书读想读的书、在浏览器看自己的read list，这样的劣势是不能整理。仿佛看完之后就结束了。 借助Cubox可以通过随机回顾来看自己曾经做过什么批注，可以将看完的东西分类放到架子（文件夹）中日后浏览，也可以将没有营养的归档或者删除。Review才是终点！ 0x04 输出和All in one：Notion 首先Notion作为知识管理的终点站在于其开放，它具有和其他系统联合并开放API，这样的开放性导致其可以综合其他内容。由此得到的后果是其可以作为所有知识收集工具的终点，同样它也是非常好的编辑器。 Databse是其最具特色的系统，我们可以通过设置不同的属性来对页面进行分类整理，将具有关系的页面根据Filter或Group来集聚，来达到自己系统管理的目的。 但是同样的在最终，在明白了自己需要做什么、在自己收集很多知识之后，考虑如何将其讲明白，写出一份给别人看的博客才是获取知识的最终途径～ 共勉","categories":[{"name":"Memo","slug":"Memo","permalink":"https://blog.tjdata.site/categories/Memo/"}],"tags":[{"name":"知识管理","slug":"知识管理","permalink":"https://blog.tjdata.site/tags/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86/"}]},{"title":"基于JS的Mermaid使用教程","slug":"Mermaid使用教程","date":"2023-05-16T01:25:31.000Z","updated":"2023-05-16T03:28:41.541Z","comments":true,"path":"posts/3be9bc5f.html","link":"","permalink":"https://blog.tjdata.site/posts/3be9bc5f.html","excerpt":"关于流程图的绘制中有很多工具，比如微软的visio 或者 PowerPoint、贝尔的Graphviz、Lucidchart、OmniGraffle、Draw.io、processOn、Latex的tikZ；但是这种基于图形界面的操作往往会受限于人本身的不精确导致不好看。所以希望借助代码生成流程图来尽可能保持协调一致的美观。","text":"关于流程图的绘制中有很多工具，比如微软的visio 或者 PowerPoint、贝尔的Graphviz、Lucidchart、OmniGraffle、Draw.io、processOn、Latex的tikZ；但是这种基于图形界面的操作往往会受限于人本身的不精确导致不好看。所以希望借助代码生成流程图来尽可能保持协调一致的美观。 0x01 使用教程 可以直接在Typora中使用，只需要输入即可 1``` mermaid 什么是Mermaid，按照官网的定义是基于JavaScript的图表工具，可以渲染受markdown启发的文本定义，用于动态创建和修改图表。其基本的语法结构包括： 1234# Diagrams definitions begin with a declaration of the diagram type # Define the blocks # Link the blocks erDiagram CUSTOMER &#125;|..|&#123; DELIVERY-ADDRESS : has CUSTOMER ||--o&#123; ORDER : places CUSTOMER ||--o&#123; INVOICE : &quot;liable for&quot; DELIVERY-ADDRESS ||--o&#123; ORDER : receives INVOICE ||--|&#123; ORDER : covers ORDER ||--|&#123; ORDER-ITEM : includes PRODUCT-CATEGORY ||--|&#123; PRODUCT : contains PRODUCT ||--o&#123; ORDER-ITEM : &quot;ordered in&quot; 常见的表格可以分为：流程图Flowchart、顺序图Sequence Diagram、类图Class Diagram、状态图State Diagram、实体关系图Entity Relationship Diagram、甘特图Gantt、饼图Pie chart、需求图Requirement Diagram、GitGraph、C4C图、思维导图Mindmaps、时间线Timelines 0x02 流程图 Flowchart 流程图由节点 (Nodes)、形状 (Edges)、箭头 （Arrows）和线条（Lines）组成，应用示例 flowchart id1(This is the text in the node1) id2[This is the text in the node2] db1[(database)] id1 --&gt; id2 db1 --&gt; id1 %% TB : top to bottom,TD %% BT: bottom to top %% RL: right to left %% LR: left to right flowchart LR subgraph BT[Define of the nodes] id1(圆角) id2([更大的圆角]) id3[长方形] id4[(数据库)] id5((圆形)) id6&gt;what] id7&#123;方形&#125; id8&#123;&#123;角&#125;&#125; id10[\\梯形 Trapezoid alt/] end subgraph LR[define of the linkes] id11[node1] id12[node2] id11 --&gt; id12 id11 --- id12 id11 -- Text ---id12 id11 ---|Text|id12 id11--&gt;|Text|id12 id11 -.-&gt; id12 id11 -. text .-&gt; id12 A == text ==&gt; id12 a --&gt;b &amp; c--&gt;d end subgraph LR B[start] C&#123;Is it?&#125; B --&gt;|yes|C C--&gt;D[rethink] D--&gt;B B--&gt;|No|E[End] E[perhaps?] end 0x03 时序图 Sequence diagrams 时序图表示用户之间相互交流的过程的图表，其中的语法主要包括：参与者（Participant）、演员（Actor）、别名（Alias）、分组（Group and box）、信息（Arrows and lines）、激活（Activate）、备注（Notes）、循环（Loop） sequenceDiagram participant A as Alice participant B as Bob participant J as John A-&gt;&gt;B:hello John B-&gt;&gt;J:Great! 123456789[Actor][Arrow][Actor]:Message Text-&gt; 实线--&gt; 没有箭头的点画线-&gt;&gt; 箭头线--&gt;&gt; 箭头点画线-X corss--X 点线带cross-）--） sequenceDiagram Alice-&gt;John: Hello John, how are you? activate John loop Every minute John--&gt;Alice: Great! end deactivate John 初次之外顺序图还需要表示一些基本的逻辑概念，比如激活（Activate）、循环（Loop）、替代（Alt）、平行（Par）、关键区域（Critical）、Break、高亮显示（Rect） sequenceDiagram participant Alice participant John rect rgb(191, 223, 255) note right of Alice: Alice calls John. Alice-&gt;&gt;+John: Hello John, how are you? rect rgb(200, 150, 255) Alice-&gt;&gt;+John: John, can you hear me? John--&gt;&gt;-Alice: Hi Alice, I can hear you! end John--&gt;&gt;-Alice: I feel great! end Alice -&gt;&gt;+ John: Did you want to go to the game tonight? John --&gt;&gt;- Alice: Yeah! See you there. sequenceDiagram participant C as Client participant S as Server autonumber note left of C: 选择初始seq number=x&lt;br/&gt;发送客户端的TCP SYN段 C-&gt;&gt;S:SYNbit=1,Seq=X note right of S:选择初始seq number=y&lt;br/&gt;发送服务端TCP SYN信息&lt;br/&gt;利用SYN+1作为回复 S-&gt;&gt;C:SYNbit=1,Seq=Y&lt;br/&gt;ACKbit=1,ACKnum=x+1 note left of C:收到SYNACK(x),确认服务器存在&lt;br/&gt;发送ACK回复SYNACK&lt;br/&gt;不包含client-to-server数据 C-&gt;&gt;S:ACKbit=1,ACKnum=y+1 note right of S:收到 ACK(y)&lt;br/&gt;确认用户存在 https://zhuanlan.zhihu.com/p/53374516 0x04 GitGraph gitGraph commit id: &quot;Set up folder&quot; branch release branch development checkout development commit branch feature01 commit id:&quot;feature1 add&quot; commit id:&quot;feature1 add2&quot; checkout development branch feature02 commit id:&quot;fixed feature2&quot; checkout development merge feature02 commit id:&quot;feature1 add3&quot; checkout development merge feature01 commit checkout main merge development tag:&quot;Beta1.0&quot; checkout release merge main tag:&quot;V1.0&quot;","categories":[{"name":"Baseline","slug":"Baseline","permalink":"https://blog.tjdata.site/categories/Baseline/"}],"tags":[{"name":"chart","slug":"chart","permalink":"https://blog.tjdata.site/tags/chart/"}]},{"title":"GIT管理和常见操作","slug":"GIT管理和常见操作","date":"2023-05-09T07:24:09.000Z","updated":"2023-05-13T13:48:46.048Z","comments":true,"path":"posts/cd758988.html","link":"","permalink":"https://blog.tjdata.site/posts/cd758988.html","excerpt":"从Git - Branches in a Nutshell中看Git的一些常见操作，主要是设计理念和本地的操作。更复杂的远程协作和项目管理后续给出。","text":"从Git - Branches in a Nutshell中看Git的一些常见操作，主要是设计理念和本地的操作。更复杂的远程协作和项目管理后续给出。 Git PRO What is git 分布式版本控制系统（具有很多优点巴拉巴拉） 几个显著的技术上的特点： snapshot，not differences，no delta- based system Git thinks of tis data more like a series of a snapshots of a miniature filesystem every time you commit, or save the state of your project, Git basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot. If the data is not changed , Git doesn’t store the file again. Nearly every operation is local you have the entire history of the project right there on your local disk, most operations seem almost instantaneous commit to local copy util you get to a network connection to upload Git has integrity you will see these hash values all over the place in Git because it uses them so much. In fact, Git stores everything in its database not by file name but 40 cahrs Git generally only adds data When you do actions in Git, nearly all over the place in Git because it uses them so much. It is hard to get the system to do anything that is not undoable or to make it erase in any way three state modified staged committed 基本的工作流程可以看作： 修改working directory的文件 当时觉得做的够好之后，add changed to the staging area 将所有暂存区的文件提交，stores that snapshot permanently to your Git directory Getting start —- First time git setup 1234567# git config 存储的三个地方[path]/etc/gitconfig：包含应用于系统上每个用户及其所有存储库的值，如果你讲选项 system传递给它会从专门的文件中读取和写入 ~/.gitconfig 或者 ～/.config/git/config 特定用户个人的库 config 当前存储目录的呃设置 Basic topic 3.1 获取Git仓库 一种方式是将当前不受版本控制的本地目录转换为Git存储库 第二种方式是从其他地方clone现有的Git仓库 3.2 记录更改 12git statusgit status -s # for short 工作目录中每个文件都存在 tracked or untracked 从生命周期来看，文件可以分为untracked、unmodified、modified、staged 💡 Github将默认转换为main、但是git默认依旧是master 同时可以设置gitignore来不希望Git自动添加，甚至限制您未追踪 123456# 常见的gitignore规则1. 忽略空白行或者 #2. 在整个工作目录中递归3. 可以使用正斜杠 / 开始模式4. 可以使用正斜杠 / 结束模式来指定目录5. 可以通过感叹号 ！ 来否定模式 GitHub中维护了一个非常好的示例https://github.com/github/gitignore 仅仅查看更改记录不够，你希望检查更改了哪些东西 12git diff # 查看更改但是未暂存git diff --staged # 查看已经提交下一个阶段的内容，或者-- cached 提交记录 1git commit 从Git中删除文件必须将其从tracked文件中删除，也就是需要从暂存区中删除 123git rmgit rm - cached FILENAME # 将文件保存在目录中，依旧保留在硬盘。但是从暂存区中删除。git mv # 重命名文件 3.3 查看提交的历史记录 上述操作可以完成基本的工作流。在这个基础上，创建很多次提交之后，我们可以使用现有提交历史记录的存储库，回顾一下发生了什么，我们可以使用git log 12345git log # 按照反向时间顺序列出提交的更改。同时也具有大量选项git log -p # 显示每个提交中引入的差异git log --stat # 缩写的统计信息git log --pretty=oneline # 将日志输出更改为默认格式以为的格式git log --pretty=format --graph 3.4 撤销操作 在任何staged，你都困难想撤销一些事情，通过回顾一些基本工具来保存撤销的更改 1git commit -amend # 如果你想重做该提交，请你忘记额外的更改，暂存他们 加入在修改两个文件之后，不小心add * 到暂存区 1234567$ git add *$ git statusOn branch masterChanges to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) modified: CONTRIBUTING.md renamed: README.md -&gt; README 但是只想commit其中的一个，那么需要 1git reset HEAD [filename you not to commit] 注意reset是非常危险的命令，checkout也可以实现 1git checkout --&lt;file&gt; # 对文件所做的任何本地更改都已经消失，替换成为最后一个分阶段或者提交的版本。 在之后常用git restore而不是git reset 1git restore --staged &lt;file&gt; # 取消暂存 3.5 远程操作 origin是Git赋予您克隆的服务器的默认名称 12345git clone [your-git-url]git remote # show your remote git namegit remote -v # 显示存储的URLgit remote add shortname url # git remote add pb &lt;https://github.com/chenxia31/blog&gt;# common line中可以使用short name来代替url 从远程仓库连接 12345git fetch &lt;remote&gt; # 从远程仓库获取数据git push origin master # 推送本地的master分支git remote show origin # 显示一些常见的信息git remote rename [oldname] [newname]git remote remove [url] 3.6 标签 和branch跟踪每次最新的commit 相反，tag是跟踪某一个特定commit的位置，如果不需要改动而仅查看的时候可以直接使用tag。推送到远程服务器需要显式的表达出tagname 1234567891011121314151617git taggit tag -l &#x27;v1.8.5.*&#x27;# 标签分为轻量级和注释git tag -a v1.4 -m &#x27;my version 1.4&#x27;git tag v1.4git push origin [tagname] # git push origin v1.5git push origin --tags# 删除标签git tag -d v1.4 # 但是这样不会从任何远程服务器删除标签git push origin --delete &lt;tagname&gt;# 查看taggit checkout v2.0 #这种会导致仓库处于“分离的HEAD状态“，如果进行更改、创建提交、标签将保持不变 3.7 别名 alias 创建自己snippets 3.8.1 （非常重要）分支模式 1234567891011git add [filename]git commit -m &#x27;message&#x27;#git的默认分支名称是master，只不过很多人懒得改git branch testinggit log --oneline --decorategit checkout testing # 更推荐git switchgit commit -a -m &#x27;new commit&#x27;git checkout mastergit commit -a -m &#x27;new commit2&#x27;git log --oneline -decorate --graph --asll 后序查看一些基本分支和合并的具体操作。想象一个工作流程，在网站上做一些工作，为一个新的故事创建一个分支，之后在另外分支做一些工作。因此可以参考一下的过程 1234567891011121314151617181920git checkout -b [NewBranchName] # git branch and git checkout 缩写# 注意在签出的分支冲突未提交更改，但是可以允许 stashing and cleaning中了解git checkout master # 专注你的主线任务git checkout -b &#x27;newfeature2&#x27;# ~~ newfeature2结束git checkout mastergit merge newfeature2# 删除分支git branch -d hotfix# 处理git checkout NewBranchName# 再次合并git checkout mastergit merge master# 两个合并出现冲突git status #查看# 手动打开文件，处理冲突git mergetool 上述导致已经会创建、合并、删除一些分支，这里还有一些分支管理工具 1234git branch -V # 查看每个分支的最后一次提交git branch --merged or --no-merged# 过滤您已经或尚未合并到您当前使用的分支中的分支git brach --move # 本地重命名分支git push --set-upstream origin main 3.8.2 分支工作流程 已经有branch和merge的基础知识，应该用此做些什么？这里将轻量级分支的常见的工作流程展示，判断是否需要将其纳入自己的开发周期 Git - Branching Workflows 常见的分类包括 master 分支中完全稳定的代码 develop或next 工作中用于测试稳定性，不一定总是稳定的。当它稳定之后可以合并到master proposed 协议更新 topic 短生命周期的分支，用于处理一些简单的feature add 3.8.3 远程分支 [ ] 待定 Git - Remote Branches 3.8.4 分支管理 3.9 Git 服务器 3.10 分布式工作流","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.tjdata.site/tags/git/"}]},{"title":"官方文档_Pandas阅读和感悟","slug":"官方文档_Pandas阅读和感悟","date":"2023-05-07T05:42:41.000Z","updated":"2023-05-13T13:52:06.562Z","comments":true,"path":"posts/9f94980a.html","link":"","permalink":"https://blog.tjdata.site/posts/9f94980a.html","excerpt":"官方文档是开发者对自己代码的解释。对于成熟的框架，官方文档可以最准确、权威的资料。如何阅读英文的官方文档一直是作为Coder weaker和English weaker的心魔，这里以Pandas文档为例子，尝试给出自己对于阅读官方文档、官方文档的查询工具、代码注释和Pandas文档的总结。","text":"官方文档是开发者对自己代码的解释。对于成熟的框架，官方文档可以最准确、权威的资料。如何阅读英文的官方文档一直是作为Coder weaker和English weaker的心魔，这里以Pandas文档为例子，尝试给出自己对于阅读官方文档、官方文档的查询工具、代码注释和Pandas文档的总结。 0x01 Why 阅读官方文档 对于质量比较高的项目，其官方文档往往能反映开发者的最直接的思想，而互联网上经过许多人的编码和解码，导致最后的意思可能和本意相差巨大。虽然可能存在其他更好的教程，但是官方文档给出的思想一定是最准确、权威的。 之前一直不知道GitHub在国内为什么访问这么慢。 在网上找到很多答案，比如修改DNS的、修改Hosts的、修改镜像源或者增加代理的，但其实本质的问题是GitHub.com的域名解析在国内往往需要多层中转进而因为污染等原因造成速度较慢，因此上述方法对应的是修改DNS、本机解析、设置镜像、走代理等多种方法，这些方法都没有错。但是只是给出这些方法会让人不能一览背后的思想而困惑。 0x02 What 官方文档 以Pandas为例子，文档通常可以分为 Getting start：新手教程，一般会教你如何搭建一个简单的应用示例。 User guide：使用教程，介绍技术的关键知识、思想和概念。 API reference：API文档，包括具体的API使用细节以及机制 Developer guide：开发文档 推荐使用 Dash gives your Mac instant offline access to 200+ API documentation sets. 来进行官方API文档的管理。作为一个API文档浏览器(API documentation brower)和代码片段管理（Code snippet manager），可以提供的帮助有 迅速 直接 本地 Alfred协作 当然常见的函数用法可以直接通过命令来获取 12345import module_name #such as import mathhelp(module_name) #模块帮助查询dir(module_name) # 查询模块下所有的函数help(module_name.func_name) #查询具体函数的用法print(func_name.__doc__) # 打印函数的用法 0x03 Pandas 新手教程 首先介绍pandas是什么： Pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real-world data analysis in Python. 其中基本的数据类型可以分为Series和DataFrame两种，基于NumPy构建。新手教程给出常见的Pandas使用的Topic。包括 3.1 创建数据、查看数据、索引数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# Series 一维标记数组，可以容纳各种数据类型(int、float、string、chat、python object)# Pandas 二维标记数据框架，可以看作是一张数据表格，或者是SQL表格# Insight01：Pandas中的数据结构可以看作是ndarray方式的标量（通过index索引），也可以看作是dict方式的字典（可以通过key索引）# Attention01:Pandas数据之间的运算通常是按照元素的，并且是broadcasting的。对于缺失值通常使用numpy.nan填补# 创建数据，可以来自于 1. ndarray、2. dict、3. scalar、4. tuple of dictd = &#123; &quot;one&quot;: pd.Series([1.0, 2.0, 3.0], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]), &quot;two&quot;: pd.Series([1.0, 2.0, 3.0, 4.0], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]),&#125;d = &#123;&quot;one&quot;: [1.0, 2.0, 3.0, 4.0], &quot;two&quot;: [4.0, 3.0, 2.0, 1.0]&#125;pd.DataFrame(d, index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;])data2 = [&#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;, &#123;&quot;a&quot;: 5, &quot;b&quot;: 10, &quot;c&quot;: 20&#125;]pd.DataFrame(data2, index=[&quot;first&quot;, &quot;second&quot;])data3= &#123; (&quot;a&quot;, &quot;b&quot;): &#123;(&quot;A&quot;, &quot;B&quot;): 1, (&quot;A&quot;, &quot;C&quot;): 2&#125;, (&quot;a&quot;, &quot;a&quot;): &#123;(&quot;A&quot;, &quot;C&quot;): 3, (&quot;A&quot;, &quot;B&quot;): 4&#125;, (&quot;a&quot;, &quot;c&quot;): &#123;(&quot;A&quot;, &quot;B&quot;): 5, (&quot;A&quot;, &quot;C&quot;): 6&#125;, (&quot;b&quot;, &quot;a&quot;): &#123;(&quot;A&quot;, &quot;C&quot;): 7, (&quot;A&quot;, &quot;B&quot;): 8&#125;, (&quot;b&quot;, &quot;b&quot;): &#123;(&quot;A&quot;, &quot;D&quot;): 9, (&quot;A&quot;, &quot;B&quot;): 10&#125;, &#125;pd.DataFrame(data3)# 查看数据.head() #查看dataframe的顶部.tail() #查看dataframe的底部.columns().index().to_numpy() #注意这个可能是一个昂贵的操作.describe() # 显示数据的快速摘要.T # 转置df.sort_index(axis=1, ascending=False) #按照轴进行排序df.sort_values(by=&quot;B&quot;)# 更改控制台显示info() # 用于快速显示dataframe信息baseball.info()to_string() # 以表格的形式返回dataframe的字符串表示print(baseball.iloc[-20:, :12].to_string())display.width # 更改单行的打印量pd.set_option(&quot;display.width&quot;, 40) # default is 80pd.set_option(&quot;display.max_colwidth&quot;, 30)pd.DataFrame(np.random.randn(3, 12))# 索引数据# 继承series的索引df[&quot;one&quot;]df[&quot;three&quot;] = df[&quot;one&quot;] * df[&quot;two&quot;]df[&quot;flag&quot;] = df[&quot;one&quot;] &gt; 2del df[&quot;two&quot;]three = df.pop(&quot;three&quot;)df[&quot;foo&quot;] = &quot;bar&quot; #自动broadcastingdf[&quot;one_trunc&quot;] = df[&quot;one&quot;][:2] # 自动符合indexdf.insert(1, &quot;bar&quot;, df[&quot;one&quot;])# assign() 始终返回数据的副本，但是原始的dataframe并不会修改iris.assign(sepal_ratio=lambda x: (x[&quot;SepalWidth&quot;] / x[&quot;SepalLength&quot;])).head()df.loc #根据标签选择df.iloc #根据下标选择df[5:10] # 切片行df[bool] # 切片行 3.2 数据缺失处理、运算函数 12345678910111213141516171819np.nan #表示丢失的数据类型df.reindex() # 允许更改、添加和删除指定轴上的索引，同时返回数据副本df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [&quot;E&quot;])df1.loc[dates[0] : dates[1], &quot;E&quot;] = 1df.dropna() # 删除任何缺少数据的行df.fillna() # 填充确实的数据isna() #获取值是否为nan默认按照broadcasting进行计算df.mean() # 计算平均值df.mean(1) # 另外一个方向df.apply() # 将用户自定义的函数应用于数据df.apply(np.cumsum)df.apply(lambda x: x.max() - x.min())values_count()df.str.ufunc() # 在str属性下，可以调用需要其他的字符串 3.3 集合之间的处理：合并、分组、重塑和多索引 1234567pd.concat([df1,df2,df3]) # 按照axis进行合并，join参数为outer或者inner，ignore_inde重建索引pd.merge(df1,df2,key) # 类似SQL中的连接，可以根据一个或者多个键将不同的dataframe连接起来pd.join() # 用于key的合并df.groupby(&quot;A&quot;)[[&quot;C&quot;, &quot;D&quot;]].sum() # 类似SQL中的group by# 重塑和多索引看不懂～ 3.4时间序列处理函数专题 12345resample() #将第二列数据转换成5min，有点意思series.tz_localize() # 将时间序列转换成为本地时区series.tz_convert() # 将时区感知时间序列转换成为另一个时区.to_period() # 转换成为时间跨度.to_timestamp() # 转换成为时间戳 0x04 Pandas 用户教程 在用户教程中，Pandas提供了一些更加细致的专题。这里只给出有趣的话题 4.1 数据结构简介 intro to data structure 和第三章的类似 4.2 关键基础函数 essential basic functionality Attention02:对于dataframe的操作可以三个维度：元素的维度、行或者列的维度、整个DataFrame的维度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# 查看.head().tail().shape.index.columns.to_numpy().array()# Attention03:更加推荐使用这两个，而不是使用values来索引。因为dataframe中常见的操作包括扩展类型，或者不同类型，使用values可能会出现性能上的问题# 运算（elementLevel）df1 &gt; df2df1*df2df1+df2# 二维运算，这里需要重视 1.高维和低维之间存在broadcasting 2.计算中数据丢失的情况.add() # 相加，可以设置axis函数.sub() # 相减，可以设置axis.mul() # 相乘，可以设置axis.div() # 相除，可以设置axis.radd().rsub().divmod() # 商，和余# 缺失值操作fill_value=0 #可选参数.fill_na() #利用函数填补# 二进制比较方法 eq ne lt qt le ge# 布尔运算符号.empty() # 测试对象是否为空.all() # 测试并.any() # 测试或.bool() # 测试单个元素#Attention 04：不可以使用 if df:...，这样不符合布尔逻辑# 描述性分析sum()mean()quantile()cumsum()cumprod()describe()idxmin() # 寻找最小值下标 argminidxmax() # 寻找最大值下标 argmaxres=df.value_counts()mode()# discretization and quantilingcut() #基于值的binqcut() #基于分位数的bin# 函数应用：pipeline(),apply(),applymap(); 聚合函数agg() and transform()# 尝试想象一下如何新增两个列def extractCityName(df): df[&#x27;cityName&#x27;]=df[&#x27;cityAndCode&#x27;].str.aplit(&quot;,&quot;).str.get(0) return dfdef addCountryName(df,countryName=None): col=&#x27;cityName&#x27; df[&#x27;cityAndCounty&#x27;]=df[col]+countryNamedf_p=pd.Dataframe(&#123;&#x27;cityAndCode&#x27;:[&#x27;chicago&#x27;,&#x27;IL&#x27;]&#125;)# 现在可以有两种方式来新增心得countryNameaddCounryName(extractCityName(df_p),country_name=&#x27;US&#x27;)#法1df_p.pipeline(extractCityName).pipe(addCountryName,countryName=&#x27;US&#x27;)#法2:或者使用pipeline# 重索引 reindex# 迭代 iterationfor label,ser in df.items(): print(label) print(ser)for row_index,row in df.iterrows(): print(row)for row in df.itertuples(): print(row)# 排序访问.sort_index().sort_values() 4.5 索引和选择数据 Indexing and selecting data 和新手教程差不多 4.6 多重下标和高级索引 MultiIndex and advanced indexing 和新手教程差不多 4.6.5 Merge、join、concatenate、compare 和SQL教程差不多 4.7 重塑和数据透视表 12345678910111213141516# pivot() 来按照元素进行堆叠,可以选择stack或者unstack date variable value0 2000-01-03 A 0.4691121 2000-01-04 A -0.2828632 2000-01-05 A -1.5090593 2000-01-03 B -1.1356324 2000-01-04 B 1.2121125 2000-01-05 B -0.1732156 2000-01-03 C 0.1192097 2000-01-04 C -1.0442368 2000-01-05 C -0.8618499 2000-01-03 D -2.10456910 2000-01-04 D -0.49492911 2000-01-05 D 1.071804pivoted = df.pivot(index=&quot;date&quot;, columns=&quot;variable&quot;, values=&quot;value&quot;) 剩余的太理论了～ 0x05 心得 文档很多，但是其中给出开发者的default的选项，可以提高对其的理解。","categories":[{"name":"Baseline","slug":"Baseline","permalink":"https://blog.tjdata.site/categories/Baseline/"}],"tags":[{"name":"pandas","slug":"pandas","permalink":"https://blog.tjdata.site/tags/pandas/"}]},{"title":"macOS使用技巧_预览Preview","slug":"macOS使用技巧_预览Preview","date":"2023-05-04T05:39:12.000Z","updated":"2023-05-13T13:49:54.370Z","comments":true,"path":"posts/de0c5bf1.html","link":"","permalink":"https://blog.tjdata.site/posts/de0c5bf1.html","excerpt":"预览Preview","text":"预览Preview 在M系列的mac上，预览的可以将扫描的PDF中的文字转换成为可编辑状态。转换时间大概200页的PDF需要5分钟～ export就会有下列选项","categories":[{"name":"Memo","slug":"Memo","permalink":"https://blog.tjdata.site/categories/Memo/"}],"tags":[{"name":"使用技巧","slug":"使用技巧","permalink":"https://blog.tjdata.site/tags/%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"}]},{"title":"CS229-10-problemSet01","slug":"CS229-10-problemSet01","date":"2023-01-10T01:03:17.000Z","updated":"2023-05-13T13:47:47.454Z","comments":true,"path":"posts/7b309918.html","link":"","permalink":"https://blog.tjdata.site/posts/7b309918.html","excerpt":"Problem set00 是关于线性代数和多元微积分学的基本知识，Problem set 01主要是监督学习。作业要求最好使用LaTex进行编写，同时需要将library保存到environment.yml文件中，并保证run.py脚本可以正常运行。","text":"Problem set00 是关于线性代数和多元微积分学的基本知识，Problem set 01主要是监督学习。作业要求最好使用LaTex进行编写，同时需要将library保存到environment.yml文件中，并保证run.py脚本可以正常运行。 0x01 线性分类（逻辑回归和广义线性模型） 1.1 问题回顾 Linear classifiers ( logistic regression and GDA) 在本次作业中将回顾之前的概率线性分类器， 判别线性分类 (discriminative linear classifier) ：逻辑回归 生成线性分类 （generative linear classifier）：高斯判别模型 两者均可以将一个数据集分成两类，但是基于不同的假设，本次问题的目的是找到两者的相同点和差异。 1.2 实际问题 注意Hessian矩阵为PSD，则说明损失函数是凸（convex）的，也就是存在极值点 p(y∣x,theta)=p(y,x,theta)/p(x,theta)=p(x,theta∣y)p(y)/p(x,theta)p(y|x,theta)=p(y,x,theta)/p(x,theta)=p(x,theta|y)p(y)/p(x,theta) p(y∣x,theta)=p(y,x,theta)/p(x,theta)=p(x,theta∣y)p(y)/p(x,theta) 1.3 问题求解 由于公式较多，只能给出思路 （1） 展开求导就能发现是大于0 （2）coding就完事了，numpy的MATLAB的矩阵计算方式 （3）GDA按照贝叶斯展开就行了 （4） 发现是相同的 （5）（6）（7）（8）是一些可视化的东西 0x02 不完整、只有正标签：Incomplete，Positive- only labels 2.1 问题回顾 假设在我们没有得到完整的标签的情况下的，只能确定性得到部分的正样本，而不能得到其他样本的标签。也就是所有负样本和剩余的正样本是没有标签的。 这道题的问题设置更像是一种引导，如何理解这种情况下如何构建模型 2.2 问题 后续是那个coding problem 2.3 问题解答 （1） 简单随机样本抽样 0x03 泊松分布的拟合 重新回归GLM中的三个基本假设： 本重新认识到： 第一个assumption给出了y的分布！这可以用来计算似然函数 第二个assumption给出如何确定hypothesis，也就是模型 第三个assumption似乎是人们设计好的，这样我们才能对一些线性模型做假设 0x04 广义线性模型的convex相关的研究 太理论了看不下去～ 0x05 加权线性回归 除了 利用gradient descent求解，也可以使用normal equation来进行参数的求解；非常的奇妙！ 注意这部分和后面的attention有关系 后面的公式太多了不想打， 0x06 感悟 动手才能发现学习的问题所在，动手才能知道代码应该如何实践！ 对于现实世界的抽象可以帮助我们进一步学习和研究，虽然矩阵的定义很简单，但是只有在这个抽象定义的基础上才能发展出线性代数这门学科，才能用此解决问题。","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"CS229-10-problemSet00","slug":"CS229-10-problemSet00","date":"2023-01-09T02:11:12.000Z","updated":"2023-05-13T13:47:43.837Z","comments":true,"path":"posts/c37a98e.html","link":"","permalink":"https://blog.tjdata.site/posts/c37a98e.html","excerpt":"CS229的homework之前一直没有写，趁这个寒假结束掉它！如有错误欢迎指正！","text":"CS229的homework之前一直没有写，趁这个寒假结束掉它！如有错误欢迎指正！ 0x01 Gradients and Hessians：求导和海森矩阵 1.1 定义回顾 Symmetric: 对称矩阵 1.2 问题 1.3 解答 (1)∇f(x)=Ax+b(1)\\nabla f(x)=Ax+b (1)∇f(x)=Ax+b (2)∇f(x)=g′(h(x))∇h(x)(2)\\nabla f(x)=g&#x27;(h(x)) \\nabla h(x) (2)∇f(x)=g​′​​(h(x))∇h(x) (3)∇2f(x)=AT=A(3)\\nabla^2f(x)=A^T=A (3)∇​2​​f(x)=A​T​​=A (4)∇2f(x)=g′′(aTx)aTa(4) \\nabla^2 f(x)=g&#x27;&#x27;(a^Tx)a^Ta (4)∇​2​​f(x)=g​′′​​(a​T​​x)a​T​​a 0x02 Positive definite matrices : 正定矩阵 2.1 定义回顾 positive semi-definite(PSD): 半正定矩阵 positive definite: 正定矩阵，eg：单位阵 Null-space: 核，表示一个算子的零空间是方程AV=0AV=0AV=0的所有解vvv的集合 Rank: 矩阵A的列秩是A线性无关的纵列的极大数目；可以用于计算线性方程组解的树木、也可以用来确定线性系统是否为可控制的、可观察的 2.2 问题 2.3 解答 (a) A^T=(zz^T)=z^Tz=zz^T=A\\\\x^Tzz^Tx=(x^Tz)(x^Tz)^T \\geq0 (b) Null（A）=\\{x \\in Z;Ax=0\\} 两边同时乘xTx^Tx​T​​ xTzzTx=(zTx)T(zTx)=0x^Tzz^Tx=(z^Tx)^T(z^Tx)=0 x​T​​zz​T​​x=(z​T​​x)​T​​(z​T​​x)=0 可以化简为 Null(A)=Null(z)=x∈z,zx=0Null(A)=Null(z)={x \\in z, z^x=0} Null(A)=Null(z)=x∈z,z​x​​=0 因为Rank(z)≤1Rank(z) \\leq 1Rank(z)≤1,但是z非零;结合Null(A)=Null(z)Null(A)=Null(z)Null(A)=Null(z) R(A)=R(z)=1R(A)=R(z)=1 R(A)=R(z)=1 (c)(c) (c) 结合A的PSD特点可以证明，略 0x03 Eigenvectors，eigenvalues，spectral theorem：特征向量、特征值、谱定理 3.1 定义回顾 Eigenvectors &amp; Eigenvalues：特征值和特征向量 求解pA(λ)=det(λI−A)p_A(\\lambda)=det(\\lambda I-A)p​A​​(λ)=det(λI−A)或者Ax=λxAx=\\lambda xAx=λx之间的关系 Diagonal matrix：对角矩阵，可以用det(d1,d2,...)det(d1,d2,...)det(d1,d2,...)表示 Orthogonal：正交矩阵 Spectral theorem：谱定理 3.2 问题 3.3 解读 (a)(a) (a) 两边同乘逆 AT=TΛAT=T\\Lambda AT=TΛ 又Λ=diag(λ1,...,λn)\\Lambda=diag(\\lambda_1,...,\\lambda_n)Λ=diag(λ​1​​,...,λ​n​​) At(i)=λit(i)At^{(i)}=\\lambda_it^{(i)} At​(i)​​=λ​i​​t​(i)​​ 所以特征值对应的向量为(λi,t(i))(\\lambda_i,t^{(i)})(λ​i​​,t​(i)​​) (b)(b) (b) 因为A是对称矩阵，U为正交矩阵，同时 AU=ΛUAU=\\Lambda U AU=ΛU 所以同上 $$Au{(i)}=\\lambda_iu{(i)}$$ (c)$$ 根据谱定理可以得到 $$\\Lambda=U^TAU \\geq 0 因此大于等于0","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"Paper04_Combining_Reinforcement_Learning_and Constraint_Programming_for_Combinatorial Optimization","slug":"Paper04_Combining_Reinforcement_Learning_and   Constraint_Programming_for_Combinatorial Optimization","date":"2022-12-18T07:49:13.000Z","updated":"2023-05-13T13:50:37.602Z","comments":true,"path":"posts/bbefc8de.html","link":"","permalink":"https://blog.tjdata.site/posts/bbefc8de.html","excerpt":"摘要","text":"摘要 https://arxiv.org/abs/2006.01610 Abstract Combinatorial Optimization 应用广泛：从航空领域、交通规划甚至到经济学中，它的目标是在有限的解空间中找到最优解（find an optimal solution among a finite set of possibilities），其面临的最严重的挑战为Q-state-action方法 中提到的 状态空间爆炸（State- space explosion problem）：问题的解空间岁问题规模增大成指数型的增大，导致对于一些大型的问题难以求解；另一方面DRL（deep reinforcement learning）在求解NP-hard 组合优化问题过程对设计好的启发式求解算法具有比较好的贡献，但是现有的方法具有两个缺点 他们仅仅专注于标准的TSP问题，不容易拓展到其他问题 通常只给出一种近似解（approximate solution），而没有给出一种系统的方法来提高或者证明它的最优性（Optimality） 在另外一种情况下，Constraint programming 是解决组合优化问题的通用工具，基于一个完整的搜索过程，通常可以在比较大的运行时间中找到最优解。其中决定性的确定搜索的方向，或者说分枝策略，或者说是探索策略。 在本文中我们提出一种通用和混合的方法（l）的方法，结合CP和DRL来求解COP，主要是基于运筹学Part01–dynamic programming 作为两者之间的桥梁，并通过实验来证明求解器在两个有挑战性的问题上进行求解：TSPTW the traveling salesman problem with time windows 和 4POP 4-moments portfolio optimization problem,实时证明比一些单独的RL或者利用通用求解器效果更好 Brief Conclusion P：具有多项式时间算法，算得很快的问题 NP：不确定需要多长时间，但是我们验证它只需要多项式时间 NP- complete：属于NP问题，同时也属于NP-hard问题 NP-hard：比NP问题都要难的问题 NP问题 指的是非确定性多项式问题（non- deterministic polynomial NP），非确定性指的是可用一定数量的运算去解决多项式时间内可解决的问题，通常解决问题包括：TSP、Hamilton回路问题、最大团问题；但是其可以在多项式时间内可以被验证其正确定的问题 NP-hard问题 指的是non- deterministic polynomial time hardness，如果所有的NP问题都可以在多项式时间规约到某个问题，则称这个问题为NP困难 Introduction 在组合优化中大多数问题为NP-hard问题，对其高效的优化算法的探索由来已久。广泛的可以将其分为两种方法 精确算法 exact algorithm 是基于对求解空间的完整并且巧妙的枚举，它的优点是可以选招到最优解，但是在对于一些大型的案例中往往会出现求解时间扩大。但也有另外的说法可以让精确算法在找到最优解之前就终止的方式来探索得到次优解。这种灵活性让精确求解算法更加appealing并且practical，也正是如此构成了现代求解器的核心 CPLEX、Gurobi、Gecode等等。这是一个CP的介绍，通过additional asset 用来求解非常大的复杂性的COP问题，通常混合整数规划mixed integer programming MIP 求解器往往只能求解线性问题或者有限的非线形问题。 Handbook of Constraint Programming 而在利用CP进行求解的过程中重要的是branching strategy，非常自然的，好的设计的启发式的探索方法可以很好的发现求解，但是差的启发式分枝策略往往会导致进入没有解的子空间。所以在CP求解问题中br分枝策略的研究是非常热门的话题 启发式算法 heuristic algorithm 是一种非完全的手段来求解得到最终解，但是不能证明解的最优性。他们通常需要特定子问题的知识才能构建他们。在近几年，Lecture01 Deep Reinforcement Learning, Decision Making,and Control 在对一些NP-hard的COP问题的近似求解中取得了非常好的成果。只要一个模型训练好，在实践中的运行时间是可以忽略不计的，利用DRL求解问题的前提是 我们知道实际问题的例子分布 我们有足够多的样本，并可以从中采样来训练模型 但是现有的DRL在COP应用中存在的一些问题表阔 仅限于求解特定的问题，比如TSP 其次，它们仅旨在充当建设性的启发式方法，并且与完整的方法（例如CP）不同，没有系统的方法来改进所获得的解决方案。 上述的精确算法 exact algorithm 和基于学习的启发式算法 heuristic algorithm 都具有好处和坏处，很自然的就有一个问题 我们是否可以将他们的优点联合起来来求解COP 在本文中我们成果将RL与CP利用运筹学Part01–dynamic programming 结合起来，动态规划在很多场合中都具有很成果的作用，是一种非常关键的建模COP问题的方法，简单来说DP问题将一个问题分解成为子问题并通过递归公式（recursive formulation，比如常见的bellman equation结合起来），其中DP面临的苦难常常是 维度灾难问题：生成的子问题的数量呈指数级增长，以至于将它们全部存储在内存中变得不可行。 据我们所知是第一次在CP求解器中内置可学习的启发式探索，详细的贡献如下： 对于COP问题新的DP编码方式来利用RL求解和CP模型 利用两种常见的RL模型，DQL、PPO，训练数据集是从问题中随机抽样得到的 与现有的CP求解过程中分枝策结合，形成三种 brand and bound \\ iterative limited discrpancy search and restart based search三种 给出有意义的结果 代码开源，为了简化后续研究的进程 通常如果没有内在的假设，比如线形和凸性，DP不能简单的编码然后利用标准的MIP方法求解，这也是驱动我们思考尝试使用CP进行编码的原因之一 下一章给出混合整数求解器求解的过程 对两个案例进行实验分析 最后给出总结 2 数据表征 这一部分总结我们提出的完整的框架，一个概括性的框架图在图一中展示，分为三个部分： 学习部分，利用随机生成的例子通过unifying representation作为RL的环境进行训练，最终训练的智能体是对求解过程中search的启发式分枝策略进行基于价值的选择（或者说是强化学习的探索） 求解部分，利用CP对模型进行求解，同时对求解的案例进行评估 联合表示阶段，讲输入的COP问题，结合Dominance pruning rules剪枝策略得到动态规划模型的建模，这样可以作为学习阶段的环境，也可以作为求解节点的输入模型 绿色表示我们的原创共享，蓝色表示已经有的框架 2.1 动态规划模型 动态规划模型是一种将数学建模与计算机编程联系起来求解复杂优化问题的手段，简单来说是将一个大的问题转换成很多小的子问题然后将他们利用recursive formulation的方式联系起来最终求解，其中包括的一些关键的影响因素 Q COP问题 controls C domain D transition T states S stage reward R validity conditions V dominance rules P 其中validity conditions 和dominance rules之间的区别在于两者之间的区别在于，有效性条件是强制性的，以确保DP模型的正确性（V （s， x） = 0 ⇔ T（s， x） = ⊥），而优势规则仅用于效率目的（P（s， x） = 0 ⇒ T（s， x） = ⊥），其中⇔、⇒和⊥表示等价性、含义、 和不可行的状态，分别。其中DP建模可以包括 S，X，T，R，V，P；根据贝尔曼方程我们可以一直计算到开头的状态的价值。 但是DP收到curse of dimensionality的影响，在解决大的状态或者动作空间下需要的内存很多，一种方法是对其进行剪枝处理，其中需要评估 此问题的部分解决方案是修剪主导操作 （P（s， x） = 0）。如果一个动作根据递归公式是有效的，那么它就是主导的，但（1）要么严格地比另一个动作差，要么（2）它不能导致可行的解决方案。在实践中，修剪这些主导操作会对搜索空间的大小产生巨大影响，但是在实践过程中找到这样的求解方案并不是容易的 而且就算在DP过程中对上述的子问题进行修建之后仍不能确保解空间足够小 2.2 强化学习编码 从DP问题中，结合一个实际COP问题可以定义一个强化学习过程，这里有一个关于强化学习的概述 介绍强化学习的作用： 介绍一个基本的过程 2.2.1 State 对于DP问题中不同的阶段，我们可以使用（Q，s_i）作为当前状态的定义，通常状态被embed一种张量作为神经网络的输入，也包括action，最终输出是最优的动作 2.2.2 Action 给定一个DP问题中的state，其中包括一种一对一关系的，aia_ia​i​​可以被采用除非xix_ix​i​​是有效的，通常可行的动作可以由domain和valid进行判断 2.2.3 Transition 输入当前状态和侗族哦，我们就可以使用DP问题来进行转换就行 2.2.4 Reward 最初的想法是使用DP问题中存在的奖励，但是这样可能会存在没有解的轨迹奖励要高于有解方案的奖励，因此在设计奖励的需要考虑COP问题中存在的两个原则 1， 如果e1比e2更坏，我们需要e1的奖励小于e2的奖励 所有找到可行解的轨迹需要比没有找到可行解的轨迹高 R(s,a)=ϕ(1+∣UB(Qp)∣+r(s,a)R(s,a)=\\phi(1+|UB(Q_p)|+r(s,a) R(s,a)=ϕ(1+∣UB(Q​p​​)∣+r(s,a) UB对应规划问题可能到达的上限，第二个问题强迫智能体去寻找到最佳的可行解，最终的scaling factor 防止最终奖励落入零值周边 2.3 学习方法 DQN PPO 有一个非常重要的假设，利用生成器得到instance的时候，得到的分布与实际问题中的问题想等，这也是在RL解决其他问题中常见的假设，强化学习的过程是希望学习出不同状态和动作下得到不同的Q，我们的策略往往是采用最大Q值的东西，利用DQN得到Q值的训练过程有 12345# Trainer——DQN（）# class Env，# class BrainDQN# class TSPTW# class state 展现代码的调用过程 这一步仅仅是希望训练出DQN的brain，而没有其他的东西 重点在环境生成，以及训练的整个过程 首先确保如何生成一个TSPTW问题 之后生成多个作为训练的集合 同时在每次训练中提高 2.4 网络框架 为了确保框架的通用型和有效性，对于网络框架我们需要确保两件事情 对于相同的COP问题，可以有不同的输入尺寸 对输入的排列保持不变 为了保证这样的架构我们通常会使用一种Transformer架构，对于TSP问题天然的我们可以采用GAT的方式来实现序列到序列的转换 对于DQN网络中最后一层的输入是不同动作对应的Q- value 2.5 CP Encoding 现在介绍如何将DP过程编码放入Constraint model CP DP variable and domains X- decision variables，set of the variables，表示动作 X X-auxiliary variables，表示state S D，set of the domain V C，set of the constraints P O，objective function 在后面N阶段中的最大值，这里的动态规划方向仅仅和x_a有关 2.6 搜索策略 与DP方式相同，我们用此来构建RL的环境（并固定CO问题）来得到动作的输出，框架的统一性是问题的核心，这一部分展示我们如何将学习的模型嵌入到CP搜索中，我们考虑几种常见的搜索方式 Depth-first branch-and-bound search iterative limited discrepancy search restart based search 这里仅介绍第一种搜索策略与DQN的结合，DFS确保了当一个可行解找到之后，下一个解需要好与当前的，当遇到没有可行的分支会回溯到之前的分支，由此来确保整个解空间都得到遍历，同时最终得到的解可以被证明是最优的optimal，这个过程中需要非常好的value- selection 在学习之后，DQN的作用是输入当前的状态，以及可行的动作，输入不同动作的最大值，这里可以贪心搜索的方式进行下去，尽管可能不是最优的，需要保证和DP问题中存在的一致性，通常这里会有一些近似变量来作为对DP问题的关键影响，但是这里不是重点 整个过程如下表所示⬇️ 3 Experimental result TSPTW是从传统的TSP问题中得到的，只是给所有的salesman增加一个时间窗的概念，最终规定需要在规定时间内沿着所有的节点走一圈。 Vehicle Routing Problem with Time Windows | OR-Tools | Google Developers 最终证明了结果 4 Discussion and Limitation 首先本文并不是第一个尝试使用ML来引导优化求解器的分支，但是他们的方法专注于监督学习并且仅限于线性问题，这里本文的共享 关注与将COP问题建模成为DP 完全利用RL进行训练 同时结合CP问题的完整性，可以更好的求解一系列问题包括非线性约束或者非线性约束函数 同时我们也不需要一些历史数据或者仿真生成器，同时是一种端到端的求解器，并且可以证明求解结果的最优性 5 Conclusion 这些结果表明，该框架可能是解决具有挑战性的组合优化问题的一种有前途的新途径。 1 总结的ppt","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"paper","slug":"paper","permalink":"https://blog.tjdata.site/tags/paper/"}]},{"title":"Paper03_Rainbow_Combining_Improvements_in_Deep_Reinforcement_Learning","slug":"Paper03_Rainbow_Combining_Improvements_in_Deep_Reinforcement_Learning","date":"2022-11-06T10:38:36.000Z","updated":"2023-05-13T13:50:20.683Z","comments":true,"path":"posts/d590ba5e.html","link":"","permalink":"https://blog.tjdata.site/posts/d590ba5e.html","excerpt":"作者：Hessel, M., Modayil, J., Van Hasselt, H., Schaul, T., Ostrovski, G., Dabney, W., … &amp; Silver, D. 实验室：Google DeepMind 论文地址：https://arxiv.org/pdf/1710.02298 发表： In Thirty-second AAAI conference on artificial intelligence.","text":"作者：Hessel, M., Modayil, J., Van Hasselt, H., Schaul, T., Ostrovski, G., Dabney, W., … &amp; Silver, D. 实验室：Google DeepMind 论文地址：https://arxiv.org/pdf/1710.02298 发表： In Thirty-second AAAI conference on artificial intelligence. 0x01 摘要 1.1 摘要–背景及问题 从DQN1推导过程中发现依旧存在很多问题，常见的改进措施Double DQN2、Dueling DQN3、Prioritized replay4、Multi-step5、Distributional RL6、Noisy Net7等方法，这些方法并不是完全独立，比如在Dueling中其实已经将Double DQN和Prioritized replay结合起来。 1.2 摘要–方法 本文希望将上述六种DQN方法结合经验融合在一起，来得到一个更好的网络。 1.3 摘要–贡献 成为Atari 2600中SOTA 我们还提供详细的消融研究的结果，该研究结果显示了每个组件对整体性能的贡献。 0x02 问题背景 2.1 RL problem &amp; 记号 强化学习希望一个具有行为（action)的智能体(agent) 在与环境(environment)交互的过程可以最大化奖励(reward),在这个过程中并不会直接监督式的学习。这里分享另外一种定义: 一、Mathematical formalism for learning- based decision making 二、Approach for learning decision making and control form experience **MDP (Markov Decision Process) {S,A,T,r,γ}\\{S,A,T,r,\\gamma\\}{S,A,T,r,γ} ** 在不同的时间步下t=0,1,2,..t=0,1,2,..t=0,1,2,..，环境状态StS_tS​t​​提供给智能体一个观测信息OtO_tO​t​​,通常我们会认为是完全观测(即St=OtS_t=O_tS​t​​=O​t​​)，同时智能体根据观测信息做出动作AtA_tA​t​​, 之后环境给出下一个奖励Rt+1R_{t+1}R​t+1​​,奖励的折扣γt+1\\gamma_{t+1}γ​t+1​​以及更新状态为St+1S_{t+1}S​t+1​​ 在这个过程通常S,AS,AS,A是有限的情况,对于环境来说状态转移（stochastic transition function)；奖励方程包括 T(s,a,s′)=P[St+1=s′∣St=s,At=a]T(s,a,s&#x27;)=P[S_{t+1=s&#x27;}|S_t=s,A_t=a] T(s,a,s​′​​)=P[S​t+1=s​′​​​​∣S​t​​=s,A​t​​=a] r(s,a)=E[Rt+1∣St=s,At=a]r(s,a)=E[R_{t+1}|S_t=s,A_t=a] r(s,a)=E[R​t+1​​∣S​t​​=s,A​t​​=a] 对于智能体来说，根据状态StS_tS​t​​（或者完全观测下的观测OtO_tO​t​​)得到得到动作AtA_tA​t​​来自于策略π\\piπ（policy),在序列决策中我们的目标是最大化某个状态采取某个动作的折扣奖励之和 P(At=a)=πθ[At=a∣St=s]P(A_t=a)=\\pi_{\\theta}[A_t=a|S_t=s] P(A​t​​=a)=π​θ​​[A​t​​=a∣S​t​​=s] maxGt=Σk=0∞rtkRt+k+1max G_t=\\Sigma_{k=0}^{\\infty}r_t^{k}R_{t+k+1} maxG​t​​=Σ​k=0​∞​​r​t​k​​R​t+k+1​​ 我们在利用算法进行梯度提升通常会经过三个步骤 生成样本 评估模型或者是计算return 提升策略 2.2 Policy Gradient：直接提升policy 为了最大化策略的回报，我们可以直接对GtG_tG​t​​最大化（REINFRORCEMENT），推导过程略 我们可以利用baseline、n-steps、discount、import sampling的方法对他进行改进。 2.3 Actor-Crtic方法：Return与Policy分开 也可以引入新的状态价值函数Vπ(s)V^{\\pi}(s)V​π​​(s)来结合拟合的方式计算GtG_tG​t​​之后最大化(A3C),也可以直接利用 Vπ(s)V^{\\pi}(s)V​π​​(s)和动作状态价值函数Qπ(s,a)Q^{\\pi}(s,a)Q​π​​(s,a)来进行基于价值函数的学习方法。 Vπ(s)=Eπ[Gt∣St=s]V^{\\pi}(s)=E_{\\pi}[G_t|S_t=s] V​π​​(s)=E​π​​[G​t​​∣S​t​​=s] Qπ(s,a)=Eπ[Gt∣St=s,At=a]Q^{\\pi}(s,a)=E_\\pi[G_t|S_t=s,A_t=a] Q​π​​(s,a)=E​π​​[G​t​​∣S​t​​=s,A​t​​=a] 我们可以利用replay buffer、神经网络来学习降低policy gradient中的方差。 2.4 Value- based method 抛弃policy Policy iteration-&gt;Value iteration-&gt;Q learning 首先从policy iteration与value iteration说起，参考链接可以看作是利用动态规划的方式反应强化学习的过程，两者的区别在于反应的是贝尔曼期望还是贝尔曼最优。 在基于价值学习算法的过程中，优点是我们只需要一个经验回放池，只需要(s,a,s′,r)(s,a,s&#x27;,r)(s,a,s​′​​,r)而不是需要完整的决策序列。我们通常会引入随机探索（exploration）的概念，常见的包括ϵ−Greedy\\epsilon-Greedyϵ−Greedy的方法，在一定概率下选择非策略产生的动作。 在 value iteration的基础上，我们可以抛弃对V(s)V(s)V(s)的学习，而只是记录Q(s,a)Q(s,a)Q(s,a);Q- iteration algorithm(或者Q−learningQ- learningQ−learning）看过程如下图所示 2.2 DQN推导 在上述我们认识对于MDP目标，从显式表达Policy，到结合Value function再到之后的完全使用Value function来使用Q- learning的方法，我们没有解决的问题包括 状态-动作空间的连续性 在状态空间和动作空间纬度大的时候无法准确刻画 状态-动作价值 随着神经网络的发展，我们希望利用网络拟合的方式来解决上述问题，同时每一步利用ϵ−Greedy\\epsilon-Greedyϵ−Greedy的方式来探索回放池中的经验，并利用梯度下降等方法最小化价值函数表达的回报 min(Rt+1+γt+1maxa′(St+1,a′)−qθ(St,At))2min (R_{t+1}+\\gamma_{t+1}max_{a&#x27;}(S_{t+1},a&#x27;)-q_{\\theta}(S_t,A_t))^2 min(R​t+1​​+γ​t+1​​max​a​′​​​​(S​t+1​​,a​′​​)−q​θ​​(S​t​​,A​t​​))​2​​ 1 初始化大小为NNN的经验回放池(PS：注意有大小限制) 2 用相同随机的网络参数初始化Qθ(s,a)Q_{\\theta}(s,a)Q​θ​​(s,a)与目标网络Qθ′(s,a)Q_{\\theta&#x27;}(s,a)Q​θ​′​​​​(s,a) 3 for 回合episode=1，N do： 4 获取环境初始状态s1s_1s​1​​ 5 for 时间步numstep=1，T do： 6 根据当前网络at=maxaQθ(s,a)a_t=max_a Q_{\\theta}(s,a)a​t​​=max​a​​Q​θ​​(s,a)结合ϵ−Greedy\\epsilon-Greedyϵ−Greedy方法来得到ata_ta​t​​（PS：注意这一步动作的确定隐含之后DQN回报偏大的特点） 7 执行动作ata_ta​t​​,获取rtr_tr​t​​,环境状态变为st+1s_{t+1}s​t+1​​ 8 存储上述采样信息到经验回放池 9 if 经验回放池数目足够： 10 采样batchsize样本{sti,ati,rti,st+1i}\\{s_t^i,a_t^i,r_t^i,s_{t+1}^i\\}{s​t​i​​,a​t​i​​,r​t​i​​,s​t+1​i​​} 11 计算目标值yti=rti+γ∗maxaQθ^(st+1i,ati)y^i_t=r^i_t+\\gamma*max_aQ_{\\hat \\theta}(s^i_{t+1},a^i_t)y​t​i​​=r​t​i​​+γ∗max​a​​Q​​θ​^​​​​(s​t+1​i​​,a​t​i​​) 12 最小化损失函数L=1N(yti−Qθ(sti,ati))2L=\\frac{1}{N}(y_t^i-Q_{\\theta}(s_t^i,a_t^i))^2L=​N​​1​​(y​t​i​​−Q​θ​​(s​t​i​​,a​t​i​​))​2​​ 13 更新网络参数 14 END FOR 15 更新目标网络参数 16 END FOR 其中非常有趣的技巧包括： 经验回放(Experience Replay )与随机探索;这一部分主要是为了提高样本采样效率，同时降低后续梯度下降中样本的相关性。 目标网络(Target Network)，由于TD误差在策略改变过程中也会改变，因此造成神经网络拟合过程的不稳定性，因此构建新的目标网络，在每次迭代过程中暂时固定，在回合结合后更新参数，这样需要两层Q网络 相关代码实现 0x03 DQN改进 虽然DQN成功让强化学习在某些方面超过人类，但是依旧有这许多限制。 3.1 改进1–Double Q- Learning 在DQN中会有估计值过高的情况，证明如下： target−value:yti=rti+γmaxat+1iQθ^(St+1i,at+1i)target-value:y^i_t=r^i_t+\\gamma max_{a_{t+1}^i}Q_{\\hat \\theta}(S^i_{t+1},a^i_{t+1}) target−value:y​t​i​​=r​t​i​​+γmax​a​t+1​i​​​​Q​​θ​^​​​​(S​t+1​i​​,a​t+1​i​​) maxat+1iQθ^(St+1i,at+1i)=Qθ^(st+1i,argmaxat+1iQθ^(st+1i,at+1i))max_{a_{t+1}^i}Q_{\\hat \\theta}(S^i_{t+1},a^i_{t+1})=Q_{\\hat \\theta}(s_{t+1}^i,argmax_{a_{t+1}^i}Q_{\\hat \\theta}(s_{t+1}^i,a_{t+1}^i)) max​a​t+1​i​​​​Q​​θ​^​​​​(S​t+1​i​​,a​t+1​i​​)=Q​​θ​^​​​​(s​t+1​i​​,argmax​a​t+1​i​​​​Q​​θ​^​​​​(s​t+1​i​​,a​t+1​i​​)) 根据期望公式 E[max(X1,X2)]&gt;max(E(X1),E(X2))E[max(X1,X2)]&gt;max(E(X1),E(X2)) E[max(X1,X2)]&gt;max(E(X1),E(X2)) 我们通过证明发现估计值较大的原因是因为我在模型选择行为和计算Q值使用同一个网络，如果降低行为选择和Q值计算的相关性就可以降低高估，因此直觉的我们可以设计两个网络 QθA(s,a)=r+γQθb(s′,a′)Q_{\\theta_A}(s,a)=r+\\gamma Q_{\\theta_b}(s&#x27;,a&#x27;) Q​θ​A​​​​(s,a)=r+γQ​θ​b​​​​(s​′​​,a​′​​) QθB(s,a)=r+γQθa(s′,a′)Q_{\\theta_B}(s,a)=r+\\gamma Q_{\\theta_a}(s&#x27;,a&#x27;) Q​θ​B​​​​(s,a)=r+γQ​θ​a​​​​(s​′​​,a​′​​) 我们的确可以新加一个网络，但是会增加学习难度，需要重新设计架构。所以为什么不直接使用Qθ(s,a)Q_{\\theta}(s,a)Q​θ​​(s,a)作为行为的估计？ (target−value−double−Q−learning):yti=rti+γQθ^(st+1i,argmaxrt+1iQθ(st+1i,at+1i))(target-value-double-Q-learning):y^i_t=r^i_t+\\gamma Q_{\\hat \\theta}(s^i_{t+1},argmax_{r^i_{t+1}Q_{\\theta}}(s^i_{t+1},a^i_{t+1})) (target−value−double−Q−learning):y​t​i​​=r​t​i​​+γQ​​θ​^​​​​(s​t+1​i​​,argmax​r​t+1​i​​Q​θ​​​​(s​t+1​i​​,a​t+1​i​​)) 3.2 改进2：Prioritized replay 在DQN学习中为高效利用（s，a，r，s）样本，我们会使用经验回放的方式来存储一定规模的样本，在梯度下降的时候通常是从经验回放中均匀采样（uniformly sampling）来进行学习，但是我们依旧会存在两个问题： 依旧没有完全解决数据之间独立同分布的假设 容易忘记一些罕见的、重要的经验数据 在该论文中作者首先制定指标“TD-error”作为衡量(sti,ati,rti,st+1i)(s_t^i,a_t^i,r_t^i,s^i_{t+1})(s​t​i​​,a​t​i​​,r​t​i​​,s​t+1​i​​)的信息量大小，作为采样的优先级，同时利用随机优先级采样、偏置和重要性采样等方式来避免贪心的问题。优先级的获取有3.2.1和3.2.2两种方式 (随机采样)P(i)=\\frac{p_i^\\alpha}{\\Sigma_kP_k^\\alpha} 3.2.1 比例优先级（Proportional prioritization） Pi=∣σi∣+ϵP_i=|\\sigma_i|+\\epsilon P​i​​=∣σ​i​​∣+ϵ 3.2.2 基于排名的优先级(Rank-based prioritization) P_i=\\frac{1}{rank(i)}$$；优点可以保证线性性质，对异常值不敏感。 上述两种是不同得到重要性的方式；在实现时候采用sum-tree的数据结构降低算法复杂程度。在采样中考虑重要性采样（importance sampling），并由此来进行热偏置（Annealing the bias）来修正误差 $$w_j=(\\frac{1}{N}*\\frac{1}{P(i)})^\\beta 3.3 改进3: Dueling networks Dueling DQN是一种针对基于价值函数的强化学习的网络结构设计，其并不直接输出Q(s,a)Q(s,a)Q(s,a)，而是输出V(s)V(s)V(s)与A(s,a)A(s,a)A(s,a),通常会共用前几层的卷积参数，在后面则是状态价值函数与优势函数各自的参数。 3.4 改进4:Multi-step learning 在对状态动作函数的优势估计时候，通常我们会分为蒙特卡洛方法与Bootstrap(或者是Actor- critic内的C)的方法 (MC-sampling)A_t=\\Sigma_{k=0}^{\\infty}\\gamma_t^{k}（R_{t+k+1}-b) (bootstrap−sampling)Gt=rt+γ∗V(st+1)−V(st)(bootstrap-sampling)G_t=r_{t}+\\gamma*V(s_{t+1})-V(s_t) (bootstrap−sampling)G​t​​=r​t​​+γ∗V(s​t+1​​)−V(s​t​​) 前者方法偏差低但是方差较大；后者方差低但是有偏。因此结合两者我们通常会有Multi-step target的方法。 同样的也可以用在DQN中对于状态动作价值函数的估计： Rtn=Σk=0n−1γtkRt+k+1R_t^{n}=\\Sigma_{k=0}^{n-1}\\gamma_t^{k}R_{t+k+1} R​t​n​​=Σ​k=0​n−1​​γ​t​k​​R​t+k+1​​ 更新之后的损失函数为 (Rtn+γtnmaxa′Qθ^(St+n,a′)−Qθ(St,At))2(R_t^{n}+\\gamma_t^nmax_{a&#x27;}Q_{\\hat \\theta}(S_{t+n},a&#x27;)-Q_\\theta(S_t,A_t))^2 (R​t​n​​+γ​t​n​​max​a​′​​​​Q​​θ​^​​​​(S​t+n​​,a​′​​)−Q​θ​​(S​t​​,A​t​​))​2​​ 3.5 改进5:Distributional RL 在基于价值函数的学习中我们通常是返回一个期望或者最大值而丢失很多其他信息，因此Distributional RL尝试利用其分布而不是单个值来进行强化学习。首先本文尝试将价值函数范围[Vmin,Vmax][V_{min},V_{max}][V​min​​,V​max​​]划分为N个各自来估计价值函数，利用Boltzmann分布表示价值函数的分布，同时利用投影的操作 由此对于分布拟合可以划分为交叉熵的形式，算法流程 3.6 改进6：Noisy Nets 在Q- learning或者是DQN中，我们的轨迹并不是完全采样的，而是与我们的探索策略相关，最原本的是ϵ−Greedy\\epsilon-Greedyϵ−Greedy策略，这里提出一种NoisyNet来对参数增加噪声来增加模型的探索能力 y=(Wx+b)+(bnoisy⊙ϵb+Wnoisy⊙ϵw)xy=(Wx+b)+(b_{noisy}\\odot\\epsilon^b+W_{noisy}\\odot\\epsilon^w)x y=(Wx+b)+(b​noisy​​⊙ϵ​b​​+W​noisy​​⊙ϵ​w​​)x 噪声的生成可以分为Independent Gaussian noise；Factorised Gaussian noise两种方式。 3.7 融合上述策略 首先将（改进5:Distributional RL）中的损失函数更换称为（改进4:Multi-step learning），并利用（改进1–Double Q- Learning）计算新的目标值 d_t^n=(R_t^n+r_t^nz,p_\\hat\\theta(S_{t+n},a^*_{t+n})) 损失函数为 DKL(Φzdtn∣∣dt)D_{KL}(\\Phi_zd_t^n||d_t) D​KL​​(Φ​z​​d​t​n​​∣∣d​t​​) 同时在采样过程中我们通常会减少TD-error，而在本文中我们的损失函数为KL损失，因此我们的（改进2：Prioritized replay）中的优先级定义为 pt∝(DKL(Φzdtn∣∣dt))wp_t\\propto (D_{KL}(\\Phi_zd_t^n||d_t))^w p​t​​∝(D​KL​​(Φ​z​​d​t​n​​∣∣d​t​​))​w​​ 同时改变（改进3: Dueling networks）由接受期望转向接受价值函数分布，最后更改所有的线性层更换为（改进6：Noisy Nets） pθ(s,a)i=exp(vηi(ϕ)+aψi(ϕ,a)−a^ψi(s))Σjexp(vηj(ϕ)+aψj(ϕ,a)−a^ψj(s))p_\\theta(s,a)^i=\\frac{exp(v^i_\\eta(\\phi)+a^i_\\psi(\\phi,a)-\\hat a_\\psi^i(s))}{\\Sigma_j exp(v^j_\\eta(\\phi)+a^j_\\psi(\\phi,a)-\\hat a_\\psi^j(s)) } p​θ​​(s,a)​i​​=​Σ​j​​exp(v​η​j​​(ϕ)+a​ψ​j​​(ϕ,a)−​a​^​​​ψ​j​​(s))​​exp(v​η​i​​(ϕ)+a​ψ​i​​(ϕ,a)−​a​^​​​ψ​i​​(s))​​ 0x04 实验 0x05 总结 5.1 结论 rainbow想比较其他现有的算法要更好，速度也会更快 在消融实现中；我们会发现（改进2：Prioritized replay）与（改进4:Multi-step learning）会造成结果中位数大幅度下降;(改进5:Distributional RL)在最开始表现良好，但是最终结果表现较差；同时（改进6：Noisy Nets）通常会有更好的中位数表现，同时由于本次状态中通常是underestimate的，所以（改进1–Double Q- Learning）效果并不显著，（改进3: Dueling networks）提升幅度不大。 5.2 讨论 作者在最后总结他们的工作，主要是从value- based的Q-learning方法集合中寻找，而没有考虑purely policy- based的算法（比如TRPO),本文从网络探索、网络初始化、数据使用、损失或函数等方面进行集合，与之相对应的同样有很多工作，未来还可以用很多其他的方法。但是我们相信 In general, we believe that exposing the real game to the agent is a promising direction for future research. 5.3 个人感悟 这篇论文看上去很水，但其实作者做了很多dirty work并最终有效，工作量非常大！ 【1】Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., &amp; Riedmiller, M. (2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602. 【2】Van Hasselt, H., Guez, A., &amp; Silver, D. (2016, March). Deep reinforcement learning with double q-learning. In Proceedings of the AAAI conference on artificial intelligence (Vol. 30, No. 1). 【3】 Schaul, T., Quan, J., Antonoglou, I., &amp; Silver, D. (2015). Prioritized experience replay. arXiv preprint arXiv:1511.05952. 【4】Multi Step Learning 【5】Wang, Z., Schaul, T., Hessel, M., Hasselt, H., Lanctot, M., &amp; Freitas, N. (2016, June). Dueling network architectures for deep reinforcement learning. In International conference on machine learning (pp. 1995-2003). PMLR. 【6】Bellemare, M. G., Dabney, W., &amp; Munos, R. (2017, July). A distributional perspective on reinforcement learning. In International Conference on Machine Learning (pp. 449-458). PMLR. 【7】Fortunato, M., Azar, M. G., Piot, B., Menick, J., Osband, I., Graves, A., … &amp; Legg, S. (2017). Noisy networks for exploration. arXiv preprint arXiv:1706.10295. 自我介绍 50～100字","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"paper","slug":"paper","permalink":"https://blog.tjdata.site/tags/paper/"}]},{"title":"CS285_Lecture08_Deep_RL_with_QFunctions","slug":"CS285_Lecture08_Deep_RL_with_QFunctions","date":"2022-11-02T14:31:42.000Z","updated":"2023-05-13T13:48:32.952Z","comments":true,"path":"posts/81031871.html","link":"","permalink":"https://blog.tjdata.site/posts/81031871.html","excerpt":"从Policy gradient，到Actor- critic，我们尝试丢弃policy，从AC到Q- iteration或者Q- learning我们彻底丢弃Policy，但是遇到不能收敛的问题。现在我们尝试改进Q- learning来实现想要的功能","text":"从Policy gradient，到Actor- critic，我们尝试丢弃policy，从AC到Q- iteration或者Q- learning我们彻底丢弃Policy，但是遇到不能收敛的问题。现在我们尝试改进Q- learning来实现想要的功能 0x01 Q- learning中的问题 上次从理论的角度看出online Q iteration很难收敛，更直观的看待问题我们会发现有以下几点的原因： Q- learning中通常使用的是单个样本，这样对于更新迭代并不友好 在第三步中的有一个类似gradient descent的公式但是其实在同一个轨迹中两者之间具有强烈相关性 不满足iid假设样本中的效果并不好 解决思路 修正样本，同样借鉴AC中的方法可以使用synchronized parallel Q- learning或者asynchronous parallel Q- learning来实现。 使用replay buffers，因为Q- learning只需要（state，action，next- state，reward）就行 0x02 Q-learning with replay- buffer的问题 按照厂里后面的一部份应该是没有梯度的，但是因为两者具有相关性我们的效果会很差，起不到梯度下降的效果。 因此我们会设置一个target network，在每次更新的时候，target也不会改变，同时这个过程中两者是某种意义上的不想关的。背后的方式是启发式的，但是实际上是一种经验很好的实践方法。通常更新的时候可以用指数平均的方法 τ=pτ0+(1−p)∗τ\\tau=p\\tau_0+(1-p)*\\tau τ=pτ​0​​+(1−p)∗τ 更高的视角 0x03 提高Q-learning 后面结合一篇论文来介绍，也就是Rainbow～","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS285","slug":"CS285","permalink":"https://blog.tjdata.site/tags/CS285/"}]},{"title":"CS285_Lecture07_Value_Function_Methods","slug":"CS285_Lecture07_Value_Function_Methods","date":"2022-11-02T13:40:33.000Z","updated":"2023-05-13T13:48:26.166Z","comments":true,"path":"posts/1e3ff77f.html","link":"","permalink":"https://blog.tjdata.site/posts/1e3ff77f.html","excerpt":"在经过Lecture04介绍RL的基本概念之后，Lecture05介绍基于policy的方法，我们直接利用return的梯度进行策略学习，之后我们尝试利用Q或者V来改进policy evaluation步骤，那么我们是否可以直接抛弃参数化的梯度（parameterized policies），转向仅仅利用Q或者V进行RL","text":"在经过Lecture04介绍RL的基本概念之后，Lecture05介绍基于policy的方法，我们直接利用return的梯度进行策略学习，之后我们尝试利用Q或者V来改进policy evaluation步骤，那么我们是否可以直接抛弃参数化的梯度（parameterized policies），转向仅仅利用Q或者V进行RL 0x01 抛弃Actor- critic中的Actor 1.1 回顾Actor- critic 第一步：我们利用现有的policy得到多个采样轨迹τi\\tau_iτ​i​​ 第二步：利用数据拟合V^ϕπ(s)\\hat V_\\phi^\\pi(s)​V​^​​​ϕ​π​​(s)（常见用蒙特卡洛方法、bootstrapped、n-step等方法） 第三步：评估优势策略A 第四步：根据优势策略得到Actor的梯度 第五步：更新Actor的梯度 但是这样存在的潜在问题是方差太大，因为我们拟合出来的state- value- function方差太大，通常我们会做经验重放等方法，但是并不能完全解决这个问题。 所以为什么我们不直接丢到有参的policy，转向生成一个π∗\\pi*π∗ π∗=argmaxatAπ(st,at)\\pi*=argmax_{a_t}A^\\pi(s_t,a_t) π∗=argmax​a​t​​​​A​π​​(s​t​​,a​t​​) 1.2 Policy Evaluation 在探讨上述可能性我们需要先了解一下policy evaluation的概念；也就是从Dynamic programming的来看我们会如何求解问题；同时从policy evaluation我们会逐渐走向value evaluation。 第一步：首先状态转移概率T是均匀的，那么我们可以在Policy evaluation()中得到每个状态下的Q-state-action-list；求平均来得到V-state-list。当然一次计算不够，我们会设置一个epsilon，当V- state变化的最大值都小于这个epsilon的时候停止更新。说明我们得到所有状态下的V- state 第二步：在得到V- state下我们便能判断什么action是好的，那么我们就利用Q- state- action与V- state之间的关系来选择不同state下的最优action，重新分配概率，也就是policy evaluation 第三步：由于policy evaluation会重新改变空间。V- state也会改变，所以需要重新计算Policy evaluation，直到收敛。 Policy evaluation与Value evaluation之间的区别在于Policy evaluation中根据Q- state- value-list得到V- state-list是求期望，还是求最大值的方式。 (policy−iteration)Vπ(s)=Ea−π(a∣s)[r(s,π(s))+γEs′−p(s′∣s,π(s))[Vπ(s′)]](policy-iteration)V^\\pi(s)=E_{a-\\pi(a|s)}[r(s,\\pi(s))+\\gamma E_{s&#x27;-p(s&#x27;|s,\\pi(s))}[V^\\pi(s&#x27;)]] (policy−iteration)V​π​​(s)=E​a−π(a∣s)​​[r(s,π(s))+γE​s​′​​−p(s​′​​∣s,π(s))​​[V​π​​(s​′​​)]] (value−iteration)Vπ(s)=maxaQ(s,a)=maxa(r(s,a)+γEs′−p(s′∣s,a)[Vπ(s′)])(value-iteration)V^\\pi(s)=max_aQ(s,a)=max_a(r(s,a)+\\gamma E_{s&#x27;-p(s&#x27;|s,a)}[V^\\pi(s&#x27;)]) (value−iteration)V​π​​(s)=max​a​​Q(s,a)=max​a​​(r(s,a)+γE​s​′​​−p(s​′​​∣s,a)​​[V​π​​(s​′​​)]) 这里参考，可以很清晰的看出policy evaluation，以及value evaluation对其做了什么简化 动手学强化学习- Dynamic Programming 0x02 Fitted value iteration and Q- iteration 2.1 我们如何表示state- value- function V(s) 在数量较少的离散中我们可以使用表格或者什么来记录，但是对于连续空间我们可能无能为力。所以我们可以使用神经网络来实现两者的近似，也就是转换为 2.2 仍然有问题 因为在离散状态下，我们需要知道状态概率转移方式。我们会假设一个平均概率再重新分配的方式来更新转移概率。但是在连续情况下虽然我们知道拟合拟合出state- value- function，但是我们还不知道状态转移概率，所以我们求解不出state- value- function 但是为什么我们需要state- function？直接利用state- action- function来取最大值就行 Qπ(s,a)=r(s,a)+γ∗maxa′Qϕ(si′,ai′)Q^\\pi(s,a)=r(s,a)+\\gamma *max_{a&#x27;}Q_\\phi(s_i&#x27;,a_i&#x27;) Q​π​​(s,a)=r(s,a)+γ∗max​a​′​​​​Q​ϕ​​(s​i​′​​,a​i​′​​) 但是这样我们并不能保证收敛性 0x03 Q- learning method 3.1 Q-iteration 的一些性质 它是off- policy的 等价优化bellman error 3.2 Online Q- learning 通常会需要一些exploration ϵ−greedy\\epsilon-greedyϵ−greedy Boltzman exploration 0x04 Value Functions in Theory 我们需要尝试解释之前取最大值的方式是否可以收敛（converge） MDP中的bellman一定是收敛的 在利用近似网络（function approximation）的方式下并不收敛 我们得到一个非常sad corollary，但是在下一张的DQN中可以让它变的更好","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS285","slug":"CS285","permalink":"https://blog.tjdata.site/tags/CS285/"}]},{"title":"CS285_Lecture06_Actor_Critic_Algorithms","slug":"CS285_Lecture06_Actor_Critic_Algorithms","date":"2022-10-30T02:58:38.000Z","updated":"2023-05-13T13:48:19.233Z","comments":true,"path":"posts/d30aca79.html","link":"","permalink":"https://blog.tjdata.site/posts/d30aca79.html","excerpt":"主要介绍演员评论家过程,从最基础的Policy Gradient中剖析如何拟合Policy Evaluation的部分，并推导得到Actor- Critic算法。可以看出从之前直观的Policy，到利用state- value或者action- state- value进行近似。这个过程中采样结果与理论推导的权衡贯穿理论推导过程。在这个基础上也会引来下一节Lecture07关于value function方法。同时突然有个新的想法，并不是所有的代码都需要手撕，baseline is always there！","text":"主要介绍演员评论家过程,从最基础的Policy Gradient中剖析如何拟合Policy Evaluation的部分，并推导得到Actor- Critic算法。可以看出从之前直观的Policy，到利用state- value或者action- state- value进行近似。这个过程中采样结果与理论推导的权衡贯穿理论推导过程。在这个基础上也会引来下一节Lecture07关于value function方法。同时突然有个新的想法，并不是所有的代码都需要手撕，baseline is always there！ 0x01 从策略梯度（Policy Gradient）到评判家（Critic） 1.1 回顾REINFORCE算法 从强化学习的三步范式出发： 第一步：通过运行策略Πθ(at∣st)\\Pi_\\theta(a_t|s_t)Π​θ​​(a​t​​∣s​t​​)得到多个样本{τi}\\{\\tau_i\\}{τ​i​​} 第二步：根据采样样本（Sample）得到策略的梯度 ∇θJ(θ)=1NΣi=1NΣt=1T[∇θlogπθ(ai,t∣si,t)][Σt′=tTr(st′i,at′i)]\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma_{i=1}^N\\Sigma_{t=1}^T [\\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})][\\Sigma_{t&#x27;=t}^Tr(s_{t&#x27;}^i,a_{t&#x27;}^i)] ∇​θ​​J(θ)=​N​​1​​Σ​i=1​N​​Σ​t=1​T​​[∇​θ​​logπ​θ​​(a​i,t​​∣s​i,t​​)][Σ​t​′​​=t​T​​r(s​t​′​​​i​​,a​t​′​​​i​​)] =∇θJ(θ)=1NΣi=1NΣt=1T[∇θlogπθ(ai,t∣si,t)][Q^i,t]=\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma_{i=1}^N\\Sigma_{t=1}^T [\\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})][\\hat Q_{i,t}] =∇​θ​​J(θ)=​N​​1​​Σ​i=1​N​​Σ​t=1​T​​[∇​θ​​logπ​θ​​(a​i,t​​∣s​i,t​​)][​Q​^​​​i,t​​] 第三步：梯度上升 1.2 回顾梯度公式 梯度公式中的log项目在REINFORCEMENT中已经详细推导过，相当于是LIkelihood的一种加权；而后面的Q^i,t\\hat Q_{i,t}​Q​^​​​i,t​​代表的是我们在轨迹τi\\tau_iτ​i​​中时间t中状态si,ts_{i,t}s​i,t​​采取ai,ta_{i,t}a​i,t​​所得到的后续state- action期望奖励（excepted reward）；下面是真实的reward to go，注意和采样时候的区别 （理论state- action-value）Q(s_t,a_t)=\\Sigma_{t'=t}^TE\\pi_\\theta[r(s_{t'},a_{t'})|s_t,a_t] 不要忘记我们的baseline，它可以起到降低方差的作用。我们可以将baseline加到REINFORCEMENT算法中。同时可以设置成为一个与状态有关的值，详细见上一个Lecture （理论state- value）V(s_t)=E_{a_t-\\pi_\\theta(a_t|s_t)}Q(s_t,a_t) 以上是理论的推导 我们在实际采样中往往只能从有限的样本中得到，所以对于某个采样轨迹得到的梯度可以计算为： （采样梯度）\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma_{i=1}^N\\Sigma_{t=1}^T \\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})[Q(s_{i,t},a_{i,t})-V(S_{i,t})] 注意这里的N代表的是总共有i个轨迹，采样和理论之间的区别，更近一步我们可以将：【某个状态下的动作总奖励】减去【某个状态下的所有动作期望】可以定义为这个【特定动作在该状态下的优势】 （理论action- state优势）A^\\pi(s_t,a_t)=Q^\\pi(s_t,a_t)-V^\\pi(s_t) 同样的和我们不知道Q和V一样，我们通常也不知道A的实际价值，但是我们使用近似（approximate）的方法来近似它，也就是我们的estimate return。通常如果我们的采样方式只是单纯的蒙特卡洛采样，我们得到的结果往往是：无偏差但是高方差的简单采样估计。 0x02 梯度评估（Policy Evaluation） 在上述我们可以看到在REINFORCEMENT里面对于policy gradient我们通常是使用【样本中特定的奖励求和】，这样带来的结果是因为我们采样的误差性导致最终结果具有high variance，这种情况下我们可能希望： 为什么不把这个函数拟合出来？------&gt; value function fitting 如果我们希望拟合函数，上述的Q(s,a),V(s),A(a,s)Q(s,a),V(s),A(a,s)Q(s,a),V(s),A(a,s)中会选择哪个函数，可以看到 Qπ(s,a)=Σt′=tTEπθ[r(st′,at′)∣s,a]Q^\\pi(s,a)=\\Sigma_{t&#x27;=t}^TE_{\\pi_\\theta}[r(s_{t&#x27;},a_{t&#x27;})|s,a] Q​π​​(s,a)=Σ​t​′​​=t​T​​E​π​θ​​​​[r(s​t​′​​​​,a​t​′​​​​)∣s,a] 但是由于当前的状态我们知道，所以可以写成 Qπ(s,a)=r(s,a)+Σt′=t+1TEπθ[r(st′,at′)∣s,a]Q^\\pi(s,a)=r(s,a)+\\Sigma_{t&#x27;=t+1}^TE_{\\pi_\\theta}[r(s_{t&#x27;},a_{t&#x27;})|s,a] Q​π​​(s,a)=r(s,a)+Σ​t​′​​=t+1​T​​E​π​θ​​​​[r(s​t​′​​​​,a​t​′​​​​)∣s,a] Qπ(s,a)=r(s,a)+Est+1−p(st+1∣st,at)Vπ(st+1)Q^\\pi(s,a)=r(s,a)+E_{s_{t+1}-p(s_{t+1}|s_t,a_t)V^\\pi(s_{t+1})} Q​π​​(s,a)=r(s,a)+E​s​t+1​​−p(s​t+1​​∣s​t​​,a​t​​)V​π​​(s​t+1​​)​​ 因此我们可以得到在理论情况下原来的policy gradient为 （理论优势）A^\\pi(s_t,a_t)=r(s,a)+E_{s_{t+1}-p(s_{t+1}|s_t,a_t)V^\\pi(s_{t+1})}-V^\\pi(s_t) 在采样情况下 （采样优势）A^\\pi(s_t,a_t)=r(s,a)+V^\\pi(s_{t+1})-V^\\pi(s_t) 2.1 Policy evaluation based on Monte Carlo sampling 我们知道 （理论state- value）V(s_t)=E_{a_t-\\pi_\\theta(a_t|s_t)}Q(s_t,a_t) 所以我们的policy评价就是 (state−action(policy))J(θ)=Es1−pθ(s)[Vπ(s1)](state-action(policy))J(\\theta)=E_{s_1-p_\\theta(s)}[V^\\pi(s_1)] (state−action(policy))J(θ)=E​s​1​​−p​θ​​(s)​​[V​π​​(s​1​​)] 如果我们只是从采样的方式来得到我们的估计，那么 （采样）V^\\pi(s_t)=\\Sigma_{t'=t}^Tr(s_{t'},a_{t'}) 虽然不想理论推导那样的优秀，但是同样是有效的。注意这里的过程是我们从REINFORCEMENT里面单纯的使用采样结果，转向构建一个state- based- function，我们需要做的是根据样本拟合这样的函数。但是注意这里！！我们有了dataset（input，output），或许我们可以使用监督学习（supervised learning）来使用一种神经网络的方法来学习一种函数关系。所以接下来问题是【我们如何从少量的样本中得到足够好的数据】 train−data:(si,t,Σt′=tTr(si,t′,ai,t′))train-data:{(s_{i,t},\\Sigma_{t&#x27;=t}^T r(s_{i,t&#x27;},a_{i,t&#x27;}))} train−data:(s​i,t​​,Σ​t​′​​=t​T​​r(s​i,t​′​​​​,a​i,t​′​​​​)) (bootstrapped−estimate)V^ϕ(si,t)=Σt′=tTr(si,t′,ai,t′))=r(si,t′,ai,t′)+V^ϕ(si,t+1)(bootstrapped-estimate)\\hat V_\\phi(s_{i,t})=\\Sigma_{t&#x27;=t}^T r(s_{i,t&#x27;},a_{i,t&#x27;}))=r(s_{i,t&#x27;},a_{i,t&#x27;})+\\hat V_\\phi(s_{i,t+1}) (bootstrapped−estimate)​V​^​​​ϕ​​(s​i,t​​)=Σ​t​′​​=t​T​​r(s​i,t​′​​​​,a​i,t​′​​​​))=r(s​i,t​′​​​​,a​i,t​′​​​​)+​V​^​​​ϕ​​(s​i,t+1​​) supervised−regression:L(ϕ)=12Σi=1N∣∣V^ϕπ(si)−yi∣∣2supervised-regression:L(\\phi)=\\frac{1}{2}\\Sigma_{i=1}^N||\\hat V_\\phi^\\pi(s_i)-y_i||^2 supervised−regression:L(ϕ)=​2​​1​​Σ​i=1​N​​∣∣​V​^​​​ϕ​π​​(s​i​​)−y​i​​∣∣​2​​ 0x03 从Evaluation到Actor- Critic 3.1 批量AC算法（actor- critic algorithm） 如果我们使用这样的算法，我们会发现其实在轨迹之间都可以对state- value进行评估，但是这样求解得到的y是不一样的，在不同轨迹中因为状态变换不一样，如果最后都达到station状态是可以的，但是对于不平稳是不OK的，因为我们的label不准确，所以我们可以增加一个discount factor （采样优势）A^\\pi(s_t,a_t)=r(s,a)+\\gamma V^\\pi(s_{t+1})-V^\\pi(s_t) 在这种情况下，如果我们采样Monte Carlo采样，计算梯度，哪一个是对的？ (option1采样）\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma\\Sigma \\nabla_\\theta \\pi_\\theta(a_{i,t}|s_{i,t})(\\Sigma_{t'=t}^T\\gamma^{t'-t}r(s_{i,t'},a_{i,t'})) (option2采样）\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma\\Sigma \\nabla_\\theta \\pi_\\theta(a_{i,t}|s_{i,t})(\\Sigma_{t'=t}^T\\gamma^{t'-1}r(s_{i,t'},a_{i,t'})) 如果只是从option1采样，我们得到的结果是从每一步重新开始做discount，这个是符合直觉的 如果是从option2采样也不是没有结果的，如果我们针对未来恐惧所以会有很多的discount。 example：这里Sergey Levine尝试使用dead来解释option1和option2的区别，两者都是对的。 所以总结我们的算法，我们可以分为batcc AC与online AC两种方法 0x04 演员评论算法 Actor- Critics Algorithm细节 4.1 拟合函数训练 我们可以选择用两个network来分别拟合state- value function与policy- state- action网络；但是在比较复杂的输入，比如游戏图片中我们往往需要使用convolution layer共享参数来减少网络的参数 4.2 在线AC训练 如果只是这样训练，相当于我们每次更新梯度使用批量batchsize=1，所以非常差。我们从采样的角度出发，我们可以使用同步并行(synchronized parallel actor-critic) 或者异步平行（asynchronous parallel actor- critic）来多次采样，但是这样的损耗太大了，我们可以使用replay buffer来存储之前采样的数据。 但是如果我们只是简单的从replay buffer中得到train-data，但是这样是没有效果的，因为不是同一个轨迹构成的policy gradient是没有效果的，所以这样的算法是不对的。所以我们会尝试将之间的抽样得到的state- value转换成为包括Q(s,a)的值 所以在这里我们不再使用state- value，而是使用action- state- value 4.3 Baseline设置 我们在Policy gradient引入一个常数，得到无偏差、但是高方差的梯度；在AC中我们使用 r+V（t+1）- V（t）来得到评估，这样会有一个低方差但是有偏的方程，所以我们如何在拟合价值函数过程中得到我们的梯度，也就是用Q-V来评估（称为蒙特卡洛方法），但是这样对采样数量要求高。 A^Cπ(st,at)=r(st,at)+γV^ϕπ(st+1)−V^ϕπ(st)\\hat A^\\pi_C(s_t,a_t)=r(s_t,a_t)+\\gamma \\hat V^\\pi_\\phi(s_{t+1})-\\hat V^\\pi_\\phi(s_{t}) ​A​^​​​C​π​​(s​t​​,a​t​​)=r(s​t​​,a​t​​)+γ​V​^​​​ϕ​π​​(s​t+1​​)−​V​^​​​ϕ​π​​(s​t​​) A^MCπ(st,at)=Σt′=tγt′−tr(st′,at′)−V^ϕπ(st′)\\hat A^\\pi_{MC}(s_t,a_t)=\\Sigma_{t&#x27;=t}\\gamma^{t&#x27;-t}r(s_{t&#x27;},a_{t&#x27;})-\\hat V^\\pi_\\phi(s_{t&#x27;}) ​A​^​​​MC​π​​(s​t​​,a​t​​)=Σ​t​′​​=t​​γ​t​′​​−t​​r(s​t​′​​​​,a​t​′​​​​)−​V​^​​​ϕ​π​​(s​t​′​​​​) 我们可以考虑使用某种方式来结合两者，也就是采样N-step returns A^nπ(st,at)=Σt′=tt+nγt′−tr(st′,at′)−V^ϕπ(st′)+γnV^ϕπ(st+n)\\hat A^\\pi_{n}(s_t,a_t)=\\Sigma_{t&#x27;=t}^{t+n}\\gamma^{t&#x27;-t}r(s_{t&#x27;},a_{t&#x27;})-\\hat V^\\pi_\\phi(s_{t&#x27;})+\\gamma^n\\hat V^\\pi_\\phi(s_{t+n}) ​A​^​​​n​π​​(s​t​​,a​t​​)=Σ​t​′​​=t​t+n​​γ​t​′​​−t​​r(s​t​′​​​​,a​t​′​​​​)−​V​^​​​ϕ​π​​(s​t​′​​​​)+γ​n​​​V​^​​​ϕ​π​​(s​t+n​​) 之后包括generalized advantage estimation推导可以发现γ\\gammaγ可以有效的降低方差 0x05 review 0x06 code 参考动手学强化学习 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import gymimport torchimport torch.nn.functional as Fimport numpy as npimport matplotlib.pyplot as pltimport rl_utilsclass ActorCritic: def __init__(self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr, gamma, device): # 策略网络 self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device) self.critic = ValueNet(state_dim, hidden_dim).to(device) # 价值网络 # 策略网络优化器 self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr) self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=critic_lr) # 价值网络优化器 self.gamma = gamma self.device = device def take_action(self, state): state = torch.tensor([state], dtype=torch.float).to(self.device) probs = self.actor(state) action_dist = torch.distributions.Categorical(probs) action = action_dist.sample() return action.item() def update(self, transition_dict): states = torch.tensor(transition_dict[&#x27;states&#x27;], dtype=torch.float).to(self.device) actions = torch.tensor(transition_dict[&#x27;actions&#x27;]).view(-1, 1).to( self.device) rewards = torch.tensor(transition_dict[&#x27;rewards&#x27;], dtype=torch.float).view(-1, 1).to(self.device) next_states = torch.tensor(transition_dict[&#x27;next_states&#x27;], dtype=torch.float).to(self.device) dones = torch.tensor(transition_dict[&#x27;dones&#x27;], dtype=torch.float).view(-1, 1).to(self.device) # 时序差分目标 td_target = rewards + self.gamma * self.critic(next_states) * (1 - dones) td_delta = td_target - self.critic(states) # 时序差分误差 log_probs = torch.log(self.actor(states).gather(1, actions)) actor_loss = torch.mean(-log_probs * td_delta.detach()) # 均方误差损失函数 critic_loss = torch.mean( F.mse_loss(self.critic(states), td_target.detach())) self.actor_optimizer.zero_grad() self.critic_optimizer.zero_grad() actor_loss.backward() # 计算策略网络的梯度 critic_loss.backward() # 计算价值网络的梯度 self.actor_optimizer.step() # 更新策略网络的参数 self.critic_optimizer.step() # 更新价值网络的参数 actor_lr = 1e-3critic_lr = 1e-2num_episodes = 1000hidden_dim = 128gamma = 0.98device = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device( &quot;cpu&quot;)env_name = &#x27;CartPole-v0&#x27;env_name=&#x27;MountainCar-v0&#x27;env = gym.make(env_name)env.seed(0)torch.manual_seed(0)state_dim = env.observation_space.shape[0]action_dim = env.action_space.nagent = ActorCritic(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, gamma, device)return_list = rl_utils.train_on_policy_agent(env, agent, num_episodes)episodes_list = list(range(len(return_list)))plt.plot(episodes_list, return_list)plt.xlabel(&#x27;Episodes&#x27;)plt.ylabel(&#x27;Returns&#x27;)plt.title(&#x27;Actor-Critic on &#123;&#125;&#x27;.format(env_name))plt.show()mv_return = rl_utils.moving_average(return_list, 9)plt.plot(episodes_list, mv_return)plt.xlabel(&#x27;Episodes&#x27;)plt.ylabel(&#x27;Returns&#x27;)plt.title(&#x27;Actor-Critic on &#123;&#125;&#x27;.format(env_name))plt.show()","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS285","slug":"CS285","permalink":"https://blog.tjdata.site/tags/CS285/"}]},{"title":"CS285_Lecture05_Policy_Gradient","slug":"CS285_Lecture05_Policy_Gradien","date":"2022-10-23T12:01:56.000Z","updated":"2023-05-13T13:48:12.179Z","comments":true,"path":"posts/ed4cf7b5.html","link":"","permalink":"https://blog.tjdata.site/posts/ed4cf7b5.html","excerpt":"本节课的目标是搞明白Policy gradient一类的REINFORCEMENT方法，并且理解背后的局限性，然后知道为什么textbook很容易讲清楚，但是在实践中不行的原因。之后从Causality和Baseline两种方法来降低On- policy PG的方差。并给出结合IS（important sampling）的Off policy的梯度方法。最后利用代码实现RL里面的hello world—CartPole-v0来实现。","text":"本节课的目标是搞明白Policy gradient一类的REINFORCEMENT方法，并且理解背后的局限性，然后知道为什么textbook很容易讲清楚，但是在实践中不行的原因。之后从Causality和Baseline两种方法来降低On- policy PG的方差。并给出结合IS（important sampling）的Off policy的梯度方法。最后利用代码实现RL里面的hello world—CartPole-v0来实现。 01 什么是Policy gradients 1.1 PG的梯度函数的下载 回顾DRL的目标，我们需要的是增加累积奖励的期望： （目标函数）max\\ E_{\\tau-p_\\theta(\\tau)}[\\Sigma_tr(s_t,a_t)] 根据(st,at)(s_t,a_t)(s​t​​,a​t​​) 对的马尔可夫性质，(在有限的情况下finite horizon case）下简化成为 max Σt=1TE(st,at)−pθ(st,at)[r(st,at)]max\\ \\Sigma_{t=1}^TE_{(s_t,a_t)-p_\\theta(s_t,a_t)}[r(s_t,a_t)] max Σ​t=1​T​​E​(s​t​​,a​t​​)−p​θ​​(s​t​​,a​t​​)​​[r(s​t​​,a​t​​)] 因此我们可以根据πθ\\pi_\\thetaπ​θ​​采样N个τ\\tauτ,然后求得期望为 （采样后的目标函数）J(\\theta)=\\frac{1}{N}\\Sigma_i\\Sigma_tr(s_{i,t},a_{i,t}) 这个式子的重要意义在于它直接给我们反应当前policy的优劣，也指明了我们需要前进的方向，就是最大化这个期望，虽然有的时候这个式子并不是容易计算。但是请把哪些问题先放放，直观的最大化这个问题，也就是用梯度提升的方法： J(\\theta)=\\int p_\\theta(\\tau)r(\\tau)d\\tau（上式简写） 那么对参数求导的结果就是；同时由于我们无法直接取值函数，我们通常需要转换为期望的方式来利用sampling—expectation的方式来求期望 （目标函数梯度）\\nabla_\\theta J(\\theta)=\\int \\nabla_\\theta p_\\theta(\\tau)*r(\\tau)d\\tau)\\\\=\\int p_\\theta(\\tau)*\\nabla_\\theta logp_\\theta(\\tau)*r(\\tau)d\\tau\\\\=E_{\\tau-p_\\theta(\\tau)}[\\nabla_\\theta logp_\\theta(\\tau)*r(\\tau)] 我们对上面的目标函数更进一步的探讨；首先疑问就是什么是pθ(τ)p_\\theta(\\tau)p​θ​​(τ),在MDP的state- observation-action- state转移中我们可以认识到 pθ(τ)=p(s1)∏πθ(at∣st)p(st+1∣st,at)p_\\theta(\\tau)=p(s_1)\\prod \\pi_\\theta(a_t|s_t)p(s_{t+1}|s_t,a_t) p​θ​​(τ)=p(s​1​​)∏π​θ​​(a​t​​∣s​t​​)p(s​t+1​​∣s​t​​,a​t​​) 所以可以很轻松的替换掉上述 logpθ(τ)=logp(s1)+Σlogπθ(at∣st)+logp(st+1∣st,at)logp_\\theta(\\tau)=logp(s_1)+\\Sigma log\\pi_\\theta(a_t|s_t)+logp(s_{t+1}|s_t,a_t) logp​θ​​(τ)=logp(s​1​​)+Σlogπ​θ​​(a​t​​∣s​t​​)+logp(s​t+1​​∣s​t​​,a​t​​) 假设我们求导的化，那么目标函数梯度就会变成 ∇θJ(θ)=Eτ−pθ(τ)[(Σt=1T∇θlogπθ(at∣st))(Σt=1Tr(st,at))]\\nabla_\\theta J(\\theta)=E_{\\tau-p_\\theta(\\tau)}[(\\Sigma_{t=1}^T \\nabla_\\theta log \\pi_\\theta(a_t|s_t))(\\Sigma_{t=1}^T r(s_t,a_t))] ∇​θ​​J(θ)=E​τ−p​θ​​(τ)​​[(Σ​t=1​T​​∇​θ​​logπ​θ​​(a​t​​∣s​t​​))(Σ​t=1​T​​r(s​t​​,a​t​​))] Stop to think : just like before we evaluated our reinforcement learning objective by generating samples by actually running our policy in the world to get an estimate of an exception 这样情况下我们就可以得到采样的后的梯度计算： ∇θJ(θ)=1NΣi=1N[Σt=1T∇θlogπθ(ai,t∣si,t)][Σt=1Tr(si,t,ai,t)]\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma_{i=1}^N[\\Sigma_{t=1}^T \\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})][\\Sigma_{t=1}^T r(s_{i,t},a_{i,t})] ∇​θ​​J(θ)=​N​​1​​Σ​i=1​N​​[Σ​t=1​T​​∇​θ​​logπ​θ​​(a​i,t​​∣s​i,t​​)][Σ​t=1​T​​r(s​i,t​​,a​i,t​​)] 虽然我们成功得到了，我们如何从采样结果中得到如何计算梯度；但是我们需要对分析它具体的含义。 1.2 理解PG含义 我们可以看到损失函数内部主要有两部分组成，第一部分是有梯度的东西，第二部份是奖励的求和；那么对于两项分别分析，可以发现第一部分梯度与简单的MLE类似，也就是直接的梯度下降，但是由于有奖励的加权，导致我们的结果是： good stuff is made more likely;bad stuff is made less likely（增加好的可能性，降低坏的可能性），也标记为“trial and error” 对于中间的一项，∇θlogπθ(ai,t∣si,t)\\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})∇​θ​​logπ​θ​​(a​i,t​​∣s​i,t​​),假设我们用一个神经网络来进行拟合，假如采用Gaussian policies；也就是我们的模型假设是 logπθ(at∣st)=N(model(st);Σ)log\\pi_\\theta(a_t|s_t)=N(model(s_t);\\Sigma) logπ​θ​​(a​t​​∣s​t​​)=N(model(s​t​​);Σ) 那么我们的损失函数，根据MLE自然而然就可以得到(参考linear regression） ∇θJ(θ)=−12Σ−1(model(st)−at)dfdθ\\nabla_\\theta J(\\theta)=-\\frac{1}{2}\\Sigma^{-1}(model(s_t)-a_t)\\frac{df}{d\\theta} ∇​θ​​J(θ)=−​2​​1​​Σ​−1​​(model(s​t​​)−a​t​​)​dθ​​df​​ 这样我们就得到我们的REINFORCEMENT algorithm；这里缩写是针对：REward Increments=nonnegative FactorOffset Reinforcement Characteristic+Eligibility 但是PG的问题在于： 我们是否可以在partial observation，也就是o不等于s情况下使用？ 具有很大的方差，对于不同的reward取值结果大不相同。 example：假设N=3；其中总的奖励分为与（一负，两正），那么更新后的策略会偏向于右边，假如是加上constant（三正），那么更新的策略会比偏向中间。这种不确定性导致最终结果的方差偏大 0x02 如何降低方差一：Causality 在未来发生的事情并不会对现在的事情造成影响（policy at time b cannot affect reward at time a when a&lt;b）,因此在t之前的梯度不会对后面造成影响 所以我们的梯度需要： ∇θJ(θ)=1NΣi=1N[Σt=1T∇θlogπθ(ai,t∣si,t)][Σi=1Tr(si,t,ai,t)]\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma_{i=1}^N[\\Sigma_{t=1}^T \\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})][\\Sigma_{i=1}^T r(s_{i,t},a_{i,t})] ∇​θ​​J(θ)=​N​​1​​Σ​i=1​N​​[Σ​t=1​T​​∇​θ​​logπ​θ​​(a​i,t​​∣s​i,t​​)][Σ​i=1​T​​r(s​i,t​​,a​i,t​​)] 变成；注意后面计算奖励的下标！有效的证明过程可能需要在paper中才能看到 ∇θJ(θ)=1NΣi=1N[Σt=1T∇θlogπθ(ai,t∣si,t)][Σt′=tTr(si,t′,ai,t′)]\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma_{i=1}^N[\\Sigma_{t=1}^T \\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})][\\Sigma_{t&#x27;=t}^T r(s_{i,t&#x27;},a_{i,t&#x27;})] ∇​θ​​J(θ)=​N​​1​​Σ​i=1​N​​[Σ​t=1​T​​∇​θ​​logπ​θ​​(a​i,t​​∣s​i,t​​)][Σ​t​′​​=t​T​​r(s​i,t​′​​​​,a​i,t​′​​​​)] 通常的我们会将后面的记为：reward to go： （reward\\ to\\ go) \\hat Q_{i,t}=\\Sigma_{t'=t}^Tr(s_{i,t'},a_{i,t'}) 0x03 如何降低发差二：Baselines 首先直觉的感受不同reward的影响，还是之前的例子，如果reward=(-1,2,2)和（1，4，4）或者是（10000，10005，10005）这样计算的结果通常是不一样的。我们需要在其中减去一个baseline，相当于unbiased in expectation，很直观的我们是减去奖励的平均值，注意！！平均值不一定是最好的 \\nabla_\\theta J(\\theta)=\\int p_\\theta(\\tau)*\\nabla_\\theta logp_\\theta(\\tau)*(r(\\tau)-b)d\\tau\\\\ 可以简单的证明减去一个baseline不会对梯度造成影响，但是会对梯度变化程度造成影响 E[∇θlogpθ(τ)b]=b∇θ∫pθ(τ)dτ=b∇θ∗1=0E[\\nabla_\\theta logp_\\theta(\\tau)b]=b\\nabla_\\theta \\int p_\\theta(\\tau)d \\tau=b\\nabla_\\theta*1=0 E[∇​θ​​logp​θ​​(τ)b]=b∇​θ​​∫p​θ​​(τ)dτ=b∇​θ​​∗1=0 除去平均值，我们会采取什么baseline来计算？我们的目标是降低模型的方差，那么最好的baseline就是让模型方差最低的，根据方差计算 Var[X]=E[X2]−E[X]2Var[X]=E[X^2]-E[X]^2 Var[X]=E[X​2​​]−E[X]​2​​ 那么 Var=E[(∇θlogpθ(τ)∗(r(τ)−b))2]−E2[∇θlogpθ(τ)∗(r(τ)−b)]Var=E[(\\nabla_\\theta logp_\\theta(\\tau)*(r(\\tau)-b))^2]-E^2[\\nabla_\\theta logp_\\theta(\\tau)*(r(\\tau)-b)] Var=E[(∇​θ​​logp​θ​​(τ)∗(r(τ)−b))​2​​]−E​2​​[∇​θ​​logp​θ​​(τ)∗(r(τ)−b)] 直接对方差Var的bias求导 dVardb=−2E[∇θlogpθ(τ)2∗r(τ)]+2bE[∇θlogpθ(τ)2]\\frac{dVar}{db}=-2E[\\nabla_\\theta logp_\\theta(\\tau)^2*r(\\tau)]+2bE[\\nabla_\\theta logp_\\theta(\\tau)^2] ​db​​dVar​​=−2E[∇​θ​​logp​θ​​(τ)​2​​∗r(τ)]+2bE[∇​θ​​logp​θ​​(τ)​2​​] 这样就可以得到最好的b值，但是通常在实践中很难计算，所以还君之好用 b=E[∇θlogpθ(τ)2∗r(τ)]E[∇θlogpθ(τ)2]b=\\frac{E[\\nabla_\\theta logp_\\theta(\\tau)^2*r(\\tau)]}{E[\\nabla_\\theta logp_\\theta(\\tau)^2]} b=​E[∇​θ​​logp​θ​​(τ)​2​​]​​E[∇​θ​​logp​θ​​(τ)​2​​∗r(τ)]​​ 0x04 Off-policy Policy gradient 我们在之前的讨论中得到最终的梯度理论公式和采样公式，但是我们仔细思考这个过程，我们需要第i次采样得到完整τi\\tau_iτ​i​​之后才能利用梯度提升更新policy，这样对于每次policy只是简单的更新一次梯度；这样的结果就是采样效率非常低。 可以简单的引入 important sampling；来尝试解决这个问题，其理论过程是这样的 Ex−p(x)[f(x)]=∫p(x)f(x)dx=Ex−q(x)[p(x)q(x)f(x)]E_{x-p(x)}[f(x)]=\\int p(x)f(x)dx=E_{x-q(x)}[\\frac{p(x)}{q(x)}f(x)] E​x−p(x)​​[f(x)]=∫p(x)f(x)dx=E​x−q(x)​​[​q(x)​​p(x)​​f(x)] 这样的好处是我们可以使用智能体旧策略pθ(τ)p_\\theta(\\tau)p​θ​​(τ) 来更新策略梯度的值,得到pθ′(τ)p_{\\theta&#x27;}(\\tau)p​θ​′​​​​(τ),也就是目标函数会变成 J(θ′)=Eτ−pθ(τ)[pθ′(τ)pθ(τ)(r(τ)−b)]J(\\theta&#x27;)=E_{\\tau-p_\\theta(\\tau)}[\\frac{p_{\\theta&#x27;}(\\tau)}{p_\\theta(\\tau)}(r(\\tau)-b)] J(θ​′​​)=E​τ−p​θ​​(τ)​​[​p​θ​​(τ)​​p​θ​′​​​​(τ)​​(r(τ)−b)] 之间的比值可以展开得到 pθ′(τ)pθ(τ)=p(s1)∏πθ(at∣st)p(st+1∣st,at)p(s1)∏πθ′(at∣st)p(st+1∣st,at)=∏πθ(at∣st)∏πθ′(at∣st)\\frac{p_{\\theta&#x27;}(\\tau)}{p_\\theta(\\tau)}=\\frac{p(s_1)\\prod\\pi_\\theta(a_t|s_t)p(s_{t+1}|s_t,a_t)}{p(s_1)\\prod \\pi_{\\theta&#x27;}(a_t|s_t)p(s_{t+1}|s_t,a_t)}=\\frac{\\prod \\pi_\\theta(a_t|s_t)}{\\prod\\pi_{\\theta&#x27;}(a_t|s_t)} ​p​θ​​(τ)​​p​θ​′​​​​(τ)​​=​p(s​1​​)∏π​θ​′​​​​(a​t​​∣s​t​​)p(s​t+1​​∣s​t​​,a​t​​)​​p(s​1​​)∏π​θ​​(a​t​​∣s​t​​)p(s​t+1​​∣s​t​​,a​t​​)​​=​∏π​θ​′​​​​(a​t​​∣s​t​​)​​∏π​θ​​(a​t​​∣s​t​​)​​ 因此可以得到 Important sampling下的目标函数的期望 ∇θ′J(θ′)=Eτ−pθ(τ)[pθ′(τ)pθ(τ)∇θ′logπθ′(τ)(r(τ)−b)]\\nabla_{\\theta&#x27;} J(\\theta&#x27;)=E_{\\tau-p_\\theta(\\tau)}[\\frac{p_{\\theta&#x27;}(\\tau)}{p_\\theta(\\tau)}\\nabla_{\\theta&#x27;}log\\pi_{\\theta&#x27;}(\\tau)(r(\\tau)-b)] ∇​θ​′​​​​J(θ​′​​)=E​τ−p​θ​​(τ)​​[​p​θ​​(τ)​​p​θ​′​​​​(τ)​​∇​θ​′​​​​logπ​θ​′​​​​(τ)(r(τ)−b)] ∇θ′J(θ′)=Eτ−pθ(τ)[∏πθ′∣(at∣st)∏πθ(at∣st)∇θ′logπθ′(τ)(r(τ)−b)]\\nabla_{\\theta&#x27;} J(\\theta&#x27;)=E_{\\tau-p_\\theta(\\tau)}[\\frac{\\prod \\pi_{\\theta&#x27;}|(a_t|s_t)}{\\prod\\pi_{\\theta}(a_t|s_t)}\\nabla_{\\theta&#x27;}log\\pi_{\\theta&#x27;}(\\tau)(r(\\tau)-b)] ∇​θ​′​​​​J(θ​′​​)=E​τ−p​θ​​(τ)​​[​∏π​θ​​(a​t​​∣s​t​​)​​∏π​θ​′​​​​∣(a​t​​∣s​t​​)​​∇​θ​′​​​​logπ​θ​′​​​​(τ)(r(τ)−b)] 继续我们之前的causality的说明，所以采样情况下上面展开得到 ∇θ′J(θ′)=Eτ−pθ(τ)[Σt=1T∇θ′logπθ′(at∣st)(∏∗t′=1Tπ∗θ′(at′∣st′)πθ(at′∣st′))(Σt′=tT(r(st′,at′−b)(Σt′′=tt′∏∗t′=1Tπ∗θ′(at′′∣st′′)πθ(at′′∣st′′)))]\\nabla_{\\theta&#x27;} J(\\theta&#x27;)=E_{\\tau-p_\\theta(\\tau)}[\\Sigma_{t=1}^T \\nabla_{\\theta&#x27;}log\\pi_{\\theta&#x27;}(a_t|s_t)(\\prod *{t&#x27;=1}^T\\frac{\\pi*{\\theta&#x27;}(a_t&#x27;|s_t&#x27;)}{\\pi_{\\theta}(a_t&#x27;|s_t&#x27;)})(\\Sigma_{t&#x27;=t}^T(r(s_{t&#x27;},a_{t&#x27;}-b)(\\Sigma_{t&#x27;&#x27;=t}^{t&#x27;}\\prod *{t&#x27;=1}^T\\frac{\\pi*{\\theta&#x27;}(a_t&#x27;&#x27;|s_t&#x27;&#x27;)}{\\pi_{\\theta}(a_t&#x27;&#x27;|s_t&#x27;&#x27;)}))] ∇​θ​′​​​​J(θ​′​​)=E​τ−p​θ​​(τ)​​[Σ​t=1​T​​∇​θ​′​​​​logπ​θ​′​​​​(a​t​​∣s​t​​)(∏∗t​′​​=1​T​​​π​θ​​(a​t​′​​∣s​t​′​​)​​π∗θ​′​​(a​t​′​​∣s​t​′​​)​​)(Σ​t​′​​=t​T​​(r(s​t​′​​​​,a​t​′​​​​−b)(Σ​t​′′​​=t​t​′​​​​∏∗t​′​​=1​T​​​π​θ​​(a​t​′′​​∣s​t​′′​​)​​π∗θ​′​​(a​t​′′​​∣s​t​′′​​)​​))] 通常reward to go里的分布会删掉，因此不影响结果（paper中有） (Σt′′=tt′∏∗t′=1Tπ∗θ′(at′′∣st′′)πθ(at′′∣st′′))(\\Sigma_{t&#x27;&#x27;=t}^{t&#x27;}\\prod *{t&#x27;=1}^T\\frac{\\pi*{\\theta&#x27;}(a_t&#x27;&#x27;|s_t&#x27;&#x27;)}{\\pi_{\\theta}(a_t&#x27;&#x27;|s_t&#x27;&#x27;)}) (Σ​t​′′​​=t​t​′​​​​∏∗t​′​​=1​T​​​π​θ​​(a​t​′′​​∣s​t​′′​​)​​π∗θ​′​​(a​t​′′​​∣s​t​′′​​)​​) 同时可以改变策略的比值，这个在之后课程中会讲到,这里采用first- order approximation， ∏∗t′=1Tπ∗θ′(si,t)πθ(si,t)πθ′(at′∣st′)πθ(at′∣st′)=∏∗t′=1Tπ∗θ′(at′,st′)πθ(at′,st′)\\prod *{t&#x27;=1}^T\\frac{\\pi*{\\theta&#x27;}(s_{i,t})}{\\pi_\\theta(s_{i,t})}\\frac{\\pi_{\\theta&#x27;}(a_t&#x27;|s_t&#x27;)}{\\pi_{\\theta}(a_t&#x27;|s_t&#x27;)}=\\prod *{t&#x27;=1}^T\\frac{\\pi*{\\theta&#x27;}(a_{t&#x27;},s_t&#x27;)}{\\pi_{\\theta}(a_t&#x27;,s_t&#x27;)} ∏∗t​′​​=1​T​​​π​θ​​(s​i,t​​)​​π∗θ​′​​(s​i,t​​)​​​π​θ​​(a​t​′​​∣s​t​′​​)​​π​θ​′​​​​(a​t​′​​∣s​t​′​​)​​=∏∗t​′​​=1​T​​​π​θ​​(a​t​′​​,s​t​′​​)​​π∗θ​′​​(a​t​′​​​​,s​t​′​​)​​ 因此得到Off-Policy Policy gradient with important sampling的目标函数梯度： ∇θ′J(θ′)=1NΣi=1N[Σt=1T∇θ′logπθ′(at∣st)(∏∗t′=1Tπ∗θ′(at′,st′)πθ(at′,st′))Q^i,t]\\nabla_{\\theta&#x27;} J(\\theta&#x27;)=\\frac{1}{N}\\Sigma_{i=1}^N[\\Sigma_{t=1}^T \\nabla_{\\theta&#x27;}log\\pi_{\\theta&#x27;}(a_t|s_t)(\\prod *{t&#x27;=1}^T\\frac{\\pi*{\\theta&#x27;}(a_{t&#x27;},s_t&#x27;)}{\\pi_{\\theta}(a_t&#x27;,s_t&#x27;)}) \\hat Q_{i,t}] ∇​θ​′​​​​J(θ​′​​)=​N​​1​​Σ​i=1​N​​[Σ​t=1​T​​∇​θ​′​​​​logπ​θ​′​​​​(a​t​​∣s​t​​)(∏∗t​′​​=1​T​​​π​θ​​(a​t​′​​,s​t​′​​)​​π∗θ​′​​(a​t​′​​​​,s​t​′​​)​​)​Q​^​​​i,t​​] 作为对比之前的on- policy gradient是： ∇θJ(θ)=1NΣi=1N[Σt=1T∇θlogπθ(ai,t∣si,t)]Q^i,t\\nabla_\\theta J(\\theta)=\\frac{1}{N}\\Sigma_{i=1}^N[\\Sigma_{t=1}^T \\nabla_\\theta log \\pi_\\theta(a_{i,t}|s_{i,t})]\\hat Q_{i,t} ∇​θ​​J(θ)=​N​​1​​Σ​i=1​N​​[Σ​t=1​T​​∇​θ​​logπ​θ​​(a​i,t​​∣s​i,t​​)]​Q​^​​​i,t​​ 0x05 代码实现 参考《动手学深度学习》 首先几个有趣的发现 在CartPole-v0成功的不一定能在MountainCar-v0中实现，这个与奖励函数的设置关系很大（小车没有上山之前都是-1，被打击到了） 不同的超参数对最终结果影响很大 推荐使用GYM 0.21版本；最新版本总会出问题 5.1 环境搭建 1234567891011121314151617181920## 环境说明：Cartpole-v0 我们采用的测试环境是 CartPole-v0，其状态空间相对简单，只有 4 个变量，因此网络结构的设计也相对简单：采用一层 128 个神经元的全连接并以 ReLU 作为激活函数。当遇到更复杂的诸如以图像作为输入的环境时，我们可以考虑采用深度卷积神经网络。# 引入一些包from pyvirtualdisplay import Displaydisplay = Display(visible=0, size=(1400, 900))display.start()import matplotlib.pyplot as pltfrom IPython import displayimport timefrom IPython import displayfrom PIL import Imageimport gymimport torchimport torch.nn.functional as Fimport numpy as npimport matplotlib.pyplot as pltfrom tqdm import tqdm 5.2 定义Policy net 输入是state，输出是action。随便一个浅层MLP就够了 123456789101112class PolicyNet(torch.nn.Module): def __init__(self,state_dim,hidden_dim,action_dim): super(PolicyNet,self).__init__() self.fc1=torch.nn.Linear(state_dim,hidden_dim) self.fc2=torch.nn.Linear(hidden_dim,action_dim) for m in self.modules(): if isinstance(m, torch.nn.Linear): torch.nn.init.normal_(m.weight, std=0.01) def forward(self,x): x=F.relu(self.fc1(x)) return F.softmax(self.fc2(x),dim=1) 5.3 定义算法 三步，首先sample generation、然后policy evaluate，之后是improve policy 12345678910111213141516171819202122232425262728293031323334from traitlets import observeclass REINFORCE: def __init__(self,state_dim,hidden_dim,action_dim,learning_rate,gamma,device): self.policy_net=PolicyNet(state_dim,hidden_dim,action_dim).to(device) self.optimizer=torch.optim.Adam(self.policy_net.parameters(),lr=learning_rate) self.gamma=gamma self.device=device def take_action(self,state): # 根据动作概率分布随机采样 state=torch.tensor([state],dtype=torch.float).to(self.device) probs=self.policy_net(state) action_dist=torch.distributions.Categorical(probs) action=action_dist.sample() return action.item() def update(self,transition_dict): reward_list=transition_dict[&#x27;rewards&#x27;] state_list=transition_dict[&#x27;states&#x27;] action_list=transition_dict[&#x27;actions&#x27;] G=0 self.optimizer.zero_grad() for i in reversed(range(len(reward_list))): # 从最后一步开始 state=torch.tensor([state_list[i]],dtype=torch.float).to(self.device) reward=reward_list[i] action=torch.tensor([action_list[i]]).view(-1,1).to(self.device) log_prob=torch.log(self.policy_net(state).gather(1,action)) G=self.gamma*G+reward loss=-log_prob*G loss.backward() self.optimizer.step() 5.3 开始实验 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859learning_rate=0.001num_episodes=1000hidden_dim=128gamma=0.98device=torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)env_name=&#x27;CartPole-v0&#x27;# env_name=&#x27;MountainCar-v0&#x27;# env_name=&#x27;LunarLander-v2&#x27;## 观察环境env=gym.make(env_name)env.seed(0)print(&#x27;state:&#123;&#125;&#x27;.format(env.observation_space.dtype))print(&#x27;action:&#123;&#125;&#x27;.format(env.action_space))print(&#x27;state shape:&#123;&#125;~&#123;&#125;&#x27;.format(env.observation_space.low,env.observation_space.high))torch.manual_seed(0)state_dim=env.observation_space.shape[0]action_dim=env.action_space.nagent=REINFORCE(state_dim,hidden_dim,action_dim,learning_rate,gamma,device)return_list = []for i in range(10): with tqdm(total=int(num_episodes / 10), desc=&#x27;Iteration %d&#x27; % i) as pbar: for i_episode in range(int(num_episodes / 10)): episode_return = 0 transition_dict = &#123; &#x27;states&#x27;: [], &#x27;actions&#x27;: [], &#x27;next_states&#x27;: [], &#x27;rewards&#x27;: [], &#x27;dones&#x27;: [] &#125; state = env.reset() # 清除当前 Cell 的输出 done = False while not done: action = agent.take_action(state) next_state, reward, done, _ = env.step(action) transition_dict[&#x27;states&#x27;].append(state) transition_dict[&#x27;actions&#x27;].append(action) transition_dict[&#x27;next_states&#x27;].append(next_state) # special for Mountain # reward=(next_state[0]+1)**5 # if abs(next_state[1])&gt;0.04: # reward+=1 transition_dict[&#x27;rewards&#x27;].append(reward) transition_dict[&#x27;dones&#x27;].append(done) state = next_state episode_return += reward return_list.append(episode_return) agent.update(transition_dict) if (i_episode + 1) % 10 == 0: pbar.set_postfix(&#123; &#x27;episode&#x27;: &#x27;%d&#x27; % (num_episodes / 10 * i + i_episode + 1), &#x27;return&#x27;: &#x27;%.3f&#x27; % np.mean(return_list[-10:]) &#125;) pbar.update(1) 假如设置三层网络结果有点奇怪，但是policy是好的 5.4 观察 123456789101112131415161718done = Falsestate = env.reset()flag=1 # 防止刷新过快while flag&lt;100: action = agent.take_action(state) next_state, reward, done, _ = env.step(action) state=next_state # 清除当前 Cell 的输出 display.clear_output(wait=True) # 渲染画面，得到画面的像素数组 rgb_array = env.render(mode=&#x27;rgb_array&#x27;) # 使用像素数组生成图片 img = Image.fromarray(rgb_array) # 当前 Cell 中展示图片 display.display(img) time.sleep(1/24) flag+=1 第一个是2层，第二是3层 视频可以看https://www.notion.so/clouddirty/Lecture-05-Policy-Gradients-9384f9b7ad1f49d5aa326f66b97f05eb#3d9149bbd9b642ce926f0df2f0bf62f0","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS285","slug":"CS285","permalink":"https://blog.tjdata.site/tags/CS285/"}]},{"title":"CS285_Lecture04_Introduction_to_Reinforcement_Learning","slug":"CS285_Lecture04_Introduction_to_Reinforcement_Learning","date":"2022-10-23T11:01:56.000Z","updated":"2023-05-13T13:48:05.659Z","comments":true,"path":"posts/e1096304.html","link":"","permalink":"https://blog.tjdata.site/posts/e1096304.html","excerpt":"Sergev Levine的课讲强化学习我唯一听得懂不同强化学习究竟有哪些分类，同时是如何进行分类的。本次Lecture的目标是完善定义Definition与记号notation，并认清楚RL objective，并给出具体强化学习算法的总结。","text":"Sergev Levine的课讲强化学习我唯一听得懂不同强化学习究竟有哪些分类，同时是如何进行分类的。本次Lecture的目标是完善定义Definition与记号notation，并认清楚RL objective，并给出具体强化学习算法的总结。 0x01 Definition of a MDP 1.1 Recap RL with imitation learning 我们在之前的Lecture02-*Supervised_Learning_of_Behavior*中认识了Notation，以及imitation learning的局限性，其中最重要的是需要一个专家智能体或者人工来提供数据。但是显然这是不可行的。所以首先我们需要认识到我们的任务应该是什么？或许我们不知道任务具体样子，但我们知道它和我们状态转变序列中的每一步的reward有关。 举个例子，在我们observation=看到红灯的情况下，action=停车往往代表更高的reward，如果action=开车闯过交叉口往往代表负的reward。 0x02 Definition of Reinforcement learning problem 在之前的强化学习-基本概念中已经给出MP、MDP、MRP的定义，这里给出CS285官方对于MDP和POMDP（Partial observation MDP，暂时不讨论）的记号 在强化学习过程中 state-observation- action- state转变中，我们可以将（s_1,a_1,...,s_T,a_T）标记为一个trajectory，不同轨迹的概率可以由下图表示；由于状态s1是随机变量，策略也会输出不同的值，因此这里通常是具有指数的trajectory，因此通常只能用采样的方法来近似的描述总体。 p_{\\theta}(\\Tau=\\tau)=p(s_1)\\prod \\limits_{i=0}^T\\pi_{\\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t) 如果我们知道所有可能的轨迹的概率，那么我们就能求解出我们策略对应的期望;很 Eτ−pθ(τ)[Σi=0Tr(st,at)]E_{\\tau-p_{\\theta}(\\tau)}[\\Sigma _{i=0}^Tr(s_t,a_t)] E​τ−p​θ​​(τ)​​[Σ​i=0​T​​r(s​t​​,a​t​​)] 很不幸的是，在τ\\tauτ的概率分布中，我们不知道s1s_1s​1​​的分布，也不知道状态转移p(st+1∣st,at)p(s_{t+1}|s_t,a_t)p(s​t+1​​∣s​t​​,a​t​​);但是我们想确定的是πθ\\pi_{\\theta}π​θ​​；所以我们需要一些知识来做演化，比如我们知道(st,at)(s_t,a_t)(s​t​​,a​t​​)是具有MP性质的，也就是 p((st+1,at+1)∣(st,at))=p(st+1∣st,at)πθ(at+1∣st+1))p((s_{t+1},a_{t+1})|(s_t,a_t))=p(s_{t+1}|s_t,a_t)\\pi_{\\theta}(a_{t+1}|s_{t+1})) p((s​t+1​​,a​t+1​​)∣(s​t​​,a​t​​))=p(s​t+1​​∣s​t​​,a​t​​)π​θ​​(a​t+1​​∣s​t+1​​)) 那么我们的奖励期望就可以等价 Σt=1TE(st,at)−pθ(st,at)[r(st,at)]\\Sigma_{t=1}^TE_{(s_t,a_t)-p_{\\theta}(s_t,a_t)}[r(s_t,a_t)] Σ​t=1​T​​E​(s​t​​,a​t​​)−p​θ​​(s​t​​,a​t​​)​​[r(s​t​​,a​t​​)] 其中的pθ(st,at)p_\\theta(s_t,a_t)p​θ​​(s​t​​,a​t​​)表示为状态动作的边缘概率分布。 我们需要做的就是找到它其中的最大值，同样的对于场景中我们会简单的区分为有限场景与无限场景 infinite horizon case，我们需要最终达到稳定分布（stationary distribution），也就是状态状态不发生改变，μ=Tμ\\mu=T\\muμ=Tμ,这时候定义平均回报公式（无折扣）的目标函数为 1. finite horizon case ,我们依旧需要 state- action marginal来求解 Question：为什么我们需要期望？ 课程中给出的解答是在现实世界中的期望不连续的情况下，通过随机性和期望我们可以将其转变称为连续（smooth）的问题 PS：个人看法除了上述之外，还有一个原因是RL中我们通常希望使用采样Sampling的方法来进行求解，因为我们不可能罗列出所有的可能性，而采样方法得到的往往是期望而不是积分式。因此在RL好的sampling方法也是很重要的。常见的有基于马尔可夫蒙特卡洛MCMC方法，在此基础上蒙地卡罗、重要性采样、基于能量采样、Gibbs采样等等奇奇怪怪的采样方式。 0x03 Anatomy of a RL algorithm 我们可以回顾一下监督学习的范式，对于dataset，我们会有一个假设hypothesis，之后我们可以在dataset中利用learning model来通过loss来optim假设中的param，然后得到我们的model，并可以evaluate。 强化学习中的方式包括 generate sample，与环境交互或者收集样本来得到基础数据 fit a model或者estimate the return，我们可以直接拟合一个策略（用神经网络）；或者计算轨迹的奖励值（reward？Q？value？）来间接反应好的策略 improve the policy，无论第二步我们采用的是什么方法，我们的最终目的是需要提升我们的policy 0x04 Brief overview of RL algorithm types 在step2中，我们天然的可以将RL算法分为两类，一类是是直接拟合policy的，一类是根据reward来间接反映policy的好坏。但是reward并不是容易计算的，所以我们会有reward、Q- function或者value - function 4.1 关于评价Policy的好坏 最直接的我们在0x02中已经定义好了，我们来展开计算它： Eτ−pθ(τ)[Σt=1t=Tr(st,at)]E_{\\tau-p_\\theta(\\tau)}[\\Sigma_{t=1}^{t=T}r(s_t,a_t)] E​τ−p​θ​​(τ)​​[Σ​t=1​t=T​​r(s​t​​,a​t​​)] =E_{s_1-p_\\theta(s_1)}[E_{a_1-\\pi(a_1|s_1)}[r(s_1,a_1)+待定]｜s_1,a_1] 如果继续写下去，我们会发现其中的“待定“是可以递归的写下去的，直到轨迹的最后，假设我们定义一种函数，名称为Q- function Q（s_1,a_1）=r(s_1,a_1)+待定 那么我们的期望奖励就成为 E_{\\tau-p_\\theta(\\tau)}[\\Sigma_{t=1}^{t=T}r(s_t,a_t)]=E_{s_1-p_\\theta(s_1)}[E_{a_1-\\pi(a_1|s_1)}[Q(s_1,t_1)]｜s_1,a_1] 更详细的定义Q- function： Qπ(st,at)=Σt′=tTEπθ[r(st′,at′)∣st,at]Q^\\pi(s_t,a_t)=\\Sigma_{t&#x27;=t}^TE_{\\pi_\\theta}[r(s_{t&#x27;},a_{t&#x27;})|s_t,a_t] Q​π​​(s​t​​,a​t​​)=Σ​t​′​​=t​T​​E​π​θ​​​​[r(s​t​′​​​​,a​t​′​​​​)∣s​t​​,a​t​​] 在MRP问题中我们会有一个状态价值的概念，同样我们这里可以由state-value- function，用来反应所有行为下的期望 Vπ(s)=E[Qπ(s,a)] under π(a∣s)V^\\pi(s)=E[Q^\\pi(s,a)]\\ under\\ \\pi(a|s) V​π​​(s)=E[Q​π​​(s,a)] under π(a∣s) 但是这样得到的Q有用吗？ （Q- learning）这样我们可以通过改变πθ\\pi_\\thetaπ​θ​​来改变总期望吗？答案是可以的，我们可以选择对应更大Q值的行为，虽然这不是数学上的描述，但是可以给我们直觉上的可能性。 （Actor- critic）尽可能选择Q&gt;V的行为，因为V反应这个状态下所有action的平均值 PS：这一段真是太棒了！！！ 4.2 Types of RL algorithm 根据第二步fit model我们可以认为是model- based RL，通常包括 planing；trajectory optimization、optimal control、MCTS improve a policy，back propagate gradients into the policy with tricks something else，dynamic programming，simulated experience for model-free leaner 后面再说 如果是evaluate return，我们可以认为是model- free RL，通常包括 policy gradients，直接计算Objective和gradient value- based，通过平局value- function和Q- function来寻找比较好的方法 actor- critic，通过评估现在的value function和Q- function，结合PG的想法来提升策略 4.3 why so many algorithms？ 模型本身有efficiency- stability；不同的assumption；以及不同问题的使用场景；正如ML中的variance-bias tradeoff，RL中通常是efficiency- stability trade-off 同时不同模型也会有不同的assumption，比如是否全观测，是否连续等 4.4 example of algorithm model- based Dyna Guided policy search model - free Policy gradient REINFORCE（REward Increments=nonnegative FactorOffset ReinforcementCharacteristic+Eligibility） Natural Policy gradient Trust region policy optimization Value function fitting methods Q- learning，DQN Temporal difference learning Fitted value iteration Actor- critic algorithms Asynchronous advantage actor- critic Soft actor- critic（SAC）","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS285","slug":"CS285","permalink":"https://blog.tjdata.site/tags/CS285/"}]},{"title":"CS285_Lecture02_Supervised_Learning_of_Behavior","slug":"CS285_Lecture02_Supervised_Learning_of_Behavior","date":"2022-10-23T10:01:56.000Z","updated":"2023-05-13T13:47:58.896Z","comments":true,"path":"posts/7d84bcc6.html","link":"","permalink":"https://blog.tjdata.site/posts/7d84bcc6.html","excerpt":"目标是明白RL中的一些定义（definition）和记号（notation），主要是从MDP的定义，然后模仿学习（Imitation learning）和ϵ\\epsilonϵ-greedy 学习的角度介绍了强化学习中的case","text":"目标是明白RL中的一些定义（definition）和记号（notation），主要是从MDP的定义，然后模仿学习（Imitation learning）和ϵ\\epsilonϵ-greedy 学习的角度介绍了强化学习中的case 0x01 Definition of Sequential decision problem 1.1 概率论 关于概率论的记号，与研一课程《应用统计》不一样。我猜想多是具有另外的规定，这里引用从《Deep learning》（2015，Lan Goodfellow）中的说明： 随机变量（random variable）是可以随机取不同值的变量，我们通常使用无格式字体（plain typeface）中的小写字母表示随机变量本身，用手写体中的小写字母表示随机变量能够取的值。x1,x2x_1,x_2x​1​​,x​2​​表示随机变量x可能的取值，对于向量（vector）的变量，我们通常用x，可能的取值为xxx。所以p(p(p(x=x）可以简写为p(x)p(x)p(x) 1.2 强化学习 与强化学习典中典的：环境（Environment）与智能体（Agent）和动作（Action）三者交互类似，CS285课程同样以这样的例子作为开端，并利用概率图的方式来分析这个过程。 （第一层）在草原这个环境中看到了某个东西，然后我们判别出来它是老虎，这个时候我们通常做出某个动作，但是我们的动作也会影响草原环境，进而影响老虎的动作 （第二层），假设草原环境作为Environment，某个时间点的状态为State，我们作为Agent通过看认识这个状态得到Observation（老虎的概率为0.99，猫的概率为0.01），之后我们会根据Observation来采取Policy( πθ(at∣ot)\\pi_\\theta(a_t|o_t)π​θ​​(a​t​​∣o​t​​))（如果是老虎，则逃跑概率=0.9，当宠物=0.1；如果是猫，则逃跑概率=0.1，当宠物=0.9）；之后我们的动作action结合现有的state会影响下一步的next-state (第三层）sts_ts​t​​得到oto_to​t​​，之后根据策略得到at=Πθ(at∣ot)a_t=\\Pi_\\theta(a_t|o_t)a​t​​=Π​θ​​(a​t​​∣o​t​​),再影响下一步st+1=P(st+1∣st,at)s_{t+1}=P(s_{t+1}|s_t,a_t)s​t+1​​=P(s​t+1​​∣s​t​​,a​t​​)；state — observation — action — next_state… 在这个过程中我们会有几个疑问： 智能体对环境是否是完全观测（fully observe），这直接会影响我们学习的策略，通常分为\\pi_\\theta(a_t|s_t)或者\\pi_\\theta(o_t|s_t) ，经常会出错 由图可以看出状态转移（state transit）是具有马尔可夫性质（Markov property），但是observation不一定、action也不一定、policy也不一定 我们的objective还不确定 在不明白目标情况下，不如去看一种简单的方式是如何学习的 PS：强化学习的记号通常认为是研究运筹或动态规划（Dynamic programming）的Richard Bellman和研究自动控制的Lev Pontryagin不同的发展。 0x02 Imitation Learning 在Lecture01中虽然对比了强化学习（reinforcement learning）与监督学习（supervised learning）之间的差别，但是我们依旧会发现两者之间相似的地方 给出一个state或者observation，来输出一个action 因此我们可以假设存在一个专家智能体，其策略可以看成最优策略，我们可以直接模仿这个专家在环境中交互状态动作（state，action）数据来训练一个policy，而不需要环境提供的reward，这样便是imitation learning研究的问题，不需要reward信号变可以达到一个专家策略，常用的方法分为 Behaviour Cloning Inverse RL Generative Adversarial Imitation Learning，GAIL 2.1 Behaviour cloning 输入（s_t，a_t）中的state作为样本输入，action作为标签，目标为 θ∗=argminθE(s,a)−τ[L(πθ(s),a)]\\theta^*=argmin_\\theta E_{(s,a)- \\tau}[L(\\pi_\\theta(s),a)] θ​∗​​=argmin​θ​​E​(s,a)−τ​​[L(π​θ​​(s),a)] Does it ok? — No 在数据量较小的情况下，我们只能得到少量的专家数据作为训练，因此只有在数据集的分布下预测准确。但是因为我们不断经历state- observation- action- state的循环，并不是监督学习的一次终止，因此我们的每次偏差都会累积，产生复合物差（compounding error）的问题，导致差距来越来大而失败。 Does it ok？yes，but more data 但是在具有很多数据的情况下是可以实现的，比如****End to End Learning for Self-Driving Cars文章中收集了足够多的数据来实现运行的稳定性** How we make it more offen？ 我们分析之间之前不同 trajectory产生偏差的原因是由于pdata(ot)!=pπθ(ot)p_{data}(o_t)!=p_{\\pi_{\\theta}}(o_t)p​data​​(o​t​​)!=p​π​θ​​​​(o​t​​),因此我们希望用某种方式来保证，因此可以使用 DAgger（Dataset Aggregation）： 但是第一点：人工标记本身就不可靠，因为我们在相同的场景下也会出现不同的行为，同时我们的动作会和一定的记忆有关；第二点我们在复杂场景中很难准确给出新的state的action，所以本质上我们依旧需要学习机器，我们需要序列学习的概念 当然我们可以使用CNN+RNN的特点，他们依旧只是复杂的模仿学习，并没有解决分布不匹配的问题。总是我们用DAgger来解决这样的问题，依旧只是在特定场景下具有可能性。 0x03 A little bit of theory for imitation learning 可以不看，因为看不懂！ 结合之前基本概念里的MRP（Markov reward process）我们可以理解reward，因此在一段轨迹中我们希望,首先我们定义cost minEs1−t,a1−t[Σc(st,at)]min E_{s1-t,a1-t}[\\Sigma c(s_t,a_t)] minE​s1−t,a1−t​​[Σc(s​t​​,a​t​​)] 同时cost反面等于奖励，也就是 r(s,a)=−c(s,a)r(s,a)=-c(s,a) r(s,a)=−c(s,a) 我们将真实的策略表示为πθ∗(s)\\pi^*_{\\theta}(s)π​θ​∗​​(s)，那么我们的奖励函数应该是 r(s,a)=logp(a=πθ∗(s))r(s,a)=log p(a=\\pi^*_{\\theta}(s))r(s,a)=logp(a=π​θ​∗​​(s))y 因此在采样错误率低于一定程度之下，我们可以得到 改进之后我们有需要其他的方式来学习，这种主要是生成模型了～ 3.1 生成对抗模型学习（generative adverbial imitation learning） 摘自动手学强化学习 （generative adversarial imitation learning，GAIL）是 2016 年由斯坦福大学研究团队提出的基于生成式对抗网络的模仿学习，它诠释了生成式对抗网络的本质其实就是模仿学习。GAIL 实质上是模仿了专家策略的占用度量即尽量使得策略在环境中的所有状态动作对的占用度量和专家策略的占用度量一致。为了达成这个目标，策略需要和环境进行交互，收集下一个状态的信息并进一步做出动作。这一点和 BC 不同，BC 完全不需要和环境交互。GAIL 算法中有一个判别器和一个策略，策略就相当于是生成式对抗网络中的生成器（generator），给定一个状态，策略会输出这个状态下应该采取的动作，而判别器（discriminator）将状态动作对作为输入，输出一个 0 到 1 之间的实数，表示判别器认为该状态动作对是来自智能体策略而非专家的概率。判别器的目标是尽量将专家数据的输出靠近 0，将模仿者策略的输出靠近 1，这样就可以将两组数据分辨开来。 0x04 总结 Lecture02主要还是利用imitation learning介绍了 监督学习用于强化学习的局限性 强化学习的notation 下一章是及其Fancy的强化学习方法的总结","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"CS285","slug":"CS285","permalink":"https://blog.tjdata.site/tags/CS285/"}]},{"title":"动手学深度学习05_循环神经网络RNN及变种","slug":"动手学深度学习05_循环神经网络RNN及变种","date":"2022-10-19T02:23:50.000Z","updated":"2023-05-13T13:51:58.356Z","comments":true,"path":"posts/2e4e1168.html","link":"","permalink":"https://blog.tjdata.site/posts/2e4e1168.html","excerpt":"承接上一会对Attention中seq2seq的模型的困惑，这里从RNN到介绍到更传统的Seq2Seq模型。同时结合最近接触的花书来利用更有利的工具解释RNN中的梯度。并给出序列学习中对于gradient或者hidden state转变的过程，在针对hidden state中的转变中引申出GRU、LSTM之类的变种，并结合D@L给出代码的实现。","text":"承接上一会对Attention中seq2seq的模型的困惑，这里从RNN到介绍到更传统的Seq2Seq模型。同时结合最近接触的花书来利用更有利的工具解释RNN中的梯度。并给出序列学习中对于gradient或者hidden state转变的过程，在针对hidden state中的转变中引申出GRU、LSTM之类的变种，并结合D@L给出代码的实现。 0x01 序列学习与RNN 1.1 序列学习Seq2Seq 输入与输出均为序列数据的模型叫做Seq2Seq，注意这里不在按照传统的监督或者非监督的方式来限定模型的类型。常见序列模型的应用包括：语音识别Speech recognition、音乐生成Music generation、情感分析 Sentiment classification、DNA序列分析DNA sequence analysis、机器翻译Machine translation、视频行为识别Video activity recognition、命名实体识别Name entity recognition。 在Seq2Seq过程中，我们很难像MLP或者CNN得到一个明确的 feature，label；并且序列数据大多是按照一定的顺序来进行的，比如文本序列、视频信号、网站浏览行为等等，并不满足之前的独立同分布的假设。 为什么RNN类似的网络在Seq中会取得好的效果？主要是解决20世纪80年代机器学习和统计模型的思想的优点：在模型的不同部分共享参数。参数共享使得模型能够拓展到不同形式的样本并进行泛化。specially：假如在seq的每一个时间点都具有一个单独的参数，但是我们不能泛化我们没有见过的类型，也不能在时间上共享不同序列长度和不同位置的统计强度。同时我们也不能理解不同顺序seq的含义（比如In 2009，I went to Nepal和I went to Nepal in 2009之间的区别） Shortly：RNN的优势主要是 跨时间权重共享 时间平移不对称 同一架构适应不同长度 1.2 RNN结构前向传播 Forward Propagation 这里先不管RNN内部的具体结构的原因，只要知道RNN包括时间步的input和output以及hidden state就可以，原因在后面会说明。计算图是形式化一组计算结构的方式，如果设计将输入和参数映射到输出和损失的计算。 先假设数据集为X=(x1,x2,..,xt,...)Rn×dX=(x^1,x^2,..,x^t,...)\\mathbb{R}^{n \\times d}X=(x​1​​,x​2​​,..,x​t​​,...)R​n×d​​ 通常的训练过程是将Ht∈R1×hH^t\\in \\mathbb{R^{1 \\times h}}H​t​​∈R​1×h​​作为hidden state来进行分析，它是根据下式子进行更新 Ht=f(Ht−1,xt;θ)H^t=f(H^{t-1},x^t;\\theta) H​t​​=f(H​t−1​​,x​t​​;θ) 如果采用神经网络，格式通常是 Ht=ϕ(xtWxh+Ht−1Whh+bh)H^t=\\phi(x^{t}W_{xh}+H^{t-1}W_{hh}+b_h) H​t​​=ϕ(x​t​​W​xh​​+H​t−1​​W​hh​​+b​h​​) 其中各项的分别为Wxh∈Rd×h,Whh∈Rh×h,bh∈R1×hW_{xh}\\in \\mathbb{R}^{d\\times h},W_{hh}\\in\\mathbb{R}^{h\\times h},b_h\\in\\mathbb{R}^{1\\times h}W​xh​​∈R​d×h​​,W​hh​​∈R​h×h​​,b​h​​∈R​1×h​​ 在得到hidden state我们可以进行下一步状态转换，也可以输出当前的值 Ot=g(Ht;θo)O^t=g(H^t;\\theta_o) O​t​​=g(H​t​​;θ​o​​) Ot=tanh(HtWoh+bo)O^t=tanh(H^tW_{oh}+b_o) O​t​​=tanh(H​t​​W​oh​​+b​o​​) 其中各项的形状为Woh∈Rh×o,bo∈R1×oW_{oh}\\in\\mathbb{R}^{h\\times o},b_o\\in\\mathbb{R}^{1\\times o}W​oh​​∈R​h×o​​,b​o​​∈R​1×o​​ 得到模型的输入和输出之后就可以计算模型的损失 L=loss(ot,yt)L=loss(o^t,y^t) L=loss(o​t​​,y​t​​) 得到 1.3 反向传播的梯度下降 Back Propagation 在之前中我们包括至少五个参数，[Wxh,Whh,bh,Who,bo][W_{xh},W_{hh},b_h,W_{ho},b_o][W​xh​​,W​hh​​,b​h​​,W​ho​​,b​o​​],通过上处更新的式子我们计算不同的梯度,比如针对WhhW_{hh}W​hh​​ \\begin{split}\\begin{aligned}\\frac{\\partial L}{\\partial w_{hh}} & = \\frac{1}{T}\\sum_{t=1}^T \\frac{\\partial l(y_t, o_t)}{\\partial w_{hh}} \\\\& = \\frac{1}{T}\\sum_{t=1}^T \\frac{\\partial l(y_t, o_t)}{\\partial o_t} \\frac{\\partial g(h_t, \\theta_o)}{\\partial h_t} \\frac{\\partial h_t}{\\partial w_{hh}}.\\end{aligned}\\end{split} 注意这里的第一项我们是知道的，第二项我们也是知道的，但是第三项它是会一直Recurrent计算下去的 ∂ht∂whh=∂f(xt,ht−1,θh)∂θh+∂f(xt,ht−1,θh)∂ht−1∂ht−1∂whh.\\frac{\\partial h_t}{\\partial w_{hh}}= \\frac{\\partial f(x_{t},h_{t-1},\\theta_h)}{\\partial \\theta_h} +\\frac{\\partial f(x_{t},h_{t-1},\\theta_h)}{\\partial h_{t-1}} \\frac{\\partial h_{t-1}}{\\partial w_{hh}}. ​∂w​hh​​​​∂h​t​​​​=​∂θ​h​​​​∂f(x​t​​,h​t−1​​,θ​h​​)​​+​∂h​t−1​​​​∂f(x​t​​,h​t−1​​,θ​h​​)​​​∂w​hh​​​​∂h​t−1​​​​. 这样梯度其实是会随着时间t不断拉长，这里通常称为长期依赖的问题这样我们可能出现梯度消失、或者梯度爆炸的情况。常见的操作有三种 完全计算直到收敛 采用N步马尔可夫模型，来截断时间步，到达时间步τ\\tauτ 采用随机截断的思想 还有针对梯度的一些操作，常见的有截断梯度和引导信息流的正则化， 针对梯度爆炸，截断梯度也就是在参数更新之前截断梯度的范数，在时间的过程中被证明是有用的。 针对梯度消失，引导信息流的正则化，一种是加入门控单元（如LSTM、GRU），也可以解决梯度爆炸的问题；一种是正则化项，后者被证明不有效 1.4 进一步。高级一点的RNN 在单向RNN的基础上，可以自然而然的联想到 双向RNN 深度RNN 递归神经网络，一个潜在的idea是研究推论 增加门控单元的不同变种GRU、LSTM 基于encoder- decoder的seq2seq框架 回声状态网络（echo state network），流体状态机（liquid state machines） 1.5 回过头解释RNN 首先我们可以回顾我们在时间序列预测中常用的一些方法：自回归模型、隐变量自回归模型、马尔可夫模型、因果关系模型等等，常用的是 xt=P(xt∣xt−1,...,x1)x_t=P(x_t|x_{t-1},...,x_1) x​t​​=P(x​t​​∣x​t−1​​,...,x​1​​) 因此我们也可以希望得到 P(xt∣xt−1,...,x1)=p(xt∣xt−1,ht−1)P(x_t|x_{t-1},...,x_1)=p(x_t|x_t-1,h_{t-1}) P(x​t​​∣x​t−1​​,...,x​1​​)=p(x​t​​∣x​t​​−1,h​t−1​​) 也就是假如一个hidden state来作为对之前序列总结，将其送入状态转变中。 0x02 变种与思考GRU、LSTM 我们之前分析了长期依赖对于梯度消失或者梯度爆炸的影响，从实际效果来看它的影响是： 早期的预测值对预测所有未来预测值具有非常重要的意义 一些词元没有相关的观测值，比如对网页内容进行情感分析可能有一些辅助HTML代码与网页传达的情绪无关 序列之间的不同部分之间存在逻辑中断 在过去采取过很多方法来进行改进，目前主流的是使用门控的方式来确定什么时候更新hidden state、什么时候重置reset。 LSTM 2.1 Gate 设计为（0，1）区间内的向量，这样我们可以进行凸组合：reset-gate允许我们控制可能还想记住的过去状态的数量，更新们能讲允许我们控制新状态中有多少是旧状态的副本 具体的计算过程如图： Rt=σ(XtWxr+Ht−1Whr+br)R_t=\\sigma (X_tW_{xr}+H_{t-1}W_{hr}+b_r) R​t​​=σ(X​t​​W​xr​​+H​t−1​​W​hr​​+b​r​​) Zt=σ(XtWxz+Ht−1Whz+bz)Z_t=\\sigma (X_tW_{xz}+H_{t-1}W_{hz}+b_z) Z​t​​=σ(X​t​​W​xz​​+H​t−1​​W​hz​​+b​z​​) 注意在求和过程会触发 广播机制,使用sigmoid函数将其转换到0，1区间，在这个基础上更新 候选隐藏状态 H¯t=tanh(XtWxh+(Rt⊗Ht−1Whh+bh))\\bar H_t=tanh(X_tW_{xh}+(R_t \\otimes H_{t-1}W_{hh}+b_h)) ​H​¯​​​t​​=tanh(X​t​​W​xh​​+(R​t​​⊗H​t−1​​W​hh​​+b​h​​)) 使用tanh非线性激活函数来保证hidden state中的值是保持在区间-1，1之间的；Hadamar元素表示按照元素进行乘积我们结合更新门来对候选隐藏状态进行进一步的修正，得到最终hidden state的取值 Ht=Zt⊗Ht−1+(1−Zt)∗H¯t−1H_t=Z_t \\otimes H_{t-1}+(1-Z_t)*\\bar H_{t-1} H​t​​=Z​t​​⊗H​t−1​​+(1−Z​t​​)∗​H​¯​​​t−1​​ 由此得到门控循环单元具有两个显著的特征 reset有助于捕获序列中的短期依赖关系 updater有助于捕获序列中的长期依赖关系 2.2 GRU 2.3 LSTM 2.4 DRNN 2.5 BRNN 0x03 逻辑过程分析 3.1 序列数据读取（example：文本数据）-token-vocab 首先文本数据集从文本读取出来是这样子的 我们总的idea是希望将上述不规则的文本，转换为可以用向量表示的数字，且为序列数据。Obviously，我们可以用一个词典vocab来将这些词语转换称为数字。那么这个词典的顺序怎么确定？通常是根据词的出现频率来实现的。同时对于出现频率过少的词可以用或者其他来表示。加入我们使用每个单词来表示，得到的vocab就是 除了单词我们也可以使用单个字符char来分割数据集 3.2 数据预处理-input： batchsize，num_steps–dataloader 在这个基础上我们就可以生成我们的dataloader，因为seq序列天然就有顺序性，而为了提高泛化性我们希望他们可以学习到顺序性，但是学习的又不太多，因此会有两种采样方式来做： 随机采样 顺序分区 批量的大小由batchsize来确定，同时单次训练的顺序包括num_steps个单词，因此经过这样我们采取送入网络训练的单个batch的形状为 batch=Xi,yi,i=X1,X2,..,Xbatchsize;Xi∈Rnum_steps,len(vocab)batch={X_i,y_i},i={X^1,X^2,..,X^{batchsize}};X_i\\in\\mathbb{R}^{num\\_steps,len(vocab)}batch=X​i​​,y​i​​,i=X​1​​,X​2​​,..,X​batchsize​​;X​i​​∈R​num_steps,len(vocab)​​ 总体的shape就是(batchsize,num_steps,len(vocab))(batchsize,num\\_steps,len(vocab))(batchsize,num_steps,len(vocab)) 这里有个操作是为了后面小批量矩阵运算，会做一个reshape，变成(num_steps,batchsize,len(vocab))(num\\_steps,batchsize,len(vocab))(num_steps,batchsize,len(vocab));可以自行计算梯度变换的方式体会 3.3 模型主干-model-loss-optim 初始化参数 选择适合的loss 定义RNN model 3.4 训练与可视化- train- predict-ppl train也就是设置learning rate和epoch训练就好了 0x04 代码实现1，2，3 这里完全参考李沐大大的代码，然后将其中的d2l的部分完全剔除得到如下的代码 4.1 数据集读取设置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175import randomimport torchimport mathfrom torch import nnfrom torch.nn import functional as F## 李沐中d2l服务器中存储的数据DATA_HUB = dict()DATA_URL = &#x27;http://d2l-data.s3-accelerate.amazonaws.com/&#x27;dataset=&#x27;time_machine&#x27;dataset_sha256=&#x27;090b5e7e70c295757f55df93cb0a180b9691891a&#x27;DATA_HUB[dataset]=(DATA_URL+&#x27;timemachine.txt&#x27;,dataset_sha256)import osimport hashlibimport requestsimport redef download(name, cache_dir=os.path.join(&#x27;..&#x27;, &#x27;data&#x27;)): #@save &quot;&quot;&quot;下载一个DATA_HUB中的文件 返回本地文件名&quot;&quot;&quot; url, sha1_hash = DATA_HUB[name] os.makedirs(cache_dir, exist_ok=True) fname = os.path.join(cache_dir, url.split(&#x27;/&#x27;)[-1]) if os.path.exists(fname): sha1 = hashlib.sha1() with open(fname, &#x27;rb&#x27;) as f: while True: data = f.read(1048576) if not data: break sha1.update(data) if sha1.hexdigest() == sha1_hash: return fname # 命中缓存 r = requests.get(url, stream=True, verify=True) with open(fname, &#x27;wb&#x27;) as f: f.write(r.content) return fnamedef read_time_machine(): #@save &quot;&quot;&quot;将时间机器数据集加载到文本行的列表中&quot;&quot;&quot; with open(download(&#x27;time_machine&#x27;), &#x27;r&#x27;) as f: lines = f.readlines() return [re.sub(&#x27;[^A-Za-z]+&#x27;, &#x27; &#x27;, line).strip().lower() for line in lines]def tokenize(lines, token=&#x27;char&#x27;): #@save &quot;&quot;&quot;将文本行拆分为单词或字符&quot;&quot;&quot; if token == &#x27;word&#x27;: return [line.split(&#x27; &#x27;) for line in lines] elif token == &#x27;char&#x27;: return [list(line) for line in lines] else: print(&#x27;错误：未知令牌类型：&#x27;+token)import collections class Vocab: #@save &quot;&quot;&quot;文本词表&quot;&quot;&quot; def __init__(self, tokens=None, min_freq=0, reserved_tokens=None): if tokens is None: tokens = [] if reserved_tokens is None: reserved_tokens = [] # 按出现频率排序 counter = count_corpus(tokens) self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True) # 未知词元的索引为0 self.idx_to_token = [&#x27;&lt;unk&gt;&#x27;] + reserved_tokens self.token_to_idx = &#123;token: idx for idx, token in enumerate(self.idx_to_token)&#125; for token, freq in self._token_freqs: if freq &lt; min_freq: break if token not in self.token_to_idx: self.idx_to_token.append(token) self.token_to_idx[token] = len(self.idx_to_token) - 1 def __len__(self): return len(self.idx_to_token) def __getitem__(self, tokens): if not isinstance(tokens, (list, tuple)): return self.token_to_idx.get(tokens, self.unk) return [self.__getitem__(token) for token in tokens] def to_tokens(self, indices): if not isinstance(indices, (list, tuple)): return self.idx_to_token[indices] return [self.idx_to_token[index] for index in indices] @property def unk(self): # 未知词元的索引为0 return 0 @property def token_freqs(self): return self._token_freqsdef count_corpus(tokens): #@save &quot;&quot;&quot;统计词元的频率&quot;&quot;&quot; # 这里的tokens是1D列表或2D列表 if len(tokens) == 0 or isinstance(tokens[0], list): # 将词元列表展平成一个列表 tokens = [token for line in tokens for token in line] return collections.Counter(tokens)def load_corpus_time_machine(max_tokens=-1): #@save &quot;&quot;&quot;返回时光机器数据集的词元索引列表和词表&quot;&quot;&quot; lines = read_time_machine() tokens = tokenize(lines, &#x27;char&#x27;) vocab = Vocab(tokens) print(vocab.idx_to_token) # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落， # 所以将所有文本行展平到一个列表中 corpus = [vocab[token] for line in tokens for token in line] if max_tokens &gt; 0: corpus = corpus[:max_tokens] return corpus, vocabdef seq_data_iter_random(corpus, batch_size, num_steps): #@save &quot;&quot;&quot;使用随机抽样生成一个小批量子序列&quot;&quot;&quot; # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1 corpus = corpus[random.randint(0, num_steps - 1):] # 减去1，是因为我们需要考虑标签 num_subseqs = (len(corpus) - 1) // num_steps # 长度为num_steps的子序列的起始索引 initial_indices = list(range(0, num_subseqs * num_steps, num_steps)) # 在随机抽样的迭代过程中， # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻 random.shuffle(initial_indices) def data(pos): # 返回从pos位置开始的长度为num_steps的序列 return corpus[pos: pos + num_steps] num_batches = num_subseqs // batch_size for i in range(0, batch_size * num_batches, batch_size): # 在这里，initial_indices包含子序列的随机起始索引 initial_indices_per_batch = initial_indices[i: i + batch_size] X = [data(j) for j in initial_indices_per_batch] Y = [data(j + 1) for j in initial_indices_per_batch] yield torch.tensor(X), torch.tensor(Y)def seq_data_iter_sequential(corpus, batch_size, num_steps): #@save &quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot; # 从随机偏移量开始划分序列 offset = random.randint(0, num_steps) num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size Xs = torch.tensor(corpus[offset: offset + num_tokens]) Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens]) Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1) num_batches = Xs.shape[1] // num_steps for i in range(0, num_steps * num_batches, num_steps): X = Xs[:, i: i + num_steps] Y = Ys[:, i: i + num_steps] yield X, Yclass SeqDataLoader: #@save &quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot; def __init__(self, batch_size, num_steps, use_random_iter, max_tokens): if use_random_iter: self.data_iter_fn = seq_data_iter_random else: self.data_iter_fn = seq_data_iter_sequential self.corpus, self.vocab = load_corpus_time_machine(max_tokens) self.batch_size, self.num_steps = batch_size, num_steps def __iter__(self): return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)def load_data_time_machine(batch_size, num_steps, #@save use_random_iter=False, max_tokens=10000): &quot;&quot;&quot;返回时光机器数据集的迭代器和词表&quot;&quot;&quot; data_iter = SeqDataLoader( batch_size, num_steps, use_random_iter, max_tokens) return data_iter, data_iter.vocab 4.2 模型搭建 12345678910111213141516171819202122232425262728293031323334353637383940414243444546## define the RNN layernum_hiddens=256rnn_layer=nn.RNN(len(vocab),num_hiddens)## define the hidden statestate=torch.zeros((1,batch_size,num_hiddens))## define the RNN modelclass RNNmodel(nn.Module): &#x27;&#x27;&#x27;Recurrent nerual netowrk model&#x27;&#x27;&#x27; def __init__(self,rnn_layer,vocab_size,**kwargs): super(RNNmodel,self).__init__(**kwargs) self.rnn=rnn_layer self.vocab_size=vocab_size self.num_hiddens=self.rnn.hidden_size # prepare for the GRU if not self.rnn.bidirectional: self.num_directions=1 self.linear=nn.Linear(self.num_hiddens,self.vocab_size) else: self.num_directions=2 self.linear=nn.Linear(self.num_hiddens*2,self.vocab_size) def forward(self,inputs,state): X=F.one_hot(inputs.T.long(),self.vocab_size) X=X.to(torch.float32) Y,state=self.rnn(X,state) # 转换y为num_steps,batch_size,num_hiddens output=self.linear(Y.reshape((-1,Y.shape[-1]))) return output,state def begin_state(self,device,batch_size=1): if not isinstance(self.rnn,nn.LSTM): return torch.zeros(self.num_directions*self.rnn.num_layers,batch_size,self.num_hiddens,device=device) else: # nn.LSTM is hidden state as dict return (torch.zeros(( self.num_directions*self.rnn.num_layers, batch_size, self.num_hiddens),device=device), torch.zeros((self.num_directions*self.rnn.num_layers, batch_size,self.num_hiddens), device=device )) 4.3 预测与训练 123456789101112131415161718192021222324252627def try_gpu(i=0): #@save &quot;&quot;&quot;如果存在，则返回gpu(i)，否则返回cpu()&quot;&quot;&quot; if torch.cuda.device_count() &gt;= i + 1: return torch.device(f&#x27;cuda:&#123;i&#125;&#x27;) return torch.device(&#x27;cpu&#x27;)device=try_gpu()net=RNNmodel(rnn_layer,vocab_size=len(vocab))net=net.to(device)def predict_ch8(prefix, num_preds, net, vocab, device): #@save &quot;&quot;&quot;在prefix后面生成新字符&quot;&quot;&quot; state = net.begin_state(batch_size=1, device=device) outputs = [vocab[prefix[0]]] get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1)) for y in prefix[1:]: # 预热期 _, state = net(get_input(), state) outputs.append(vocab[y]) for _ in range(num_preds): # 预测num_preds步 y, state = net(get_input(), state) outputs.append(int(y.argmax(dim=1).reshape(1))) return &#x27;&#x27;.join([vocab.idx_to_token[i] for i in outputs])predict_ch8(&#x27;time traveller&#x27;,10,net,vocab,device) 下面选择一个模型就ok # 实际训练过程 # params setting from matplotlib.pyplot import isinteractive # model setting net=RNNmodel(rnn_layer,vocab_size=len(vocab)) net=net.to(device) 12345672. ``` # 第二种GRU num_inputs=len(vocab) gru_layer=nn.GRU(num_inputs,num_hiddens) net=RNNmodel(gru_layer,len(vocab)) net=net.to(device) # 第三种LSTM num_inputs=len(vocab) num_layers=2 lstm_layer=nn.LSTM(num_inputs,num_hiddens,num_layers) net=RNNmodel(lstm_layer,len(vocab)) net=net.to(device) 123456784. ``` # 第四种 Deep-LSTM num_inputs=len(vocab) num_layers=32 lstm_layer=nn.LSTM(num_inputs,num_hiddens,num_layers) net=RNNmodel(lstm_layer,len(vocab)) net=net.to(device) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566num_epochs, lr = 5000, 0.5# loss functionloss=nn.CrossEntropyLoss()# optimer or updaterdef sgd(params, lr, batch_size): &quot;&quot;&quot;Minibatch stochastic gradient descent. Defined in :numref:`sec_utils`&quot;&quot;&quot; with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_()if isinstance(net,nn.Module): # what is for?? updater=torch.optim.SGD(net.parameters(),lr)else: print(&#x27;net is not as nnModule&#x27;) updater=lambda batch_size:sgd(net.params,lr,batch_size)def grad_clipping(net, theta): #@save &quot;&quot;&quot;裁剪梯度&quot;&quot;&quot; if isinstance(net, nn.Module): params = [p for p in net.parameters() if p.requires_grad] else: params = net.params norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params)) if norm &gt; theta: for param in params: param.grad[:] *= theta / normpredict=lambda prefix:predict_ch8(prefix,50,net,vocab,device)use_random_iter=Falsefor epoch in range(num_epoches): state=None res=[] for X,Y in train_iter: if state is None or use_random_iter: state=net.begin_state(batch_size=X.shape[0],device=device) else: if isinstance(net,nn.Module) and not isinstance(state,tuple): state.detach_() else: for s in state: s.detach_() y=Y.T.reshape(-1) X,y=X.to(device),y.to(device) y_hat,state=net(X,state) l=loss(y_hat,y.long()).mean() if isinstance(updater,torch.optim.Optimizer): # judge is handSGD updater.zero_grad() l.backward() grad_clipping(net,1) updater.step() else: # define in d2l.sgd l.backward() grad_clipping(net,1) updater(batch_size=1) res.append(l) print(&#x27;困惑度&#123;&#125;&#x27;.format(str(res[-1]))) 4.5 结果 肯定都能训练出来 使用word的训练时间会大于char很多 给他一个time traveller，可以得到这个： time traveller stooping to light a spill at the fire then he turned lighting his pipe to look at the psychologist s face the psychologist to show that he was not unhinged helped himself to a cigar and tried to light it uncut what is more i have a big machine nearly ----- 时间旅行者弯腰在火上点燃一个溢出物，然后他转动点亮他的烟斗，看着心理学家的脸，心理学家表明他不是不合时宜地帮助自己抽雪茄，并试图点燃它未切割，更重要的是我有一个大机器几乎 深层RNN不一定有效 0x05 Discussion（个人见识） MLP或者CNN有点像顺序结构，RNN有点像循环结构，Attention有点像判断结构 不同结构带来的是不同的感受野，MLP的感受野是个点，CNN的感受野可能是长方形，RNN的感受野可能是很长的序列，Attention则是选择感受野 RNN很土 序列模型——吴恩达深度学习课程笔记（五） 动手学深度学习 Deep learning，lan Goodfellow.etal","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"D2L","slug":"D2L","permalink":"https://blog.tjdata.site/tags/D2L/"}]},{"title":"动手学深度学习04_Attention","slug":"动手学深度学习04_Attention","date":"2022-10-13T02:23:50.000Z","updated":"2023-05-13T13:51:55.258Z","comments":true,"path":"posts/907ab853.html","link":"","permalink":"https://blog.tjdata.site/posts/907ab853.html","excerpt":"","text":"本来就以Attention为基础的Transformer结构很感兴趣，想直接从CNN跳到Attention来学习，但是通过了解一些基本的背景发现并不现实，transformer的提出本来就是在机器翻译的基础上，所以先天的在一些问题场景的解释中并不是以回归数据、或者说二维图像数据，而是基于序列（seq）类型的数据进行解释的，所以需要在了解认清楚seq2seq学习之后才能对attention有一些理解。这次只是对attention作为简单的了解，并对深度学习中一些做出review，来修正自己之前错误的看法以及重建新的世界观。 0x01 什么是Attention（文字版） 1.1 从生物学玄学的说起注意力 attention ​ （很有意思的一段） 注意力是稀缺的，而环境中干扰注意力的信息并不少。比如我们的视觉神经系统大约收到10e8位的信息，远远超过了大脑能够完全处理的水平，但是幸运的是我们的祖先已经通过经验认识到“并非感官的所有输入都是一样的”，在整个人类历史中，这种将注意力引向感兴趣的一部分信息的能力使得我们的大脑能够更加明智地分配资源来生存、成长和社交，例如发现天敌、找寻食物或者伴侣 生物学中常见的利用双组件（tow- component）来解释注意力，将注意力划分为两类： 非自发：单纯的根据观察到的”数据“来确定你所注意的的东西，比如桌子上有试卷、可乐、游戏机、一个钥匙和一个活动的公鸡；你可能最先关注的鸡 自发性：在自我意识的控制下来选择关注合适的元素，比如上述如果你是为了寻找一个钥匙而来，那么你就会将注意力专注到对应的元素中。 1.2 害死人的Q（query）、K（key）、V（value） 这里的起源利用另外一种Notation来表述，定义如下： query：自主性提示成为query key：自主性提示 attention pooling：注意力汇聚，将 选择（output）引导感官输入 感官输入称为value，每一个value都与一个key匹配 1.4 利用找书小故事来解释QKV模型（个人猜想！） 我们将图书馆里面所有的书称为Key，每个书可能会对应不同的value（看或者不看）；当我们有自己的query（想看交通方面的书），就会将query对不同的key进行attention pooling，这样output就是与交通相关的书才会看，与交通不相关的书不看。 1.5 从机器学习里的{x(i),y(i)}i=1,...n\\{x^{(i)},y^{(i)}\\}i=1,...n{x​(i)​​,y​(i)​​}i=1,...n来看（个人猜想！） 其中的XXX相当于Key，yyy相当于Value 当我们对一个新的xxx预测的时候相当于是对这个发出query，这个时候我们会怎么样？ 首先根据xxx与X=x(i)i=1...nX={x^{(i)}}i=1...nX=x​(i)​​i=1...n进行attention score的计算，然后再归一化（比如softmax） 之后再利用归一化的结果作为 权重 来拟合得到output 这里与线性回归的区别在于权重的确定和使用上，线性回归的权重是严格推导并使用在X的不同特征上，而attention的权重是通过学习并使用在X（key）对应的y（value） 同时这里的attention value的权重可以是通过学习，也可以是通过人为定义来得到的，因为我们采用的vector形式的学习，因此我们可以使用kernel function或者线性空间一些距离度量来作为计算方式，在后续进化版的升级中，我们可能会会有其他score的度量，比如书与书之间是好度量的，但是说的话和书之间如何度量？ 0x02 可视化Attention 接着上述的1.5我们可以看出《D2L》书中介绍Nadaraya- Watson核回归，只不过其中的attention score 的计算方式是用核机器；幸运的是我们在SVM里面已经初步了解过，它只是一种将低纬度的向量距离投射到高纬度，比如我们可以采用Gaussian Kernel K(X1,X2)=1(2∗π)∗exp(−(X1−X2)22)K(X1,X2)=\\frac{1}{\\sqrt(2*\\pi)}*exp(-\\frac{(X1-X2)^2}{2}) K(X1,X2)=​√​(​​​2∗π)​​1​​∗exp(−​2​​(X1−X2)​2​​​​) 这样取评价之后就可以得到我们对于新的query的x的预测为 y¯=Σi=1nexp(−0.5(x−xi)2)Σj=1j=nexp(−0.5(x−xj)2)yi\\bar y=\\Sigma_{i=1}^n\\frac{exp(-0.5(x-x_i)^2)}{\\Sigma_{j=1}^{j=n} exp(-0.5(x-x_j)^2)}y_i ​y​¯​​=Σ​i=1​n​​​Σ​j=1​j=n​​exp(−0.5(x−x​j​​)​2​​)​​exp(−0.5(x−x​i​​)​2​​)​​y​i​​ 这里取的就是按照一种高斯距离，离的越近越好，如果按照这个方式得到的attention score可以看出近大远小的特点。 但是另外一种我们希望可以对于不同query具有不同的高斯函数的宽度，也就是我们希望方差不一样 y¯=Σi=1nexp(−0.5w(x−xi)2)Σj=1j=nexp(−0.5w(x−xj)2)yi\\bar y=\\Sigma_{i=1}^n\\frac{exp(-0.5w(x-x_i)^2)}{\\Sigma_{j=1}^{j=n} exp(-0.5w(x-x_j)^2)}y_i ​y​¯​​=Σ​i=1​n​​​Σ​j=1​j=n​​exp(−0.5w(x−x​j​​)​2​​)​​exp(−0.5w(x−x​i​​)​2​​)​​y​i​​ 这样对于不同的value就会有不同的权重（注意这里的权重值得不是w），指的是利用w计算出来的attention score 0x03 对于attention的初识 所以attention是啥，如果利用QKV的角度来看比较复杂，如果从简单的回归问题角度来看它只是另外一种计算权重方式的函数。 但是！attention的作用不仅局限于回归问题，它从seq问题中而来，解决的就是CNN或者RNN对于距离的敏感性。 就像CNN的感受野，对于单层感受野可能是固定好的（与kernel size、padding、step有关），但是多层累积中感受野是可以逐渐扩大的。但是CNN适用于图像的可能解释是一，图像的维度是固定size的（像素无论多大都是有限的） 而RNN的感受野，借鉴被人的说法是取决于词元模型和hidden layer，但是由于hidden layer也是具有顺序的特征，它的感受野也不会传递的太远。 attention利用attention socre对不同的key进行筛选，来得到一个足够远但是量不大的感受野。选择重要的数据。 同时在Attention中关于attention score的计算过程中，由于没有接触过seq2seq模型，在后面的计算中可能需要了解之后才能有更近一步的认识。目前的理解是利用一种可学习的方式来得到合理的attention score的计算方式。 flag： 看懂RNN、GRU、LSTM 明白seq2seq框架，encoder- decoder的框架 0x04 Discussion 4.1 一致记号的重要性 还是很喜欢CS229的讲义中Notation一致性的思考，这样前后的公式推导会很清晰，在解释问题中会有一致性 D2L中沐神讲的真的很好，但是在写作中似乎还是缺少这种基本的素养。这样的素养对于大佬是锦上添花，但是对于初学者是保证不出错的围栏。 4.2 模拟（print）的重要性 对于不同的抽象问题，利用具体的东西打印出来一步一步就好了。尤其是向量的每一步的size 4.3 ML&amp;DL的一些思考 可能是沿着D2L书的缘故，对深度学习的认识过程是从MLP到CNN/GCN到RNN到Transformer，可能还有其他的，这样网络结果一样但又似乎不太一样，主要对特征提取方式上。 下面这张图可能内容不对或者不全，但是分类的思路从学习的角度还是有益的","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"D2L","slug":"D2L","permalink":"https://blog.tjdata.site/tags/D2L/"}]},{"title":"强化学习01_基本概念","slug":"强化学习01_基本概念","date":"2022-09-30T08:02:58.000Z","updated":"2023-05-13T13:52:18.553Z","comments":true,"path":"posts/3e3a5c92.html","link":"","permalink":"https://blog.tjdata.site/posts/3e3a5c92.html","excerpt":"初始强化学习最难的地方在于晦涩的专业词汇以及复杂的数学推导；同时深度强化学习并不是强化学习的终点，在这个过程中依旧需要human在其中扮演的地方。这里浅薄看蘑菇书来了解。主要作为了解强化学习的基本概念，希望从随机过程出发，来给出强化学习中智能体agent与环境 env之间的基本概念","text":"初始强化学习最难的地方在于晦涩的专业词汇以及复杂的数学推导；同时深度强化学习并不是强化学习的终点，在这个过程中依旧需要human在其中扮演的地方。这里浅薄看蘑菇书来了解。主要作为了解强化学习的基本概念，希望从随机过程出发，来给出强化学习中智能体agent与环境 env之间的基本概念 0x01 随机过程的基础 概率论和应用统计是研究概率论中多个随机事件所构成的具有一般性规律的学科；而随机过程则是对这个过程进行描述。 1.1 马尔可夫过程 MP- Markov process 马尔可夫性质指的是一个随机过程在给定现在状态和所有过去状态的情况下，未来分布概率仅依赖于当前的状态；也就是在知道当前的状态，将来与未来是独立的 P(XT+1=xt+1∣X0=x0,x1=x1,...,XT=xt)=P(XT+1=xt+1∣XT=xt)P(X_{T+1}=x_{t+1}|X_0=x_0,x_1=x_1,...,X_T=x_t)=P(X_{T+1}=x_{t+1}|X_T=x_t) P(X​T+1​​=x​t+1​​∣X​0​​=x​0​​,x​1​​=x​1​​,...,X​T​​=x​t​​)=P(X​T+1​​=x​t+1​​∣X​T​​=x​t​​) 如果一个随机过程是离散的，可以被称为马尔可夫链（Markov chain） 在这个过程中我们看到不同状态之间的概率转换 1.2 马尔可夫奖励过程-MRP- Markov reward- process 在上述马尔可夫链的基础上，我们引入一个新的概念： 奖励- reward function：是一个期望，表示我们到达某个过程能够获得的最大的奖励，通常用horizon表示有个回合的长度，那么在奖励的基础上我们可以得到随机过程序列的回报 回报- return Gt=rt+1+γ∗rt+2+γ2∗rt+3+...G_t=r_{t+1}+\\gamma*r_{t+2}+\\gamma^2*r_{t+3}+...G​t​​=r​t+1​​+γ∗r​t+2​​+γ​2​​∗r​t+3​​+... 这里的γ\\gammaγ代表折扣系数；这个位置是表示这个一系列的随机过程所带来的回报，但是通常为收敛会规定 回报- return的长度来；在回报- return的基础上我们可以得到每个状态- state的价值- value；也就是回报- return的期望就是价值 V(ST)=E(GT∣ST=st)V(S_T)=E(G_T|S_T=s_t) V(S​T​​)=E(G​T​​∣S​T​​=s​t​​) 这里有待讨论，感觉和高中物理中的万有引力与势能很相似 关于价值- value的求解会有很多方法 利用定义，遍历多种状态得到value 利用蒙特卡洛MC随机采样的方法 利用Bellman equation得到解析解 其他的方法，比如TD learning等 1.25关于MRP贝尔曼方程求解 太菜了，所以用手写，这样我们看出MRP重点是在知道转移概率P和各状态奖励reward以及折扣因子γ\\gammaγ的基础上，求解出状态的价值（用不同的方法） 1.3 马尔可夫决策过程-MDP-Markov- decision- process MRP在MP中增加来 “奖励reward、回报return和价值value”，MDP则是继续在MRP的基础中增加动作项目action π(a∣s)=P(AT=at∣ST=st)\\pi(a|s)=P(A_T=a_t|S_T=s_t) π(a∣s)=P(A​T​​=a​t​​∣S​T​​=s​t​​) 这里的π\\piπ称为是策略，在这个基础上，下一个状态应该取决于当前的状态和动作 P(ST+1∣ST,AT)=P(ST+1∣hT,aT)P(S_{T+1}|S_T,A_T)=P(S_{T+1}|h_T,a_T) P(S​T+1​​∣S​T​​,A​T​​)=P(S​T+1​​∣h​T​​,a​T​​) 同样 奖励reward 的定义也会更加复杂 R(ST=st)=E(rt[ST=st,At=a])R(S_T=s_t)=E(r_t[S_T=s_t,A_t=a]) R(S​T​​=s​t​​)=E(r​t​​[S​T​​=s​t​​,A​t​​=a]) 2022-09-30 这部分后面就不太懂啦～～未完待续 1.4 举个例子 计算状态 比如状态空间包括{wechat；class1;class2;class3;sleep;pass;pub} 之间的状态概率为 不同状态的reward是 利用贝尔曼方程就可以得到最终的value结果 1.5 MDP的核心问题 虽然2022-09-30还没有搞懂MDP的数学过程，但是可以看出起核心的问题包括 【预测】与【控制】 预测就是给出 state、action、P、R与policy来得到每个状态的value 控制就是给出state、action、P、R来得到value与policy 在求解中常分为 策略迭代policy- iteration与价值迭代 value- iteration 细节后面在了解 0x02 强化学习概述 最经典就是这样的图，强化学习的过程可以看作是实际化的MDP过程；我们可以知道我们将问题分为 智能体agent与环境env两部分；状态state与奖励reward由env给出；agent会根据状态与奖励来实现不同的动作action（动作序列也就是需要学习的策略policy），再得到下一个状态以及当前状态得到的奖励 0x03 强化学习与监督学习 3.1 监督学习 我们首先假设我们有大量被标注的数据，假设之间满足同分布，之间是没有关联的。在这个基础上我们训练我们的模型（比如一个分类器），我们可能通过将标签信息传递给神经网络，当神经网络做出错误的预测的时候我们会给他一个错误的反馈，我们利用这个错误写出一个 损失函数 loss- function，通过 反向传播 back propagate来训练 假设1:输出的数据应该是没有关联的 假设2:我们需要告诉学习正确的标签是什么，这样它可以通过正确的标签来修正自己的预测 3.2 强化学习 在强化学习中，监督学习的上述的两个假设都不满足 每个frame之间具有非常强的连续性，同时没有iid 强化学习中得到的训练数据是一个玩游戏的序列，我们将这个序列放进网络、希望网络输出一些动作，在这个问题中我们并没有标签来说明现在这个动作是正确的还是i错误的，必须等到游戏结束才能知道，因此这里我们面临 [[延迟奖励delayed- reward]] 的问题 3.3 区别总结 第一点，强化学习输入的样本是序列数据，不是iid 第二点，学习器并没有告诉我们每一步正确的动作应该是什么，学习器需要自己去发现那细微动作可以带来最多的奖励 第三点，智能体获得自己能力的过程就是 [[不断试错探索trial-and-error- exploration]]的过程， 探索exploration 和 利用exploitation 第四点，在强化学习过程中并没有非常强的 监督者supervisor ，只有 [[奖励信号reward- signal]]，并且具有 [[延迟奖励delayed- reward]] 的情况 0x04 序列决策 4.1 奖励 reward的定义 是环境给的一种 [[标量反馈信号-scalar-feedback-signal]]，这种信号显示智能体在某一步才去某个策略的表现如何 4.2 序列过程描述 强化学习中一个重要的课题就是近期奖励和远期奖励的权衡，也就是如何让智能体可以获得更多的远期奖励 在与环境的交互过程中， [[智能体agent]] 会获得很多 [[观测observation]] ，针对每个 [[观测observation]] ， [[智能体agent]]会采取一个 [[动作action]]，然后获得 [[奖励reward]]，所以这样的序列是 Ht=o1,a1,r1,...,ot,at,rtH_t=o_1,a_1,r_1,...,o_t,a_t,r_t H​t​​=o​1​​,a​1​​,r​1​​,...,o​t​​,a​t​​,r​t​​ [[智能体agent]]在采取当前动作的时候会依赖之前得到的历史，因此可以将整个学习的[[状态state]]看作是这个历史的函数 st=f(Ht)s_t=f(H_t) s​t​​=f(H​t​​) 4.3 观测 observation 与 状态state区别 4.4 动作action 分为离散与连续 4.5 智能体分类 第一种分类： 基于policy划分；随机与确定 基于value- function；value或Q函数 模型model；模型决定下一步的状态，状态取决于当前的状态以及当前采取的动作，由 [[状态转移概率]]和 [[奖励函数]]组成 第二种分类： 基于价值的智能体 基于策略的智能体 演员评论员智能体","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"蘑菇书","slug":"蘑菇书","permalink":"https://blog.tjdata.site/tags/%E8%98%91%E8%8F%87%E4%B9%A6/"}]},{"title":"动手学深度学习03_经典卷积神经网络实现","slug":"动手学深度学习03_经典卷积神经网络实现","date":"2022-09-23T08:12:59.000Z","updated":"2023-05-13T13:51:52.377Z","comments":true,"path":"posts/d43999e4.html","link":"","permalink":"https://blog.tjdata.site/posts/d43999e4.html","excerpt":"在初等卷积神经网络中，我们可以看出从平移不变和缩放不变性质而得到的卷积性质的基础上，在上个世纪诞生的LeNet成功实现与之前不同的路径，在GPU诞生之后，新的网络AlexNet、VGG、NiN、GoogLeNet、Residual Net、DenseNet逐渐发展。卷积神经网络从变深变多，逐渐到变成块以及一些trick的增加。","text":"在初等卷积神经网络中，我们可以看出从平移不变和缩放不变性质而得到的卷积性质的基础上，在上个世纪诞生的LeNet成功实现与之前不同的路径，在GPU诞生之后，新的网络AlexNet、VGG、NiN、GoogLeNet、Residual Net、DenseNet逐渐发展。卷积神经网络从变深变多，逐渐到变成块以及一些trick的增加。 0x01 introduction 1.1 PyTorch 之前在讲座中听到深度学习框架是深度学习时代的操作系统，怎么说这个比喻有点粗旷但是又不失正确性。个人感觉在计算机时代人们协作的能力达到空前的地步，我们可以上千人共同开发app，这种和建造房屋似的过程充分体现了软件工程的魅力。与土建中规划、设计、建造、 验收等流程相似，个人验证计算机成就的结果是建立在一层一层的抽象的基础上的。 从硬件的角度，现在并不是所有人都需要关心芯片上的三极管，也不需要关心加法器的构成。从之前手工焊机，到芯片的模块化设计，到更高级的抽象工艺和建造工艺的诞生，人们设计更高水平的芯片产生了可能。正是有这些抽象我们才能往前走。 从深度学习框架的角度也是如此，从零实现某个网络在学习过程是有意思的，但是从汇编语言包装成高级编程语言，再包装成一个一个package而形成框架，在前人抽象好的基础上，在深度学习框架搭建的基础上，在使用者的角度更应该重视如何高效的使用。 基于torch构建的PyTorch便是抽象好深度学习的框架。 这里并没有参照 PyTorch官网 而是找到一个开源的 PyTorch中文手册 来了解这个深度学习框架 123456789Torch is not going anywhere. PyTorch and Torch use the same C libraries that contain all the performance: TH, THC, THNN, THCUNN and they will continue to be shared.We still and will have continued engineering on Torch itself, and we have no immediate plan to remove that.PyTorch is an open source machine learning library for Python, based on Torch, used for applications such as natural language processing. It is primarily developed by Facebook&#x27;s artificial-intelligence research group, and Uber&#x27;s &quot;Pyro&quot; software for probabilistic programming is built on it.PyTorch is a Python package that provides two high-level features: Tensor computation (like NumPy) with strong GPU acceleration Deep neural networks built on a tape-based autograd systemYou can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed. 1.2 GPU 这里参照wiki所给的解释：图形处理器GPU解释 图形处理器（英语：Graphics Processing Unit，缩写：GPU；又称显示核心、显卡、视觉处理器、显示芯片或绘图芯片）是一种专门在个人电脑、工作站、游戏机和一些移动设备（如平板电脑、智能手机等）上执行绘图运算工作的微处理器。 GPU不同于传统的CPU，如Intel i5或i7处理器，其内核数量较少，专为通用计算而设计。相反，GPU是一种特殊类型的处理器，具有数百或数千个内核，经过优化，可并行运行大量计算。虽然GPU在游戏中以3D渲染而闻名，但它们对运行分析、深度学习和机器学习算法尤其有用。GPU允许某些计算比传统CPU上运行相同的计算速度快10倍至100倍。 1.3 数据集输入和结果计算 12345678910111213141516171819202122# 读取fashion数据集def load_fashion_mnist(batchsize,resize=None): # resize相当于基本的填充模块 import torch from torch.utils import data import torchvision from torchvision import transforms if resize: trans=[transforms.ToTensor()] trans.insert(0, transforms.Resize(resize)) trans = transforms.Compose(trans) else: trans=transforms.ToTensor() train_mnist=torchvision.datasets.FashionMNIST(root=&#x27;../data/FashionMNIST&#x27;,train=True,transform=trans,download=True) test_mnist=torchvision.datasets.FashionMNIST(root=&#x27;../data/FashionMNIST&#x27;,train=False,transform=trans,download=True) train_iter=data.DataLoader(train_mnist,batch_size=batchsize,shuffle=True,num_workers=4) test_iter=data.DataLoader(test_mnist,batch_size=batchsize,shuffle=True,num_workers=4) return train_iter,test_iter batchsize=256train_iter,test_iter=load_fashion_mnist(batchsize,224) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import torchdef accuracy(y_hat,y): # 数正确的数量 if len(y_hat.shape)&gt;1 and y_hat.shape[1]&gt;1: y_hat=y_hat.argmax(axis=1) cmp=y_hat.type(y.dtype)==y return float(cmp.type(y.dtype).sum())def gpu_acc(model,data_iter,device=None): acc=0 num=0 if isinstance(net,nn.Module): net.eval() if not device: device=next(iter(net.parameters())).device with torch.no_grad(): for X,y in data_iter: if isinstance(X,list): # 这里的if仅仅是为之后bert微调所需的 X=[x.to(device) for x in X] else: X=X.to(device) y=y.to(device) acc+=accuracy(net(X),y) num+=y.numel() return acc/numdef trainer(net,train_iter,test_iter,num_epoches,lr,device): &#x27;&#x27;&#x27;用GPU训练模型&#x27;&#x27;&#x27; #初始化参数 def init_weights(m): if type(m)==nn.Linear or type(m)==nn.Conv2d: nn.init.xavier_uniform_(m.weight) #nn.init.normal_(m.weight,std=0.01) net.apply(init_weights) print(&#x27;training on&#x27;,device) # print(torch.cuda.get_device_name(0)) net.to(device) optimizer=torch.optim.SGD(net.parameters(),lr=lr) loss=nn.CrossEntropyLoss() train_acc=[] test_acc=[] loss_epoches=[] for epoch in range(num_epoches): temp_train_acc=0 loss_epoch=0 num=0 net.train() for i,(X,y) in enumerate(train_iter): optimizer.zero_grad() X,y=X.to(device),y.to(device) with torch.no_grad(): temp_train_acc+=accuracy(net(X),y) y_hat=net(X) l=loss(y_hat,y) l.backward() optimizer.step() loss_epoch+=l*X.shape[0] num+=y.numel() train_acc.append(float(temp_train_acc/num)) test_acc.append(gpu_acc(net,test_iter)) loss_epoches.append(float(loss_epoch)/num) print(&#x27;本轮&#123;&#125;训练的结果，test—acc:&#123;&#125;,train-acc:&#123;&#125;,train-loss:&#123;&#125;&#x27;.format(str(epoch+1),str(test_acc[-1]),str(train_acc[-1]),str(loss_epoches[-1]))) import matplotlib.pyplot as plt plt.plot(list(range(1,1+num_epoches)),test_acc,label=&#x27;test_acc&#x27;) plt.plot(list(range(1,1+num_epoches)),train_acc,label=&#x27;train_acc&#x27;) plt.plot(list(range(1,1+num_epoches)),loss_epoches,label=&#x27;loss&#x27;) plt.legend() plt.show() lr,num_epoches=0.2,20device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)trainer(net,train_iter,test_iter,num_epoches,lr,device) 0x02 经典的CNN 2.1 AlexNet 之前的阅读笔记paper02-2012-imagenet-classification-with-deep-convolutional-neural-networks 主要的贡献，以及后面没有用的地方 引入了ReLu激活函数，让训练的更快 利用双GPU训练，注意这里对网络结构进行划分（对网络不同层进行切割而不是切割成两种小的部分），工程能力太强了 （没有用）一种local response normalization，但是确实需要在这个方面做trick，在后面的resNet中可以看到 （没有用）新的overlapping pooling，一种新的池化方法，这个与双GPU有关 （有用，但是解释不对）将dropout引入训练过程，尝试解释为ensemble learning，但现在更偏向于regularization 数据增强，才有随机抽样数据的方式，将256提取得到224来扩充数据集 123456789101112131415161718192021222324252627import torch from torch import nn#AlexNetnet = nn.Sequential( # 这里，我们使用一个11*11的更大窗口来捕捉对象。 # 同时，步幅为4，以减少输出的高度和宽度。 # 另外，输出通道的数目远大于LeNet nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2), # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数 nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2), # 使用三个连续的卷积层和较小的卷积窗口。 # 除了最后的卷积层，输出通道的数量进一步增加。 # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度 nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(), # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合 nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(p=0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5), # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000 nn.Linear(4096, 10)) 2.2 VGG VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION AlexNet证明 #卷积神经网络 CNN convolutional- neural-network 的深度是有效的，但并没有给出模版来进行创建网络。这里一个直觉的想法 与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构设计也逐渐变成更加抽象，研究人员开始从单个神经元的角度思考问题，发展到整个层，转向可以复用层的块的模式 #memo 使用 #循环loop 和 子函数 来实现 #VGG 主要做出的贡献 利用复用的思路构建卷积块 作者尝试各种架构，最终发现深且窄的网络效果是较好的 12345678910111213141516171819202122232425262728293031import torch from torch import nndef vgg_block(num_convs, in_channels, out_channels): layers = [] for _ in range(num_convs): layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)) layers.append(nn.ReLU()) in_channels = out_channels layers.append(nn.MaxPool2d(kernel_size=2,stride=2)) return nn.Sequential(*layers)def vgg(conv_arch): conv_blks = [] in_channels = 1 # 卷积层部分 for (num_convs, out_channels) in conv_arch: conv_blks.append(vgg_block(num_convs, in_channels, out_channels)) in_channels = out_channels return nn.Sequential( *conv_blks, nn.Flatten(), # 全连接层部分 nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 10))conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))ratio = 4small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]net = vgg(small_conv_arch) 2.3 NiN Network in network AlexNet提出使用深度卷积神经网络，VGG给出如何复用的构建卷积神经网络，VGG则是在这个基础上利用MLP对多通道输入和多通道输出进行操作，取代之前简单的加权方式，NiN利用这来对网络的扩大和深度。 2.4 GoogLeNet Going deeper with convolutions GoogLeNet借用NiN的思想，在它的基础上设置来inception块，用来实现多个卷积核对图形特征的提取 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 网络3.5 GoogLeNetimport torchfrom torch import nnfrom torch.nn import functional as Fclass Inception(nn.Module): # c1--c4是每条路径的输出通道数 def __init__(self, in_channels, c1, c2, c3, c4, **kwargs): super(Inception, self).__init__(**kwargs) # 线路1，单1x1卷积层 self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1) # 线路2，1x1卷积层后接3x3卷积层 self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1) self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1) # 线路3，1x1卷积层后接5x5卷积层 self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1) self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2) # 线路4，3x3最大汇聚层后接1x1卷积层 self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1) def forward(self, x): p1 = F.relu(self.p1_1(x)) p2 = F.relu(self.p2_2(F.relu(self.p2_1(x)))) p3 = F.relu(self.p3_2(F.relu(self.p3_1(x)))) p4 = F.relu(self.p4_2(self.p4_1(x))) # 在通道维度上连结输出 return torch.cat((p1, p2, p3, p4), dim=1)b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1), nn.ReLU(), nn.Conv2d(64, 192, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32), Inception(256, 128, (128, 192), (32, 96), 64), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64), Inception(512, 160, (112, 224), (24, 64), 64), Inception(512, 128, (128, 256), (24, 64), 64), Inception(512, 112, (144, 288), (32, 64), 64), Inception(528, 256, (160, 320), (32, 128), 128), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128), Inception(832, 384, (192, 384), (48, 128), 128), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10)) 2.5 ResNet Deep Residual Learning for Image Recognition 在之前介绍更深、更广的基础上，resnet更多的是解释如何提高神经网络的性能 部分的数学基础，从学习理论的角度出发，如果模型的复杂程度逐渐增加，这样寻找之前的函数集合的范围是比较大，这样寻找到之后的结果是非常困难的，因此可以尝试将恒等映射转换成为包含数量本身和残差之间的关系 借鉴GBDT中梯度提升的思想，残差问题在现实中往往更加容易优化，同时在模型为理想参数更容易捕捉恒等映射的细微波动，；在实际训练中，残差块中输入可以通过跨层数据线路更快的向前传播 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lclass Residual(nn.Module): #@save def __init__(self, input_channels, num_channels, use_1x1conv=False, strides=1): super().__init__() self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1, stride=strides) self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1) if use_1x1conv: self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides) else: self.conv3 = None self.bn1 = nn.BatchNorm2d(num_channels) self.bn2 = nn.BatchNorm2d(num_channels) def forward(self, X): Y = F.relu(self.bn1(self.conv1(X))) Y = self.bn2(self.conv2(Y)) if self.conv3: X = self.conv3(X) Y += X return F.relu(Y)b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))def resnet_block(input_channels, num_channels, num_residuals, first_block=False): blk = [] for i in range(num_residuals): if i == 0 and not first_block: blk.append(Residual(input_channels, num_channels, use_1x1conv=True, strides=2)) else: blk.append(Residual(num_channels, num_channels)) return blkb2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))b3 = nn.Sequential(*resnet_block(64, 128, 2))b4 = nn.Sequential(*resnet_block(128, 256, 2))b5 = nn.Sequential(*resnet_block(256, 512, 2))net = nn.Sequential(b1, b2, b3, b4, b5, nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10)) 2.6 DenseNet Densely Connected Convolutional Networks ～还没看不重要捏 0x03 Result 0x04 Discussion 卷积神经网络提取特征的基本在于特征的平移不变和缩放不变，在这个基础上利用互相关操作（错误的被称为卷积）在提取特征。同时在这个过程中围绕了如何构建深度卷积神经网络，主流的blakcbone给出自己自己的发展历史： lenet最早给出卷积神经网络的雏形 alexnet从训练硬件、训练网络、训练数据、数据预处理、训练过程多个方面给出了自己的trick，为后面打下基础 vgg围绕如何构建更深的网络，引入复用 nin提出一个trick来构建更广的网络 Googlenet在nin的基础上，受启发采用多个卷积核提取特征 在前人构建好完整的网络的基础上，resnet给出如何保持网络稳定性的方法 densenet还没有了解 这个过程非常的有意思，可以看到别人是如何前进的。这些都归功李沐老师的总结！","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"D2L","slug":"D2L","permalink":"https://blog.tjdata.site/tags/D2L/"}]},{"title":"动手学深度学习02_初等卷积神经LeNet实现","slug":"动手学深度学习02_初等卷积神经LeNet实现","date":"2022-09-16T14:41:17.000Z","updated":"2023-05-13T13:51:49.580Z","comments":true,"path":"posts/c3baf47e.html","link":"","permalink":"https://blog.tjdata.site/posts/c3baf47e.html","excerpt":"上一篇文章中介绍一个基本的机器学习模型线性回归实现的整个过程，将其步骤分为八个部分。之后D2L中介绍了soft Max、MLP等简单的模型。这里迈向深度学习，利用简单的卷积神经网络来介绍深度学习API的使用过程，从零开始搭建模型，将其分为数据集预处理、构建模型和训练及评估三个步骤。","text":"上一篇文章中介绍一个基本的机器学习模型线性回归实现的整个过程，将其步骤分为八个部分。之后D2L中介绍了soft Max、MLP等简单的模型。这里迈向深度学习，利用简单的卷积神经网络来介绍深度学习API的使用过程，从零开始搭建模型，将其分为数据集预处理、构建模型和训练及评估三个步骤。 0x01 Introduction of CNN 1.1 卷积的由来 我们可以将MNIST数据集中的输入变量（28，28）的二维张量给展平（flatten）成为784的向量，然后在使用足够深的MLP来进行训练，但是这样造成最直观的结果就是模型的参数会直线上升，因为我的输入足够多，同时为希望模型结果好的情况需要也需要足够深，这样造成训练过程的计算开销是巨大的。（这是很直观的，但是理论上这样训练出来的网络会非常好。可能是这样？） 为了弥补算力的不足，需要寻找新的方式？分析图像识别中目标我们会看出具有两个基本特性： 平移不变性translating- invariance，不管检测对象出现在图像的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应 局部性locality，神经网络前几层应该只探索输入图像中的局部区域，而不是过度在意整个图像其他区域的关系 同时在信号处理中我们也有会滤波器的概念，其基本思想是利用像素之间变化的趋势来进行处理，比如中值滤波可以降噪、利用差分可以识别图像轮廓 我们可以看出卷积的操作是有效的，同时使用（3，3）的filter来对（28，28）的图像处理最终得到（26，26）的图像，执行的操作次数仅为26*26.会让参数数量下降 1.2 卷积的实现（互相关运算、填充padding、步长stride、多通道） 具体公式就不再这里展开，dddd。 经过下列的二维卷积操作会将（n，m）经过（k，k）转换为大小（n+1-k，m+1-k） 1234567891011121314151617class Conv2D(nn.module): def __init__(self,kernel_size): super().__init__() self.weight=nn.Parameter(torch.rand(kernel_size)) self.bias=nn.Parameter(torch.zeros(1)) def forward(self,x): return corr2d(x,self.weight)+self.bias def corr2d(X,k): ‘’‘计算二维互相关运算``` h,w=k.shape Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i,j]=(X[i:i+h,j:j+w]*K).sum() return Y 直接进行卷积操作可以看出向量是会变化的，我们还会有两种操作：填充padding和步长stride。 针对二维的图像边缘，我们通常需要设置填充padding来保留周边信息，通常是填充0 （n,m)经过（k，k）后，填充p，得到的结果为（n+p+1-k，m+p+1-k） 针对清晰度不够的照片，我们可能认为其中部分像素冗余，因此可以利用步幅stride来降低采样 （n，m）经过（k，k）加上p之后s的输出是（（n+p-k+s）//s，（m+p-k+s）//s ）（向下取整） 在二维基础上，理解多通道卷积，首先是多通道输出一个的情况，就是设计三个卷积核然后相加 然后多通道输入对应多通道输出，就是设计output*input个卷积核，然后output的卷积核相加即可 1.3 CNN与深度之间的关系（感受野 receptive- field、汇聚层pooling） CNN中感受野的问题，对于一个（3，3）所感受的是一个（3，3）的区域，但是如果再有一个（3，3）他所感受的就是（5，5）的区域。因此随着卷积层数的增加，卷积神经考虑到的值是越来越大的。 这里也会存在一个trade-off，我们希望卷积的结果感受野不会太小，这样我可以得到一些纹理信息，但是我们也不希望感受野太大，不然所训练出来的CNN会对输入敏感，因此在常见的操作中我们会使用汇聚层来对卷积结果进行平滑或者重新采样。 0x02 Program structure analysis with PyTorch API 2.1 代码整体框架分析（尽可能解耦） 首先神经网络的训练必然是需要多个epoch的，同时在每轮epoch中由于物理空间的限制，我们需要设置batchsize来分批的将数据送入网络，当所有的batch走完说明我们完成一个epoch，这个时候需要记录训练损失（train-loss），训练精度（train-acc）和验证精度（valid- acc）。所以步骤分为： 第一部分 输入：原始数据集，batchsize 输出：训练数据集（可迭代形式）、验证数据集（可迭代形式） 第二部分 输入：网络结构、学习率lr 输出：网络结构net、损失函数loss、优化算法trainer 第三部分 输入：epoch数量num- epoches，训练数据集、验证数据集、net、loss、trainer等 输出：训练好的网络，评估指标 2.2 PyTorch高效API 这个看官网，或者看别人的代码多悟就行 加载数据集 dataset dataloader 定义网络 torch.nn.module Torch.nn.sequential 访问与初始化参数 net.apply() def init_weigths(self) 0x03 Code of LeNet 3.0 LeNet简介 LeNet是最早发布的卷积神经网络，起源于89年，在当时还没有强算力的时代，被广泛应用于ATM机器中，帮助处理支票中的数字 这里因为Fashion-MNIST是（28，28）的数据集，因此在这个基础上稍微更改一下 各层参数设置： 输入：（28，28） 第一层：（5，5）卷积，输出6通道，填充=2 -&gt;输出（6，28，28） 第二层：（2，2）池化，步长=2 -&gt; 输出（6，14，14） 第三层：（5，5）卷积，输出16通道，-&gt;输出（16，10，10） 第四层：（2，2）池化，步长=2 -&gt;输出（16，5，5） 之后展平 3.1 数据集获取 12345678910111213141516# 读取fashion数据集def load_fashion_mnist(batchsize): import torch from torch.utils import data import torchvision from torchvision import transforms trans=transforms.ToTensor() train_mnist=torchvision.datasets.FashionMNIST(root=&#x27;../data/FashionMNIST&#x27;,train=True,transform=trans,download=True) test_mnist=torchvision.datasets.FashionMNIST(root=&#x27;../data/FashionMNIST&#x27;,train=False,transform=trans,download=True) train_iter=data.DataLoader(train_mnist,batch_size=batchsize,shuffle=True,num_workers=4) test_iter=data.DataLoader(test_mnist,batch_size=batchsize,shuffle=True,num_workers=4) return train_iter,test_iter batchsize=256train_iter,test_iter=load_fashion_mnist(batchsize) 3.2 模型定义 123456789101112import torch from torch import nnnet=nn.Sequential( nn.Conv2d(1,6,kernel_size=5,padding=2),nn.Sigmoid(), nn.AvgPool2d(kernel_size=2,stride=2), nn.Conv2d(6,16,kernel_size=5),nn.Sigmoid(), nn.AvgPool2d(kernel_size=2,stride=2), nn.Flatten(), nn.Linear(16*5*5,120),nn.ReLU(), nn.Linear(120,84),nn.ReLU(), nn.Linear(84,10)) 3.3 训练过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879def accuracy(y_hat,y): # 数正确的数量 if len(y_hat.shape)&gt;1 and y_hat.shape[1]&gt;1: y_hat=y_hat.argmax(axis=1) cmp=y_hat.type(y.dtype)==y return float(cmp.type(y.dtype).sum())def gpu_acc(model,data_iter,device=None): acc=0 num=0 if isinstance(net,nn.Module): net.eval() if not device: device=next(iter(net.parameters())).device with torch.no_grad(): for X,y in data_iter: if isinstance(X,list): # 这里的if仅仅是为之后bert微调所需的 X=[x.to(device) for x in X] else: X=X.to(device) y=y.to(device) acc+=accuracy(net(X),y) num+=y.numel() return acc/numdef trainer(net,train_iter,test_iter,num_epoches,lr,device): &#x27;&#x27;&#x27;用GPU训练模型&#x27;&#x27;&#x27; #初始化参数 def init_weights(m): if type(m)==nn.Linear or type(m)==nn.Conv2d: nn.init.xavier_uniform_(m.weight) #nn.init.normal_(m.weight,std=0.01) net.apply(init_weights) print(&#x27;training on&#x27;,device) print(torch.cuda.get_device_name(0)) net.to(device) optimizer=torch.optim.SGD(net.parameters(),lr=lr) loss=nn.CrossEntropyLoss() train_acc=[] test_acc=[] loss_epoches=[] for epoch in range(num_epoches): temp_train_acc=0 loss_epoch=0 num=0 net.train() for i,(X,y) in enumerate(train_iter): optimizer.zero_grad() X,y=X.to(device),y.to(device) with torch.no_grad(): temp_train_acc+=accuracy(net(X),y) y_hat=net(X) l=loss(y_hat,y) l.backward() optimizer.step() loss_epoch+=l*X.shape[0] num+=y.numel() train_acc.append(float(temp_train_acc/num)) test_acc.append(gpu_acc(net,test_iter)) loss_epoches.append(float(loss_epoch)/num) print(&#x27;本轮&#123;&#125;训练的结果，test—acc:&#123;&#125;,train-acc:&#123;&#125;,train-loss:&#123;&#125;&#x27;.format(str(epoch+1),str(test_acc[-1]),str(train_acc[-1]),str(loss_epoches[-1]))) import matplotlib.pyplot as plt plt.plot(list(range(1,1+num_epoches)),test_acc,label=&#x27;test_acc&#x27;) plt.plot(list(range(1,1+num_epoches)),train_acc,label=&#x27;train_acc&#x27;) plt.plot(list(range(1,1+num_epoches)),loss_epoches,label=&#x27;loss&#x27;) plt.legend() plt.show() lr,num_epoches=0.2,20device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)trainer(net,train_iter,test_iter,num_epoches,lr,device) 3.4 训练结果 （秀一下3090～） CS229中关于模型选择中的bias- variance trade off在这里依旧适用 0x04 Discussion and conclusion 4.1 module和sequential之间的区别？ What is difference between nn.Module and nn.Sequential 使用module定义模型的时候，我们需要额外def forward，对于卷积神经网络这种按照顺序的结构并不需要关心，所以前向传播是按照sequential进行的，但是在后面的学习中更现代化的CNN或者RNN等会进行输出的迁移，这个时候使用module会更好 4.2 归一化 normalization和标准化standardization之间的区别？ 不太懂，先留着 可以参考这个 还有这个 4.3 如何写出规范的代码？ 多看别人的代码 看完自己敲出来 4.4 为什么loss会大于1 虽然说看loss只需要下降就好了，但是还是不太明白为什么在mean之后还是大于1 在手敲出来上面的代码能够清晰的感受到，工程对于软件构建的重要性，可能需要先做规划？了解好API才能用别人的抽象好的工具实现更多的功能。虽然这是一个简单的wheel，但是在初始解的基础上可以再次优化","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"D2L","slug":"D2L","permalink":"https://blog.tjdata.site/tags/D2L/"}]},{"title":"动手学深度学习01_线性回归实现","slug":"动手学深度学习01_线性回归实现","date":"2022-09-11T00:20:24.000Z","updated":"2023-05-13T13:51:46.303Z","comments":true,"path":"posts/35609ff6.html","link":"","permalink":"https://blog.tjdata.site/posts/35609ff6.html","excerpt":"在CS229中主要关注的是一些传统机器学习的模型，包括广义线性模型（GLM）包含的Logistic Regression、Softmax Regression，生成模型的高斯判别式、Decision Tree、Support Vector Machine、浅层神经网络；侧重于对于理论的介绍。李沐课程中对于实际操作的代码实现过程给出了详细的介绍，是非常有意思的。其实整个学习过程的框架无论是简单的逻辑回归还是复杂的YOLO之类的代码框架其实都已经给好了，如何高效的利用框架所提供的抽象好的API来实现复杂的功能是值得思考的。","text":"在CS229中主要关注的是一些传统机器学习的模型，包括广义线性模型（GLM）包含的Logistic Regression、Softmax Regression，生成模型的高斯判别式、Decision Tree、Support Vector Machine、浅层神经网络；侧重于对于理论的介绍。李沐课程中对于实际操作的代码实现过程给出了详细的介绍，是非常有意思的。其实整个学习过程的框架无论是简单的逻辑回归还是复杂的YOLO之类的代码框架其实都已经给好了，如何高效的利用框架所提供的抽象好的API来实现复杂的功能是值得思考的。 0x00 Environment build（with conda） 环境安装，性能测试与横向对比中给出Pytorch安装的三种方式：1. 直接安装、2. conda环境、3. Docker安装。后面有时间可以借鉴一下思路来使用Docker管理环境而不是Conda。本次还是利用conda来管理环境 ps：关于conda与docker管理环境之间的差异 – 个人看法 如果有更好的回答希望可以发送到 chenxia31@outlook.com 交流！ 作为一个计算机小白，在最初接触Python的时候知道一个电脑中会存在不同版本的python，这个需要我们来进行不同环境的隔离，常见的有python的envs、或者conda管理工具。这样不同的python环境可以使用不同的package。 但是docker可以说是一个更高level的工具，实际上他是一个弱化的虚拟机，并不是从硬件层面来虚拟一整套冯诺依曼体系，而是利用部分硬件和软件调度的方式来降低虚拟机所需要的硬件资源而实现虚拟机的操作系统和主机操作系统之间隔离的目的。在这个过程中可以实现某种意义上的硬件方式的环境隔离。 两者可以说是风马牛，但是在管理python环境中却又有着异曲同工之妙，都能起到环境隔离的作用，但是实现的过程是不一样的： conda是python的package的管理者，它为不同的python提供不同的package的路径。这也就是conda install的package值需要装一份就可以为所有环境使用（如果版本一致的话） docker是操作系统层面的硬件管理者，它为不同的虚拟机提供硬件和软件资源 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151# 新建conda环境conda create -n &#x27;datastudy&#x27; python=3.9# 设置一下pip镜像# 清华镜像源https://mirrors.tuna.tsinghua.edu.cn/help/pypi/python -m pip install --upgrade pippip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 安装pytorch，https://pytorch.org/get-started/locally/# 默认配置好CUDA# ps：中文教程很多安装pytorch好复杂，其实很多东西官网都给好了conda install pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge# 检查是否成功，import torchprint(torch.__version__)print(torch.cuda.get_device_name(0))# 检查代码是否能跑，参考链接如下# Summary: 使用PyTorch玩转MNIST # Author: Amusi# Date: 2018-12-20 # github: https://github.com/amusi/PyTorch-From-Zero-To-One# Reference: https://blog.csdn.net/victoriaw/article/details/72354307 from __future__ import print_functionimport argparseimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torchvision import datasets, transformsfrom torch.autograd import Variable # Training settingsparser = argparse.ArgumentParser(description=&#x27;PyTorch MNIST Example&#x27;)parser.add_argument(&#x27;--batch-size&#x27;, type=int, default=64, metavar=&#x27;N&#x27;, help=&#x27;input batch size for training (default: 64)&#x27;)parser.add_argument(&#x27;--test-batch-size&#x27;, type=int, default=1000, metavar=&#x27;N&#x27;, help=&#x27;input batch size for testing (default: 1000)&#x27;)parser.add_argument(&#x27;--epochs&#x27;, type=int, default=10, metavar=&#x27;N&#x27;, help=&#x27;number of epochs to train (default: 10)&#x27;)parser.add_argument(&#x27;--lr&#x27;, type=float, default=0.01, metavar=&#x27;LR&#x27;, help=&#x27;learning rate (default: 0.01)&#x27;)parser.add_argument(&#x27;--momentum&#x27;, type=float, default=0.5, metavar=&#x27;M&#x27;, help=&#x27;SGD momentum (default: 0.5)&#x27;)parser.add_argument(&#x27;--no-cuda&#x27;, action=&#x27;store_true&#x27;, default=False, help=&#x27;disables CUDA training&#x27;)parser.add_argument(&#x27;--seed&#x27;, type=int, default=1, metavar=&#x27;S&#x27;, help=&#x27;random seed (default: 1)&#x27;)parser.add_argument(&#x27;--log-interval&#x27;, type=int, default=10, metavar=&#x27;N&#x27;, help=&#x27;how many batches to wait before logging training status&#x27;)args = parser.parse_args()args.cuda = not args.no_cuda and torch.cuda.is_available() torch.manual_seed(args.seed) #为CPU设置种子用于生成随机数，以使得结果是确定的if args.cuda: torch.cuda.manual_seed(args.seed)#为当前GPU设置随机种子；如果使用多个GPU，应该使用torch.cuda.manual_seed_all()为所有的GPU设置种子。 kwargs = &#123;&#x27;num_workers&#x27;: 1, &#x27;pin_memory&#x27;: True&#125; if args.cuda else &#123;&#125;&quot;&quot;&quot;加载数据。组合数据集和采样器，提供数据上的单或多进程迭代器参数：dataset：Dataset类型，从其中加载数据batch_size：int，可选。每个batch加载多少样本shuffle：bool，可选。为True时表示每个epoch都对数据进行洗牌sampler：Sampler，可选。从数据集中采样样本的方法。num_workers：int，可选。加载数据时使用多少子进程。默认值为0，表示在主进程中加载数据。collate_fn：callable，可选。pin_memory：bool，可选drop_last：bool，可选。True表示如果最后剩下不完全的batch,丢弃。False表示不丢弃。&quot;&quot;&quot;train_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=args.batch_size, shuffle=True, **kwargs)test_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=args.batch_size, shuffle=True, **kwargs) class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5)#输入和输出通道数分别为1和10 self.conv2 = nn.Conv2d(10, 20, kernel_size=5)#输入和输出通道数分别为10和20 self.conv2_drop = nn.Dropout2d()#随机选择输入的信道，将其设为0 self.fc1 = nn.Linear(320, 50)#输入的向量大小和输出的大小分别为320和50 self.fc2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2))#conv-&gt;max_pool-&gt;relu x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))#conv-&gt;dropout-&gt;max_pool-&gt;relu x = x.view(-1, 320) x = F.relu(self.fc1(x))#fc-&gt;relu x = F.dropout(x, training=self.training)#dropout x = self.fc2(x) return F.log_softmax(x) model = Net()if args.cuda: model.cuda()#将所有的模型参数移动到GPU上 optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum) def train(epoch): model.train()#把module设成training模式，对Dropout和BatchNorm有影响 for batch_idx, (data, target) in enumerate(train_loader): if args.cuda: data, target = data.cuda(), target.cuda() data, target = Variable(data), Variable(target)#Variable类对Tensor对象进行封装，会保存该张量对应的梯度，以及对生成该张量的函数grad_fn的一个引用。如果该张量是用户创建的，grad_fn是None，称这样的Variable为叶子Variable。 optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target)#负log似然损失 loss.backward() optimizer.step() if batch_idx % args.log_interval == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) def test(epoch): model.eval()#把module设置为评估模式，只对Dropout和BatchNorm模块有影响 test_loss = 0 correct = 0 for data, target in test_loader: if args.cuda: data, target = data.cuda(), target.cuda() data, target = Variable(data, volatile=True), Variable(target) output = model(data) test_loss += F.nll_loss(output, target).item()#Variable.data pred = output.data.max(1)[1] # get the index of the max log-probability correct += pred.eq(target.data).cpu().sum() test_loss = test_loss test_loss /= len(test_loader) # loss function already averages over batch size print(&#x27;\\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\\n&#x27;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) if __name__ == &#x27;__main__&#x27;: for epoch in range(1, args.epochs + 1): train(epoch) test(epoch) 别人总结的 Pytorch handbook，看上去还不错 0x01 Review of linear regression 线性回归是非常经典的模型，其求解方法并不是只有梯度下降一种，CS229-01–线性模型之前的blog中给出了相关的介绍，这里再重新复述一下和关于自己在其中新的思考 1.1 记号和引言 假设每个sample包含feature（n1）和label（11），也就是[(x(i),y(i)),i=0:...:m][(x^{(i)},y^{(i)}),i=0:...:m][(x​(i)​​,y​(i)​​),i=0:...:m],在这种情况下我们希望构建一个model（或者说一种function）来作为feature和label之间的映射关系，这样在一个新的feature到来的时候，可以做出了预测。这个model其实就是实例化的hypothesis，实例化的过程便是optimization确定模型parameters的过程，其中包括loss function与optim method 1.2 模型实现的过程 对于线性回归，所做出的hypothesis自然是线性的，这也是它属于广义线性模型的原因 h(x)=wT∗x+bh(x)=w^T*x+b h(x)=w​T​​∗x+b w:n∗1w:n*1 w:n∗1 b:1∗1b:1*1 b:1∗1 对于优化过程，第一步是确定损失函数，第二步是利用损失函数来找到对应的w,bw,bw,b参数值使得最小 损失函数是用来描述预测值和实际值之间的差别，通常模型越好损失函数需要最小，这里采用的是欧氏距离作为损失函数，具体原因在1.3中解释 argminw,b12Σi=0i=m−1(h(x(i))−y(i))2argmin_{w,b}\\frac{1}{2}\\Sigma_{i=0}^{i=m-1}(h(x^{(i)})-y^{(i)})^2 argmin​w,b​​​2​​1​​Σ​i=0​i=m−1​​(h(x​(i)​​)−y​(i)​​)​2​​ 之后便是求解这个优化问题的方式，对于线性回归有两种，一种是利用矩阵的normal equation方法得到解析解；二是利用深度学习中常用的梯度下降（gradient descent）的启发式方法来得到近似解（ps：和做时刻表一样） normal equation，利用导数为0的极值点得到取值，推导过程略 gradient descent，利用导数下降的方式来探索的接近极值点 w=w−lr∗∂∂wL(w,b)w=w-lr*\\frac{\\partial}{\\partial w}L(w,b) w=w−lr∗​∂w​​∂​​L(w,b) w=w−lr∗(h(x)−y)xw=w-lr*(h(x)-y)x w=w−lr∗(h(x)−y)x 线性模型的梯度比较好求解 1.3 模型解释 机器学习最方便的就是可解释性。首先我们的假设中认为features和labels之间是关于线性分布，但是通常情况下总会有各种各样的因素也就是高斯分布的假设，所以如果有Ground- truth的话，那必然是，主义嗷对于不同 h(x)=wT∗x+b+ϵh(x)=w^T*x+b+\\epsilon h(x)=w​T​​∗x+b+ϵ p(ϵ)=1(2∗Π)∗σexp(−(ϵ(i))22σ2)p(\\epsilon)=\\frac{1}{\\sqrt(2*\\Pi)*\\sigma}exp(-\\frac{(\\epsilon^{(i)})^2}{2\\sigma^2}) p(ϵ)=​√​(​​​2∗Π)∗σ​​1​​exp(−​2σ​2​​​​(ϵ​(i)​​)​2​​​​) 我们可以使用最大似然法（maximum likelihood） 的方式来推导我们想要什么？抛弃传统距离的概率，我们用概率的方式来表示.（我们的目的都是预测值和真实值相接近，可以用距离、也可以用分布概率） 由上我们可以看出预测值的概率值（不是概率分布！！） p(y^(i))=p(h(x))=1(2∗Π)∗σexp(−(y(i)−h(x(i)))22σ2)p(\\hat y^{(i)})=p(h(x))=\\frac{1}{\\sqrt(2*\\Pi)*\\sigma}exp(-\\frac{(y^{(i)}-h(x^{(i)}))^2}{2\\sigma^2}) p(​y​^​​​(i)​​)=p(h(x))=​√​(​​​2∗Π)∗σ​​1​​exp(−​2σ​2​​​​(y​(i)​​−h(x​(i)​​))​2​​​​) 我们希望所有的数据集中的概率都尽可能的大，所以 argmax∏i=0i=m−1p(y^(i))argmax \\prod_{i=0}^{i=m-1} p(\\hat y^{(i)}) argmax​i=0​∏​i=m−1​​p(​y​^​​​(i)​​) 这个时候就可以求导得到等价于1.2中损失函数的式子! 1.4 回顾过程 1.1 给出为什么要这么做、1.2 给出理论推导过程、1.3给出模型的解释。这里一个困惑的点在于loss function是先有还是先可以被解释的。我的个人理解是它先有欧氏距离的方式，后面随着发展才逐渐利用概率方式解释，同时这种解释的范式我们也可以推广给其他模型。 比如在逻辑回归中，并不是给出假设就给出损失函数，而是利用概率方式来**推导（！！）**得到损失函数，这里常用的方式是MLP和MAE或者其他的方式，在选择合适的优化算法来寻找参数 不同于机器学习目的是得到一个有效的模型，传统的统计分析会给出参数估计的优劣以及检验是否合理，并就得到的参数给出自变量和因变量之间的关系。 0x02 Manual implementation process（eight step） 接下来就是利用代码实现上述功能，这里参考李沐老师的d2l，在最开始软件模块的设计中就已经给出来代码的框架。 2.1 生成数据集/读取数据集 12345678910111213# 第一步，生成包含随机噪音的数据import randomimport torchdef synthetic_data(w,b,num_examples): &#x27;&#x27;&#x27;生成包含随机噪音的线性回归数据&#x27;&#x27;&#x27; X=torch.normal(0,1,(num_examples,len(w))) y=torch.matmul(X,w)+b y+=torch.normal(0,0.01,y.shape) return X,y.reshape(-1,1)true_w=torch.tensor([2,-3.4])true_b=4.2features,labels=synthetic_data(true_w,true_b,1000) 2.2 数据观察与预处理（暂无） 1234# 第二步，简单的观察feature与labels之间的关系# 本文中有feature为（1000，2），因此可以看第二个特征和labels之间的关系import matplotlib.pyplot as pltplt.scatter(features[:,1],labels) 2.3 数据迭代器（Dataloader） 这里采用的小批量（batch）的梯度下降；在梯度下降的过程中最直接的是计算所有数据集的梯度进行更新，这样对于memory的压力比较大，因此可以一个epoch进行划分，划分不同的batch_size，再利用batch进行参数更新。 但是这样的疑问在于batch能代表整个训练集进行更新吗？所以这样子就需要训练很多次，在某种特殊情况下会震荡多次，所有也会有更多的优化算法，来添加噪音或者动量，提升优化算法的健壮性。 12345678910111213# 第三部，对数据集进行迭代处理，这样可以保证在随机梯度下降过程中会慢慢转换进去def data_iter(batch_size,features,labels): num_examples=len(features) indices=list(range(num_examples)) random.shuffle(indices) for i in range(0,num_examples,batch_size): batch_indices=torch.tensor(indices[i:min(i+batch_size,num_examples)]) yield features[batch_indices],labels[batch_indices]# yield的作用这里的迭代的结果是逐步发出来的batch_size=10for X,y in data_iter(batch_size,features,labels): print(X,&#x27;\\n&#x27;,y) break 2.4 初始化参数 123# 第四步，初始化参数w=torch.normal(0,0.01,size=(2,1),requires_grad=True)b=torch.zeros(1,requires_grad=True) 2.5 定义模型（net） 其实这里net的输入参数应该是X和param，因为在后续的模型中肯定会有参数和训练样本的输入，但是计算方式和linreg并不是相似，如果输入参数规定好为w和b，在后续更改会比较麻烦。 123456# 第五步，定义模型def linreg(X,w,b): &#x27;&#x27;&#x27;linear regression&#x27;&#x27;&#x27; # X M*n # w n*1 return torch.matmul(X,w)+b 2.6 定义损失函数（loss） 损失函数表征的是预测值和真实值之间的差距，因此函数的输入应该为预测值与真值，这样就可以被复用 1234# 第六步，定义损失函数def squared_loss(y_hat,y): &#x27;&#x27;&#x27;均方误差&#x27;&#x27;&#x27; return (y_hat-y.reshape(y_hat.shape))**2/2 2.7 定义优化算法（optim） 这里还是使用给好的API实现，同时在优化过程中我们需要设置的除了批量梯度下降的batch-size之外，还需要确定学习率。这个在任何情况下都是需要设置的 123456# 第七步，定义优化算法def sgd(params,lr,batch_size): with torch.no_grad(): for param in params: param-=lr*param.grad/batch_size param.grad.zero_() 2.8 完整的训练过程 1234567891011121314# 第八步，完整的训练过程lr=0.03num_epoch=3net=linregloss=squared_lossfor epoch in range(num_epoch): for X,y in data_iter(batch_size,features,labels): l=loss(net(X,w,b),y) l.sum().backward() sgd([w,b],lr,batch_size) with torch.no_grad(): train_l=loss(net(features,w,b),labels) print(&#x27;epoch&#123;&#125;,loss&#123;&#125;&#x27;.format(str(epoch+1),str(float(train_l.mean())))) 0x03 Automatic implementation process （Pytorch） 回顾上述的过程，为了2.8最后的训练过程，我们首先需要生成数据集和读取数据集；之后我们写来一个dataloader来将数据集转换为可迭代（iterable）的对象来方便后续的梯度下降，dataloader中我们需要设置数据集、batch-size、是否可以被打乱；后面定义模型、损失函数和优化算法，模型是需要根据param和x来得到预测值、损失函数需要根据预测值和真实值得到结果、优化算法需要根据学习率、batch size来进行参数更新 1234567891011121314151617181920212223242526272829303132333435import numpy as npimport torchfrom torch.utils import data# 第一步生成数据集true_w=torch.tensor([2,-3.4])true_b=4.2features,labels=synthetic_data(true_w,true_b,1000)# 第二步读取数据集def load_array(data_arrays,batch_size,is_train=True): dataset=data.TensorDataset(*data_arrays) return data.DataLoader(dataset,batch_size,shuffle=is_train)batch_size=10data_iter=load_array((features,labels),batch_size)# 这里data_iter的方式与之前的方式相似# 第三步，可视化掠过# 第四步，定义模型from torch import nnnet=nn.Sequential(nn.Linear(2,1))net[0].weight.data.normal_(0,0.01)net[0].bias.data.fill_(0)loss=nn.MSELoss()trainer=torch.optim.SGD(net.parameters(),lr=0.03)num_epoch=3for epoch in range(num_epoch): for X,y in data_iter: l=loss(net(X),y) trainer.zero_grad() l.backward() trainer.step() l=loss(net(features),labels) print(&#x27;epoch&#123;&#125; loss is &#123;&#125;&#x27;.format(str(epoch+1),str(float(l)))) 0x04 Discussion 在了解整个代码实现过程之后，才能更好的了解到后续的逻辑回归、图像深度学习等代码实现的方式，以及如何学习pytorch的结构","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"D2L","slug":"D2L","permalink":"https://blog.tjdata.site/tags/D2L/"}]},{"title":"Review：WebPage_Request的完整过程","slug":"WebPage_Request的完整过程","date":"2022-08-30T03:48:05.000Z","updated":"2022-10-17T08:18:08.947Z","comments":true,"path":"posts/cb0af509.html","link":"","permalink":"https://blog.tjdata.site/posts/cb0af509.html","excerpt":"摘要","text":"摘要 应用层协议 计算机网络学习笔记 – 应用层协议 万维网 HTTP Proxy 电子游戏 SMTP POP3IMAP 局域网IP地址分配 DHCP 域名解析 DNS 网络下载 P2P 流媒体 CDN 运输层协议 计算机网络学习笔记 – 运输层协议 UDP TCP 网络层协议 计算机网络学习笔记 – 网络层协议 IP协议 - 数据层面 IP协议 - 控制层面 链路层协议 比较偏低层，不重视 以太网 物理层协议 完全底层，不重视 IEEE802.11 0x02 完整的使用过程 问题描述：在学校，学生是如何通过校园网链接到网络，然后下载www.baidu.com的主页面的 涉及到的协议：应用层的DHCP、DNS、HTTP；运输层的UDP；网络层的IP；链路层的以太网 2.1 User启动它的PC，可以使用一根以太网电缆或者WI-FI与学校的以太网交换机连接，学校的交换机也和学校的Router连接。 学校的Router与本地的ISP（可能是中国移动也有可能是其他的什么东西，原文中的历史comcast.net)连接，因此提供DNS服务，也就是说DNS服务器是在ISP的网络中 User为了连接网络，首先需要通过DHCP来获得自己的IP地址，因此它通过DHCP请求报文来获得自己的IP地址 请求报文放到目的端口67和请求端口68的UDP报文段，放到广播IP（255.255.255.255）和源IP地址（0.0.0.0）的IP数据报中 包含IP数据报防止道以太网帧中，目的MAC地址（FF.FF.FF.FF.FF.FF），源Mac地址就是User的PC的Mac地址，比如说是3c:a6:f6:05:15:2c Router接受到对应的Mac地址后，从以太网Frame中抽取出IP数据报，然后获得UDP报文段，由此得到了DHCP的请求报文 假设Router中处理 DHCP请求报文的方式是使用CIDR，68.85.2.0/24分配IP地址，因此分配68.85.2.101给PC、网关地址68.85.2.1和子网掩码68.85.2.0/24的DHCPACK报文和DNS的地址，放到UDP报文段、IP数据报、以太网数据帧，发送回发出请求的PC的mac地址 ⚠️返回的时候mac地址并不是广播的，在DHCP的ACK到达PC的时候，开始得到自己的IP地址和DNS的IP地址，可以开始上网了！ 当User键入www.google.com之后，web浏览器生成一个TCP socket开始发送HTTP request，这里需要得到www.google.com的IP地址 为了得到www.google.com的IP地址，需要经历DNS查询报文，这个报文需要有DNS服务器的地址（比如68.87.71.226）以及源IP地址（68.85.2.101），以及字符串（‘www.google.com’) 为了得到学校网络的网关路由器，需要通过ARP得到网关路由器的Mac地址 得到网关路由器的地址之后，PC发出的Frame中的IP数据报的目的IP地址为DNS、源IP地址为PC地址、帧的目的地址是网关路由器的地址 网关路由器接受到Frame病抽取包含DNS查询的IP数据报，解析在重新原则路由器，再将IP数据报放置到链路层Frame中国发送 到达之后，重新返回给PC 得到www.google.com的IP地址之后，就可以进行交互了，需要TCP连接和HTTP协议","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"Review","slug":"Review","permalink":"https://blog.tjdata.site/tags/Review/"}]},{"title":"paper02-2012-imagenet-classification-with-deep-convolutional-neural-networks","slug":"paper02-2012-imagenet-classification-with-deep-convolutional-neural-networks","date":"2022-08-27T03:27:20.000Z","updated":"2023-05-13T13:50:13.214Z","comments":true,"path":"posts/d4d56670.html","link":"","permalink":"https://blog.tjdata.site/posts/d4d56670.html","excerpt":"LeNet和AlexNet是从传统手工特征提取SIFI、HOG等向深度卷积神经网络转变的过渡期。","text":"LeNet和AlexNet是从传统手工特征提取SIFI、HOG等向深度卷积神经网络转变的过渡期。 NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf 0x01 Abstract 训练一个deep convolutional nerual network来区分ImageNet的LSVRC-2010比赛中的120万张 high-resolution到1000个不同的class （网络效果）在我们的test中，我们错误率从37.5%到17%的提升，显著的好于现有的SOTA （网络结构）该neural network包括600万参数和65万参数，包括5个convolutional layers，顺序是1个max-pooling layers、3个fullyconnected layers、以及最终的1000个softmax （训练过程）我们使用 non-saturating神经元和高效的GPU卷积实现，同时为了减少overfitting，我们使用最近一种新的regularization方法dropout 1 Introduction 在object recognition中的关键方法是采用一些 machine learning 的方法；由此我们收集更多的dataset、研究更强的models、以及使用更好的训练techniques来防止 overfitting。的却在一些大量数据集的加持下，一些简单的识别任务可以非常轻松的解决。比如在MNIST数据集中错误已经和人相当，同时数据集小的情况也被认识到缺点，因此新的更大的数据集LabelMe和ImageNet被开发出来 为了从数百万的图片中学习数千数据集，我们需要一个新的模型。从一些论文中我们可以看到 deep convolutional nerual network在训练中是有效的，但是我们的数据集是如此之大以至于其中的prior knowledge并不能被人为获得，而是需要从数据集中得到【 owever, the immense complexity of the object recognition task means that this problem cannot be specified even by a dataset as large as ImageNet, so our model should also have lots of prior knowledge to compensate for all the data we don’t hav】；同时CNN的复杂度可以由深度和广度决定，同时其卷积天然的具有强有力的图片先验知识、同时因为卷积层存在其比feedforward neural network的参数要小但是性能并没有明显的下降 尽管CNN的有效，依旧很难在高分辨率的图像中进行训练，但是幸运的是现有的GPU可以高度有效2D的卷积操作来实现大范围的训练。在本文中采用两块GTX580 3GB，训练时间为5～6天 本文的贡献 The specific contributions of this paper are as follows: we trained one of the largest convolutional neural networks to date on the subsets of ImageNet used in the ILSVRC-2010 and ILSVRC-2012 competitions [2] and achieved by far the best results ever reported on these datasets. We wrote a highly-optimized GPU implementation of 2D convolution and all the other operations inherent in training convolutional neural networks, which we make available publicly1. Our network contains a number of new and unusual features which improve its performance and reduce its training time, which are detailed in Section 3. The size of our network made overfitting a significant problem, even with 1.2 million labeled training examples, so we used several effective techniques for preventing overfitting, which are described in Section 4. Our final network contains five convolutional and three fully-connected layers, and this depth seems to be important: we found that removing any convolutional layer (each of which contains no more than 1% of the model’s parameters) resulted in inferior performance. 0x02 DataSet ImageNet ILSVRC，其中常见的指标为top1和top5 其中前 5 个错误率是测试图像中正确标签不在模型认为最可能的五个标签中的部分 重采样256*256，对于非长方形的数据scale到相同的像素。我们并没有做其他与处理 4.1 Data Augmentation 0x03 Architecture 3.1 ReLU Nonlinearity 常见的激活函数f(x)=tanh(x)或者\\[f(x)=(1+e^&#123;-x&#125;)^-1\\]属于saturating非线性神经元 而ReLU函数\\[f(x)=max(0,x)\\]属于 non-saturating非线性神经元 后者速度要显著快于前者,这个对于大训练集的训练是非常有效的 同样我们并不是第一个去考虑替换激活函数，比如 有人尝试使用\\[f(x)=|tanh(x)|\\] 3.2 Training on Multiple GPUs 如何使用不同的GPU进行训练 GPU存在的问题是3GB的显存并不够完整数据的网络在其中训练（只能包含12万参数），因此我们将网络划分在两个GPU中训练，整个过程只有效 3.3 Local Response Normalization card ReLU中并不需要输入 normalization来方式神经元 saturating，只需要发生正样本则会产生训练结果，但是我们仍然发现下面的 normalization对于泛化性能是有效 $$b_{x,y}i=\\frac{a_{x,y}i}{(k+a\\Sigma_{j=max(0,i-n)/2}{min(N-1,i+n/2)}(a_{x,y}j)2){\\beta}}$$ k、n、[\\alpha]、[\\beta]都是超参数，取值分别为2、5、1e-4、0.75，这是由训练集表现来确定的 3.4 Overlapping Poolingcard 一般来说两个pooling是不重叠的，但是这里采用了一种对传统的pooling改进的方式，效果很好 3.5 Overall Architecture 完整的网络结构如图所示，借用(动手学深度学习-现代卷积神经网络-AlexNet)[https://zh.d2l.ai/chapter_convolutional-modern/alexnet.html#id11] 123456789101112131415161718192021222324252627AlexNet( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)) (1): ReLU(inplace=True) (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (4): ReLU(inplace=True) (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU(inplace=True) (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (9): ReLU(inplace=True) (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace=True) (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) ) (avgpool): AdaptiveAvgPool2d(output_size=(6, 6)) (classifier): Sequential( (0): Dropout(p=0.5, inplace=False) (1): Linear(in_features=9216, out_features=4096, bias=True) (2): ReLU(inplace=True) (3): Dropout(p=0.5, inplace=False) (4): Linear(in_features=4096, out_features=4096, bias=True) (5): ReLU(inplace=True) (6): Linear(in_features=4096, out_features=1000, bias=True) )) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class AlexNet(nn.Module): def __init__(self, num_classes=1000, init_weights=False): super(AlexNet, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) if init_weights: self._initialize_weights() def forward(self, x): x = self.features(x) x = torch.flatten(x, start_dim=1) x = self.classifier(x) return x def _initialize_weights(self): for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=&#x27;fan_out&#x27;, nonlinearity=&#x27;relu&#x27;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) nn.init.constant_(m.bias, 0) 特点 因为在两块GPU上运行，因此网络结构被一分为二 五层 convolutional layers加上三层 fullyconnected layers 2，4，5层仅与自己之前的核有关系，也就是仅与自己这个GPU前一层训练的输出有关，第三层与前一层的两个GPU有关，在通道上做了一层融合 Local Response Normalization运用在第一层和第二层 每一层都使用了 ReLu 0x04 Reducing overfitting 4.1 Data Augmentation 这里的输入是256*256，但是网络的输入是224*224，因为为了扩充数据集的大小，在之后的训练过程中可以随机选择，这样可以得到2^11=2048倍的扩充 另外一种方法是使用PCA对RGB进行修正，是的数据的数量得到增多，最终的效果也是成功的 4.2 dropout 0.5的概率将一些神经元的输出设置为0，可以有效的降低过拟合 0x05 Details of learning SGD，随机梯度下降，增加动量的选项 初始化参数，使用均值为0、方差为0.01的高斯随机变量初始化权重参数 LearningRate设置为0.01 0x06 Results 0x07 参考别人的复现 to be continued ~~","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"paper_reading","slug":"paper-reading","permalink":"https://blog.tjdata.site/tags/paper-reading/"}]},{"title":"作业记录","slug":"作业记录","date":"2022-08-20T11:20:52.000Z","updated":"2022-10-17T08:18:08.949Z","comments":true,"path":"posts/eac26b.html","link":"","permalink":"https://blog.tjdata.site/posts/eac26b.html","excerpt":"作业记录","text":"作业记录 引言 项目来源是百度飞桨的【飞桨领航团AI达人养成营】的大作业，算是小白的奇文共赏了。第一次接触百度的paddle框架，本来是中文的深度学习框架结果中文论坛活跃度不够、官方文档的表意并不清楚。而且感觉API的设计不是很合理。似乎没有太重视设计原则导致有的地方API过于简单（但也很难定制化）。 本实践旨在通过一个美食分类的案列，让大家理解和掌握如何使用飞桨2.0搭建一个卷积神经网络。 特别提示：本实践所用数据集均来自互联网，请勿用于商务用途。 解压文件，使用train.csv训练，测试使用val.csv。最后以在val上的准确率作为最终分数。 0x01 数据预处理 思考并动手进行调优，以在验证集上的准确率为评价指标，验证集上准确率越高，得分越高！模型大家可以更换，调参技巧任选，代码需要大家自己调通。 1234!unzip -oq /home/aistudio/data/data120156/lemon_homework.zip!unzip -oq /home/aistudio/lemon_homework/lemon_lesson.zip!unzip -oq /home/aistudio/lemon_lesson/test_images.zip!unzip -oq /home/aistudio/lemon_lesson/train_images.zip 12345678910111213141516# 导入所需要的库from sklearn.utils import shuffleimport osimport pandas as pdimport numpy as npfrom PIL import Imageimport paddleimport paddle.nn as nnfrom paddle.io import Datasetimport paddle.vision.transforms as Timport paddle.nn.functional as Ffrom paddle.metric import Accuracyimport warningswarnings.filterwarnings(&quot;ignore&quot;) 123456df=pd.read_csv(&#x27;lemon_lesson/train_images.csv&#x27;)d=df[&#x27;class_num&#x27;].hist().get_figure()# 图像分类竞赛常见难点# 类别不均衡# one-shot和few-shot分类# 细粒度分类 图像标准化与归一化，最常见的图像预处理方式有两种，一种是图标标准化处理，将数据按照比例缩放，使之落入一个特定的区间中，将数据通过去均值，实现中心化。第二种是数据归一化，将数据统一映射到0-1区间中 它的作用 有利于初始化的进行 避免给梯度数值更新带来数值问题 有利于学习率数值的调整 加快寻找最优解速度 123456789101112# 定义数据预处理data_transforms = T.Compose([ T.Resize(size=(224, 224)), T.RandomHorizontalFlip(1), T.RandomVerticalFlip(1), T.Transpose(), # HWC -&gt; CHW T.Normalize( mean=[0, 0, 0], # 归一化 std=[255, 255, 255], to_rgb=True) ]) 0x02 数据集分割和loader建立 1234567891011121314## 数据集划分train_images = pd.read_csv(&#x27;lemon_lesson/train_images.csv&#x27;, usecols=[&#x27;id&#x27;,&#x27;class_num&#x27;])# 划分训练集和校验集all_size = len(train_images)print(all_size)train_size = int(all_size * 0.8)train_image_path_list = train_images[:train_size]val_image_path_list = train_images[train_size:]print(len(train_image_path_list))print(len(val_image_path_list)) 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 构建Datasetclass MyDataset(paddle.io.Dataset): &quot;&quot;&quot; 步骤一：继承paddle.io.Dataset类 &quot;&quot;&quot; def __init__(self, train_list, val_list, mode=&#x27;train&#x27;): &quot;&quot;&quot; 步骤二：实现构造函数，定义数据读取方式 &quot;&quot;&quot; super(MyDataset, self).__init__() self.data = [] # 借助pandas读取csv文件 self.train_images = train_list self.test_images = val_list if mode == &#x27;train&#x27;: # 读train_images.csv中的数据 for row in self.train_images.itertuples(): self.data.append([&#x27;train_images/&#x27;+getattr(row, &#x27;id&#x27;), getattr(row, &#x27;class_num&#x27;)]) else: # 读test_images.csv中的数据 for row in self.test_images.itertuples(): self.data.append([&#x27;train_images/&#x27;+getattr(row, &#x27;id&#x27;), getattr(row, &#x27;class_num&#x27;)]) def load_img(self, image_path): # 实际使用时使用Pillow相关库进行图片读取即可，这里我们对数据先做个模拟 image = Image.open(image_path).convert(&#x27;RGB&#x27;) return image def __getitem__(self, index): &quot;&quot;&quot; 步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签） &quot;&quot;&quot; image = self.load_img(self.data[index][0]) label = self.data[index][1] return data_transforms(image), np.array(label, dtype=&#x27;int64&#x27;) def __len__(self): &quot;&quot;&quot; 步骤四：实现__len__方法，返回数据集总数目 &quot;&quot;&quot; return len(self.data) 12345678# 定义数据loader#train_loadertrain_dataset = MyDataset(train_list=train_image_path_list, val_list=val_image_path_list, mode=&#x27;train&#x27;)train_loader = paddle.io.DataLoader(train_dataset, places=paddle.CPUPlace(), batch_size=128, shuffle=True, num_workers=0)#val_loaderval_dataset =MyDataset(train_list=train_image_path_list, val_list=val_image_path_list, mode=&#x27;test&#x27;)val_loader = paddle.io.DataLoader(val_dataset, places=paddle.CPUPlace(), batch_size=128, shuffle=True, num_workers=0) 1234567891011print(&#x27;=============train dataset=============&#x27;)for image, label in train_dataset: print(&#x27;image shape: &#123;&#125;, label: &#123;&#125;&#x27;.format(image.shape, label)) breakfor batch_id, data in enumerate(train_loader()): x_data = data[0] y_data = data[1] print(x_data) print(y_data) break =============train dataset============= image shape: (3, 224, 224), label: 0 Tensor(shape=[128, 3, 224, 224], dtype=float32, place=CPUPlace, stop_gradient=True, [[[[0.10980392, 0.10196079, 0.10588235, ..., 0.10588235, 0.11372549, 0.14117648], [0.11372549, 0.10980392, 0.10196079, ..., 0.11372549, 0.14509805, 0.16470589], [0.14901961, 0.11764706, 0.10196079, ..., 0.15686275, 0.23137255, 0.25098041], ..., ..., [0.50980395, 0.50980395, 0.50980395, ..., 0.73333335, 0.74117649, 0.73725492], [0.50588238, 0.50588238, 0.50588238, ..., 0.72941178, 0.73725492, 0.73725492], [0.50196081, 0.50196081, 0.50196081, ..., 0.72156864, 0.73333335, 0.73333335]]]]) Tensor(shape=[128], dtype=int64, place=CPUPlace, stop_gradient=True, [0, 0, 2, 2, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 3, 2, 0, 0, 0, 0, 1, 1, 0, 2, 2, 2, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 1, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 0, 3, 0, 2, 0, 3, 3, 2, 2, 1, 3, 3, 2, 1, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 3, 0, 0, 2, 0, 0, 3, 0, 3, 3, 1, 2, 3, 0, 0, 0, 1, 0, 2, 0, 1, 2, 3, 3, 3, 2, 0, 0, 0, 1, 2, 0, 2, 3, 0, 0, 0, 0, 2, 0, 1, 0, 1, 3, 0, 1, 1, 0, 0]) 0x03 模型选择（唯一收获是特征图计算） 首先肯定是选择自己的baseline啦，这个看上去是VGG？感觉挺土的 理想情况中，模型越大拟合能力越强。图像尺寸越大，保留的信息也越多，在实际情况中模型越复杂训练 时间越长，图像越长尺寸越大训练时间也越长 比赛开始有限使用最简单的resnet，快速跑完整个训练和预测流程，分类模型的选择需要根据任务复杂度来 进行选择，并不是精度越高的模型月适合参加比赛 在实际的比赛中可以逐步增加尺寸，在64-64的尺寸下让模型收敛，进而将模型放到128-128的尺寸爱训练 在选择的过程中baseline应该遵循几点原则 复杂度地，代码结构简单 loss收敛正确，metric出现提升 迭代快速，没有很fancy的模型结构、loss function或者图像预处理方法之类的 需要编写正确并简单的测试脚本，能够提交submission之后获得正确的分数 在网络模型中输入输出根据卷积来就行，如果涉及到调参就需要一些神学概念，比如之前被忽悠惨的感受野。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# Sequential形式组网class MyNet(paddle.nn.Layer): def __init__(self, num_classes=4): super(MyNet, self).__init__() self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=64, kernel_size=(7, 7), stride=2, padding = 3) self.pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2) self.conv2 = paddle.nn.Conv2D(in_channels=64, out_channels=64, kernel_size=(3,3), stride=1, padding = 1) self.conv3 = paddle.nn.Conv2D(in_channels=64, out_channels=128, kernel_size=(3,3), stride=2, padding = 1) self.conv4 = paddle.nn.Conv2D(in_channels=128, out_channels=256, kernel_size=(3,3), stride=2, padding = 1) self.conv5 = paddle.nn.Conv2D(in_channels=256, out_channels=512, kernel_size=(3,3), stride=2, padding = 1) # # self.pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2) # self.conv3 = paddle.nn.Conv2D(in_channels=448, out_channels=448, kernel_size=(3,3), stride=2, padding = 0) # self.conv4 = paddle.nn.Conv2D(in_channels=448, out_channels=448, kernel_size=(3,3), stride=2, padding = 1) self.flatten = paddle.nn.Flatten() self.linear1 = paddle.nn.Linear(in_features=25088, out_features=64) self.linear2 = paddle.nn.Linear(in_features=64, out_features=num_classes) def forward(self, x): x = self.conv1(x) x = F.relu(x) x = self.pool1(x) print(x.shape) x = self.conv2(x) x = F.relu(x) x = self.conv3(x) x = F.relu(x) # # print(x.shape) x = self.conv4(x) x = F.relu(x) x = self.conv5(x) x = F.relu(x) # x = self.conv4(x) # x = F.relu(x) # # print(x.shape) x = self.flatten(x) x = self.linear1(x) x = F.relu(x) x = self.linear2(x) return xmodel = paddle.Model(MyNet())model.summary((1, 3, 224, 224)) [1, 64, 56, 56] --------------------------------------------------------------------------- Layer (type) Input Shape Output Shape Param # =========================================================================== Conv2D-21 [[1, 3, 224, 224]] [1, 64, 112, 112] 9,472 MaxPool2D-5 [[1, 64, 112, 112]] [1, 64, 56, 56] 0 Conv2D-22 [[1, 64, 56, 56]] [1, 64, 56, 56] 36,928 Conv2D-23 [[1, 64, 56, 56]] [1, 128, 28, 28] 73,856 Conv2D-24 [[1, 128, 28, 28]] [1, 256, 14, 14] 295,168 Conv2D-25 [[1, 256, 14, 14]] [1, 512, 7, 7] 1,180,160 Flatten-59 [[1, 512, 7, 7]] [1, 25088] 0 Linear-7 [[1, 25088]] [1, 64] 1,605,696 Linear-8 [[1, 64]] [1, 4] 260 =========================================================================== Total params: 3,201,540 Trainable params: 3,201,540 Non-trainable params: 0 --------------------------------------------------------------------------- Input size (MB): 0.57 Forward/backward pass size (MB): 10.72 Params size (MB): 12.21 Estimated Total Size (MB): 23.51 --------------------------------------------------------------------------- &#123;'total_params': 3201540, 'trainable_params': 3201540&#125; 123456789101112131415161718192021222324252627282930313233343536# 注意过程中特征图的计算# 定义优化器optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())model.prepare( optim, paddle.nn.CrossEntropyLoss(), Accuracy() )from visualdl import LogReader, LogWriterargs=&#123; &#x27;logdir&#x27;:&#x27;./vdl&#x27;, &#x27;file_name&#x27;:&#x27;vdlrecords.model.log&#x27;, &#x27;iters&#x27;:0,&#125;# 配置visualdlwrite = LogWriter(logdir=args[&#x27;logdir&#x27;], file_name=args[&#x27;file_name&#x27;])#iters 初始化为0iters = args[&#x27;iters&#x27;] #自定义Callbackclass Callbk(paddle.callbacks.Callback): def __init__(self, write, iters=0): self.write = write self.iters = iters def on_train_batch_end(self, step, logs): self.iters += 1 #记录loss self.write.add_scalar(tag=&quot;loss&quot;,step=self.iters,value=logs[&#x27;loss&#x27;][0]) #记录 accuracy self.write.add_scalar(tag=&quot;acc&quot;,step=self.iters,value=logs[&#x27;acc&#x27;]) `./vdl/vdlrecords.model.log` is exists, VisualDL will add logs to it. 123456789# 模型训练与评估model.fit(train_loader, val_loader, log_freq=1, epochs=15, callbacks=Callbk(write=write, iters=iters), verbose=1, ) The loss value printed in the log is the current step, and the metric is the average value of previous step. Epoch 1/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 1.4849 - acc: 0.2266 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 6.7525 - acc: 0.2930 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 1.8031 - acc: 0.2708 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 1.3808 - acc: 0.2480 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 1.2969 - acc: 0.2750 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 1.2021 - acc: 0.3164 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 1.1513 - acc: 0.3360 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 1.0067 - acc: 0.6797 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 1.0514 - acc: 0.6606 - 1s/step Eval samples: 221 Epoch 2/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.9772 - acc: 0.7734 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.8334 - acc: 0.7734 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.6969 - acc: 0.7604 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 2.3449 - acc: 0.6484 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 1.3612 - acc: 0.6516 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 1.5054 - acc: 0.6380 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 1.1878 - acc: 0.6436 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.9094 - acc: 0.7266 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.8898 - acc: 0.7195 - 1s/step Eval samples: 221 Epoch 3/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.9101 - acc: 0.6641 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.8710 - acc: 0.6836 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.8483 - acc: 0.6875 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.8448 - acc: 0.7031 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.8475 - acc: 0.7063 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.7537 - acc: 0.7122 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.6307 - acc: 0.7185 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.6840 - acc: 0.7891 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.6577 - acc: 0.7783 - 1s/step Eval samples: 221 Epoch 4/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.7030 - acc: 0.7344 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.4887 - acc: 0.8203 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.5533 - acc: 0.8333 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.4893 - acc: 0.8438 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.5349 - acc: 0.8375 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.3818 - acc: 0.8411 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.2702 - acc: 0.8490 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.5461 - acc: 0.8125 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.3558 - acc: 0.8416 - 1s/step Eval samples: 221 Epoch 5/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.4032 - acc: 0.8281 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.2782 - acc: 0.8828 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.2537 - acc: 0.8932 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.3106 - acc: 0.9004 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.3652 - acc: 0.8953 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.2224 - acc: 0.8984 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.3256 - acc: 0.8990 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.3408 - acc: 0.8438 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.3114 - acc: 0.8326 - 1s/step Eval samples: 221 Epoch 6/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.2124 - acc: 0.9062 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.1708 - acc: 0.9258 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.2870 - acc: 0.9167 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.1881 - acc: 0.9180 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.3036 - acc: 0.9156 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.3152 - acc: 0.9089 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.1624 - acc: 0.9092 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.3151 - acc: 0.9141 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.3244 - acc: 0.9050 - 1s/step Eval samples: 221 Epoch 7/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.4050 - acc: 0.8750 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.1410 - acc: 0.9023 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.2465 - acc: 0.9089 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.2190 - acc: 0.9121 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.1823 - acc: 0.9109 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.2198 - acc: 0.9102 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.2194 - acc: 0.9115 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.2905 - acc: 0.8672 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.2588 - acc: 0.8733 - 1s/step Eval samples: 221 Epoch 8/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.1634 - acc: 0.9062 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.1506 - acc: 0.9219 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.1242 - acc: 0.9297 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.3063 - acc: 0.9199 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.1786 - acc: 0.9219 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.1867 - acc: 0.9232 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.1735 - acc: 0.9262 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.2529 - acc: 0.8750 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.2749 - acc: 0.8688 - 1s/step Eval samples: 221 Epoch 9/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.1865 - acc: 0.9141 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.2470 - acc: 0.9023 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.0620 - acc: 0.9297 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.1055 - acc: 0.9375 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.2145 - acc: 0.9344 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.0945 - acc: 0.9388 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.1622 - acc: 0.9387 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.2351 - acc: 0.8906 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.2440 - acc: 0.9005 - 1s/step Eval samples: 221 Epoch 10/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.1562 - acc: 0.9375 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.1392 - acc: 0.9531 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.1352 - acc: 0.9479 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.0883 - acc: 0.9551 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.1463 - acc: 0.9531 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.1493 - acc: 0.9505 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.1267 - acc: 0.9523 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.2258 - acc: 0.9062 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.1954 - acc: 0.9186 - 1s/step Eval samples: 221 Epoch 11/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.1226 - acc: 0.9531 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.1305 - acc: 0.9453 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.1340 - acc: 0.9453 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.0711 - acc: 0.9551 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.0544 - acc: 0.9609 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.1100 - acc: 0.9596 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.1838 - acc: 0.9569 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.1604 - acc: 0.9531 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.2993 - acc: 0.9367 - 1s/step Eval samples: 221 Epoch 12/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.1236 - acc: 0.9453 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.0547 - acc: 0.9688 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.2062 - acc: 0.9505 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.1316 - acc: 0.9492 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.0759 - acc: 0.9563 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.0801 - acc: 0.9609 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.2175 - acc: 0.9580 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.2175 - acc: 0.9219 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.1687 - acc: 0.9367 - 1s/step Eval samples: 221 Epoch 13/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.1188 - acc: 0.9531 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.0690 - acc: 0.9609 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.1382 - acc: 0.9557 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.1006 - acc: 0.9551 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.0434 - acc: 0.9625 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.0742 - acc: 0.9635 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.1249 - acc: 0.9637 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.1632 - acc: 0.9453 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.2240 - acc: 0.9412 - 1s/step Eval samples: 221 Epoch 14/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.0547 - acc: 0.9766 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.0427 - acc: 0.9844 - ETA: 6s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.0513 - acc: 0.9818 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.0545 - acc: 0.9824 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.0608 - acc: 0.9812 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.0513 - acc: 0.9831 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.0402 - acc: 0.9852 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.1093 - acc: 0.9531 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.2143 - acc: 0.9548 - 1s/step Eval samples: 221 Epoch 15/15 [128, 64, 56, 56] step 1/7 [===&gt;..........................] - loss: 0.0608 - acc: 0.9766 - ETA: 7s - 1s/step[128, 64, 56, 56] step 2/7 [=======&gt;......................] - loss: 0.0476 - acc: 0.9805 - ETA: 5s - 1s/step[128, 64, 56, 56] step 3/7 [===========&gt;..................] - loss: 0.0400 - acc: 0.9844 - ETA: 4s - 1s/step[128, 64, 56, 56] step 4/7 [================&gt;.............] - loss: 0.0271 - acc: 0.9863 - ETA: 3s - 1s/step[128, 64, 56, 56] step 5/7 [====================&gt;.........] - loss: 0.0198 - acc: 0.9891 - ETA: 2s - 1s/step[128, 64, 56, 56] step 6/7 [========================&gt;.....] - loss: 0.0367 - acc: 0.9896 - ETA: 1s - 1s/step[113, 64, 56, 56] step 7/7 [==============================] - loss: 0.0152 - acc: 0.9909 - 1s/step Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.1904 - acc: 0.9609 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.2047 - acc: 0.9502 - 1s/step Eval samples: 221 12result = model.evaluate(val_loader,batch_size=32,log_freq=1, verbose=1, num_workers=0, callbacks=None)print(result) Eval begin... The loss value printed in the log is the current batch, and the metric is the average value of previous step. [128, 64, 56, 56] step 1/2 [==============&gt;...............] - loss: 0.0984 - acc: 0.9688 - ETA: 1s - 1s/step[93, 64, 56, 56] step 2/2 [==============================] - loss: 0.3313 - acc: 0.9502 - 1s/step Eval samples: 221 &#123;'loss': [0.33130556], 'acc': 0.9502262443438914&#125; 0x04 one more thing GitHub的学生礼包里面有好多好东西，digital ocean有100刀的额度，绑定PayPal就可以使用啦。国外的服务器还是有一些小作用的","categories":[{"name":"homework","slug":"homework","permalink":"https://blog.tjdata.site/categories/homework/"}],"tags":[{"name":"nothing","slug":"nothing","permalink":"https://blog.tjdata.site/tags/nothing/"}]},{"title":"Reading01-GUI的历史以及macOS窗口","slug":"Reading01-GUI的历史以及macOS窗口","date":"2022-08-19T06:23:46.000Z","updated":"2023-05-13T13:50:45.396Z","comments":true,"path":"posts/ed74d391.html","link":"","permalink":"https://blog.tjdata.site/posts/ed74d391.html","excerpt":"本次主要想总结一些目前使用的GUI界面，以及macOS界面中的窗口和应用程序的概念。首先对于一个新的东西了解之前是采用浏览引擎，从百度到Google，或者新生代的duckduckgo等等；但是因为互联网的垃圾太多，自己去寻找的过程也是挑挑拣拣的过程，直到发现wiki 百科。","text":"本次主要想总结一些目前使用的GUI界面，以及macOS界面中的窗口和应用程序的概念。首先对于一个新的东西了解之前是采用浏览引擎，从百度到Google，或者新生代的duckduckgo等等；但是因为互联网的垃圾太多，自己去寻找的过程也是挑挑拣拣的过程，直到发现wiki 百科。 0x01 引言：从Vscode引起的macOS应用和窗口的疑惑 macOS的文档（Document）、窗口（window）和应用程序（application）的关系之前一直分不清楚，使用的时候能感受到和window不一样的地方，但是一直不知道区别在哪里。直到使用vs code对于默认打开文件夹的疑惑。 事情是这样的，我的vs code每次打开的时候都不会显示上次打开的文件夹，在网上搜索设置的时候看到可以在 1windows.restore = &#x27;one&#x27; // 可以打开上次关闭的文件夹 但是如果我使用左上角的红 ’x‘关闭，还是会退出文件夹，但是并没有关闭vs code（因为指示灯还是开着）；如果使用dock内的vs code’退出‘则可以关闭vs code并在下次打开的时候正常出现文件夹 0x02 GUI的发展历史 我们使用鼠标（mouse）进行交互，使用单击（click）图标启动程序，使用图形控件（graphical control）操作屏幕上的各种窗口（window），这些都和图形操作有关，这里参照wiki百科–GUI 2.1 没有计算机的时代 1930年，Vannevar Bush首次编写一种称为 Memex的设备，设想像一个桌子，上面有两个触摸屏图形显示器、一个键盘和一个扫描仪，允许用户使用与超链接的工作方式来访问所有的人类知识。注意这个时候并没有数字计算机，所以这个想法并没有得到任何讨论，《信息机器Memex》–阮一峰 这种机器内部用微缩胶卷（microfile）存储信息，也就是自动翻拍，可以不断往里面添加新的信息；桌面上有阅读屏，用来放大阅读微缩胶卷；还有许多个按钮，每一个按钮代表一个主题，只要按一下，相应的微缩胶卷就会显示出来。每一个胶卷内部还记录着相关的其他胶卷的编号，可以方便地切换，形成同主题阅读 2.2 Douglas Englebart – 诞生初期 1968年，被称为GUI之父的Douglas Englebart （道格拉斯·恩格尔巴特）在NACA（NASA前身）在某些开车上班的日子EMO的时候突然想到，作为一名工程师，他真正的使命不是从事可能只会让少数人受益的小项目。因此回顾布什的文章来思考如何建造一台可以增强人类智力的机器，在战争时期担任雷达操作员，主要设想围绕阴极射线管构建显示系统；在1962年在一篇《AUGMENTING HUMAN INTELLECT: A Conceptual Framework》提出认为数字计算机可以提供最快的方法来提高一个人处理复杂问题情况的能力，获得理解以适应他的特殊需求，并得到问题的解决方案，他也设想计算机不是人类智力的替代品，而是增强智力的工具，比如建筑师使用使用CAD来设计建筑物，而不是机器自己设计建筑物 这个时候时间点还是1962年，人们采用的计算机的体积非常巨大，通常用户会使用打孔纸带和他们进行交互，然后计算机在数小时或者数天之后输出结果。但是人们的想象力并不会拘束与时代！ 因为这是一项全新的技术，Englebart的演示使用电视摄像机对准他的脸、手和正在观看的小显示屏，用来给人们展示一些全新的概念。这个显示系统基于矢量图形技术，可以在同一屏幕上显示文本和实线，受限于内存大小，它只能显示大写字母。Englebart采用的交互工具包括：一个标准打字机键盘、一个五键“和弦键盘”以及一个长方形三个按钮的盒子 这个长方形的盒子、用着长电线连接到计算机，就是鼠标（mouse）；没有人知道谁先叫它鼠标的，但是它在当时出现，并一直保留到现在，在机械上，它与现代鼠标略有不同，因为连接到内部电位器的两个圆形轮子直接在桌面上滚动，而不是由单个鼠标球与滚轮摩擦来操纵。然而，对于最终用户来说，它的操作几乎与现代鼠标相同。其他输入设备也曾尝试过（如触摸屏和光笔），但用户测试发现鼠标是操作屏幕光标最自然的方式。今天仍然如此。 鼠标的发明的伴生 – 指针也出现了，在当时演示的系统中指针是一个箭头，大约是单个字符的高度，指向正上方，指针在最初被称为‘Bug’。但是这个称呼并没有传承下来，而是pointer 在当时的演示中包括：超文本连接（hypertext linking）、全屏文档编辑（full screen document editing）、上下文操作（context- sensitive help）、网络文档协同（networked document collaboration）、电子邮件（email）、即时消息（instant message）、视频会议（video meeting）；但是由于视频系统的显示很难分辨发生了什么。 可惜没有钱来实现商业化 2.3 PARC – 施乐（Xerox） 复印机公司的自救 当复印机厂商看到了computer带来的电子文档进行协作创作的时候，会担心自己的公司会在无纸化的进程中不可避免的消亡，这个时候他们需要做的是确保自己控制这项新的技术，因此在1970年成立了PARC（帕洛阿尔托研究中心），来使用五年的时间自由的做感兴趣的任何事情 第一件发明是激光打印机，是复印机业务的自然补充，因为打印需要一种更图形化的方式来让计算机开始准备文件，因为当时没有这样的计算机，它们方面来自己的计算机称为ALTO，它的显示屏的界面为606*808，每个像素都可以独立打开和关闭，但是只能显示固定的文本字符。但是具有一个键盘和更加现代化的Englebart鼠标，这个鼠标具有三个按钮，本身也变成了位图图像，并首次使用我们熟悉的对角线箭头形状，并可以根据正在执行的任务变成其他形状。Alto上软件开始非常粗糙，包括文件管理器（Norton commander）、图形文字处理器（Bravo，DOS的word前身）、位图图形编辑器（类似paint）；但是这些不同的应用程序需要一个一致的用户界面，因此它们发明了Smalltalk，第一个现代GUI 第二件，smalltalk是一种易于使用的编程语言和开发环境，也可以算得上是第第一个面向对象的编程语言，其中程序代码和数据可以封装到称为对象的单元中来进行复用而不用了解其中实现细节，在1974年具有雏形并不不断完善，Smalltalk是一个图形开发环境，类似于windows和visual studio之间的感觉。Smalltalk 中的各个窗口都包含在图形边框中，并在其下方背景的灰色图案中显得格外醒目。他们每个人在每个窗口的顶行都有一个标题栏，可用于识别窗口并在屏幕上移动它。与 BeOS 类似，标题栏并没有延伸到窗口的整个长度，而是从左上角开始，仅延伸到标题本身。窗口可以与屏幕上的其他窗口重叠，并且选定的窗口会将自身移动到“堆栈”的顶部。此时还发明了“图标”的概念——程序或文档的小图标表示，可以单击以运行或操作它们。弹出菜单也是同时发明的——用户单击鼠标按钮之一并分层，基于手头任务的图形菜单将出现在鼠标光标的最后位置。首次出现的还有滚动条、单选按钮和对话框。 第三件便是Xerox star 8010文档，Smalltalk是如此优美，但是施乐公司管理层并没有允许其作为商业产品推销，而是在1981年推出了ALTO精简版Alto，最重要的是取消了重叠窗口的功能，但是对于公众来说太混乱了。但是太晚了，因为Apple Computer.Inc在1976年创立. 2.4 Apple/Steven Jobs - - 推动商业化的典范，从Lisa到Macintosh 1976年，Steve Jobs和Steve Woznlak在车库内创立一家Apple Computer的小型创业公司，在推出饱受欢迎具有传统命令行界面的Apple II，因为其年轻的属性，资金充裕同时愿意冒险，在继承诸多Xerox PARC工程师之后，Apple的下一代计算机Lisa（Local Integrated Software Architecture）也因此改变，从商业用途的传统基于文本的命令行计算机直到转变为第一台采用GUI和鼠标的个人电脑。Lisa 界面的许多不同原型都在 Apple ]II上进行了模拟，包括一个基于任务的界面被称为“二十个问题”，因为它似乎需要很长时间才能让计算机做任何事情，以及一个类似的四列文件浏览器与 Smalltalk 一起出现的，后来在 NeXTstep 和 Mac OSX 中重新出现。Lisa 团队最终确定了一个基于图标的界面，其中每个图标都表示一个文档或一个应用程序，并开发了第一个下拉菜单栏，所有菜单都出现在屏幕的最顶行。 LISA中创新包括，选定菜单项旁边显示复选标记、键盘快捷键、固定高度的滚动条、垃圾桶、灰显的菜单。但是也将鼠标从三个键简化称为一个键，所以引入双击的概念。同时也提出图标来代替文件系统中的文件，并使用分层目录结构浏览这些文件 1983年发布的Lisa因为高昂的售价并没有成功，在1984年（也是IBM被打倒的一年），推出了Macintosh项目配备9英寸、128KB、没有多任务处理、低成本的图形计算机，并成功实现商业化。在1984年底销量开始下降、以及其他问题乔布斯在1985年9月17日离开苹果，前往NeXT Macintosh的名称来自于，公司员工喜欢的苹果品种（真的苹果）为mcIntosh，但是有一家音响公司为McIntosh，因此拼为Macintosh 1988 年发布了 NeXTSTEP，这是史蒂夫·乔布斯的 NeXT 计算机的新 GUI 和操作系统，这是他在 1985 年离开 Apple 后的第一个重大项目。NeXTSTEP 为其所有 GUI 组件引入了锐利的 3D 斜面外观，是第一个使用“X”符号表示关闭窗口小部件，并在左上角引入了垂直菜单条的想法，也可以在任何时候“撕掉”，以便用户可以随时离开特定菜单点在屏幕上。NeXTSTEP 也有一个位于屏幕任意一侧的 Dock（但默认位于右侧）。 2.5 Windows - - 更加商业化的GUI推广 1985年的windows1.0版本，比尔盖茨来源于VisiOn、Dos的word的交叉，包括彩色界面、具有常见的GUI组件滚动条、窗口控件小部件和菜单；但是不想LIsa或者Macintosh上的单个菜单栏，每个应用程序都有自己的菜单栏；同时采用平铺的窗口而不是可以重叠的窗口，但是后续会改进 1987年，Windows2.0，采用现有的传统的重叠方法，增加了最大化和最小化窗口，也由此与Apple发生专利冲突 1990的3.0、1992年的3.1版本的发布，一致到windows95的巩固其在GUI操作系统的领先地位 2.6 others GUI界面也包括其他厂商的努力，比如GEM、Amiga Workbench、GEOS、Acorn等等 0x03 Mac中的窗口、文档的概念 参考 在GUI的设计中面向用户的概念有三个：应用、窗口和文档。在三者之间的关系可以分为MDI、SDI和TDI MDI（multiple document interface），多份文档包含在窗口下，多个窗口保存在同一个应用 SDI（Single Document interface），每个窗口都是独立的应用，由OS自动调度。这也是windows的首创，因此一个窗口就是一份应用，也就是一个文档 TDI（Tab document interface）比如chrome，术语两者的混合体 每个应用可以打开一个或者多个窗口，每个窗口可以打开一份或者多份文档。 这个简单的概念在只有128KB的Macintosh上这一层抽象并不容易，这样多个窗口的共存可能需要多个应用的同步，因为当时的内存只能跑一个前台程序，因此需要传达给用户 一个应用在逻辑上只能打开一个窗口 用户应当尽可能的停留在单个页面 所以Mac系统的红x对应的是关闭现有的窗口，以及其打开的文档，但是并没有退出应用，退出的话可以用dock里面的退出或者使用“command+Q” 而windows代表的操作系统让应用可以实现多开，逐渐弱化了窗口的概念，每份文档对应每个app，关闭文档也就是关闭对应的app 更对应的，在ios或者android、harmony中已经完全失去了文档的概念，只存在应用和窗口。 0x04 使用注意 macOS中窗口的概念由内存和算力限制而诞生，也因现有GUI发展而茁壮，在使用中注意区分application和window的区别，关闭window使用红‘x’、退出应用使用‘command+Q’；或许这就是window- server内存为什么这么高的原因吧 1984年Macintosh模拟 参考链接 PARC：Palo Alto Research Center，帕洛阿尔托研究中心 Lisa：（Local Integrated Software Architecture），但是显然是Jobs的女儿名字 https://www.zhihu.com/question/21143701/answer/2521552530 https://arstechnica.com/features/2005/05/gui/","categories":[{"name":"Memo","slug":"Memo","permalink":"https://blog.tjdata.site/categories/Memo/"}],"tags":[{"name":"Translation","slug":"Translation","permalink":"https://blog.tjdata.site/tags/Translation/"}]},{"title":"数据结构与算法08-算法刷题-枚举｜递归｜分治｜回溯","slug":"数据结构与算法08-算法刷题-枚举｜递归｜分治｜回溯","date":"2022-07-31T03:25:07.000Z","updated":"2023-05-13T13:52:59.535Z","comments":true,"path":"posts/551748b9.html","link":"","permalink":"https://blog.tjdata.site/posts/551748b9.html","excerpt":"在前面稍微的完整了解的基础的线性表结构，知道数组、链表、队、栈、哈希表、堆之后；本来按照数据结构要学习高级数据结构字符串和二叉树，但是在学习KMP的时候对一些算法中的基本概念不清晰，同时需要对前一阶段中的排序、二分、双指针、优先队列、单调栈等进行总结，所以借此机会了解一下算法。算法中最基础的就是枚举或者说迭代，之后便是递归为基础的分治和回溯算法。","text":"在前面稍微的完整了解的基础的线性表结构，知道数组、链表、队、栈、哈希表、堆之后；本来按照数据结构要学习高级数据结构字符串和二叉树，但是在学习KMP的时候对一些算法中的基本概念不清晰，同时需要对前一阶段中的排序、二分、双指针、优先队列、单调栈等进行总结，所以借此机会了解一下算法。算法中最基础的就是枚举或者说迭代，之后便是递归为基础的分治和回溯算法。 0x01 枚举算法（Enumeration Algorithm） 1.1 枚举算法简介 穷举算法，指的是按照问题的本身的性质，来列举出所有该问题可能存在的解，并在逐一枚举的过程中讲它们逐一和目标状态进行比较来得到满足问题要求的解 枚举算法的核心是需要列举问题的所有状态，并与目标状态进行比较。它的优点是，容易编程调试、算法的正确性容易证明；它的缺点是效率比较低，不适合求解规模较大的问题 1.2 枚举算法的思路 确定枚举对象、 枚举范围和判断条件，并判断条件设立的正确性 一一枚举可能的情况并验证是否是问题的解 考虑提高枚举算法的效率 1.3 枚举算法的应用 LC78 子集 如果集合A的任意一个元素都是集合S的元素，则集合A事集合S的子集，枚举子集的方法很多，一种简单有效的枚举方法是二进制枚举子集算法 1234567891011121314class Solution: def subsets(self, nums: List[int]) -&gt; List[List[int]]: res=[] path=[] def backtracking(nums,index): res.append(path[:]) if index&gt;=len(nums): return for i in range(index,len(nums)): path.append(nums[i]) backtracking(nums,i+1) path.pop() backtracking(nums,0) return res python 的位运算符； &amp; ：and运算，参与运算的两个值相应位为1，则结果为1 ｜：or 运算，只要对应的两个二位有一个为1，结果就为1 ^: XOR运算，两个对应的相异的时候，结果为1 ～：not运算， &lt;&lt; 左移运算符， 12345678910111213class Solution: def subsets(self, S: List[int]) -&gt; List[List[int]]: sub_sets=[] n=len(S) # 1&lt;&lt;n 相当于2^n次方，range(1&lt;&lt;n)相当于0～2^n-1 for i in range(1&lt;&lt;n): sub_set=[] for j in range(n): # &amp;1 相当于取最后一位 if i&gt;&gt;j&amp;1: sub_set.append(S[j]) sub_sets.append(sub_set) return sub_sets LC221 最大正方形 需要用到一些简单的DP 123456789101112131415161718192021222324class Solution: def maximalSquare(self, matrix: List[List[str]]) -&gt; int: # 最大面积的正方形 # 积分图的方式 max_len=0 m,n=len(matrix),len(matrix[0]) dp=[] for i in range(m): sub_dp=[] for j in range(n): matrix[i][j]=int(matrix[i][j]) if matrix[i][j]==1: max_len=1 sub_dp.append(matrix[i][j]) dp.append(sub_dp) for i in range(1,m): for j in range(1,n): if matrix[i][j]==1 and dp[i-1][j]&gt;=1 and dp[i][j-1]&gt;=1 and dp[i-1][j-1]&gt;=1: dp[i][j]=min(dp[i-1][j-1],dp[i-1][j],dp[i][j-1])+1 if dp[i][j]&gt;max_len: max_len=dp[i][j] return max_len*max_len LC204 计算质数 和以前在学校学习的就玩就完全不一样，枚举最重要的不是要确定列举的对象，还需要确定剪枝的条件。所以本题可以有筛子的概念 1234567891011class Solution: def countPrimes(self, n: int) -&gt; int: is_prime = [True]*(n) ans = 0 for num in range(2,n): if is_prime[num]: ans+=1 # 右边界:因为数字最大是n-1 所以只需要到(n-1)//num 右边是开区间 所以+1 for k in range(1,(n-1)//num+1): is_prime[num*k]=False return ans 0x02 递归算法 2.1 递归简介 是一种通过重复讲原问题分解为同类的子问题而解决的方法，在绝大数编程语言中，可以通过在函数中再次调用函数自身的方式来实现递归 简单的例子就是阶乘的计算 1234def fact(n): if n==0: return 1 return n*fact(n-1) 递归可以分为两个部分： （递推过程）先逐层向下调用自身，直到达到结束条件；指的是将原问题一层一层分解为与原问题形式相同、规模更小的字问题，直到达到结束条件时停止，此时返回最底层问题的解 然后想上逐层返回结果，直到返回原问题的解；指的是从最底层字问题的解开始，逆向逐一回归，最终达到递推开始的原问题，直到返回原问题的解 2.2 递推与数据归纳法 多米罗骨牌类似的数学归纳法的步骤是： 证明当n==b的时候，基本情况下成立 证明当n&gt;b的时候，n=k成立的情况下，可以推导得出n=k+1成立 这个时候需要解决的递归就需要 递归的终止条件 递归的过程 回归过程 2.3 递归的模版 2.3.1 递归公式 需要找到原问题分解称为子问题的规律，并且根据规律写出递推公式。这里的关键是需要找到原问题分解称为子问题的规律，并抽象称为递推公式。 注意，在思考递归公式的时候没有必要将整个递推过程和回归过程一层层的想清楚，这样可能还没有递推到栈底就已经绕晕了。重点在于想清楚n=k到n=k+1这个步骤，而不是n=i到n=i+1（i=1:m）；也就是找到递归过程中的循环不变量（loop variant），先假设子问题解决了，再看如何将原问题分解 2.3.2 终止条件 递归的终止条件也叫做递归出口，在写出递推公式之后，就需要考虑递归的终止条件是什么。通常条件下，递归的终止条件是问题的边界值 2.3.3 翻译成代码 第一步，定义递归函数，明确函数意义、input和output 第二步，根据循环不变量来推论得到递归公式 第三步，明确递归的终止条件 第四步，伪代码 1234def recursion(大规模）： if 终止条件： 终止条件处理 return recursion（小规模） 2.3.4 递归的注意点 避免栈溢出 避免重复运算 2.4 递归的应用 递归在使用的过程需要明确你的loop variant是什么，在每次运行过程中循环不变量是什么 LC509 斐波那契数列 LC70爬楼梯 LC344 反转字符串 LC24 交换节点 123456789101112131415161718192021222324252627# Definition for singly-linked list.# class ListNode:# def __init__(self, val=0, next=None):# self.val = val# self.next = nextclass Solution: def swapPairs(self, head: ListNode) -&gt; ListNode: if head==None or head.next==None: return head dummy=ListNode(0,head) node1=head res=ListNode(0,head.next) node2=head.next while(node1!=None and node2!=None): # 交换两者 node1.next=node2.next node2.next=node1 dummy.next=node2 # 更新node dummy=node1 if node1.next==None: break node1=node1.next node2=node1.next return res.next LC119 杨辉三角 LC104 二叉树最大深度 1234567891011# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightclass Solution: def maxDepth(self, root: Optional[TreeNode]) -&gt; int: if not root: return 0 return max(self.maxDepth(root.left),self.maxDepth(root.right))+1 LC226 翻转二叉树 12345678910111213141516# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightclass Solution: def invertTree(self, root: TreeNode) -&gt; TreeNode: if root == None: return root # 等于左边的反转 加上 右边的反转 left=self.invertTree(root.left) right=self.invertTree(root.right) root.right=left root.left=right return root LC779 第K个语法符号 12345678class Solution: def kthGrammar(self, n: int, k: int) -&gt; int: if n == 0: return 0 if k % 2 == 1: return self.kthGrammar(n-1, (k+1) // 2) else: return abs(self.kthGrammar(n-1, k // 2) - 1) LC95 不同的二叉搜索树II 12345678910111213141516171819202122232425262728# Definition for a binary tree node.# class TreeNode:# def __init__(self, val=0, left=None, right=None):# self.val = val# self.left = left# self.right = rightclass Solution: def generateTrees(self, n: int) -&gt; List[TreeNode]: if n==0: return [] def recursionTree(left,right): # 生成left-right之间的树 if left&gt;right: return [None] trees=[] for i in range(left,right+1): left_trees=recursionTree(left,i-1) right_trees=recursionTree(i+1,right) for left_tree in left_trees: for right_tree in right_trees: curr_tree=TreeNode(i) curr_tree.left=left_tree curr_tree.right=right_tree trees.append(curr_tree) return trees return recursionTree(1,n) offer62 圆圈中最后剩下的数字 123456class Solution: def lastRemaining(self, n: int, m: int) -&gt; int: ans = 0 for i in range(2, n + 1): ans = (m + ans) % i return ans 0x03 分治法（Divide and Conquer) 这里只是简单的了解，以归并排序作为基础。理解一个算法的好处就是去模拟它 1234567891011121314151617181920212223242526272829303132333435def mergeSort(arr): # 归并排序的基本思想： # 采用经典的分治策略，先递归将当前序列平均分成两半，然后将有序序列合并，最终合并成一个有序序列 # # 【算法步骤】 # 1. 将数组中的所有数据堪称n有序的子序列 # 2. 将当前序列组中的有序序列两两归并，完成一遍之后序列组里的排序序列的个数减版，每个子序列的长度加倍 # 3. 重复上述操作得到一个长度为n的有序序列 # def merge(left_arr,right_arr): arr=[] while left_arr and right_arr: if left_arr[0]&lt;=right_arr[0]: arr.append(left_arr.pop(0)) else: arr.append(right_arr.pop[0]) while left_arr: arr.append(left_arr.pop(0)) while right_arr: arr.append(right_arr.pop(0)) return arr size =len(arr) # 边界情况 if size&lt;2: return arr mid =size//2 left_arr,right_arr=arr[0:mid],arr[mid:] return merge(mergeSort(left_arr),mergeSort(right_arr)) 0x04 回溯算法(Backtracking algorithm) 4.1 回溯算法简介 一种能够避免不必要搜索的穷举式的搜索算法，采用尝试错误的思想，在搜索尝试过程中寻找问题的解，当探索到某一步的时候，发现原先的选择并不满足求解条件、或者还需要满足更多的求解条件的的时候，就退回一步重新选择。这个过程中走不通就退回的技术称为回溯法、满足回溯条件的某个状态的点称为回溯点 回溯算法通常用简单的递归的方法来实现，在进行回溯的过程中可能会出现两种情况： 找到一个可能存在的正确答案 在尝试所有可能的分布方法之后宣布该问题没有答案 4.2 回溯算法的例子 比如求解1，2，3的全排列的问题： 123456789101112131415161718192021def premute(nums): res=[] # 存放所有符合条件结果的集合 path=[] # 存放当前符合条件的结果 def backtracking(nums): if len(path)==len(nums): res.append(path[:]) return for i in range(len(nums)): if nums[i] not in path: # 从当前路径中没有出现的数字中选择 path.append(nums[i]) # 递归搜索 backtracking(nums) # 撤销选择 path.pop() backtracking(nums) return resprint(premute([1,2,3,4])) 4.3 回溯算法的过程 回溯算法的解题步骤比较抽象，这里只是做一个简单的介绍 第一步：结合所给的问题，定义问题的求解空间，包括求解的组织形式和显性约束 解的组织形式，将解的组织形式都规范称为一个n元祖 显约束，对解分量的取值范围限定，用来控制解空间的大小 第二步：确定解空间的组织结构，解空间的组织借口通常用解空间树的方式形象表达，根据解空间树的不同，解空间分为子集树、排列树和m叉树 第三步：按照深度优先搜索策略，根据隐约束，在解空间中搜索问题的可行解或者最优解，当发现当前节点不满足求解条件时候回溯尝试其他的路径 上面的是解题的抽象逻辑，后面根据code书写回溯算法的步骤可以分为： 明确所有的选择，画出搜索过程的决策树，根据决策树来确定搜索路径 明确终止条件，推敲出递归的终止条件，以及递归终止时要执行的处理方法 将决策树和终止条件翻译成代码 4.4 回溯算法的应用 初步的回溯算法是将现有的可能性分类，然后选择其中的一个递归到下一层，并允许返回后执行下一个可能性。重点在于每一层递归都会有N个可能性，所以更近一步需要考虑剪枝。当然需要先把回溯学会，才能学会剪纸 LC46 全排列 12345678910111213141516class Solution: def permute(self, nums: List[int]) -&gt; List[List[int]]: res=[] path=[] def bt(nums): if len(path)==len(nums): res.append(path[:]) return for i in range(len(nums)): if nums[i] not in path: path.append(nums[i]) bt(nums) path.pop() bt(nums) return res LC 47全排列II LC560 和为k的子数组 1234567891011121314class Solution: def subarraySum(self, nums: List[int], k: int) -&gt; int: pre_dic = &#123;0: 1&#125; pre_sum = 0 count = 0 for num in nums: pre_sum += num if pre_sum - k in pre_dic: count += pre_dic[pre_sum - k] if pre_sum in pre_dic: pre_dic[pre_sum] += 1 else: pre_dic[pre_sum] = 1 return count LC22 括号生成 123456789101112131415161718class Solution: def generateParenthesis(self, n: int) -&gt; List[str]: ans = [] def backtrack(S, left, right): if len(S) == 2 * n: ans.append(&#x27;&#x27;.join(S)) return if left &lt; n: S.append(&#x27;(&#x27;) backtrack(S, left+1, right) S.pop() if right &lt; left: S.append(&#x27;)&#x27;) backtrack(S, left, right+1) S.pop() backtrack([], 0, 0) return ans LC 17 电话号码的字母组合 123456789101112131415161718192021class Solution: def letterCombinations(self, digits: str) -&gt; List[str]: num2letter=[&#x27;abc&#x27;,&#x27;def&#x27;,&#x27;ghi&#x27;,&#x27;jkl&#x27;,&#x27;mno&#x27;,&#x27;pqrs&#x27;,&#x27;tuv&#x27;,&#x27;wxyz&#x27;] n=len(digits) res=[] if not digits: return [] def backtracking(S): if len(S)==n: res.append(&#x27;&#x27;.join(S)) return index=len(S) num=int(digits[index]) print(num) for i in num2letter[num-2]: S.append(i) backtracking(S) S.pop() backtracking([]) return res LC784 字幕大小写全排列 123456789101112131415161718192021222324252627class Solution: def letterCasePermutation(self, s: str) -&gt; List[str]: res=[] path=[] def backtracking(path,index): if index==len(s): # 所有的字母都遍历完毕 res.append(&#x27;&#x27;.join(path[:])) return char=s[index] if char.isdigit(): # 如果是数字，直接加上去就行 path.append(char) backtracking(path,index+1) path.pop() else: path.append(char.lower()) backtracking(path,index+1) path.pop() path.append(char.upper()) backtracking(path,index+1) path.pop() backtracking([],0) return res LC79 单词搜索 暂时还不会hhh 12345678910111213141516171819202122232425262728293031class Solution: def exist(self, board: List[List[str]], word: str) -&gt; bool: directions = [(0, 1), (0, -1), (1, 0), (-1, 0)] def check(i: int, j: int, k: int) -&gt; bool: if board[i][j] != word[k]: return False if k == len(word) - 1: return True visited.add((i, j)) result = False for di, dj in directions: newi, newj = i + di, j + dj if 0 &lt;= newi &lt; len(board) and 0 &lt;= newj &lt; len(board[0]): if (newi, newj) not in visited: if check(newi, newj, k + 1): result = True break visited.remove((i, j)) return result h, w = len(board), len(board[0]) visited = set() for i in range(h): for j in range(w): if check(i, j, 0): return True return False LC1079 活字印刷 1234567891011121314151617181920212223242526272829class Solution: def numTilePossibilities(self, tiles: str) -&gt; int: res=set() path=[] hashmap=&#123;&#125; for i in range(len(tiles)): if tiles[i] in hashmap: hashmap[tiles[i]]+=1 else: hashmap[tiles[i]]=1 def backtracking(tiles): temp=&#x27;&#x27;.join(path[:]) if temp!=&#x27;&#x27; and temp not in res: res.add(temp) for i in range(len(tiles)): while(hashmap[tiles[i]]==0): i=i+1 if i ==len(tiles): return hashmap[tiles[i]]-=1 path.append(tiles[i]) backtracking(tiles) va=path.pop() hashmap[va]+=1 backtracking(tiles) return len(res) LC93 复原IP地址 123456789101112131415161718192021222324252627class Solution: def restoreIpAddresses(self, s: str) -&gt; List[str]: res=[] path=[] flag=4 def backtracking(s,index): temp=&#x27;&#x27;.join(path[:]) if len(temp)==len(s)+4: res.append(temp[:-1]) return nonlocal flag for i in range(index+1,len(s)+1): if flag&gt;0 and int(s[index:i])&lt;=255: if i!=index+1 and int(s[index])==0: return path.append(s[index:i]) path.append(&#x27;.&#x27;) flag-=1 else: return backtracking(s,i) path.pop() path.pop() flag+=1 backtracking(s,0) return res LC51-N皇后 感觉N皇后是回溯里面最简单的一种了；确实比较经典 1234567891011121314151617181920212223242526272829303132333435class Solution: def solveNQueens(self, n: int) -&gt; List[List[str]]: res=[] path=[] def backtracking(n): if len(path)==n: res.append(path[:]) return for i in range(n): # 根据前面的path可以得出目前行能走的路线 forbid=[] for j in range(len(path)): forbid.append(path[j]) forbid.append(path[j]+len(path)-j) forbid.append(path[j]+j-len(path)) if i not in forbid: path.append(i) backtracking(n) path.pop() backtracking(n) rest=[] # 翻译 for i in range(len(res)): rest.append([]) for j in range(len(res[0])): temp=[&#x27;.&#x27; for _ in range(n)] temp[res[i][j]]=&#x27;Q&#x27; #合成 ts=&#x27;&#x27; for k in temp: ts+=k rest[-1].append(ts) return rest 0x05 总结（Conclusion） 理解一个算法，并不像一个数据结构一样直观。所以模拟运行，一步一步的执行才能理解其中的一些关键点。只是单纯的看概念是不ok的 无论是算法还是数据结构，学习的过程并不是一个创造性的过程，只是将计算机的单条指令执行的思维强加在人身上，再写出利用合适的数据结构和算法能得到一个解决方案 分治和回溯的根基还是递归，理解递归需要理解循环不变量 剪枝后面再看趴","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.tjdata.site/tags/Leetcode/"}]},{"title":"数据结构与算法07-算法刷题-哈希表部分","slug":"数据结构与算法07-算法刷题-哈希表部分","date":"2022-07-20T15:47:53.000Z","updated":"2023-05-13T13:52:56.718Z","comments":true,"path":"posts/c3b3eb20.html","link":"","permalink":"https://blog.tjdata.site/posts/c3b3eb20.html","excerpt":"新的数据结构，查找速度贼快的哈希表！！","text":"新的数据结构，查找速度贼快的哈希表！！ s0x01 为什么我们需要哈希表？ 首先我们细数之前学过的线性数据结构，其中最基本的分类为数组（Array）和链表（Linked list），按照我个人的看法，最大的区别在于数组按址取值的方式让其在索引速度很快、链表由于数据之间的隔离让其在插入修改等速度很快。 然后在这个基础上，我们可以人为的设计规则（FIFO或者LIFO）来更好的描述这个物理世界，也就是在数组和链表基础上所加的一层抽象（就像程序语言在寄存器基础上抽象一样），但是在学习优先队列的时候，发现堆（Heap）的出现是在数组和链表之间的Trade-off，它实现了查找的logN、修改删除的logN时间，发现非常的Amazing 所以为什么我们需要哈希表呢？因为我们需要实现值的查找 (Sedgewick and Wayne, 2021)在&lt;算法，第四版&gt;中的第三章（查找）中所描述的： 现代计算机和网络使我们能够访问海量的信息。高效检索这些信息的能力是处理它们的重要前 提。本章描述的都是数十年来在广泛应用中经过实践检验的经典查找算法。没有这些算法，现代信 息世界的基础计算设施都无从谈起。 我们会使用符号表这个词来描述一张抽象的表格，我们会将信息（值）存储在其中，然后按照 指定的键来搜索并获取这些信息。键和值的具体意义取决于不同的应用。符号表中可能会保存很多 键和很多信息，因此实现一张高效的符号表也是一项很有挑战性的任务。 符号表有时被称为字典，类似于那本将单词的释义按照字母顺序排列起来的历史悠久的参考书。 在英语字典里，键就是单词，值就是单词对应的定义、发音和词源。符号表有时又叫做索引，即书 本最后将术语按照字母顺序列出以方便查找的那部分。在一本书的索引中，键就是术语，而值就是 书中该术语出现的所有页码。 在说明了基本的 API 和两种重要的实现之后，我们会学习用三种经典的数据类型来实现高效的 符号表：二叉查找树、红黑树和散列表。在总结中我们会看到它们的若干扩展和应用，它们的实现 都有赖于我们在本章中将会学到的高效算法。 简单来说，就比如说我们需要删除[1,2,3,4]中3这个值，如果从数组的角度需要知道3对应的下标，就会比较麻烦，所以我们希望借助哈希表的方式来快速找到这个值 0x02 哈希表和哈希映射 **哈希表（Hash Table），**通过键 key和一个映射函数 Hash(key)计算出对应的值 value ，把关键码值映射到表中一个位置来访问记录，以加快查找的速度。 举个例子，我们通过value=Hash(key)=key//1000作为哈希函数，由此可以实现插入和查找： 比如插入0138，我们可以通过哈希函数计算出value=0，然后分配到0对应的区块中 查找2321，通过哈希函数可以得到2，在2对应的区块中寻找就可以了 在这个过程中最终的点在哈希函数(Hash Function)**和**哈希冲突（Hash Collision）,首先看哈希函数，本质上是一个多对一的映射，要求： 容易计算的，并且计算的索引值可以均匀分布 所得到的哈希值是一个固定长度的输出 多对一，如果Hash（key1）！=Hash（key2），则key1和key2一定不想等 如果Hash（key1）==Hash（key2—），则两者可能相同，也可能不同（冲突） 上述第4点中的不同key得到相同的hash（key）就是哈希冲突（Hash Collision），这也是好理解的有得必有失，会有针对哈希冲突的优化。这就需要精妙的设计能力了。 2.1 哈希函数的方法 直接定址法 除留余数法 平方折中法 基数转换法 等等 这里大部分不会用的，需要了解的可以配合搜索引擎使用 2.2 哈希冲突的解决 开放地址法（Open Addressing） 链地址法（Chaining）-- 用python会很简单 0x03 哈希表和哈希映射的设计 T705 设计哈希集合 1234567891011121314151617181920212223242526class MyHashSet: def __init__(self): self.set=[[] for _ in range(1000)] def add(self, key: int) -&gt; None: index=key%1000 for i in range(len(self.set[index])): if self.set[index][i]==key: break self.set[index].append(key) return self.set def remove(self, key: int) -&gt; None: index = key%1000 for i in range(len(self.set[index])): if self.set[index][i]==key: self.set[index][i]=-1 return self.set def contains(self, key: int) -&gt; bool: index=key%1000 for i in range(len(self.set[index])): if self.set[index][i]==key: return True return False T706 设计哈希映射 1234567891011121314151617181920212223242526272829class MyHashMap: def __init__(self): self.N=1000 self.hashMap=[[] for _ in range(self.N)] def put(self, key: int, value: int) -&gt; None: index=key%self.N for values in self.hashMap[index]: if values[0]==key: # 更新值 values[1]=value return None self.hashMap[index].append([key,value]) def get(self, key: int) -&gt; int: index = key % self.N for values in self.hashMap[index]: if values[0]==key: return values[1] return -1 def remove(self, key: int) -&gt; None: index = key% self.N for i in range(len(self.hashMap[index])): if self.hashMap[index][i][0]==key: self.hashMap[index].pop(i) return None return -1 0x04 哈希表的应用 比较有意思的是原地哈希 T217 存在重复元素 T219 存在重复元素II T220 存在重复元素III 这里不能简单的使用之前的哈希函数，因为我不能在一个桶里面比较，我还需要和其他桶对比 12345678910111213141516171819202122232425class Solution: def containsNearbyAlmostDuplicate(self, nums: List[int], k: int, t: int) -&gt; bool: bucket_dict = dict() for i in range(len(nums)): # 将 nums[i] 划分到大小为 t + 1 的不同桶中 num = nums[i] // (t + 1) # 桶中已经有元素了 if num in bucket_dict: return True # 把 nums[i] 放入桶中 bucket_dict[num] = nums[i] # 判断左侧桶是否满足条件 if (num - 1) in bucket_dict and abs(bucket_dict[num - 1] - nums[i]) &lt;= t: return True # 判断右侧桶是否满足条件 if (num + 1) in bucket_dict and abs(bucket_dict[num + 1] - nums[i]) &lt;= t: return True # 将 i-k 之前的旧桶清除，因为之前的桶已经不满足条件了 if i &gt;= k: bucket_dict.pop(nums[i-k] // (t + 1)) return False T136 只出现一次的数字 T001 两数之和 第一道题，很经典 1234567class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: headMap=&#123;&#125; for i in range(len(nums)): if nums[i] in headMap: return [i,headMap[nums[i]]] headMap[target-nums[i]]=i T015 三数之和 重大打击的一题，也很经典 12345678910111213141516171819202122232425262728293031class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: res=[] def twoSum(arr,target): left=0 right=len(arr)-1 while(left&lt;right): temp_sum=arr[left]+arr[right] if temp_sum==target: if left&gt;0 and arr[left]==arr[left-1]: left+=1 elif right&lt;len(arr)-1 and arr[right]==arr[right+1]: right-=1 else: res.append([target*(-1),arr[left],arr[right]]) left+=1 right-=1 elif temp_sum&lt;target: left+=1 elif temp_sum&gt;target: right-=1 nums.sort() for i in range(len(nums)): if nums[i]&gt;0: break if i&gt;0 and nums[i]==nums[i-1]: continue twoSum(nums[i+1:],(-1)*nums[i]) return res T454 四数相加II 大事化小 123456789101112131415161718class Solution: def fourSumCount(self, nums1: List[int], nums2: List[int], nums3: List[int], nums4: List[int]) -&gt; int: hashMap1=&#123;&#125; for num1 in nums1: for num2 in nums2: if num1+num2 in hashMap1: hashMap1[num1+num2]+=1 else: hashMap1[num1+num2]=1 count=0 for num3 in nums3: for num4 in nums4: if -(num3+num4) in hashMap1: count+=hashMap1[-(num3+num4)] return count T442 数组中重复的数据 很有意思 123456789101112class Solution: def findDuplicates(self, nums: List[int]) -&gt; List[int]: # 依旧使用原地哈希 # hashtable(key)=key-1 # 数组中只会存在两种情况，一种是正常映射、另外一种是重复的，每次交换的终止条件是 # 1. i处的正常映射 # 2. i处与nums[i]出现重复 for i in range(len(nums)): while nums[i]!=i+1 and nums[i]!=nums[nums[i]-1]: nums[nums[i]-1],nums[i]=nums[i],nums[nums[i]-1] return [num for i, num in enumerate(nums) if num - 1 != i] T149 直线上最多的点数 需要注意python运算的时候，小数的问题，比如0.1+0.2=0.333334；结合贪心的思想使用更佳 12345678910111213141516171819202122232425262728293031323334353637class Solution: def maxPoints(self, points: List[List[int]]) -&gt; int: n = len(points) if n &lt; 3: return n ans = 0 for i in range(n): line_dict = dict() line_dict[0] = 0 same = 1 for j in range(i+1, n): dx = points[j][0] - points[i][0] dy = points[j][1] - points[i][1] if dx == 0 and dy == 0: same += 1 continue gcd_dx_dy = math.gcd(abs(dx), abs(dy)) if (dx &gt; 0 and dy &gt; 0) or (dx &lt; 0 and dy &lt; 0): dx = abs(dx) // gcd_dx_dy dy = abs(dy) // gcd_dx_dy elif dx &lt; 0 and dy &gt; 0: dx = -dx // gcd_dx_dy dy = -dy // gcd_dx_dy elif dx &gt; 0 and dy &lt; 0: dx = dx // gcd_dx_dy dy = dy // gcd_dx_dy elif dx == 0 and dy != 0: dy = 1 elif dx != 0 and dy == 0: dx = 1 key = (dx, dy) if key in line_dict: line_dict[key] += 1 else: line_dict[key] = 1 ans = max(ans, same + max(line_dict.values())) return ans T811 子域名的访问计数 学会python的字符串操作还是很有用的 12345678910111213141516171819202122class Solution: def subdomainVisits(self, cpdomains: List[str]) -&gt; List[str]: ans=&#123;&#125; for domain in cpdomains: count,domains=domain.split() count=int(count) subdomains=domains.split(&#x27;.&#x27;) temp=&#x27;&#x27; for subdomain in subdomains[::-1]: if temp: temp=subdomain+&#x27;.&#x27;+temp else: temp=subdomain if temp in ans: ans[temp]+=count else: ans[temp]=count res=[] for key,value in ans.items(): res.append(str(value)+&#x27; &#x27;+key) return res","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.tjdata.site/tags/Leetcode/"}]},{"title":"数据结构与算法06-算法刷题-队列-堆部分","slug":"数据结构与算法06-算法刷题-队列-堆部分","date":"2022-07-13T09:05:21.000Z","updated":"2023-05-13T13:52:53.390Z","comments":true,"path":"posts/1bbb5318.html","link":"","permalink":"https://blog.tjdata.site/posts/1bbb5318.html","excerpt":"和栈相似，队列也是一种依赖顺序的数据结构，不过它的规则是先进先出（FIFO），在这个基础上会有很多新的操作，和单调栈相似的单调队列、以及不同优先级的基于堆的优先队列方法","text":"和栈相似，队列也是一种依赖顺序的数据结构，不过它的规则是先进先出（FIFO），在这个基础上会有很多新的操作，和单调栈相似的单调队列、以及不同优先级的基于堆的优先队列方法 0x01 队列的基础知识 队列Queue：是一种线性表数据结构，是一种只允许在表的一端进行插入操作，而在表的另外一端进行删除操作的线性表 队尾（rear）：队列中允许插入一端 队头（front）：允许删除的另一端 当表中没有任何可操作的数据元素称为空队 同样的队列的设计包括顺序存储的队列和链式存储的队列 队列这种数据结构的基本操作可以分为： 初始化队列init，定义队列的大小size、队头元素指针front、队尾元素rear 判断队列是否为空is_empty 判断队列是否已满，is_ful 插入元素（入队） 删除元素（出队） 获取队列队头元素 0x02 队列的基本设计 T 622 设计循环列 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class MyCircularQueue: def __init__(self, k: int): self.size=k self.queue=[None for _ in range(k)] self.front=-1 self.rear=-1 self.num=0 def enQueue(self, value: int) -&gt; bool: if self.isFull(): return False else: self.num+=1 self.rear=(self.rear+1)%self.size self.queue[self.rear]=value return True def deQueue(self) -&gt; bool: if self.isEmpty(): return False else: self.num-=1 self.front=(self.front+1)%self.size return True def Front(self) -&gt; int: if self.isEmpty(): return -1 else: return self.queue[(self.front+1)%self.size] def Rear(self) -&gt; int: if self.isEmpty(): return -1 else: return self.queue[self.rear] def isEmpty(self) -&gt; bool: if self.num==0: return True else: return False def isFull(self) -&gt; bool: if self.num==self.size: return True else: return False T 239 滑动窗口最大值 1234567891011121314151617class Solution: def maxSlidingWindow(self, nums: List[int], k: int) -&gt; List[int]: stack=[] # stack用来存储最大值的下标，使用单调递减栈【3，2，1】 arr=[] for i in range(len(nums)): # 需要遍历每个数组 # 优先考虑index超出范围的，第i个数的时候，边界局势i-k+1 while stack and stack[0]&lt;i-k+1: stack.pop(0) # 之后考虑值的大小 while stack and nums[stack[-1]]&lt;nums[i]: stack.pop() stack.append(i) arr.append(nums[stack[0]]) return arr[k-1:] 0x03 优先队列 队列的作用十分有限，常见的是优先队列，是一种特殊的队列，在优先队列中元素被赋予不同的优先级，当访问队列元素时，按照具有高优先级的元素最先删除；优先对立与普通队列最大的不同点在于出队顺序，优先队列按照优先级来实现 最高级先出的规则 ps：个人认为，和单调栈类似，优先队列的重点在于“优先”，也就是找到一种数据方式，每次插入和删除的时候可以保证最上面一层是自己想的 优先队列的应用场景非常多： 数据压缩的 huffman编码 最短路径算法 Dijkstra 最小生成树算法 prim算法 任务调度器 根据优先级执行系统任务 事件驱动仿真 顾客排队算法 选择问题 查找第K最小元素 0x04 优先队列设计和使用 设计优先级队列，设计的操作主要在于和普通队列的enqueue和dequeue之间的不同 队列的实现方式也不同，可以使用数组实现、链表实现和二叉队实现 数组实现优先队列，入队操作直接插入rear（O1）、出队操作需要遍历整个数组，找到优先级最高的元素，返回并删除该元素，时间复杂对为O（n） 链表实现优先队列，链表中的元素按照优先级排序，入队操作需要为待插入元素创建节点，并在链表中找合适的插入位置，时间复杂度为ON 二叉堆结构实现优先队列，按照优先级进行排序，入队操作就是将元素插入二叉堆中合适位置，时间复杂对为logN、出队操作就是返回二叉堆中优先级最大节点删除，时间复杂度也是O（logN） 当然除了这种笨拙的利用原始数据生成优先队列的方式之外，别人已经写好了轮子，比如java里面的priority Queue、C++的priority queue和python的heapq 4.1 什么是堆？ 4.2 堆排序 我们知道小顶堆的特点是堆顶永远是最小的数，虽然我们不知道其他顺序，但是我们知道堆顶是最小的，所以我们可以使用堆数据结构来排序，每次取出最小的，来实现排序。 对于输入的nums数组，我们调用buildMinHeap来实现数组向小顶堆的转变，具体过程是不断调整数组。 在建立小顶堆之后，我们每次取出堆顶元素到数组尾部，并对前面的【0:n-2】进行堆调整，由此来保持堆的特性（这里的heapfiy就是heap Adjust） 1234567891011121314151617181920212223242526272829303132333435363738394041424344def sortArray(nums): def heapfiy(arr,index,end): # 调整成为大顶堆 left=index*2+1 right=left+1 while left&lt;=end: min_index=index if arr[left]&lt;arr[min_index]: min_index=left if right&lt;=end and arr[right]&lt;arr[min_index]: min_index=right if index == min_index: break arr[index],arr[min_index]=arr[min_index],arr[index] # break index=min_index left=index*2+1 right=left+1 def buildMinHeap(arr): size=len(arr) # 堆里面最重要的一个性质就是，子节点的下标等于i*2+1、i*2+2 # 最后一个非叶节点（size-2)//2 for i in range((size-2)//2,-1,-1): heapfiy(arr,i,size-1) return arr def minHeapSort(arr): # 原始序列构建大顶堆 # 交换最大值和n-1的顺序 # 新的序列重新构建大顶堆 arr=buildMinHeap(arr) print(arr) size=len(arr) for i in range(size): arr[0],arr[size-i-1]=arr[size-i-1],arr[0] heapfiy(arr,0,size-i-2) return arr return minHeapSort(nums)print(sortArray([23,34,23,1,3,9,667,9,0])) 4.3 基于堆实现优先队列 我们知道优先队列是分为两个部分的，一个是优先级、一个是原始数据；因此我们通常需要用堆来存储原始数据，但是在调整的过程中利用优先级来比较。（和单调栈中数据的值和数据的下标类似） T703 数据流中的第K大元素 很经典就是维护一个长度为k的优先队列，如果数据长了就pop出堆顶元素来保持保持自身的完整性 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class KthLargest: # 重点在于是否可以利用add之前数据排列方式 def __init__(self, k: int, nums: List[int]): self.k=k self.arr=nums self.buildHeap(self.k) while len(self.arr)&gt;self.k: self.heapPop() # 维护一个大小的为k的最小堆 def add(self, val: int) -&gt; int: self.heapPush(val) while len(self.arr)&gt;self.k: self.heapPop() return self.arr[0] def buildHeap(self,k): size=len(self.arr) for i in range((size-2)//2,-1,-1): # 自下往上的维护一个堆 self.heapAdjust(i,size-1) def heapAdjust(self,index,end): # index代表是父节点 child_l=index*2+1 child_r=child_l+1 while(child_l&lt;=end): min_index=index if self.arr[child_l]&lt;self.arr[min_index]: min_index=child_l if child_r &lt;=end and self.arr[child_r]&lt;self.arr[min_index]: min_index=child_r if index==min_index: break self.arr[min_index],self.arr[index]=self.arr[index],self.arr[min_index] index=min_index child_l=index*2+1 child_r=child_l+1 def heapPop(self): size=len(self.arr) self.arr[0],self.arr[-1]=self.arr[-1],self.arr[0] top=self.arr.pop() # 重新整理 if size&gt;0: self.heapAdjust(0,size-2) return top def heapPush(self,val): self.arr.append(val) size=len(self.arr) i=size-1 cur_root=(i-1)//2 while(cur_root&gt;=0): if self.arr[cur_root]&lt;val: break self.arr[i]=self.arr[cur_root] i=cur_root cur_root=(i-1)//2 self.arr[i]=val T347 前K个高频元素 这里与之前类似的地方，还是求K个满足条件的值，只不过不是值本身，而是涉及值的元素，所以可以说是堆，也可以说是优先队列，只不过代表的实际值需要翻译一下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution: def topKFrequent(self, nums: List[int], k: int) -&gt; List[int]: num_dict=dict() for num in nums: if num in num_dict: num_dict[num]+=1 else: num_dict[num]=1 new_nums=list(set(nums)) def heapfiy(heap,index,end): child_l=index*2+1 child_r=index*2+2 while(child_l&lt;=end): min_index=index if num_dict[heap[min_index]]&gt;num_dict[heap[child_l]]: min_index=child_l if child_r&lt;=end and num_dict[heap[min_index]]&gt;num_dict[heap[child_r]]: min_index=child_r if num_dict[heap[index]]==num_dict[heap[min_index]]: break # 交换堆里面的位置 heap[min_index],heap[index]=heap[index],heap[min_index] index=min_index child_l=index*2+1 child_r=index*2+2 def heappush(heap,val): heap.append(val) i=len(heap)-1 while((i-1)//2&gt;=0): cur_root=(i-1)//2 if num_dict[heap[cur_root]]&lt;num_dict[val]: break heap[i]=heap[cur_root] i=cur_root heap[i]=val return heap def heappop(heap): heap[0],heap[-1]=heap[-1],heap[0] heap.pop() heap=heapfiy(heap,0,len(heap)-1) return heap # 维护一个堆，每次push一个元素 # 长度超过k，需要pop一个元素 # 需要维护的是最小堆 res=[] for num in new_nums: heappush(res,num) while(len(res)&gt;k): heappop(res) return res T973 最接近原点的K个点 一样的，只不过计数变成了欧氏距离，有点无聊的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Solution: def kClosest(self, points: List[List[int]], k: int) -&gt; List[List[int]]: def disCounting(point): return point[0]*point[0]+point[1]*point[1] def heapAdjust(heap,index,end): child_l=index*2+1 child_r=index*2+2 while(child_l&lt;=end): max_index=index if disCounting(heap[child_l])&gt;disCounting(heap[max_index]): max_index=child_l if child_r&lt;=end and disCounting(heap[child_r])&gt;disCounting(heap[max_index]): max_index=child_r if max_index==index: break heap[index],heap[max_index]=heap[max_index],heap[index] index=max_index child_l=index*2+1 child_r=index*2+2 def heappush(heap,val): # 距离为优先级 # 里面的元素为point heap.append(val) i=len(heap)-1 while((i-1)//2&gt;=0): cur_root=(i-1)//2 if disCounting(heap[cur_root])&gt;disCounting(val): break heap[i]=heap[cur_root] i=cur_root heap[i]=val def heappop(heap): heap[0],heap[-1]=heap[-1],heap[0] heap.pop() heapAdjust(heap,0,len(heap)-1) res=[] for point in points: heappush(res,point) while(len(res)&gt;k): heappop(res) return res","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.tjdata.site/tags/Leetcode/"}]},{"title":"数据结构与算法05-算法刷题-堆栈部分","slug":"数据结构与算法05-算法刷题-堆栈部分","date":"2022-07-08T14:18:18.000Z","updated":"2023-05-13T13:52:49.359Z","comments":true,"path":"posts/3ad3c8e3.html","link":"","permalink":"https://blog.tjdata.site/posts/3ad3c8e3.html","excerpt":"数据结构、算法思想，具体问题的设计能力，以及一些黑话也是有必要的，比如双指针、滑动窗口、单调栈、优先队列等","text":"数据结构、算法思想，具体问题的设计能力，以及一些黑话也是有必要的，比如双指针、滑动窗口、单调栈、优先队列等 0x01 堆栈的基本知识 **堆栈（Stack）**简称为栈。一种线性表数据结构，是一种只允许在表的一端进行插入和删除操作的线性表。 我们把栈中允许插入和删除的一端称为 **「栈顶（top）」；**另一端则称为 「栈底（bottom）」 。当表中没有任何数据元素时，称之为 「空栈」。 主要操作分为插入和删除操作，分别是入栈操作和出栈操作。 让我们来设计一个堆栈，对一个非直观的数据结构掌握的最好方法是用基本的数据结构来实现它，参照：T155 最小栈设计 1234567891011121314151617181920212223242526class MinStack: def __init__(self): self.stack=[] self.topPointer=-1 self.min=[] def push(self, val: int) -&gt; None: self.stack.append(val) self.topPointer+=1 if self.topPointer==0: self.min.append(val) else: if val&lt;self.min[-1]: self.min.append(val) else: self.min.append(self.min[-1]) def pop(self) -&gt; None: self.min.pop() self.stack.pop() self.topPointer-=1 def top(self) -&gt; int: return self.stack[-1] 0x02 堆栈的基本作用 与其说堆栈是一种数据结构，它更多的是一种设计算法的技巧（如果单纯从算法的角度来说），当然在实际硬件中也存在由于硬件的限制（比如磁带）导致顺序的问题。 从算法的角度来说，堆栈具有的作用 使用堆栈可以很方便的保存和取用信息，因此长被用作算法和程序中的辅助存储结构，临时保存信息，供后面操作中使用。 例如：操作系统中的函数调用栈，浏览器中的前进、后退功能。 堆栈的后进先出规则，可以保证特定的存取顺序。 例如：翻转一组元素的顺序、铁路列车车辆调度。 0x03 堆栈的题目 3.1 有效的括号 T20 有效的括号 一个非常经典的题目，算是堆栈的先入后出的典型的应用 1234567891011121314151617181920class Solution: def isValid(self, s: str) -&gt; bool: if (len(s)%2==1): return False flagStack=[] pair=&#123;&#x27;)&#x27;:&#x27;(&#x27;,&#x27;&#125;&#x27;:&#x27;&#123;&#x27;,&#x27;]&#x27;:&#x27;[&#x27;&#125; for char in s: if len(flagStack)!=0: if char in pair and flagStack[-1]==pair[char]: flagStack.pop() else: flagStack.append(char) else: flagStack.append(char) if flagStack: return False else: return True 3.2 基本计算器II T227 基本计算器II 重点思想是将每个元素，都看成num在option的后面，但是逐个取出num和option；z这里没有考虑 到python的字符串操作功能 123456789101112131415161718192021222324252627282930s Solution: def calculate(self, s: str) -&gt; int: size=len(s) stack=[] op=&#x27;+&#x27; index=0 num=&#x27;&#x27; while(index&lt;size): if s[index] in &#x27;+-*/&#x27;: # 如果是运算符 num=&#x27;&#x27; op=s[index] index+=1 else: # 需要将num取出来 while(index&lt;size and s[index] not in &#x27;+-*/&#x27;): num+=s[index] index+=1 num=int(num) if op==&#x27;+&#x27;: stack.append(num) elif op==&#x27;-&#x27;: stack.append(-num) elif op==&#x27;*&#x27;: top=stack.pop() stack.append(top*num) elif op==&#x27;/&#x27;: top=stack.pop() stack.append(int(top/num)) 3.3 逆波兰表达式求值 T150 逆波兰表达式求值 思路和T227差不多 12345678910111213141516171819class Solution: def evalRPN(self, tokens: List[str]) -&gt; int: numStack=[] for char in tokens: if char in &#x27;+-*/&#x27;: # 取出来前两个数字 num1=numStack.pop() num2=numStack.pop() if char==&#x27;+&#x27;: numStack.append(num1+num2) elif char==&#x27;-&#x27;: numStack.append(num2-num1) elif char==&#x27;*&#x27;: numStack.append(num1*num2) else: numStack.append(int(num2/num1)) else: numStack.append(int(char)) return numStack.pop() 3.4 字符串解码 用这个栈来记录当前的元素，如果为】就向后一直搜寻到【，得到num和str，来反复 12345678910111213141516171819202122232425class Solution: def decodeString(self, s: str) -&gt; str: elementStack=[] temp=&#x27;&#x27; num=&#x27;&#x27; for char in s: elementStack.append(char) if char==&#x27;]&#x27;: # 提取字符串 elementStack.pop() while(elementStack[-1]!=&#x27;[&#x27;): top=elementStack.pop() temp+=top[::-1] elementStack.pop() while(len(elementStack)&gt;0 and elementStack[-1].isdigit()): num+=elementStack.pop() # 新的字符 for i in range(int(num[::-1])): elementStack.append(temp[::-1]) num=&#x27;&#x27; temp=&#x27;&#x27; res=&#x27;&#x27; for e in elementStack: res+=e return res 3.5 验证栈序列 T946 验证栈序列 感觉这个就非常考验思维能力，因为pushed和popped相当于为逆反操作，因此可以翻归来按照堆栈的方式继续 1234567891011121314class Solution: def validateStackSequences(self, pushed: List[int], popped: List[int]) -&gt; bool: # 和括号一样的 # 既然pushed和popped都是按照stack的规则 # 反过来也可以用stack的规则来进行排序 j=0 stack=[] j=0 for p in pushed: stack.append(p) while(stack and stack[-1]==popped[j]): stack.pop() j+=1 return j==len(pushed) 0x04 单调栈（Monotone stack）基础知识 单调栈只是具有更强限制的栈，它需要人为设置规则（设置递增或者递减）的单调栈，由此可以实现的目的为：【可以在常数时间内找到一定数组内的最大值或者最小值；同时精简删除一些无用的信息】，所以在算法设计上需要更加巧妙。 通常可以分为单调递增栈和单调递减栈，这个顺序和什么是栈顶、什么是栈底一样很难让人理清楚顺序，因此只需要考虑在单调栈中栈的大小顺序是单调的，由此可以设计进出栈的顺序，以单调递增栈为例： 假设当前进栈元素为 x，如果 x 比栈顶元素小，则直接入栈。 否则从栈顶开始遍历栈中元素，把小于 x 或者等于 x 的元素弹出栈，直到遇到一个大于 x 的元素为止，然后再把 x 压入栈中。 0x05 单调栈的使用场景 网上有很多博客，也有很多的教学视频，这里摘选一些总结的，单调栈主要解决的问题为： 左侧第一个比当前元素大的元素 左侧第一个比当前元素小的元素 右侧第一个比当前元素大的元素 右侧第一个比当前元素小的元素 在实际的应用中，需要先将实际问题抽象称为上述的四种问题，再利用单调栈求解，有点过于抽象了，结合问题来看会好一点 5.1 寻找左侧第一个比当前元素大的元素 从左到右遍历元素，构造单调递增栈（从栈顶到栈底递增）：一个元素左侧第一个比它大的元素就是将其「插入单调递增栈」时的栈顶元素。如果插入时的栈为空，则说明左侧不存在比当前元素大的元素。 5.2 寻找左侧第一个比当前元素小的元素 # 从左到右遍历元素，构造单调递减栈（从栈顶到栈底递减）：一个元素左侧第一个比它小的元素就是将其「插入单调递减栈」时的栈顶元素。如果插入时的栈为空，则说明左侧不存在比当前元素小的元素。 5.3 寻找右侧第一个比当前元素大的元素 # 从左到右遍历元素，构造单调递增栈（从栈顶到栈底递增）：一个元素右侧第一个比它大的元素就是将其「弹出单调递增栈」时即将插入的元素。如果该元素没有被弹出栈，则说明右侧不存在比当前元素大的元素。 从右到左遍历元素，构造单调递增栈（从栈顶到栈底递增）：一个元素右侧第一个比它大的元素就是将其「插入单调递增栈」时的栈顶元素。如果插入时的栈为空，则说明右侧不存在比当前元素大的元素。 5.4 寻找右侧第一个比当前元素小的元素 # 从左到右遍历元素，构造单调递减栈（从栈顶到栈底递减）：一个元素右侧第一个比它小的元素就是将其「弹出单调递减栈」时即将插入的元素。如果该元素没有被弹出栈，则说明右侧不存在比当前元素小的元素。 从右到左遍历元素，构造单调递减栈（从栈顶到栈底递减）：一个元素右侧第一个比它小的元素就是将其「插入单调递减栈」时的栈顶元素。如果插入时的栈为空，则说明右侧不存在比当前元素小的元素。 123456def 递增栈(nums): stack=[] for num in nums: while stack and num&gt;=stack[-1]: stack.pop() stack.append(num) 0x06 单调栈的实际应用 6.1 下一个更大元素I T496 下一个更大元素 I 这个很符合单调栈使用的场景的，所以主要是需要熟悉单调栈求解问题的方法 1234567891011121314151617181920212223242526272829class Solution: def nextGreaterElement(self, nums1: List[int], nums2: List[int]) -&gt; List[int]: # 第二种使用单调递增栈，因为nums1是num2的子集，所以可以遍历nums2 # 构造单调递增栈，求出nums2每个元素右侧下一个最大的元素，然后存储在哈希表中 # # 【具体做法】 # res存储答案，使用stack表示单调递增栈，使用哈希表num-map存储nums2中比下一个当前 # 元素大的数值，当前数值：下一个比当前元素大的数值 # # 遍历nums2，对于当前元素，如果小则入栈，如果元素大则一直出栈，出栈元素是第一个大 # 于当前元素值的元素 # # 遍历玩数组nums2周，建立好哈希表之后，遍历数组1 # # 从num-map中取出对应的值 res=[] stack=[] num_map=dict() for num in nums2: while(stack) and num&gt;stack[-1]: num_map[stack[-1]]=num stack.pop() stack.append(num) print(stack) for num in nums1: res.append(num_map.get(num,-1)) return res 6.2 下一个更大元素II T503 下一个更大元素II 和上面一样，遍历两次就好了 123456789101112131415class Solution: def nextGreaterElements(self, nums: List[int]) -&gt; List[int]: res=[] stack=[] temp=[-1 for _ in range(len(nums))] stack_index=[] for i in range(len(nums)*2): while stack and nums[i%len(nums)]&gt;stack[-1]: index=stack_index.pop() stack.pop() temp[index]=nums[i%len(nums)] stack_index.append(i%len(nums)) stack.append(nums[i%len(nums)]) return temp 6.3 每日温度 T739 每日温度 也是单调栈解题的常规思路 12345678910111213class Solution: def dailyTemperatures(temperatures): # 因为等价于找第i元素后，高于这个元素的index之差 # 可以考虑使用一个stack来记录递减元素的下标 size=len(temperatures) ans=[0 for _ in range(size)] stack=[] for i in range(size): while( stack and temperatures[i]&gt;temperatures[stack[-1]]): index=stack.pop() ans[index]=i-index stack.append(i) return ans 6.4 股票时间跨度 T901 股票价格跨度 单调栈可以存储值，也可以存储对应的下标 1234567891011121314151617class StockSpanner: # 小于或等于今天价格的最大连续日数 # 等价于求解左侧最近的一次大于价格的日数 def __init__(self): self.stack=[] self.day=[] def next(self, price: int) -&gt; int: dayT=1 while(self.stack and price&gt;=self.stack[-1]): dayT+=self.day.pop() self.stack.pop() self.day.append(dayT) self.stack.append(price) return dayT 6.5 去除重复字母 T316 去除重复字母 这一题看上去是和单调栈没有关系的，这里就需要将现实问题转换称为单调栈的问题；首先结果的字典序最小，就是尽可能的将a放到b前面、c放到d前面，因此我们每次遍历的时候需要对应字符放入结果并排序。但是我们要警惕后面是否还剩字符，因此就需要先遍历字符串中字符对应的数量，然后在遍历删除的时候根据字符串是否有剩余来决定删不删字符。amazing！ 1234567891011121314151617181920212223242526class Solution: def removeDuplicateLetters(self, s: str) -&gt; str: # 首先需要统计各种字符串出现的次数 # 对s进行遍历 # 要求字典序最小，也就是a要尽可能在b前面，b要尽可能在c前面 # 这就需要用单调栈来约束，但是需要注意单调栈中元素是否存在 charMap=dict() resStack=[] for char in s: if char in charMap: charMap[char]+=1 else: charMap[char]=1 for char in s: if char not in resStack: # 如果不在resStack中,我需要设置一个尽可能小的序列 # 同时需要保证还有数 while resStack and char&lt;resStack[-1] and charMap[resStack[-1]]&gt;0: resStack.pop() resStack.append(char) charMap[char]-=1 else: charMap[char]-=1 return &#x27;&#x27;.join(resStack) 6.6 最短无序连续子数组 T581 最短无序子数组 同样的这个需要先分析问题，我们需要找到什么，隐含的就是序列一定是先递增、然后乱序、然后递增，这个第一个递增序列的最大值是后面的最小值、第二个递增序列的最小值是后面的最大值；由此就可以用单调栈的方式来求解问题 123456789101112131415161718192021222324class Solution: def findUnsortedSubarray(self, nums: List[int]) -&gt; int: # 如果必然存在这样的一个数组，那么肯定是单调递增，然后***、然后单调递增 # 从小到大，找到左边界 if len(nums)&lt;2: return 0 stack=[] size=len(nums) left=size-1 right=0 for i in range(size): while(stack and nums[i]&lt;nums[stack[-1]]): left=min(left,stack.pop()) stack.append(i) stack[:]=[] for i in range(size-1,-1,-1): while(stack and nums[i]&gt;nums[stack[-1]]): right=max(right,stack.pop()) stack.append(i) if right-left+1&gt;0: return right-left+1 else: return 0","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.tjdata.site/tags/Leetcode/"}]},{"title":"数据结构与算法04-算法刷题-数组部分","slug":"数据结构与算法04-算法刷题-数组部分","date":"2022-07-03T13:56:28.000Z","updated":"2023-05-13T13:52:45.590Z","comments":true,"path":"posts/ee1b4739.html","link":"","permalink":"https://blog.tjdata.site/posts/ee1b4739.html","excerpt":"无论概念看的有多少，都需要自己实战。刷题的过程并不是一个研究的过程，而是更好的理解人作为机器的计算方式，emmm其实是让人变得更像计算器并找到一些计算机式的便捷思考方式。扯的远了，数组作为一种比较基本的数据结构方式，常见的算法技巧有排序算法、二分查找、双指针、滑动窗口","text":"无论概念看的有多少，都需要自己实战。刷题的过程并不是一个研究的过程，而是更好的理解人作为机器的计算方式，emmm其实是让人变得更像计算器并找到一些计算机式的便捷思考方式。扯的远了，数组作为一种比较基本的数据结构方式，常见的算法技巧有排序算法、二分查找、双指针、滑动窗口 数据结构与算法01- 向量 ｜ 列表 ｜ 栈和队列 0x01 数组排序 1.1 冒泡排序 1234567891011121314def bubbleSort(arr): # 冒泡排序的思想 # 相邻元素之间的比较和变换，将值较小的元素逐步从后面移到前面，值较大的元素从前面移到后面 # # 冒泡排序的步骤 # 逐步将i和i+1元素相比较，如果大小不合适则交换，这样重复一次可以保证下标为n的值最大 # 之后对n-2元素重复操作，一直到排序结束 # for i in range(len(arr)): for j in range(len(arr)-i-1): if arr[j]&gt;arr[j+1]: arr[j],arr[j+1]=arr[j+1],arr[j] return arr 1.2 选择排序 123456789101112131415161718def selectSort(arr): # 选择排序的思想 # 每一次排序中，从剩余未排序元素中选择一个最小的元素，未排好序的元素最前面的那个元素交换位置 # # 选择排序算法步骤 # 在算法中设置整型变量i，既可以作为排序树木的计算、同时i也作为执行第i次排序的时候，参加排序的后n-i+1元素的位置 # 整型变量 min_i记录最小元素的下标 # 结束之中交换两者之间的顺序 for i in range(len(arr)-1): min_i=i for j in range(i+1,len(arr)): if arr[j]&lt;arr[min_i]: min_i=j if i!=min_i: arr[i],arr[min_i]=arr[min_i],arr[i] return arr 1.3 插入排序 123456789101112131415161718def insertSort(arr): # 插入排序的基本思想 # 每一次排序中，将剩余无序列序列的第一个元素，插入到有序序列的适当位置上 # # 插入排序的基本步骤 # 将第一个元素看作一个有序序列 # 从头到尾扫描无序序列，将扫描到的每个元素插入到有序序列的适当位置上 for i in range(1,len(arr)): temp=arr[i] j=i # 0-（i-1）都是有序数组 while j&gt;0 and arr[j-1]&gt;temp: arr[j]=arr[j-1] # 因为肯定需要移动一个位置 j-=1 arr[j]=temp return arr 1.4 希尔排序（没搞懂干什么） 1234567891011121314151617181920212223242526def shellSort(arr): # 希尔排序的基本思想 # 按照一定的间隔取值划分为若干个子序列，每个子序列按照插入排序，然后逐渐缩小间隔进行 # 下一轮划分子序列和插入排序，一直到最后一轮排序间隔为1 # # 希尔排序是在插入排序的基础上进行改进的，因为我们可以看出插入排序在已经排好序的效率非常高 # 但是插入排序效率比较低的原因是每次只能将数据移动以为 # # 希尔排序的算法步骤 # 1. 确定元素间隔Gap，将序列按照1开始划分为若干个子序列，之间元素的间隔为一个gap # 2. 减少间隔数，并重新将整个序列按照新的间隔数分成若干个子序列，并对每个子序列进行排序 # # size=len(arr) gap=size//2 while gap&gt;0: for i in range(gap,size): temp=arr[i] j=i while j&gt;=gap and arr[j-gap]&gt;temp: arr[j]=arr[j-gap] j-=gap arr[j]=temp gap=gap//2 return arr 1.5 归并排序（很喜欢的排序） 1234567891011121314151617181920212223242526272829303132333435def mergeSort(arr): # 归并排序的基本思想： # 采用经典的分治策略，先递归将当前序列平均分成两半，然后将有序序列合并，最终合并成一个有序序列 # # 【算法步骤】 # 1. 将数组中的所有数据堪称n有序的子序列 # 2. 将当前序列组中的有序序列两两归并，完成一遍之后序列组里的排序序列的个数减版，每个子序列的长度加倍 # 3. 重复上述操作得到一个长度为n的有序序列 # def merge(left_arr,right_arr): arr=[] while left_arr and right_arr: if left_arr[0]&lt;=right_arr[0]: arr.append(left_arr.pop(0)) else: arr.append(right_arr.pop[0]) while left_arr: arr.append(left_arr.pop(0)) while right_arr: arr.append(right_arr.pop(0)) return arr size =len(arr) # 边界情况 if size&lt;2: return arr mid =size//2 left_arr,right_arr=arr[0:mid],arr[mid:] return merge(mergeSort(left_arr),mergeSort(right_arr)) 1.6 快速排序（第二喜欢） 1234567891011121314151617181920212223242526272829303132333435def quickSort(arr,low,high): # 快速排序，排序的边界条件 low比high小 def resort(arr,low,high): # 这里的数组中，目标数已经放到的最右边 # 现在需要把大于目标值的数据放到右边 flag=low-1 for j in range(low,high+1): # 双指针 if arr[j]&lt;=arr[high]: flag+=1 arr[flag],arr[j]=arr[j],arr[flag] return flag def random_index(arr,low,high): # 当然还需要进行一些小的操作 index=(low+high)//2 # 默认左边都是最小的 arr[index],arr[high]=arr[high],arr[index] return resort(arr,low,high) if low&lt;high: # 每次按照队列排序 # 需要返回标杆的下标 index =random_index(arr,low,high) # 之后还需要继续分解 quickSort(arr,low,index-1) quickSort(arr,index+1,high) return arr 1.7 堆排序（没看懂，感觉太难了） 1234567891011121314151617181920212223242526272829303132333435363738394041def heapSort(arr): # 借用堆结构所设计的排序算法，将数组转换为大顶堆，重复从大顶堆中取出数值最大的节点，并让剩余的堆维持大顶堆的性质 # # 【堆的定义】 # 大顶堆，根节点值大于子节点值 # 小顶堆，根节点值小于等于子节点值 # # 【算法步骤】 # 1. 首先将无序序列构造成第1个大顶堆，使得m个元素的最大值在序列的第一个值 # 2. 交换序列的最大值元素与最后一个元素的位置 # 3. 将前面n-1元素组成的序列调整称为一个新的大顶堆，这样得到第2个最大值元素 # 4. 如此循环下去，知道称为一个有序序列 # arrLen =len(arr) def heapify(arr,i): left=2*i+1 right=2*i+2 largest=i if left&lt;arrLen and arr[left]&gt;arr[largest]: largest=left if right&lt;arrLen and arr[right]&gt;arr[largest]: largest=right if largest!=i: arr[i],arr[largest]=arr[largest],arr[i] heapify(arr,largest) print(arr) def buileMaxHeap(arr): for i in range(len(arr)//2,-1,-1): heapify(arr,i) buileMaxHeap(arr) print(&#x27;buil&#x27;) for i in range(arrLen-1,0,-1): arr[0],arr[i]=arr[i],arr[0] arrLen-=1 heapify(arr,0) return arr 1.8 计数排序(没意思) 12345678910111213141516171819def countingSort(arr): # 【基本思想】 # 使用一个额外的数组counts，其中counts元素是排序数组中arr等于i的个数 # 根据数组counts来将arr的元素排列到正确位置 min_arr,max_arr=min(arr),max(arr) counts =[0 for _ in range(max_arr-min_arr+1)] for num in arr: counts[num-min_arr]+=1 for j in range(1,max_arr-min_arr+1): counts[j]+=counts[j-1] res=[0 for _ in range(len(arr))] for i in range(len(arr)-1,-1,-1): res[counts[arr[i]-min_arr]-1]=arr[i] counts[arr[i]-min_arr]-=1 return res 1.9 基数排序（很有意思，注意有负数的情况） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647def raidxSort(arr): # 基数排序radix sort【基本思想】 # 将整数按照位切割称为不同的数字，然后按照个位数来从小到达进行排列 # 注意这个排序方式是先比较个位数，然后逐渐向高位数 # 首先需要了解到基数排序中最大位数 max_radix=0 for num in arr: if num&gt;0: temp=len(str(num)) if max_radix&lt;temp: max_radix=temp else: temp=len(str(num))-1 if max_radix&lt;temp: max_radix=temp for radix in range(max_radix): # 从最低位到最高位开始计算 # 按照位数来生成 buckets=[[] for _ in range(10)] # 按照个位数，放到每个篮子，再按照十位数放到篮子 for num in arr: # 提取radix对应的位数，0代表个位 # 这里使用转换为字符串的方式来方便理解 if len(str(abs(num)))&lt;(radix+1): # 位数不够的时候，说明这个位置没有0，就需要放到第一格 buckets[0].append(num) else: index=str(abs(num))[len(str(abs(num)))-1-radix] buckets[int(index)].append(num) # 提取到buckets之后需要重新解析arr中 arr.clear() for bukcet in buckets: for num in bukcet: arr.append(num) neg_arr=[] pos_arr=[] for num in arr: if num&gt;0: pos_arr.append(num) else: neg_arr.append(num) return neg_arr[::-1]+pos_arr 1.10 桶排序（听着就没意思） 跳过 排序相关的题目： 189 轮转数组 66 加一 724 寻找数组中心下标 485 最大连续1的个数 238除自身以外乘积 498对角线遍历 48旋转图像 118 杨辉三角 119 杨辉三角2 73矩阵置零 54螺旋数组 59 螺旋数组2 移动零 215数组第K大元素 75颜色分类 506 相对名次 912排序数组 88合并两个有序数组 169 多数元素 最大间距 0x02 二分查找 注意二分查找不同边界条件可以求解不同的问题，可以简单的查找数组中存在元素的位置，也可以查找第一个大于等于数组的下标，也可以查找最后一个小于等于该数据的下标，也可以查询相关的元素的值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# ====================================================================## ==========================二分查找====================================## # 【算法概述】# 确定待查找元素所在的区间范围，再逐步缩小范围，直到找到元素或者找不到该元素为止# # 【算法思想】# 经典的减而治之的思想，减小问题规模来解决问题，每一次查找排除掉一定不存在目标元素的# 区间，在剩下可能存在的目标元素的区间中继续查找，每一次通过一些条件判断，将待搜索的# 区间逐渐缩小，来达到减少问题规模的目的# # 【算法过程】# 1. 每次查找从数组的中间元素开始，如果中间元素正好是查找的元素，则搜索过程结束# 2. 如果特定元素大于或者小于中间元素，则在大于或者小于的元素中查找# 3. 如果在某一步骤数组为空则代表找不到# # 【算法重点】# 1. 区间的开闭问题？# 2. mid的取值问题# 3. 出界条件的判断？# 4. 搜索区间的范围选择问题？# =====================================================================## def baseBinarySearch(nums,target): # nums是一个升序 # 存在下标就返回 # 不存在就返回-1 # 因为要返回下标，所以采用index采用 left=0 right=len(nums)-1 #=========================================# # 【二分查找的开闭问题】 # 第一种：左闭右闭，区间中所有的点都可以得到 # 第二种：左闭右开，右边界的点不能被取到 #=========================================# while(left&lt;=right): #=========================================# # 【出界条件的判断】 # left&lt;=right # 说明查找的元素不存在 # left&lt;right # 此时查找的区间不 # #=========================================# mid=(left+right)//2 #=========================================# # 【MID的取值问题】 # 第一种：(left+right)//2 # 第二种：left+（right-left）//2 # 前者是常见写法，后者是为了防止整型溢出。//2的代表的中间数是向下取整 # 同时这种倾向于寻找左边的数组，这里可以选择 # mid=(left+right+1)//2或者mid=left（right-left+1）//2 # 同时这里的查找过成功1/2，也可以选择靠左一点、或者靠右一点 # 从一般的意义上来说，趣中间位置元素在平均意义中达到的效果最好 #=========================================# if nums[mid]&lt;target: #=========================================# # 【搜索区间的选择】 # 直接法，在循环体中元素之间返回 # 排除法，在循环体中排出目标元素一定不存在区间 #=========================================# # 说明target在右边 left=mid+1 elif nums[mid]&gt;target: # 说明target在左边 right=mid-1 else: return mid return -1nums=[1,1,2,3,4,44]target=4# print(baseBinarySearch(nums,target)) 704 二分查找 374 猜数字大小 35 搜索插入位置 34 排序数组中查找元素的第一个和最后一个元素 167两数之和 153 寻找旋转数组最小值 74 搜索二维矩阵 x的平方根 0x3 双指针 123456789101112131415161718192021222324252627282930313233343536373839404142434445# ====================================================================## ==========================数组双指针====================================## # 【算法概述】# 在遍历元素的过程中，不是使用单个指针进行访问，而是使用双指针来访问达到目的# # 【算法思想】# 根据指针的方向，可以分为# 对撞指针：两个指针的方向相反# 快慢指针：指针方向相同# 分离双指针：如果两个指针分别属于不同的数组或者链表# # =====================================================================## def threeSum(nums): res=[] def twoSum(arr,target): left=0 print(arr) print(target) right=len(arr)-1 while(left&lt;right): temp_sum=arr[left]+arr[right] if temp_sum==target: res.append([target*(-1),arr[left],arr[right]]) left+=1 right-=1 elif temp_sum&lt;target: left+=1 elif temp_sum&gt;target: right-=1 nums.sort() for i in range(len(nums)): if nums[i]&gt;0: break if i&gt;0 and nums[i]==nums[i-1]: continue twoSum(nums[i+1:],(-1)*nums[i]) return resnums = [-1,0,1,2,-1,-4]# print(threeSum(nums))# # 167 两数之和 344 反转字符串 345反转字符串中的元音字母 11 最多的容器 15三数之和 16最接近的三数之和 0x04 滑动窗口 下周任务 0x05 简单题中也会蕴含着一些基本的操作 比如设置一些标志位、边界条件的设计、辅助元素的设置，这些需要潜移默化的刷题的过程中才能看到","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.tjdata.site/tags/Leetcode/"}]},{"title":"计算机网络-04-Chapter04 网络层协议","slug":"计算机网络-04-Chapter04 网络层协议","date":"2022-06-28T03:17:18.000Z","updated":"2023-05-13T13:53:42.470Z","comments":true,"path":"posts/582ef9f0.html","link":"","permalink":"https://blog.tjdata.site/posts/582ef9f0.html","excerpt":"在应用层我们可以解释数据传输的目的、在运输层分析可以看出两个主机进程之间逻辑通信、在本次的网络层将涉及主机与主机之间的通信服务是如何实现的。由于网络层的复杂性，其可以分为数据层面和控制层面。","text":"在应用层我们可以解释数据传输的目的、在运输层分析可以看出两个主机进程之间逻辑通信、在本次的网络层将涉及主机与主机之间的通信服务是如何实现的。由于网络层的复杂性，其可以分为数据层面和控制层面。 0x01 运输层overview 假设从H1向H2转送信息 H1中的网络层取得来自于H1运输层的报文段，将每个报文段封装成一个数据报，然后向相邻路由器R1发送数据， 在网络中经过多个路由器的转发和控制，到达接收方的路由器； 在网络的过程中每台路由器的功能是从输入链路向输出链路的转变；控制层面是协调本地的路由器转发动作，然后整个过程的数据报沿着origin和end主机之间的路由器路径进行主机之间端到端传送。 在接收方主机H2收到来自相邻路由器的R2的数据报，提取出运输层的数据段，并将其上交给H2的运输层，在传递给应用层 转发（forwarding）：指的将分组从一个输入链路接口转移到适当的输出链路接口的路由本地工作 路由选择（routing）：确定分组从origin到end次的网络范围处理过程 转发表（forwarding table）：路由器检查到达分组首部的一个或多个字段值，进而实现这些首部值在其转发表中索引，通过这种方法来转发分组 转发表制定的方法？？ 传统方法，路由器中物理存在的所有转发表的内容是由人类网络操作员直接配置的 SDN方法，远程控制器计算和分发转发表来供每台路由器选择；这个需要设计在具有高可靠性和冗余性的远程数据中心，由IDP或者第三方管理。此时路由器和远程控制器之间的通信通过软件定义网络（software defined networking，SDN）来控制 0x02 运输层分析 我们可以用开阔的视野来专注于我们引入的新东西并考虑网络层可能提供的不同类型的服务；在这样一个复杂的情况中可能存在的问题包括： 运输层如何将多个分组交付给目的地？ 运输层之后是否可以保持顺序？ 发送两个分组和接收分组的时间间隔相同吗？ 网络层如何提供拥塞的信息给运输层？ 在发送主机和接收主机之间连接运输层通道的抽象特性是什么？ === 这些答案都是对网络层提供的服务模型进行描述所决定。网络服务模型（network service model）定义数据分组在分送与接收端系统之间端到端的运输特性 我们首先考虑网络层所能提供可能的服务： 确保交付，该服务确保分组将最终到达目的地 时延上界，在特定的主机与主机之间的最大延迟 有序分组交付，确保分组按照发送顺序到达目的地 确保最小带宽，模仿发送和接收按照特定速率传输链路 安全性，网络层能够在源加密所有数据报，并在目的地解密这些分组 以及一些其他的方式 但是！因特网的网络层只提供一种服务，尽力而为服务（best- effort service）；其他的网络体系结构定义和实现了超过因特网尽力而为服务的服务模型，例如ATM网络体系实现了确保顺序恶化时间延迟、有边界时延迟的确保足校带宽、以及一些继承服务体系结构提供端到端的时延保证。但是因特网这种尽力而为的服务模型已经被证明足够好。 后面我们将讨论： 路由器内部硬件操作，包括输入和输出分组、内部交换机制以及分组排队和调度 传统的ip转发，其中分组基于它们的目的IP地址转发到输出端口，将学习到IP寻址 以及更近一步的一般转发，基于大量首部值来转发到输出端口 转发和交换两个术语；约定 分组交换机：指的是一台通用分组交换，根据分组首部字段的值，从输入链路转移到输出分组 链路层交换机：根据链路帧中的字段值做出转发决定 路由器（router）：其他的分组交换机称为路由器，基于网络层的数据报中的首部字段值做出转发决定 0x03 路由器工作原理 输入端口（input port）（硬件） 执行进入 物理链路的物理层功能 链路远端的数据链路层交互来执行数据链路层功能 输入端口需要执行查找功能 对于控制分组从输入端口转发到路由选择处理器 交换结构（switch）（硬件） 将路由器的输入端口连接到输出端口 网络路由器内部网络 输出端口（output port）（硬件） 存储从交换结构接收的分组，并执行必要的链路层和物理层功能 路由选择处理器（router select process） 传统控制，执行路由选择协议、维护路由选择表与关联链路状态信息 SDN控制，与远程控制器通信、输入输出端口安装表项 为什么路由器需要使用硬件实现？比如10Gpbs和64字节为单位的IP数据报，其输入端口在另一个数据报到达之间只有51.2ns来处理数据报，如果N各端口结合在一块线路卡上，数据处理速率必须以N倍速率来运行，远远超过软件实现的速率；数据层面以ms或者s的方面运行，执行包括路由选择协议、上下线路响应、远程控制通信和执行管理功能 在深入讨论路由器内部细节之前，我们需要明确路由器处理需要什么信息？ 有目的地转发 通用转发 3.1 输入端口处理和基于目的地转发 线路端接 数据链路处理（协议、拆封） 查找、转发、排队 交换结构 首先看出一个最基本的例子，路由器的输入端口分为四条链路，我们不必对路由器的映射包括40亿可能存在的地址；我们可以设置不同的匹配原则来进行交换，但是由于IP地址编码的存在，我们需要使用最大前缀匹配规则（longest prefix matching rule）来进行匹配 在转发表确定的此技术，查找是简单的，也就是实现硬件逻辑下的最大前缀IP，但是在Gpbs速率下，这种查找必须在ns执行，因此必须要用硬件执行查找、还需要对大型转发表使用超出简单线性搜索技术，硬件常时间DRAM、SRAM、TCAM等 确定分组的输出端口，该分组能够发送进入交换结构，如果其他分组正在使用，我们在进入交换结构时候暂时阻塞，因此一个被阻塞的分组必须在输入端口出排队，并等待稍后被及时调度来通过交换结构 必须出现物理层和链路层处理 必须检查分组的版本号、检验和以及寿命字段，并且重写这两个字段 必须更新用户网络管理的计数器 匹配+动作 3.2 交换 三种交换技术 内存交换 总线交换 互联网络交换 3.3 输出端口处理 3.4 排队分析 在输入端口和输出端口都会出现排队的现象，当路由器的缓存空间耗尽的时候就会出现丢包的现象 那么在什么情况下（输入速率、N和交换速率）在多少的时候会出现拥堵？如何缓解拥堵现象？ 输入排队：线路前部阻塞（HOL head of the line） 输出排队，弃尾（drop tail）、以及提供主动队列管理（active queue management，AQM算法）、随机早期检测（Random Early Detection，RED） 3.5 分组调度 排队的分组如何经输出链路传输的问题，这里存在一些基本的规则 先进先出 优先权排序 priority queuing 循环排序规则 round robin queueing discipline 0x04 网络层协议 – 网际协议（IPv4、IPv6） 4.1 IPv4数据报格式 关键字段分析 版本号 首部长度 服务类型TOS 数据报长度，因为该字节为16bit，所以IP数据报理论长度为65536；但是一般很少超过1500 标识、标志、片偏移，与IP分区有关，但是IPv6不允许分组 寿命TTL，time to live 协议，比如6标识TCP、17表示UDP；协议号类似运输层报文段中端口号字段起到的作用 首部检验和 源和目标IP地址 选项，意味着IP首部允许被拓展 数据，有效载荷，处理TCP、UDP还包括ICMP等协议 4.2 IPv4数据报切片 网络层下面的链路层的不同，其承载网络分组的长度也不同，有的协议能承载大数据报、有的协议只能承载小的分组。比如以太网不能超过1500字节、某些广域网不能超过576字节，这个被称为最大传送单元（Maximum Transmission Unit，MTU） 为了保证在所以的链路中都可以传输，我们需要将IP数据报中的数据分片成多个较小的IP数据报，用单独的链路层帧（Frame）来封装这些较小的IP数据报，然后通过输出链路发送这些帧，每个较小的数据报称为片（Fragment） 4.3 IPv4编址 在讨论IP编址之前，我们简要了解主机与路由器接入网络的方法，一台主机通常只有一条链路连接到网络，当主机中的IP想发送一个数据报，他就需要在该链路发送，这件称为接口（interface）；路由器由于是网络中的设置，因此具有多个接口；同时因为主机和路由器都可以发送和接收IP数据报，因此都需要拥有自己的iP地址，从技术上说，IP地址与一个接口相关联，而不是与包括该接口的主机或路由器相关联 IPv4采用点分十进制记法，比如192.168.0.1 在全球因特网中每台主机和路由器上的每个接口都必须有全球唯一的IP地址（在NAT后面的接口除外），这些地址不能随意自由选择 互联这主机接口和路由器接口形成一个子网（subnet），IP编址为这个子网分配一个地址，223.1.1.0/24.称为子网掩码（network mask） 因特网的地址分配策略为无类别域间路由选择（Classless interDomain routing，CIDR）将子网寻址概念化为a.b.c.d/x 构成IP地址的网络部分；网络中剩余的32-x比特被认为是用于区分该组织内部设置的，其中的额所有的设备具有相同的前缀 在CIDR被采用之前，IP地址的网络部分为选址为8、16、24比特，称为分类编址（classful addressing），称为A、B和C类网络，但是C类网络只能使用254台、B类可以65534太多了 特殊的IP地址，255.255.255.255为IP广播地址，该数据交付给同一个网络的所有主机 在详学习IP编址，我们需要知道主机或者子网最初是如何得到地址的 第一步：获取地址，可以从ISP获得、ISP从因特网名字和编号分配机构（Internet corporation for assigned Names and Numbers，ICANN）管理，其还管理DNS服务器 第二部，主机与路由器接口分配IP地址，系统管理员通常手工配置IP地址，主机地址也可以手动配置但是通常使用动态主机配置协议（Dynamic Host configuration，DHCP），允许主机自动获取一个IP地址，允许主机每次和网络连接的时候都会获得一个相同的IP地址或者临时的IP地址 4.4 地址转换与通信过程 对于家庭网络等专用网络（private network）和具有专用地址的地域（realm with private address），其中的IP地址只有在专用网络中才有作用；但是在专用网中至少需要有一个公网IP地址的设备，此时这个路由器是如何获取自己的iP地址的？使用的是ISP提供的DHCP服务 之间通信的过程是这样的： 专用网10.0.01:3345想和公网IP的128.119.40.186:80进行通信；专用网中的公网IP路由器为138.76.29.7，这个时候可以将专用网和公网IP路由器新增一个映射，10.0.0.1:3345和128.76.29.7:5001（5001任意），然后数据通过128.76.29.7：5001和128.119.40.186：80进行通信，路由器负责两者之间的转换，同时路由的NAT协议支持超过60000个并行连接 NAT协议的批评者指出： 路由器或者设备是用来进行进程寻址、而不是主机寻址的，这种违规用法在运行家庭网络中的服务器会出现问题；这里需要NAT穿越（traversal）或者通用即插即用（Universal Plug and play，UPnP协议） 违反了主机之间应当直接对话的原则 4.5 IPv6 0x05 控制层面 其中算法过于硬核，这里不做介绍，可以看出转发表的制作分为两种 预先物理设置 由SDN来软件控制 软件控制面临集中还是分散的区别、面临静态路由和动态路由、面临负载敏感或迟钝的问题 0x06 实际应用和感悟 6.1 一个实际的例子 6.2 一些实际的应用 ssh连接远程主机 搭建自己的webdav云盘 开放自己的MC服务器 利用腾讯云服务器实现内网穿透","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"network","slug":"network","permalink":"https://blog.tjdata.site/tags/network/"}]},{"title":"计算机网络-03-Chapter03 运输层协议","slug":"计算机网络-03-Chapter03 运输层协议","date":"2022-06-24T02:16:56.000Z","updated":"2023-05-13T13:53:36.145Z","comments":true,"path":"posts/30d17536.html","link":"","permalink":"https://blog.tjdata.site/posts/30d17536.html","excerpt":"尝试将课本中的知识重新整理成为自己的post，虽然用自己的理解去描述可能会带来错误，但是“太对的话并没有新的价值”，本次主要描述位于计算就网络应用层和网络层之间的运输层的通信协议，以及其在传递过程中的：可靠性和拥塞控制两个基本问题。","text":"尝试将课本中的知识重新整理成为自己的post，虽然用自己的理解去描述可能会带来错误，但是“太对的话并没有新的价值”，本次主要描述位于计算就网络应用层和网络层之间的运输层的通信协议，以及其在传递过程中的：可靠性和拥塞控制两个基本问题。 0x01 背景 1.1 运输层概述 运输层为运行在不同主机上的应用进程之间提供逻辑通信（logic communication），从应用程序的角度来说，运行不同进程的主机之间好像直接相连一样，而不用考虑承载这些物理基础设施的细节。 运输层协议是在端系统中而不是路由器中实现的： 在发送端，运输层将从发送应用程序进程接收到报文转换成运输层分组成为运输层报文段（segment），（后续网络层可能会封装成网络层分组（数据报）向目的地发送，在这个过程中网络路由器仅作用于该数据报的网络层字段），在接收端网络层从数据报中提取出运输层字段，并将报文上交给运输层 网络应用程序中可以有多种运输层协议，在因特网中包括UDP和TCP协议。 ？运输层和网络层区别？ 运输层主要负责两个host之间不同进程之间的通信；而网络层提供host之间的逻辑通信；以寄快递的方式来描述： 应用层报文是快递里面的东西，运输层主要负责收件人的具体信息，运输层协议主要负责各地区收集和分发快递人员；网络层主要负责收货地址，网络层协议主要负责运输车辆、方式的分配 这种解耦的过程可以为不同进程通信之间规定不同的协议，而不是每个人都安排一辆车或者一种地址编码方式来造成杂乱的情况；同时不同的运输层协议也可以搭配不同的网络层协议。 1.2 因特网运输层概述 UDP：用户数据报协议，这个进程提供一种不可靠、无连接的服务 TCP：传输控制协议，提供可靠的、面向连接的服务 结合IP层理解可能会更好，这里需要了解的是：因特网网络协议的为IP协议（网际协议），提供主机与主机之间的逻辑通信，服务模型是尽力而为角度，并不作任何确保，也就是称为不可靠服务，在这一章我们需要知道的是每一台主机都有一个IP地址 UDP和TCP的基本责任是将两个端系统之间的IP交付服务拓展到端系统上两个进程之间的交付服务，这个称为多路复用（transport- layer multiplexing）和多路分解（demultiplexing）。除此之外TCP还会提供可靠数据传输（reliable data transfer）和拥塞控制（congestion control） 举个例子：当你坐在计算机下载web页面，这个时候需要运行一个FTP会话和两个Telnet会话，这样4个网络应用进程在运行，在这个时候我们需要将主机接受到的信息分配给这4个进程中的一个，这就是运输层负责事情。应用层里面是通过套接字（socket）将数据从应用层传向运输层和向运输层进程传递数据的门户，因此在任何一个时刻主机上存在多个套接字，套接字具有唯一的标识符。 ？那么主机如何将一个到达的运输层报文定向到适当的套接字？ 这个就需要我们在运输层报文段中定义一些字段，在接收端运输层来解析这些字段来将报文定向到套接字，这个就是多路分解（demultiplexing）的过程；在源主机上将报文段传递到运输层这个工作称为多路复用（multiplexing）；但是当然TCP相比较UDP的解析过程会更加复杂 1.3 规范语言 报文段（segment）：经过网络层到达运输层后生成的分组报文 数据报（datagram）：运输层的报文到达网络层生成的分组报文 socket：应用层进程和运输层之间数据通信的方式，同一个host存在多个套接字，每个套接字具有唯一标识符 多路复用：多个数据传输到运输层 多路分解：收到下层数据转移到上层多个进程 0x02 基本原理 2.1 可靠数据传输原理（Reliable Data Transfer Protocol） 在数据传输的过程中，我们会遇到差错、损坏和丢失的现象，想要按照原来数据复原就是可靠数据传输协议需要规范的事情，这种协议可以看作是策略方面的method，因为它不仅可以适用于运输层、也可以网络层或者应用层，更重要的是内在思想，而TCP相比较UDP的一方面就是使用了可靠数据传输的东西 可以参考https://blog.csdn.net/qq_40177015/article/details/112836182 最基本的模型如下图所示，后面我们可以层层递进来看这个是如何实现的： 2.1.1 RDT1.0 – 底层信道可靠的情况 那就只需要 发送端：接受上层的data、转换（make-pkt）成数据段packet、然后发送（send） 接收端：接受下层的packet、提取extract出数据data、然后移交deliver给上层 2.1.2 RDT2.0 – 底层差错的情况（但不会丢失） 出现差错我们的第一反应是需要：如何检查出差错、以及如果告诉发送方错了、以及重新发送，这种称为基于自动重传请求（ARQ、automatic repeat request） 2.1.3 RDT2.1&amp;2.2 但是RDT2.0并没有考虑ACK和NAK错误的情况，这个时候发生发送端忘记重传或者过度重传，这个时候我们需要对报文进行标记，也就是需要增加数据分组编号（sequence number）来帮助区分，这也就是RDT2.1的工作 由于同时检验ACK和NAK很麻烦，因此可以设计单纯只用ACK的确认和否定就可。 2.1.4 RDT3.0 – 经过比特差错和丢包信道的可靠信息传输 针对丢包，我们需要设置定时器（？如何针对每个报文设置），在一定的时间间隔（？后面介绍这么确定）下，没有收到ACK就重新发送 2.1.4 暂停思考RDT RDT是一个功能完全正确的协议，但是它是一个停等协议，在于我每个分组报文需要等到上一个ACK到来的时候再重新发送，信道中只有一个报文必然是浪费的 因此我们可以采用流水线的方式，不停的发送报文，但是这个时候又会面临新的问题 2.1.5 流水线-退回N步（GBN） 由于流水线允许发送发连续发送多个分组而不需要等待确认，在这个过程中出现某个数据分组差错或者丢失的情况就非常麻烦，GBN设置是错误就退回N步重新发送，这样的缺点是通信系统可能会被许许多多的无用报文充斥 2.1.6 流水线-选择重传（SR） 为了解决GBN的问题，可以使用选择重传的协议，对于错误之后的序列号接收端保存 2.1.7 总结 在经过上述可靠数据传输机制的描述之后，存在一些基本概念： 差错检验（checksum） 定时器（timer） 序号（sequence number） 确认（acknowledgement） 否定确认（NAK） 窗口、流水线（windows、pipeline） 2.2 拥塞控制原理 https://zhuanlan.zhihu.com/p/37379780 2.2.1 什么是拥塞 作用于网络的，避免过多的无效重传数据充斥在传输网络中 第一种情况：两台机器之间+无限缓存的路由器 第二种情况：两台机器之间+有限缓存的路由器 第三种情况：多台机器之间+有限缓存的路由器 2.2.2 拥塞控制方法 第一种方法：端到端的拥塞控制，比如根据报文丢包情况来观察网络拥塞状态，进而缩小自己的窗口（TCP采用的） 第二种方法：网络辅助拥塞控制，网络中路由器等传输给端设备，高速拥堵情况 0x03 UDP/TCP 3.1 UDP传输协议 3.1.1 UDP报文 源端口：发送方的进程对应的socket的端口 目的端口：接收方的进程对应的socket端口 报文长度：用来检查报文是否会出错 检验和：最基本的差错的checksum检验 3.1.2 UDP套接字编程 1234567891011121314151617181920UDPClient.pyfrom socket import *serverName=&#x27;hostname;serverPort=12000// 常见客户端的套接字clientSocket=socket(AF_INET，SOCK_DGRAM)// 第一个参数代表使用了ipv4；第二个参数代表该套接字是SOCK——DGRAM类型的message=raw_input(&#x27;Input your message:&#x27;)//有了信息和发送端socketclientSocket.sendto(message.encode(),(serverName,serverPort))//之后等待服务器的数据modifiedMessage,serverAddreess =clientSocket.recvfrom(2048)// 2048代表分组信息到达该客户端套接字，该分组的数据的放到变量modified message中// 源地址放置到变量server Address，取缓存长度2048作为输入print(modifiedMessage.decode())clientSocket.close() 3.2 TCP传输协议 3.2.1 TCP报文 首部包括16比特源端口号和16比特目的端口号，被用于多路复用/分解来自或者送到上层应用的数据 32比特的序号字段（sequence number field）和32比特的确认号字段（acknowledgment number field）用于实现可靠数据传输服务，随机的初始序列号还是很有意思的；讨论见后 4比特的首部字段长度（header length field），指示以32比特的字为单位的TCP首部长度，由于TCP选项字段的原因，TCP首部的长度是可变的，一般为空则说明典型长度为20字节 8比特的标志字段（flag field） ACK，指示确认字段的值是有效的 RST、SYN、FIN，用于连接和拆除 CWR、ECE，拥塞通知里面使用 PSH，有值时，应当指示接收方立即将数据交给上层 URG，指示报文段中存在的被发送端的上层设置为紧急的数据，最后一个字节有紧急数据指针字段给出 16比特的接受窗口（receive windows field），用于流量控制，用于指示接收方愿意接受的字节数量 校验和字段（checksum field） 16比特的紧急数据指针（urgent data pointer field） 3.2.2 TCP整个过程 TCP连接是在复杂的物理网络中建立两台主机（host）之间的点对点（point to point）之间的连接；两台主机之间连接的简约过程是通过三次握手（three-way handshake）进行的： 客户端发送一个特殊的TCP报文段，服务器使用另一个特殊的TCP报文段来响应，之后客户端利用第三个特殊报文段作为响应，第三个可以包含有效负荷（也就是应用层数据），整个过程称为三次握手；之后包括四次挥手的过程；详细如下： 第一步，client首先向服务器TCP发送一个特殊的TCP报文段，SYN报文段设计为1，同时client随机选择一个初始序号，包装在一个IP数据报发送给server 第二步，这个特殊的TCP报文段到达server后，该TCP连接分配缓存和变量，并向client发送允许连接的报文段，这个允许的报文段包括三个重要的信息：SYN比特为1、确认号设置client-isn+1、设置服务器的server-isn字段，这个被称为SYNACK segment client在受到回复之后，为该连接分配缓存和变量，client向server发送另外一个报文段，对于服务器的允许连接的报文段进行确认，server-isn+1设置到TCP报文段首部确认字节，这里可以报文段中携带数据 拆除： 通过FIN字段来设置关闭报文段，client发送包含FIN报文，server发送ACK；之后server发送FIN，client回复ACK，如果没有关闭设置超时重传机制 之后应用层通过套接字（socket）来传递数据流，这些数据被引导到连接到发送缓存（send buffer）中，之后TCP会时不时地从发送缓存中取出来一块数据，并将数据传递到网络层，这里取出多少数据受限于最大报文段长度（maximum segment size，MSS），这个通过由最初确定的最大链路层帧长度（MTU）确定 3.2.3 TCP的可靠数据传输 定时器的重要设计是需要了解多长时间才是超时？因此需要对两个host之间的传送时间进行确认，这个需要考虑的这个超时时间间隔重传的设置，它必须要大于该链接的往返时间（RTT），以及是否需要为所有未确认的报文段各设置一个定时器 TCP连接为每一个时间段做出一次SampleRTT，结合历史估计的Estimate RTT来做移动平均（EWMA，exponential weighed moving average）；同时定义偏差DevRTT EstimateRTT=0.875EstimateRTT+0.125SampleRTT DevRTT=0.75DevRTT+0.25（SampleRTT- EstimateRTT） 设置时间间隔为 Timeout Interval=EstimateRTT+4DevRTT 在可靠性传输章节我们可以看到对于丢包最重要的是定时器的设置、对于发送方最重要的是定义如何重传数据，因此在TCP中采用的方法如图：也就是采用一个定时器的超时重传机制。 超时间隔加倍 定时器时限过期之后超时间间隔的长度，在这种修改中，没当超时事件发生后，TCP重传具有最小序号的还未被确认的报文段，只是每次TCP重传都会将以下一次超时间隔设置为前面的2倍；这种修改提供了一种形式受限的拥塞控制，因为时延增加并且重传会导致拥塞更严重 快速重传 上述的超时重传的问题在于超时周期可能相对较长，当一个报文段丢失时，这种长超时周期使得发送方延迟重传丢失的分组，从而增加了端到端的时延，这里可以采用冗余ACK（duplicate ACK）来帮助检测丢包 GBN or SR TCP更多的事选择确认（selective acknowledgement），属于两者之间balance 3.2.4 TCP的拥塞控制 还没看懂～～ https://zhuanlan.zhihu.com/p/37379780 这位博主总结为 慢开始、拥塞避免 快重传、快恢复 https://zhangbinalan.gitbooks.io/protocol/content/tcpde_yong_sai_kong_zhi.html 慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )。 3.3 两者对比 既然TCP比UDP多出来这么多功能？两者之间的优劣在哪里呢，UDP提供了速度快、报文传递多的特点，而TCP虽然点对点安全传递但是计算开销大，适合用于安全性较强的业务。 关于发送什么数据以及何时发送的应用层控制更为精细；采用UDP主需要进程将数据传送给UDP即可，但是TCP具有拥塞控制机制；在一些应用中更加强调实时性，而不必要数据的完整性 无须连接建立，对于网页HTTP连接中可靠性是重要的，同时实时性也是重要的，所以谷歌的QUIC协议是在UDP协议的基础上在应用层协议中实现了可靠性 无连接状态，TCP需要保持连接状态，这个包括接受和发送缓存、拥塞控制i参数以及序号与确认好的参数，而UDP不需要追踪这些参数，因此在某些特定应用使用UDP可以支持更多的并发用户 分组首部开销小，TCP报文段20字节的首部开销、UDP仅有8字节 同时在UDP不可靠的基础上，可以在应用层上增加可靠传输协议来实现可靠UDP（比如Google的QUIC协议） 0x04 回顾、收获和展望 将本科信息传输原理、通信网络基础没有听懂的数据报整明白了出处；并且在描述一件事情的过程最好先简化一个基本模型、然后逐步添加。同时理清楚其中的原理、策略和具体操作之间的区别和联系","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"network","slug":"network","permalink":"https://blog.tjdata.site/tags/network/"}]},{"title":"计算机网络-02-Chapter02 应用层协议","slug":"计算机网络-02-Chapter02 应用层协议","date":"2022-06-18T11:43:22.000Z","updated":"2023-05-13T13:53:26.643Z","comments":true,"path":"posts/e75be22e.html","link":"","permalink":"https://blog.tjdata.site/posts/e75be22e.html","excerpt":"网络应用是计算机网络存在的理由，如果我们不能构想出任何游有用的应用，也就没有必要支持它们的网络协议来，正是因特网的全面发展以来，的确开发众多有用的、有趣的网络应用，正是这些应用程序成为因特网成功的驱动力。 一些非常有意思的历史： 20世纪70年年代到80年年代，流行的经典的基于文本的应用，比如电子邮件、远程访问计算机等； 20世纪90年代中期引入的万维网，包括Web冲浪、搜索和电子商务 20世纪末，引入的即时通讯和对等P2P文件分享 之后出现来：IP电话、视频电话、视频网站、在线游戏 再到智能手机发展：签到、约会和地图导航等等 贲本章主要学习网络应用的原理和实现方面的只是，从关键的应用层概念开始，描述网络服务、客户和服务器、进程和运输层接口，之后设计开发运行在TCP和UDP的网络应用程序，之后学习Socket接口来编写一些简单的客户-服务器应用程序。","text":"网络应用是计算机网络存在的理由，如果我们不能构想出任何游有用的应用，也就没有必要支持它们的网络协议来，正是因特网的全面发展以来，的确开发众多有用的、有趣的网络应用，正是这些应用程序成为因特网成功的驱动力。 一些非常有意思的历史： 20世纪70年年代到80年年代，流行的经典的基于文本的应用，比如电子邮件、远程访问计算机等； 20世纪90年代中期引入的万维网，包括Web冲浪、搜索和电子商务 20世纪末，引入的即时通讯和对等P2P文件分享 之后出现来：IP电话、视频电话、视频网站、在线游戏 再到智能手机发展：签到、约会和地图导航等等 贲本章主要学习网络应用的原理和实现方面的只是，从关键的应用层概念开始，描述网络服务、客户和服务器、进程和运输层接口，之后设计开发运行在TCP和UDP的网络应用程序，之后学习Socket接口来编写一些简单的客户-服务器应用程序。 2.1 应用层协议原理 在应用层程序开发过程中，最重要的一点是不必要关心网络中路由设置等等情况。 2.1.1 网络应用程序体系结构（ Application architecture） 应用程序研发者设计，规定如何在各种端系统上组织该应用程序，在选择应用程序体系结构时，应用程序研发者很可能利用现代网络应用程序所使用的两种主流体系结构之一：客户-服务器体系结构和对等P2P体系结构 Client-server architecture，可能会出现多台客户端想服务器响应，在这个过程服务器的IP地址是固定的，但是会出现单独的服务器主机跟不上所有客户请求的情况，因此需要设置多个数据中心Data center用来创建强大的虚拟服务器，通常一个数据中心可能存在数十万台服务器 P2P architecture，应用程序对于专用服务器的具有最小的依赖，相反应用程序在间断连接的主机之间使用直接通信，这些主机对称为对等方，服务器用于跟踪用户的IP地址，但是用户到用户的报文在用户主机之间无须通过中间服务器直接发送，一个比较大的特点是具有自拓展性（self-scalability） 2.1.2 进程通信（Process communication） 在构建网络应用需要对运行在多个端系统上的程序是如何进行通信的情况进行了解，⚠️计算机网络中并不关注于同一台主机的进程，而是不同端系统的进程（Process）之间的通信机制 在进程之间的通信会话场景中，发起通信的称为客户（Clinet）、在会话开始等待联系的是服务器（Server） 进程与网络之间通信的接口需要使用套接字（Socket）的软件接口向网络发送message和接受message；调用系统提供的socket api和操作系统，将其转换为不同的流量的tCP再发送。我们可以在Socket中选择什么？ 选择运输层的协议 设定几个运输层参数，比如最大缓存和最大报文长度 同时在进程需要考虑地址IP和端口Port的选择 TCP/UDP端口列表 - 维基百科，自由的百科全书 2.1.3 可供应用程序使用的运输服务 针对不同的Application自然需要不同的运输方式，比如实际的火车、飞机各有不同，计算机网络传输方式也是相同。需求分析需要从之间的计算机网络的基本特性出发 可靠性数据传输（reliable data transfer） 吞吐量（Bandwidth） 定时（Time delay） 安全性（Security） 2.1.4 因特网（或者抽象模型下次层）提供的运输服务 提供TCP和UDP传输协议，这个是运输层提供的选择 TCP的主要特点是面向连接的服务，会有握手的过程，同时提供可靠的数据传输服务以及拥塞控制机制。 UDP提供不必要服务的轻量级运输协议，面向无连接的 额外的会有Security Socket Layer来将进行加密，提供关键进程到进程的安全性服务 2.1.5 应用层协议（application-layer protocol） 学习如何构造报文发送到Socket实现网络进程之间的相互通信，如何构造这些报文？如何明确这些报文中字段的含义？在何时发送报文？这些都是由协议规定的： 交换的报文类型，利用request和response报文 报文中字段是如何描述 字段的语义 确定一个进程何时以及如何发送报文 2.2 Web和HTTP Web是一个引起公众注意的因特网应用，极大的改变了人与工作环境交流的方式，它将人们从被动接受转向按需操作 2.2.1 HTTP概况（HyperText Transfer Protocol，HTTP） 超文本传输协议是Web的核心，主要由客户端程序和服务器程序组成，在两个不同的host中，通过交换HTTP报文进行会话，需要回顾Web术语。 Web页面（web page）是由对象（Object）组成的，包括HTML文件、JPEG图片、JAVA程序或者视频等 URL是这些文件寻找地址的东西，多数Web页面包含HTML文本和5个JPEG图形，浏览器（Web browser）实现了HTTP的客户端、服务器（Web server）实现了HTPP的服务器端，用于存储web对象 HTTP也定义了客户端请求和回复Web页面的方式，HTTP使用TCP作为支撑运输协议，即HTTP一定能保证报文可以传递，同时在请求和回复的状态中，服务器并不会保存关于客户的任何信息，因此是一个无状态协议（Stateless protocol） 2.2.2 非持续连接和持续连接（yes or no persistent connection） 也就是客户端和服务器之间会存在一个持续文件交互是采用单独的TCP连接，还是经过不同的TCP连接，经过激烈的讨论希望在一定时间间隔内采用持续性连接的方式，超过之后采用非持续性连接的方式 2.2.3 HTTP报文格式 第一种请求报文，第一行是request line，后面的行header line， 请求行包括方法字段、URL字段和HTTP版本 常用的方法有GET、POST、HEAD、PUT、DELETE HOST提供信息是web代理高速缓存所需要的 Connection：高速服务器不要使用持续连接 User-agent：指明用户代理，也就是服务器的类型 Accept-language：表示拥护想要该对象的版本 三个部分：初始状态行status line、六个首部行header line、实体行entity body HTTP以及状态码 connection 表示发送完之后将关闭tcp连接 200 OK请求成功 301对象被永久转移了 400通用差错代码 404 请求的文档不在服务器上 505 服务器不支持请求报文使用的HTTP协议版本 Date 表示服务器从文件系统中检索到该对象，并插入响应报文并发送该报文的时间 Server：表示服务器产生 Last-modified：表示对象创建或者最后修改的日期和时间 Content-Length：包含的字节数 content-type：对象是HTML文本 2.2.4 服务器缓存 cookie 无状态的HTTP服务器简化了设计，但是为了识别用户，还是希望将请求内容与用户身份联系起来，为此使用Cookie，其主要由四个组件构成 在HTTP响应报文中一个cookie首部行 在HTTP请求报文中一个cookie首部行 在用户端系统中保留有一个cookie文件，并由用户的浏览器进行管理 位于web站点的一个后端数据库 但是结合cookie用户提供的账户信息，web站点可以知道许多用户的信息 2.2.5 Web缓存（cache） 也叫做代理服务器（proxy server），是能够代表初始Web服务器来满足HTTP请求的网络实体 web缓存可以大大减少客户请求的响应时间， 同时可以大大减少一个机构的接入链路到因特网的通信量，通过内容分发网络（Content Distribution Network，CDN），web缓存器正在让因特网发挥越来越多的作用 但是web缓存的一个重要的问题可能是，存放在缓存器中的对象副本可能是陈旧的，这就需要缓存器证实对象是最新的，也就是条件GET（conditional GET方法） 2.3 Mail和SMTP、POP3、IMAP、HTTP 当因特网还在襁褓之中，电子邮件已经称为来最流行的应用程序，是一种异步通信媒介，也就是人们方便的时候可以收发邮件，不必与他人计划进行协调。同时电子邮件的优势在于具有附件、超链接、html格式文本的图片的报文。 首先看电子邮件的总体结构以及关键组成部分 用户代理 user-agent 邮件服务器 mail-server 简单邮件传输协议 simple-Mail-Transfer-Protocol，SMTP 重要的场景： SMTP一般不使用中间邮件服务器发送邮件，即时这两个邮件服务器位于地球两端也是这样的，即使另一个服务器没有开机，这样的报文也会保留在ALice的邮件服务器上等待进行新的尝试 2.3.1 SMTP协议 2.3.2 SMTP协议与HTTP协议对比 HTTP 从Web服务器向客户端传送文件；但是HTTP是一个pull protocol，在方便的时候，某些人在Web服务器上装载信息，用户使用HTTP协议从服务器上拉取这些协议 SMTP 从一个邮件服务器向另一个邮件服务器传送文件，也就是发送邮件服务器将文件推向接受邮件服务器 其他的区别： STMP要求每个报文按照7比特ASCII格式，如果含有非法的7比特或者二进制的图形文件，需要按照7比特ASCII进行编码，HTTP不受这样的限制 如何处理包含文本和图形的文档，HTTP将其封装在HTTP响应报文中，SMTP则把所有报文对象放在一个报文中 2.3.3 邮件报文格式 类似与SPI、CAN，无线传递都需要使用首部行来作为标识，只是作为应用层的标识可能更人性化一点，但是这样的人性化可能在一定程度上让人产生费解，之后理解背后的机理才能更好理解别人。 2.3.4 邮件访问协议 之前讨论的SMTP协议，必须要求发送端发送的时候，接收端在线，但是由于PC或者手机不能一种保持在线，因此通常需要一个共享的邮件服务器，但是这个服务器和代理之间不能通过SMTP传送，因为SMTP只能Push，不能PULL文件，因此需要一些流行的邮件访问协议，包括 第三版的邮局协议，POST-OFFCIE-PROTOCOL，POP3 第一个阶段：特许（Authorization） 第二个阶段：事务处理 第三个阶段：更新 特点，一旦将邮件下载到本地主机就能简历邮件文件夹，并将下载的邮件放入该文件夹中，之后Bob可以删除报文，可以在文件夹之间移动报文，并查询报文，但是POP3协议没有给用户提供任何创建远程文件夹并为报文指派文件夹的方法 因特网邮件访问协议 Internet Mail Access Protocol，IMAP IMAP协议是一个邮件访问协议，每个报文与一个文件夹联系起来，当报文第一次到达服务器时，与收件人的inbox的文件夹相关联，收件人则能够把邮件转移到一个新的、用户创建的文件夹中，阅读邮件、删除邮件等 还提供了在远程文件夹中查询邮件的命令 维护了IMAP会话的用户状态信息 （重要）允许用户代理获取报文某些部分的命令 HTTP 在上述选择和获取的过程采用的是http的协议 但是邮件传输的过程中仍然采用的是SMTP协议 2.4 URL和DNS 一件事物通常可以通过多种方式来进行标识，我们可以通过姓名来标识，也可以通过身份证来标识、也可以通过社保账号来有限的、通过某个学校的学号来确定的认识一个人，在不同的场景下可以采用不同的识别方式，对于计算机网络中的主机有多种方式 主机名称（Host name），www.baidu.com等，但是主机几乎没哟提供主机在因特网中的位置信息 IP地址，利用4字节组成，具有严格的层次结构，这里将在第四章中进行讨论 2.4.1 DNS（Domain Name System，域名系统） 人们容易记住主机名标识方式，但是路由器喜欢定长的、有着层次结构的IP地址，为了这些不同的偏好，我们需要一种将主机名称转换到IP地址的目录服务，这就是域名系统的主要功能 一个分层的DNS服务器实现的分布式数据库 一个是的主机能够查询分布式数据库的额应用层协议 DNS服务器通常是运行BIND（Berkeley internet name domain）软件的UNIX，使用53端口，考虑它如何使用，可以观察一个客户端发送URL请求会发生什么样的过程： 用户主机上运行DNS应用的客户端 浏览器从上述URL中抽取出主机名，也就是URL，传递给DNS应用的客户端 DNS客户端向DNS服务器发送包含主机的请求 返回ip地址的报文 一旦浏览器没收到来自DNS的IP地址，向该IP地址的80端口的HTTP服务器进程发送一个TCP连接 除进行主机到IP地址的转换之外还提供服务 主机名到ip地址转换 主机别名 host aliasing 邮件服务器别名 mail server aliasing 负载分配 load distribution 用于在冗余的服务器之间进行负载分配，繁忙的站点被冗余分布在多台服务器中，每台服务器均运行在不同的端系统高上，因此ip地址集合可以与同一个规范主机名相联系。一些内容分发公司也以更加复杂的方式使用DNS来提供web内容分发 2.4.2 DNS工作原理概述 DNS客户端使用gethostbyname() 的方法可以简单的得到IP地址的报文，但是对于DNS内部机理复杂，因为它是由分布在全球大量的DNS服务器以及定义DNS服务器与查询主机通信方式的应用层协议组成 如果一个网络只存在一个DNS服务器 单点故障 a single point of failure 通信容量 traffic volume 远距离的集中式数据库 distant centralized database 维护 maintenance，因此需要采用不同层次方式组织 需要分布式、层次数据库 根DNS 顶级域 Top Level Domain TLD 权威DNS服务器 本地DNS服务器，这个由ISP提供，本地DNS服务器通常使用DHCP与其他本地DNS服务器连接，在本次网络中可能与用户的服务器临近，起到了代理的作用 这里使用到了递归查询（recursive query）和迭代查询（iterative query）两种方式 💡 DNS缓存 为了改善时延和减少互联网上的DNS报文数量，广泛使用缓存的概念，一般情况下DNS服务器在同一段时间内会丢弃缓存的信息，这样会让的根服务器或者TLD的服务器被绕过 💡 DNS记录和报文 共同实现了DNS分布式数据库的所有DNS服务器存储的资源记录，只有查询和回答报文 2.5 File Share和P2P 到目前为止，本章描述的应用包括web、电子邮件和DNS都采用了客户-服务器体系结构，极大依赖于总是打开的基础u设施服务器，使用P2P体系结构对于总是打开的基础设置设施服务器有最小的依赖，与之相反，成间歇连接的主机批次直接通信，这些对等方并不为服务提供商ISP所拥有，而是受用户控制的桌面计算机和个人计算机 本次章节将研究一个非常自然的P2P应用，即从单一服务器向大量对等方发送大文件，这里可能是Linux操作系统，也有可能是MP3音乐文件等，在客户-服务器文件分发中，该服务器必须向每个对等方发送该文件的副本，服务器承担了极大的负担，并且消耗了大量的服务器带宽；在P2P文件分发中，每个对等方能够收到任何其他对等方重新分发已经收到的该文件的任何部分，而从在分发过程中协助该服务器，2016年中最重要的是BitTorrent 2.5.1 P2P体系结构的拓展性 为了将客户-服务器体系结构与P2P体系结构进行比较，阐述P2P的内在自拓展性，我们现在考虑一个用于两种体系结构类型的简单定量模型 2.6 VIdeo Stream和内容分发网CDN 在本节我们将对如何在今天的因特网实现流行的视频流服务进行概述，实现的方式是通过应用层协议和像高速缓存那样方式运行的服务器。 2.6.1 因特网视频 video是一系列的图像，通常是按照一种恒定的速率来，这些是通过像素阵列组成，通过比特编码来实现亮度或者颜色，因此比特率越高、图像质量越好，用户的总体视觉感受越好，因此视频网站也会根据视频设置不同清晰度的版本 2.6.2 HTTP流和DASH（dynamic adaptive streaming over HTTP） HTTP流中，视频只是存储在HTTP服务器中作为一个普通的文件，每个文件都有一个特定的URL，当用户查看这个视频的时候，客户与服务器创建一个TCP连接并发送对该URL的get请求，服务器则以底层网络协议和流量条件允许的尽可能快的速率，发送视频文件，另一端字节被收集到客户应用缓存中，一段超过预先设定的门限，客户应用程序就可以开始播放 对于相同的客户的不同时间也有可能存在不同的带宽，因此需要根据不同时段，设计不同的比特率，对应于不同的质量水平，客户动态选择来自高速率版本的快，当可用带宽量较低的时候，客户可以自然选择来自低速率版本的快 2.6.3 内容分发网 content distribution network 对于一个因特网视频公司，最直观的是建立单一的大规模数据中心，在数据中心中存储所有的视频，并直接从该数据中心向世界范围的客户传输流式视频，会存在一些问题 如果客户远离数据中心，服务器到客户的分组将跨越许多通信链路并肯呢个经过不同的ISP，导致烦人的通信时延 经过多条链路会浪费网络带宽 单个数据中心代表着单点故障 2.7 课后习题 课后习题和问题_与君共勉的技术博客_51CTO博客 课后习题和问题 复习题 2.2～2.5节_与君共勉的技术博客_51CTO博客 1nslookup blog.tjdata.site","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"network","slug":"network","permalink":"https://blog.tjdata.site/tags/network/"}]},{"title":"工科生研0的Macbook Air M1 13inch（16+256）深度使用感受","slug":"工科生研0的Macbook Air M1 13inch（16+256）深度使用感受","date":"2022-06-12T03:49:56.000Z","updated":"2023-05-13T13:52:11.846Z","comments":true,"path":"posts/9148fb62.html","link":"","permalink":"https://blog.tjdata.site/posts/9148fb62.html","excerpt":"在深度使用M1一年之后，在即将比如研究生生活之前，介绍一次Mac。同时也会结合自己的华为Mate40pro介绍macOS+ipadOS+harmonyOS在日常使用的习惯，说明常用的软件、硬件的配件、文件管理和同步以及password以及GTD管理、环境管理中Linux和python环境以及Git使用等，作为一次Summary 本次介绍的主体是2020年发布的M1芯片的Mac，也经历了结构更迭之苦，当然一年之后能看到ARM架构的优越性。具体规格配置如图 MacBook Air (M1 芯片机型) - 技术规格 【写作时间】2022年6月12日","text":"在深度使用M1一年之后，在即将比如研究生生活之前，介绍一次Mac。同时也会结合自己的华为Mate40pro介绍macOS+ipadOS+harmonyOS在日常使用的习惯，说明常用的软件、硬件的配件、文件管理和同步以及password以及GTD管理、环境管理中Linux和python环境以及Git使用等，作为一次Summary 本次介绍的主体是2020年发布的M1芯片的Mac，也经历了结构更迭之苦，当然一年之后能看到ARM架构的优越性。具体规格配置如图 MacBook Air (M1 芯片机型) - 技术规格 【写作时间】2022年6月12日 01 Software management 在使用的过程中，很多软件都没有兼容M1，兼容M1的破解版也少的可怜 常用的Mac软件下载网站： MacWk - 精品mac软件下载 1.1 处理不同格式文件软件 Office 三件套：docx、ppt、xlsx WPS ：同office，虽然功能会少一点，但是带来的是性能的提升 Typora：Markdown Sublime Text：打开、轻编辑 【code】、markdown、latex（快） Skim：打开PDF文件，搭配Sublime Text使用（快） PDF Expert：编辑PDF文件 iMovie：编辑视频文件 IINA：视频播放软件（快） Capture One：修图软件 1.2 牛刀类工具 Notion：非常好用的笔记软件 Zotero：文献管理软件，可以搭配notion使用 Marginnote3 : 阅读PDF和知识管理软件，不太好用 OmniGraffle ： 流程图绘制软件（平替 draw.io网站） Xmind：思维导图软件，正在用的 Edge：很不错的浏览器 Axure RP：原型设计软件 Parallels Desktop：虚拟机管理 Terminus：终端增强 1.3 润物细无声的小工具 ClashX：代理软件简介 Rectangle：窗口管理 欧路词典：查单词 iStat：硬件状态 iPic Free：markdown的图片上传 Aldente：充电管理 GifSki：压缩生成GIF文件 SVGview：查看SVG Hidden bar：状态栏设置隐藏 iShot：截图软件，可以长截图和标记（command shift 4/5可以截图和录屏） Better Zip：解压缩文件 ClipborderManagement：剪贴板管理 坚果云+Nextcloud：Webdav文件管理 cheetsheet：快捷键提醒 Monitor Control：管理显示器的亮度 Mail+Calendar+Reminder+Notes+Music：自带的软件都非常高 1.4 娱乐类工具 B站客户端 腾讯视频 虚拟机内的植物大战僵尸 微信-QQ 百度网盘+阿里云盘 02 Hardware management Anker Nano II 65W充电头 小米100w快充线（2m） Belkin七合一拓展坞 罗技Master 2s DP1.4绿联转接线 西数移动硬盘*2T 华为原装TypeC耳机 03 File management and workflow 3.1 Mac本地文件管理和备份 256G的固态硬盘用起来比较着急，好在速度很快，全新 M1 MacBook Air 的固态硬盘写入速度为 2190 MB/s，读取速度为 2675 MB/s；相比较手机的sfs的速度可发现该机连续读取约为 1966M/s，持续写入 1280M/s；相比较UFS3.1通常为1200M/s和800M/s，速度感觉非常不错。 在日常使用的文件中主要分为： 大文件，比如下载的4K电影、爱死机系列片等，这一类文件在使用之后可以放到移动硬盘作为存储，或者上传到百度网盘 不常用的文件，比如下载的文件PDF、下载的PPT、不用的课程PPT，这一类文件通常在一个阶段结束之后可以备份，比如放在移动硬盘或者放到百度网盘中 小而杂的文件，临时做的ppt、下载的通知，这是管理的重点 管理方法Tag+Folder： 作为一个对macOS的的Finder热爱的人来说，非常喜欢提供tag的选项，但是常常利用Tag也会让我感到苦恼，因为会因为一个文件满足多个tag而不知道如何区分，然后新建一个Temp文件夹，久而久之所有的文件都会被放到这个临时文件夹中。就在苦苦思考的时候，我们会发现天然的无论是windows还是macOS都给我提供好了应该有的方法Folder，按照Document、Picture、Video、Download、Desktop的文件夹方式来进行分类，这里的管理原则是： 首先按照文件的时效性区分开： 时效较短的 download desktop 时效较长的 document、picture、video 再根据自己的Project来对不同文件类型的文件进行标记Tag，方便自己查找 Tag存在的意义是让自己容易找到他，而不是分类，因为Folder天然具有分类的作用 3.2 基于Webdav的多端同步Sync ！！macOS12还没有适配坚果云的云桥模式！！ 网盘通常可以分为两种 大容量，作为资源库仅限App操作的，比如百度网盘、阿里云盘、夸克云盘等 同步网盘，比如iCloud、坚果云、DropBox、nextcloud、one drive等 针对第一种网盘纯粹可以当作备份盘处理，虽然百度网盘推出同步空间，体验依旧非常不好。第二种网盘主要针对写作办公和同步，如果你是iPhone+iPad+Mac当然iCloud是最佳的选择，没有之一，在国内的环境使用非常的舒服，但是如果没有则需要挑选，主要的选择有： 时不时抽风的one drive 会员当道的坚果云 自建webdav协议的nextcloud 3.2.1 第一种one drive 速度有时候莫名的快，有时候莫名的慢，使用很难受。同步必须在自己的电脑中新建一个文件夹作为同步，不能实现同步其他任意文件夹的功能，比较鸡肋。但是可以释放本地空间，以快捷方式保存在本地，同时作为学生可以享受超大容量。 3.2.2 第二种 坚果云 目前开了一年的会员，在尝试其中的使用技巧，利用坚果云来构建Mac+iPad+Mate40pro之间的文件共享体系（重点！华为居然可以将文件夹放在桌面，太好用），在国内的同步速度非常快，快到看不见。但是目前macOS12应该是不支持云桥模式的api，也就是我文件都是同步的，而不能释放本地空间 3.2.3 第三种 webdav协议自建nextcloud 因为本人自己有一台腾讯云服务器，所以尝试使用nextcloud构建自己的云盘，但是因为功能比较初级，想要在Mac系统中集成需要走HTTPS协议，暂时还没有搞好，但是webdav协议除了可以下载文件之外，还可以同步日历等，构建macOS+iPados+HarmonyOS的同步，但是目前https协议还没有搞好，期待后面的使用 3.3 Password管理 密码管理的重要性，无论是个人信息中需要的密码管理，还是掌握服务器中的使用，都需要掌握良好的米阿们 拖库:拖库就是指黑客通过各种社工手段、技术手段将数据库中敏感信息非法获取，一般这些敏感信息包括用户的账号信 息如用户名、密码;身份信息如真实姓名、证件号码;通讯信息如电子邮箱、电话、住址等。 洗库:在拖库后，取得大量的用户数据之后，黑客会通过一系列的技术手段和黑色产业链将有价值的用户数据变现。 撞库:撞库是黑客通过收集互联网已泄露的用户和密码信息，生成对应的字典表，尝试批量登陆其他网站 后，得到一系列可以登录的用户。很多用户在不同网站使用的是相同的帐号密码，因此黑客可以通过获取 用户在A网站的账户从而尝试登录B网址，这就可以理解为撞库攻击。 手机内部华为自带的密码管理器真的是太差劲了，为了满足多端同步的功能，既然用不了Apple的钥匙串服务，Google密码在华为中用不了，只能使用微软的EDGE，电脑和平板端使用浏览器，手机端开启浏览器外部填充功能。 当时实际的密码最好还是用备忘录或者笔记本记下来！！ 3.4 GTD管理 它的所有方法都围绕着把所有事情都从大脑中弄出来并体系化地管理，让人专注于眼前的工作，完全信任外部体系的事务管理。 因此，GTD的方法最适用以下情况： 事务繁杂，容易忘记和混淆 害怕忘记任务而反复回想，浪费时间造成压力 杂务纷扰，重要的事常来不及做 通常使用reminder来将需要做的事情记录下，收集所有的事情，然后划分到长期和短期应用，之后在日历calendar中记录准确的事情，在同步过程中，依旧采用微软的outlook邮箱来实现多端同步，手机上需要下载一个Microsoft ToDo，很简洁！ 3.5 Notes管理 笔记整理中，通常的来源包括 讲座、会议等的会议记录和总结 对于视频、文档、课本的阅读和总结 个人博客 自己的代码仓库 由于使用不同文件就让自己的笔记整理困难，因此个人选择的ALl in one的Notion来管理自己的笔记，作为一个基于Web的笔记管理，很好用，个人笔记的特征管理选择 Area-user ：笔记中主要分为person（自己的思考、自己的整理、自己的读书记录）；或者是school（课题组的项目、讲座）；以及一些第三方的东西，我是去study，或者做一些record Group-Tag：用于分类的依据，将自己的笔记分为四种：Library（个人的汇总表）、Post（一些单独的文章）、Wiki（完整知识体系，帮助学习）、Log（项目的日志） Name：该页面的主要名称，汇总表建议带上汇总两字、series的课程或者希望可以带上&lt;名称&gt;作为标识 Create Date：创建日期 Resource： 这个页面的根源是什么，包括个人的管理类或者思考类、school的项目日志或一些杂事、study的课程或文档 Area：随便的一些tag 04 Environment management 4.1 Homebrew —软件包管理工具 Homebrew Homebrew是一款macOS的软件包管理工具，通过其可以很方便的install or uninstall软件工具，类似与Linux下的apt-get、node的npm等包管理工具、centos下的yum，使用homebrew可以安装系统没有预装的东西，，同时会将软件包安装到独立目录，也就是local文件夹下面的homebrew自己安装的文件，然后再通过软链接到usr/local 1/bin/bash -c &quot;$(curl -fsSL &lt;https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh&gt;)&quot; （可选的，如果希望将homebrew添加到环境变量） 12echo &#x27;eval &quot;$(/opt/homebrew/bin/brew shellenv)&quot;&#x27; &gt;&gt; ~/.zprofileeval &quot;$(/opt/homebrew/bin/brew shellenv)&quot; 常用的一些命令 1234567891011121314brew install 包名brew uninstall 包名brew upgrade 包名brew updatebrew upgradebrew outdated// 查看Homebrew版本brew --versionbrew listbrew homebrew info 包名brew doctor 4.2 Mini forge3 — macOS的conda 一种是下载sh脚本，然后自己安装 使用homebrew安装mini forge3 Anaconda和Miniconda到现在都没有提供M1处理器的conda环境，可以使用conda-forge提供miniforge，用来支持Apple Silicon的版本软件 下载软件的地址 GitHub - conda-forge/miniforge: A conda-forge distribution. 下载好mini forge3中对应的macOS+apple silicon的脚本，假设下载咋download文件夹 12345678910cd download// 之后安装脚本// 假如之前安装过，可以重新卸载再安装// 卸载的脚本 // rm -rf ~/miniforge3 // rm -rf .conda // rm -rf .condarc// 没有以上可以略过bash Miniforge3-MacOSX-arm64.sh 完成安装之后，需要重新激活配置文件 1source .zshrc 完成之后可以测试conda是否安装完成 1conda --version 第二种方法是使用homebrew安装 1brew install miniforge conda常见命令的使用 1234567891011121314151617181920212223242526272829303132333435363738394041// conda环境的创建、激活# 查看所有conda环境conda info -e# 创建虚拟环境conda create -n env_name python=python_versionEg:conda create -n py39 python=3.9# 激活虚拟环境conda activate env_nameEg: conda activate py39# 退出虚拟环境conda deactivate# 删除虚拟环境conda remove -n env_name --all// 包的查看、安装、删除和更新# 查看环境下所有安装的包conda activate env_nameconda list# 查看是否安装特定的包conda activate env_nameconda list package_name# 安装包conda antivate env_nameconda insatall package_name# 删除包conda antivate env_nameconda remove package_name # 更新包conda antivate env_nameconda update package_name// conda 安装本地包# 进入包所在路径 cd /d路径cd /dE:\\\\Download# 安装包 conda install --use-local 包名conda install --use-local pytorch-1.8.0-py3.7_cuda11.1_cudnn8_0.tar.bz2// conda清理环境conda clean -pconda clean 4.3 Git — 版本控制 4.3.1 常见指令 Book 常用 Git 命令清单 123456789101112131415161718192021222324252627282930313233343536373839404142// 新建代码库# 在当前目录新建一个 Git 代码库$ git init# 新建一个目录，将其初始化为 Git 代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url]// 配置git，配置文件为gitconfig，可以在用户主目录，也可以在项目目录# 显示当前的 Git 配置$ git config --list# 编辑 Git 配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot;等等# 添加所有文件git commit -m &#x27;[your message]&#x27;# 上传，应该是上一次add的文件夹的信息# GitHub的本地ssh的设置# GitHub的本地git config --global --listgit config --global user.name &quot;这里换上你的用户名&quot;git config --global user.email &quot;这里换上你的邮箱&quot;ssh-keygen -t rsa -C &quot;这里换上你的邮箱&quot;# 后续确认就行，在GitHub上进行GUI的设置就OKSettings -- SSH and GPG keys# 为dnf添加sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo# 安装就好dnf install gh# 之后认证gh auto login# 按照规定输入选择输入token就行了 4.3.2 Git - PyCharm - GitHub操作 首先安装好自己的git，然后在pycharm中的version control system中为当前的项目构建自己的git同步目录，其中的 git每次的文件会存储在相对应的.git文件夹的目录下，所以也会导致在每次提取的过程会逐渐变的越来越大，同时为自己的GitHub账户中的一些操作 chenxia31.github.io ,主要是个人blog的使用，在其中使用markdown来撰写相关的推文，使用hexo g、hexo d，以及GitHub page来管理域名来完成自己的公开 code_study_pratice 这个是过去的一些操作，这里就删除，算是最开始的algorithm的东西，因为名字不好听以后就删除来，为啥不换个名字，算了换一个名字重新开始 Mercury这里以后就是代码学习的地方，主要分为BaseSkill（比如pandas的操作）、Course（比如CS229、CS61A、李宏毅之类的）、Kaggle（其中比赛的名称）、Leetcde（包括力扣官网的，还有一些关于算法导论中习题的刷）、latex中的一些模版、如果想要更近一步还需要有其他代码语言比如web开发、C++语言等属于Special Area 4.3.3 Git - VsCode - GitHub操作 暂时不需要 4.4 （Python）Tensorflow + Pytorch 2022-04-09 pytorch暂时没有支持GPU加速，仅仅是讨论阶段，tensorflow已经支持GPU加速，使用的是apple提供的metal的toolkit 1conda install -c pytorch pytorch torchvision Tensorflow Plugin - Metal - Apple Developer 在conda管理中，直接使用homebrew安装的miniforge可能会有问题，可以选择第一种下载之后手动安装的方式来管理 之后是新建一个conda环境，然后activate进去 利用conda安装相关依赖 12// 可以管理安装的版本conda install -c apple tensorflow-deps==2.6.0 然后在环境内使用pip安装相对应的tensorflow和插件 1234567// 安装python -m pip install tensorflow-macospython -m pip install tensorflow-metal// 如果需要卸载之后重新安装python -m pip uninstall tensorflow-macospython -m pip uninstall tensorflow-metal 测试代码 12345678910111213141516171819202122232425262728from tensorflow.keras import layersfrom tensorflow.keras import modelsmodel = models.Sequential()model.add(layers.Conv2D(32, (3, 3), activation=&#x27;relu&#x27;, input_shape=(28, 28, 1)))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation=&#x27;relu&#x27;))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation=&#x27;relu&#x27;))model.add(layers.Flatten())model.add(layers.Dense(64, activation=&#x27;relu&#x27;))model.add(layers.Dense(10, activation=&#x27;softmax&#x27;))model.summary()from tensorflow.keras.datasets import mnistfrom tensorflow.keras.utils import to_categorical(train_images, train_labels), (test_images, test_labels) = mnist.load_data()train_images = train_images.reshape((60000, 28, 28, 1))train_images = train_images.astype(&#x27;float32&#x27;) / 255test_images = test_images.reshape((10000, 28, 28, 1))test_images = test_images.astype(&#x27;float32&#x27;) / 255train_labels = to_categorical(train_labels)test_labels = to_categorical(test_labels)model.compile(optimizer=&#x27;rmsprop&#x27;, loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])model.fit(train_images, train_labels, epochs=5, batch_size=64)test_loss, test_acc = model.evaluate(test_images, test_labels)test_acc https://zhuanlan.zhihu.com/p/408877901) 4.5 Linux使用 Linux 系统启动过程 内核的引导 BIOS开机自检，按照BIOS中设置的启动设备来启动，操作系统接管硬件之后，首先读入/boot目录下的内核文件 运行init init是系统所有进程的起点，首先读取配置文件 /etc/inittab 系统初始化 建立终端 用户登陆系统 命令行 ssh 图形界面 Linux 系统目录结构 12345678910111213141516171819ls：查看文件目录常见目录的解释：/bin =binaries 二进制文件的缩写，这个目录存放最常用使用的明林/boot 存放启动Linux的核心文件，包括一些连接文件以及镜像文件/dev 是device的缩写，存放的是Linux的外部设备，Linux中饭昂问设备和访问文件的方式是相同的/etc 是etcetera的缩写，用来存放所有的系统管理所需要的配置文件和子目录/home 用户的主目录，一般该目录是用用户的账号名称/lib 是library，存放在和系统最基本的动态链接库/media 系统会将识别的设备挂载到这个目录下/mnt 让用户临时挂载到别的文件系统/opt optional，是主机额外安装软件所摆放的目录，弄人是空的/proc 是processes的缩写，是虚拟文件下i痛，这个目录的netting不再硬盘上而是在内存里面，可以直接修改里面的文件来屏蔽命令/root 系统管理员的用户主目录/sbin superuser binaries的缩写，存放的额是系统管理员使用的系统管理程序/selinux 是centos特有的目录，类似于Windows的额防火墙/usr unix shared resources的缩写，用户的许多应用程序和文件/usr/bin 系统用户使用的应用程序/usr/sbin /usr/src 内核源代码默认的存放目录 Linux系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限，为来保护系统的安全性，Linux系统对不同的用户访问相同的文件的权限做出了不同的规定，在Linux中常用一下两个命令来修改文件或者目录所述的用户与权限 chown（change owner）修改所属的user和group chmod（change mode）修改用户的权限 12ll 或者ls-l来显示一个文件的属性以及文件所属于的user和group Linux 文件和目录管理 Linux的目录结构为tree结构，最顶级的目录为根目录，其他目录通过挂载可以添加到tree中，通过解除挂载可以移除他们，首先区分绝对路径和相对路径 绝对路径 /usr/share/doc 相对路径 …/man 处理目录的常用命令 123456789ls：list file 列出目录及文件名cd：change directory 切换目录pwd：佩内塔 work directory 显示目前的目录mkdir：make directory 创建一个新的目录rmdir：remove directory 删除一个空的目录cp：copy file复制文件rm：remove删除文件或者目录mv：move file 移动文件与目录man 【command】来查看使用文档 Linux的文件内容查看 1234567cat 由第一行开始显示文本内容tac 从最后一行开始显示nl 显示的时候输出行号more 一页一页的显示内容less 可以head 前几行tail 只看后几行 Linux的连接link的概念，一种是硬连接，另外一种是符号连接 hard link 通过索引界面的来连接，保存在磁盘分区汇总的文件不管是什么类型都给它分配一个编号成为inode index，在Linux汇总多个文件名指向同一个索引届电视存在的，硬连接允许一个文件拥有多个有效的文件名 symbolic link：类似于快捷方式 Linux 用户和用户组管理 Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户都必须首先向系统管理员申请一个账号，然后用账号的身份进入系统 用户的账号一方面可以帮助系统管理员对使用系统得到用户进行跟踪并控制他们对系统资源的访问，另一方面也可以帮助用户组织文件，并为用户提供安全性防护 实现用户账号的管理，要完成的工作主要有几个方面 用户账号的添加、删除和修改 用户口令的管理 用户组的管理 Linux磁盘管理好坏直接关系到整个系统的性能问题 Linux磁盘管理常用的命令为df、du、fidsk disk full（df） disk used（du） fdisk 用于磁盘分区 我的base环境是我之前用的 首先安装anaconda： wget -P /tmp https://repo.anaconda.com/archive/Anaconda3-2021.11-Linux-x86_64.sh wget是工具的名称，后面的🔗是对应的下载地轴 后面的/tmp是让下载文件存储在这个文件夹下面 常见的command yum yellow dog update modified 是一个在fedora和redhat以及suse的shell前端软看包管理器，基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次性安装所有依赖软件包，无须繁琐对的一次次下载 1234567891011121314151617grammar of yum：yum 【option】 【command】* option 可选，包括-h（help） -y（yes） -q（不显示安装过程）* command 要进行的操作* package 安装的包名常见的命令：check-updateupdateinstall &lt;package-name&gt;update &lt;package -name&gt;yum listyum remove &lt;package -name&gt;yum search &lt;keyword&gt;yum clean packagesyum clean headersyum clean oldheaders apt (advanced packageing tool 是一个在debian和ubuntu终端额shell前端软件挂你了工具 利用bash Anaconda3-2021.11-Linux-x86_64.s h 来安装对应的文件 安装的位置会默认在root/anaconda的目录下面 从yum安装dnf 4.6 Docker使用 123456789101112131415161718yum list installed | grep docker卸载安装yum -y remove docker-ce-cli.x86_64yum -y remove docker-ce.x86_64yum -y remove containerd.io安装依赖yum install -y yum-utils device-mapper-persistent-data lvm2安装yum圆头yum-config-manager --add-repo &lt;https://mirrors.cloud.tencent.com/docker-ce/linux/centos/docker-ce.repo&gt;安装Dockeryum install -y docker-ce docker-ce-cli containerd.iodocker version 启动 123456systemctl start docker设置为开机启动systemctl enable docker查看运行状态 配置 1234567891011mkdir -p /etc/docker//配置加速tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;&lt;https://mirror.ccs.tencentyun.com&gt;&quot;]&#125;EOF// 重启守护进程并重启dockersystemctl daemon-reload &amp;&amp; systemctl restart docker 运行第一个容器 1234docker run --name=hello hello-world查看docker ps -a 或者一步一步运行一个容器 123456789101112131415161718docker pull johngong/calibre-web查看现有docker images根据创建镜像 docker create --name=calibre-web -p 80:8083 -v /data/calibre-web/library:/library -e WEBLANGUAGE=zh_CN johngong/calibre-webdocker create 是创建容器的命令--name=calibre-web 表示创建的容器的名称-p 80:8083 表示该容器将 80 端口映射到 8083 端口-v /data/calibre-web/librery:/libray 表示该容器将 /data/calibre-web/library 目录映射为 /library 目录-e WEBLANGUAGE=zh_CN 表示该容器定义了一个变量，变量名是 WEBLANGUAGE，变量值是 zh_CNjohngong/calibre-web 是容器的镜像，这里也就是我们前面拉取的镜像启动刚才创建好的镜像docker start calibre-web 停止镜像 123456789101112docker stop calibre-web或者docker kill calibre-web删除容器docker rm calibre-webdocker rmi hello-worlddocker rmi `docker images -q`删除所有 Docker部署python 网站 安装Docker虚拟机环境 学习docke常用命令 安装Python SDK和MySQL镜像 为Flask添加SQL Alchemy拓展库 为什么要Docker?虚拟化环境的重要性 直接程序安装或者部署在Linux操作系统上面，容易引发资源冲突 程序卸载不干净，导致无法安装或者部署新程序 每次部署之前要安装很多软件，修改复杂的配置文件 无法让服务器硬件资源实现多租户服务 增大了在Linux系统上部署集群和分布式的难度 在Linux上安装docker，了解docker hub的 设置dockerhub的加速器DaoCloud 了解Docker镜像与容器的关系，了解镜像和容器之间的关系，学习常用的docker命令 什么是docker镜像？ 为了快速打包和部署软件环境，docker引入image机制 镜像是一个配置好的只读层软件环境 可以通过dockerfile文件创建镜像，也可以从docker仓库中下载到镜像中 什么是docker容器 容器是在镜像基础上创建出的虚拟实例，内容可读可写 一个docker image 可以创建多个container，而且container之间相互隔离，部署的程序之间不会相互干扰，所有的容器直接使用宿主的主机的Linux内核 docker run -it —name=p1 python:3.8 bash docker 会为每个容器创建网址 学习docker网络，docker的容器端口映射，目录挂载技术，FTP程序来管理文件，可以将宿主机挂载在目录挂载 docker network create —subnet=172.18.0.0/16 mynet 网段的ip 123docker network create --subnet=172.18.0.0/16 mynetdocker network rm mynetdocker run -it --name=p2 --net mynet --ip 172.18.0.2 python:3.8 bash 默认情况下，除来宿主机之外，任何主机无法访问远程访问的docker容器，通过端口映射可以把容器端口映射到宿主机的端口，这样其他的主机就能访问容器来，映射到宿主机的端口，不需要设置防火墙规则 1docker run -it -p9500:5000 -p9600:3306 python3.8:bash 为能把一部分业务数据保存在docker环境中，可以使用ftp，但是比较麻烦，因此可以使用目录映射。因为ftp会导致文件删除，只支持文件目录挂载，不支持文件挂载，而且一个容器可以挂载多个目录 -v /root/test:/root/project()前面是宿主机，后面是 docker run -it -p 9500:5000 python:3.8 -v /usr/local/JDBUS:/root/project bash","categories":[{"name":"Memo","slug":"Memo","permalink":"https://blog.tjdata.site/categories/Memo/"}],"tags":[{"name":"PersonPost","slug":"PersonPost","permalink":"https://blog.tjdata.site/tags/PersonPost/"}]},{"title":"计算机网络-01-Chapter01 计算机网络和因特网","slug":"计算机网络-01-Chapter01 计算机网络和因特网","date":"2022-06-11T14:44:25.000Z","updated":"2023-05-13T13:53:19.719Z","comments":true,"path":"posts/f10c5200.html","link":"","permalink":"https://blog.tjdata.site/posts/f10c5200.html","excerpt":"暑假新坑，自顶向下的学习计算机网络，虽然作为交通人学过了信号与系统、信息传输原理、嵌入式系统中，了解到了比特传输以及协议的初步概念，但是和实际应用中的计算机网络还存在比较大的GAP，自顶向下成功的介绍了如何去看计算机网络，而且作者行文非常有趣！Computer Networking_ A Top-Down Approach, Global Edition, 8th Edition.pdf,自己nextcloud搭建的webdav网盘分享！","text":"暑假新坑，自顶向下的学习计算机网络，虽然作为交通人学过了信号与系统、信息传输原理、嵌入式系统中，了解到了比特传输以及协议的初步概念，但是和实际应用中的计算机网络还存在比较大的GAP，自顶向下成功的介绍了如何去看计算机网络，而且作者行文非常有趣！Computer Networking_ A Top-Down Approach, Global Edition, 8th Edition.pdf,自己nextcloud搭建的webdav网盘分享！ chapter01 计算机网络和因特网 概述计算机网络和因特网，这章的目标是从整体上粗线条勾勒出计算机网络的概貌，并且描述这本书的内容框架，包含大量计算机网络的背景知识，并放到整个网络的大环境中讨论结果。 在介绍基本术语和概念后，将首先查看构成网络的基本硬件和软件组建，从网络的边缘开始考察网络中运行的端设备；之后探究网络的核心，包括传输数据的链路和交换机，以及将端系统和网络核心相连接的接入网和物理媒体 后半部分将从更广泛、更抽象的角度来考察计算机网络，包括其中的数据的时间延迟、丢包和吞吐量；介绍其中的关键体系结构原则，如协议分层和服务模型，我们将了解到计算机网络对于许多不同类型的攻击来说是脆弱的 1.1 是什么是因特网（Internet） 1.1.1 硬件角度描述 computer network似乎有点过时，因为除了电脑、服务器智能手机、电视、游戏机、温度调节设备都逐渐连接到因特网中，而这些设备通常称为主机（Host）或者端系统（End system） **端系统（End system）通过通信链路（Communication link）和分组交换（Packet switch）**连接到一起， 其中通信链路由不同的物理媒介组成，包括同轴电缆、铜线、光纤等，最重要的是传输速率 其中分组交换是将从一组输入链路到达另外一个输出链路，在这个过程由许多特色的分组交换机，其中最著名的包括路由器（router）和链路层交换机（link-layer switch） ### 1.1.2 软件角度描述 互联网应用处理传统的电子邮件、web冲浪等传统应用外，还包括移动智能手机和平板电脑应用程序，其中包括即时通讯、地图导航、流媒体等，这些应用程序涉及多个相互交互数据的端系统，因此称为分布式应用系统（distributed application） 💡 ？？假设你希望对分布式因特网有一个激动人心的想法，如何将这种想法转换称为一种实际的因特网应用呢？？也就是运行在一个端系统上的应用程序怎样才能通过互联网获得在另一个端系统上的软件发送的数据？ 与因特网的端系统提供了一个套接字 socket interface，规定了运营在一个端系统上的程序 请求因特网基础设施向运行在另一个端系统上的特定目的地程序交付数据的方式，是发送程序必须遵循的规则集合 协议（protocol）定义了两个或多个通信实体之间交换的报文的格式和顺序，以及报文发送和或接受一条报文或其他时间所采取的动作 不同的协议用于完成不同的通信任务 1.2 网络详细 — 网络边缘 端系统称为主机（host），也被叫做端系统（End system），主机可以进一步划分为客户（Client）和服务器（Server） 传输的物理媒介到底是什么？也就是信息传输原理中传递信息的方式，从发射器到接收器中的物理媒介和引导型媒介 物理媒介（Physical medium） 双绞铜线，用来减少临近类似的双绞线的嗲你去干扰，无屏蔽双绞线（UTP）通常用于建筑物内的计算机网络（LAN） 同轴电缆，由两个铜导体组成的，但是这两个导体是同心的而不是并行的，可以达到较快的数据传输速率 光纤，一种细而柔软的能够引导光脉冲的媒介，衰减低同时难以窃听，由于光频率的特殊性，以51.8Mpbs作为标准版 导引性媒介（Guided media） 陆地无线电信道，极大的依赖于传播环境和信号传输的举例，分为短、中、长三类 卫星无线信道，通常使用两类卫星，同步卫星（geostationary satellite）和近地轨道（low-earth satellite） 边缘设备和网络链接需要考虑接入网，也就是将端系统物理设备连接到边缘路由器（Edge router），常见的方式有： 家庭接入，DSL、电缆、FTTH、拨号和卫星 DSL（Digital Subscriber Line）数字用户线，受限于价格或者物理贷款，上行速率和下行速率并不相同 电缆（Cable Internet Access）利用有线电视公司现有的有线电视基础设施，通常使用同轴电缆和光纤混合的方式（Hybrid Fiber Coax，HFC） 光纤到户（Fiber to the home，FTTH)，分为主动光纤网络和被动光纤网络 非常慢、适合偏远地区的卫星和拨号（传统电话线） 公共场所，以太网和WiFi 使用局域以太网将设备连接到交换机，比如使用双绞铜线连接到减缓集 一种基于IEEE802.11的LAN介入方式 虽然以太网和Wi-Fi接入网最早出现在企业或大学，但是今年来也已经成为家庭网络中相当常见的部件 移动网络，3G、LTE、5G 利用基站布设来获取速度 LTE（long term evolution）最差首字母缩写词，取得了10Mpbs的速率 1.3 网络详细 —网络核心 由通信链路和交换机组成的网状系统，在网络链路和交换机移动数据的两种基本方法，电路交换（circuit switching）和分组交换（packet switching） 1.3.1 分组交换 传递报文，但是会根据数据包有时延，因为交换机需要存储文件然后发出去 1.3.2 电路交换 面向电路的连接，无论时时分复用、频分复用还是码分复用 1.4 网络详细 — 评价指标：时延、丢包和吞吐量 在理想情况下，我们希望因特网服务能够在任意两个端系统之间随心所欲瞬间移动数据而没有任何数据丢失，但是受限于系统的实际传递速率，可能会丢到分组的报文，一方面这个是网络的巨大问题，另一方面也是计算机网络存在的意义 1.4.1 时延的概述 当分组报文从一个节点沿着这条路到达下一个节点，该分组在沿途中的每个节点经受了几种不同类型的时延，其中最重要的包括 节点处理时延（Nodal processing delay），比如检查比特差错所需要的时间、等时间 排队时延（Queuing delay），在队列中，在链路上等待传世的时间，如果流量很大，则不能传输无需等待 传输时延（Transmission delay），这个适用于报文分组所需要的时间毫秒级到微秒级别 传播时延（Propagation delay），这个是实际上在路径上运行的额记录，一旦一个比特走向了链路，该比特所需要的路由器传播 不同业务场景对于计算机网络的性能处理方式并不相同。 1.4.2 排队时延和丢包的关系 当然是时延越长，丢包越多啦 1.4.3 端到端时延 略 1.4.4 计算机网络的吞吐量 略 1.5 网络详细 — 协议层次和服务模型 在计算机网络中虽然存在大量的饮用程序协议、各种个样的端系统、分组交换机以及各种类型的链路级媒体，面对这种复杂性，还存在组织网络体系结构的希望吗？答案是肯定的，OSI参考模型 1.5.1 分组的体系结构 利用分层的体系结构就可以讨论一个大而复杂系统的定义良好的特定部分，这种简化本身由于提供模块化而具有很高价值，这是的某层所提供的服务容易改变，只要该曾对上面提供相同的服务并且使用来自下层的相同服务，就可以保持不断更新，这种改变服务的实现而不影响该系统其他组件是分组的另一种重要优点。但是分层的一个潜在缺点是一层可能容易较低层的功能。将这些综合起来，各层的所有协议被成为协议栈（protocol stack） 应用层，比如HTTP、SMTP、FTP、SFTP、DNS解析 运输层，TCP、UDP 网络层，将数据报datagram从一台主机移动到另一太主机，包括著名的网际协议你IP，也包括路由选择协议等，统一称作IP层 链路层，包括以太网、WIFI、电缆接入网DOCSIS协议，这里的分组成为frame 物理层，通过物理协议传输","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"netowrk","slug":"netowrk","permalink":"https://blog.tjdata.site/tags/netowrk/"}]},{"title":"Single-02-决策树中的Boosting方法","slug":"Single-02-决策树中的Boosting方法","date":"2022-05-22T13:36:41.000Z","updated":"2023-05-13T13:50:55.859Z","comments":true,"path":"posts/cc1abdc.html","link":"","permalink":"https://blog.tjdata.site/posts/cc1abdc.html","excerpt":"对决策树中有关的boosting方法进行总结，包括最基本的Adaboost、然后了解从提升树（Boosting Tree）到之后的梯度提升回归树（Gradient boosting decision tree），希望可以了解其中的Boosting方法的脉络，也为之后的XGBoost和LightGBM的学习奠定基础","text":"对决策树中有关的boosting方法进行总结，包括最基本的Adaboost、然后了解从提升树（Boosting Tree）到之后的梯度提升回归树（Gradient boosting decision tree），希望可以了解其中的Boosting方法的脉络，也为之后的XGBoost和LightGBM的学习奠定基础 0x01 背景知识 1.1 决策树（Decision tree） 决策树是一种基本的机器学习模型，具有分类和回归的功能。它的特点是具有分类速度快，模型容易可视化的解释，缺点是容易发生过拟合 决策可以分为分类树和回归树 1.2 集成学习 （Ensemble learning） 为了将弱学习器（Weak learner）集中其中形成这个具有多学习器综合的条件，我们可以采用不同的算法和数据集融合的方式来构建模型、也可以采用不同的融合方法比如平均法投票法stacking、或者采用特殊的技巧比如bagging和boosting的方式 其中XGboost和GD都属于boosting的方法范畴，其工作原理是初始训练集训练得到一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得之前基学习器出错的训练样本后续可以得到更多的关注，然后基于调整后的样本分布来重新训练学习器，最终继承多个学习器并根据错误进行加权来得到最终的学习器 f(x)=w_0+\\Sigma_{m=1}^Mw_m\\phi_m(x)\\\\w\\ for\\ weigths\\\\ \\phi\\ is\\ weaker\\ learner 1.3 回顾机器学习 机器学习从组成部分中最重要可以说分为四个部分 数据集（dataset） 模型（model）和参数（parameters） 目标函数（objective）= 损失（loss）+正则化（regularization） 优化方法（optimization method） 0x02 AdaBoost算法 2.1 简介 每次学习之后，迭代更新样本数据集中的权重来重新生成一颗决策树，之后根据准确率来组合所有的学习器实例得到最终的结果 2.2 算法过程 给定一个二分类的数据集T={(xi,yi)}i=1i=NT=\\{(x_i,y_i)\\}_{i=1}^{i=N}T={(x​i​​,y​i​​)}​i=1​i=N​​，X是特征集合，y是标记集合。 算法的流程(AdaBoost) 输出为G（X） 1-1 首先，初始化训练数据中的权重分布，最初都相同权重 D1=(w11,...,w1N),w1i=1/ND_1=(w_{11},...,w_{1N}),w_{1i}=1/N D​1​​=(w​11​​,...,w​1N​​),w​1i​​=1/N 之后训练M颗树，对于M=1，2，…，M 2-1 根据权重分布DmD_mD​m​​训练数据集来得到基本分类器 《李航统计学习》没有提到的部分就是如何根据权重来重新计算分类器；个人推测是在决策树分类的过程中，对不同类别的比例按照权重来重新计算，比如均匀分布的时候1和-1的比例为6:4；如果有权重需要根据对其中错误的类别进行分类：（30.07+30.16）：4*0.07 Gm(x)−&gt;:{−1,+1}G_m(x)-&gt;:\\{-1,+1\\} G​m​​(x)−&gt;:{−1,+1} 2-2 计算得到的分类器在训练数据集中的误差率 em=P(Gm(Xi)≠yi)e_m=P(G_m(X_i) \\neq y_i) e​m​​=P(G​m​​(X​i​​)≠y​i​​) 2-3 由此来得到分类器对应的权重 αm=12log1−emem\\alpha_m=\\frac{1}{2}log\\frac{1-e_m}{e_m} α​m​​=​2​​1​​log​e​m​​​​1−e​m​​​​ 2-4 在进行下一步计算的过程中，更新下一次的训练的权重，ZmZ_mZ​m​​的作用是为来归一化 W_{m+1}=\\frac{w_m}{Z_m}exp(-\\alpha_my_iG_m(X_i))\\\\Z_m=\\Sigma w_m exp(-\\alpha_my_iG_m(X_i)) 3-1 这样反复迭代得到基本分类器的线性组合 f(x)=\\Sigma \\alpha_mG_m(X)\\\\G(X)=sign(f(x)) G(x)就是最终的输出，有时候为了防止过拟合，也可以使用学习率来控制f(x)f(x)f(x)的增加速度 2.3 AdaBoost例子 见《李航统计学习131页》 2.4 算法的分析和解释 关于AdaBoost的解释可以分为两种 是通过统计学习的理论来推到出AdaBoost的训练误差边界、和相关推广的定理 认为它是模型为集成策略为additive、损失函数为exp、学习算法为前向分布算法（forward Stagewise algorithm） 其实AdaBoost中一个问题就是权重的选取为什么是这个样子的？ 这里我们可以结合前向分布来进行推导,这里的目标函数是 loss=exp(−y∗y^)loss=exp(-y*\\hat y) loss=exp(−y∗​y​^​​) 也正是因为这个限制，AdaBoost只能作为二分类来学习， 1-1 加法模型，就是我们可以 Gm(x)=Gm−1(x)+αm∗fm(x)G_{m}(x)=G_{m-1}(x)+\\alpha_m*f_m(x) G​m​​(x)=G​m−1​​(x)+α​m​​∗f​m​​(x) 其中 αm\\alpha_mα​m​​为权重，fm(x)f_m(x)f​m​​(x)是根据第M次训练得到的分类器，接下来就是确定这两者的取值，我们的目标是 min exp(−y∗Gm(X))=min exp(−y[Gm−1(x)+αm∗fm(x)])min\\ exp(-y*G_m(X))=min\\ exp(-y[G_{m-1}(x)+\\alpha_m*f_m(x)]) min exp(−y∗G​m​​(X))=min exp(−y[G​m−1​​(x)+α​m​​∗f​m​​(x)]) 由于在M次训练的时候，Gm−1(X)G_{m-1}(X)G​m−1​​(X)没有影响，所以可以分离开来作为比例项 min wmexp(−yαmfm(x))min\\ w_mexp(-y\\alpha_mf_m(x)) min w​m​​exp(−yα​m​​f​m​​(x)) 根据加权数据来重新训练得到fm(X)f_m(X)f​m​​(X)。 对于αm\\alpha_mα​m​​可根据求导得到答案 [−yfm(X)]∗exp(−yαmfm(X))=0[-yf_m(X)]*exp(-y\\alpha_mf_m(X))=0 [−yf​m​​(X)]∗exp(−yα​m​​f​m​​(X))=0 注意这里只是一个二分类的问题，所以化简之后得到的答案 ⁍ 2.5 优缺点 优点： 分类精度高，可以用各种回归分类模型作为构建学习，非常灵活，不容易过拟合 缺点： 对于异常值敏感，会获得较高的权重 0x03 梯度提升简介 Gradient Boosting 3.0 直觉background 参考链接5，下文给出，写的非常好 3.1 提升树 Boosting Tree 提升树是按照分类树或者回归树作为基本分类器的提升方法，提升树被认为是统计学习中性能最好的方法之一，针对不同问题的提升树的学习算法主要在于损失函数不同，包括平方误差损失函数、指数损失函数的分类问题和一般损失函数的一般决策问题 回归问题中的提升树算法 1-1 初始化模型 2-1 对于m=1，2，…，M不断迭代 2-2 计算上一个模型留下来的残差 rmi=y−fm−1(x)r_{mi}=y-f_{m-1}(x) r​mi​​=y−f​m−1​​(x) 2-3 重新计算一个回归树 2-4 更新现有的模型 2-5 得到最终的回归树 gradient_boosting.pdf 每一次建立模型是在之前建立模型损失函数的梯度下降方法，损失函数是评价模型性能，如果可以让损失函数可以持续下降，就能够使得模型可以不断改变提升性能，其中最好的方法是让损失函数可以沿着梯度的下降进行更新迭代 3.2 梯度提升 Gradient Boosting（for regression DT） 最开始GBDT只能解决回归问题，但是后续工业的调整之后允许分类 从上述我们可以看出对于分类和回归模型下来的思路，但是后续我们应该怎么办？对于其他类型的损失函数，我们如何去训练整个过程，这个时候就需要利用梯度下降（Gradient decent的思路） 残差其实是根据很直觉的想法来得到的，但是对于更加复杂的损失函数比如交叉熵之类的，简单的残差是没有意义的，所以为了保证整个算法可以走下去，使用梯度下降的方法 −∂L(y,fm−1(x))fm−1(x)-\\frac{\\partial L(y,f_{m-1}(x))}{f_{m-1}(x)} −​f​m−1​​(x)​​∂L(y,f​m−1​​(x))​​ 在其中使用shrinkage的方法，来保证每次仅仅改变一丝，来逐渐的得到梯度提升回归树 ⁍ 可以看出梯度提升（Gradient Boosting）和AdaBoost之间的细微的区别在于：对于错误的数据，AdaBoost采用改变其样本分布的权重增大比例，而梯度提升是利用残差的大小来提高错误数据在模型中的重要性 reference： 《统计学习方法》-李航 《机器学习》-周志华 https://blog.csdn.net/shine19930820/article/details/65633436 https://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf [https://blog.csdn.net/shine19930820/article/details/65633436](","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"Single","slug":"Single","permalink":"https://blog.tjdata.site/tags/Single/"}]},{"title":"力扣top100-1～20","slug":"力扣top100-1～20","date":"2022-05-13T15:18:46.000Z","updated":"2023-05-13T13:51:35.355Z","comments":true,"path":"posts/67984991.html","link":"","permalink":"https://blog.tjdata.site/posts/67984991.html","excerpt":"适合初始算法与数据结构的新手和想要在短时间内高效提升的人，熟练掌握这100道题，可以具备在代码世界通行的基本能力。想借这一百道题来了解一下算法的一些基本思想。本次主要为题号1～20共11道题。第四题是重点。","text":"适合初始算法与数据结构的新手和想要在短时间内高效提升的人，熟练掌握这100道题，可以具备在代码世界通行的基本能力。想借这一百道题来了解一下算法的一些基本思想。本次主要为题号1～20共11道题。第四题是重点。 0x00 自我总结 数据结构和算法是看待一道题目的不同解读。数据结构更多的是如何去表述一件事情，不同的数据结构具有不同的时间空间复杂度的性能和不同的接口，这也是不同数据结构的特点所在，算法更多的是解决问题的流程，如何把手里面已经有的数据结构通过三种基本的逻辑运算结合形成高效的操作流程。 在刷题之前掌握具有哪些常见的数据结构和算法是有必要的，数据结构可以分为线性数据结构：栈和队列、数据与矩阵；半线性结构：树，非线性结构：链表、数组、图、位运算等；从算法的角度可以分为基本：分治、贪心、动态规划、回溯、分枝定界；和一些特殊的技巧双指针、二分查找、搜索法等，以及特定的场景排序、树的搜索等 0x01 T1 两数之和 标签：数组、哈希表 难度：简单 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案。 12345678910class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: hashtable=dict() # 新建一个哈希表，来记录每个数字它对应的补数 for i in range(len(nums)): if target-nums[i] in hashtable: # 在这个哈希表中就OK了，而且这个时间复杂度并不高 return [hashtable[target-nums[i]],i] hashtable[nums[i]]=i return [] 0x02 T2 两数相加 标签：递归、链表、标签 难度：中等 给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。 请你将两个数相加，并以相同形式返回一个表示和的链表。 你可以假设除了数字 0 之外，这两个数都不会以 0 开头。 123456789101112131415161718192021222324252627282930313233343536373839404142# Definition for singly-linked list.# class ListNode:# def __init__(self, val=0, next=None):# self.val = val# self.next = nextclass Solution: def addTwoNumbers(self, l1,l2): def addTwoNumbers2(l1, l2, flag): &#x27;&#x27;&#x27; 三种情况 情况1：链表都存在，l1!=None 情况2：链表不存在，赋值为0 计算两数之和 如果大于10，则val为余数 flag值为1 链表不存在并且flag==0，则循环终止，输出最终的链表 链表存在，则继续下一个循环 &#x27;&#x27;&#x27; if l1!=None: num1=l1.val l1=l1.next else: num1 = 0 if l2!=None: num2=l2.val l2=l2.next else: num2 = 0 # 更新求和 sum_result = num1 + num2 + flag # 结果求余 val = sum_result % 10 # 更新flag，大于9设置为1，其他的则为0 if sum_result &gt; 9: flag = 1 else: flag = 0 # 终止条件，l1为空，并且flag为0 if l1 == None and l2==None and flag == 0: return ListNode(val) return ListNode(val, addTwoNumbers2(l1, l2, flag)) return addTwoNumbers2(l1,l2,0) 0x03 T3 无重复字符的最长子串 标签：字符串，滑动窗口哈希表 难度：中等 给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度 123456789101112131415161718class Solution: def lengthOfLongestSubstring(self, s: str) -&gt; int: # 感觉比较简单 if not s:return 0 left = 0 lookup = set() n = len(s) max_len = 0 cur_len = 0 for i in range(n): cur_len += 1 while s[i] in lookup: lookup.remove(s[left]) left += 1 cur_len -= 1 if cur_len &gt; max_len:max_len = cur_len lookup.add(s[i]) return max_len 0x04 T4 寻找两个正序数组的中位数 标签：数组、二分查找、分治 难度：困难 给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的 中位数 。 算法的时间复杂度应该为 O(log (m+n)) 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution(object): def findMedianSortedArrays(self, nums1, nums2): # even 需要找（m+n+1）/2 # odd 需要找（m+n）/2 （m+n）/2+1 m=len(nums1) n=len(nums2) if (m+n)%2 ==1: # odd return self.getK(nums1,nums2,(m+n+1)/2) else: # even a=self.getK(nums1,nums2,(m+n)/2) b=self.getK(nums1,nums2,(m+n)/2+1) return (a+b)/2 def getK(self,nums1,nums2,k): # nums1：第一个正序的数组 # nums2：第二正序的数组 # k：两个并列数组中第k大的数组 # 终止条件为，k为1 k=int(k) m=len(nums1) n=len(nums2) index1,index2=int(min(k//2,m))-1,int(min(k//2,n))-1 # 两个正序数组中的值 if m==0: # 第一个数组到头 return nums2[k-1] if n==0: # 说明第二个数组到头 return nums1[k-1] if k==1: return min(nums1[0],nums2[0]) # 下面来看如何更新迭代 value1=nums1[index1] value2=nums2[index2] if value1 &lt;= value2: k=k-index1-1 nums1=nums1[index1+1:] else: k=k-index2-1 nums2=nums2[index2+1:] return self.getK(nums1,nums2,k) 0x05 T5 最长回文子串 标签：字符串，动态规划 难度：中等 给你一个字符串 s，找到 s 中最长的回文子串。 123456789101112131415161718192021222324252627class Solution: def longestPalindrome(self, s: str) -&gt; str: ## dynamic programing ,基本步骤是确定下标的含义和递推公式的含义 # 第一步，确定dp数据，用dp【i,j】来表示区间范围内的淄川是否为回文子串dp[i][j]是否为true # 第二步，确定递推的三种情况，回文数取真的情况分为 # 1. i=j相等，true # 2. i和j相差等于1，true # 3. i和j相差大于1的情况，如果i和j相等，需要查看i和j的区间内部是不是相等，也就是dp[i+1][j-1]是不是true # 第三步，确定dp数组如何初始化，当然都是false # 第四步，为了保证dp[i+1][j-1]要最新开始计算,所以可以先将第一种情况和第二种情况先得到 dp=[[0 for i in range(len(s))] for j in range(len(s))] left = 0 right = 0 maxlength=0 for i in range(len(s)-1,-1,-1): for j in range(i, len(s)): if s[i]==s[j]: if (j - i &lt;= 1): dp[i][j] = 1 elif dp[i + 1][j - 1] == 1: dp[i][j] = 1 if dp[i][j] == 1 and j - i + 1 &gt; maxlength: maxlength = j - i + 1 left = i right = j return s[left:right + 1] 0x06 T10 正则表达式匹配 标签：字符串、递归、动态规划 难度：困难 给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 ‘.’ 和 ‘*’ 的正则表达式匹配。 ‘.’ 匹配任意单个字符 ‘*’ 匹配零个或多个前面的那一个元素 所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。 1234567891011121314151617181920212223class Solution: def isMatch(self, s: str, p: str) -&gt; bool: m, n = len(s), len(p) def matches(i: int, j: int) -&gt; bool: if i == 0: return False if p[j - 1] == &#x27;.&#x27;: return True return s[i - 1] == p[j - 1] f = [[False] * (n + 1) for _ in range(m + 1)] f[0][0] = True for i in range(m + 1): for j in range(1, n + 1): if p[j - 1] == &#x27;*&#x27;: f[i][j] |= f[i][j - 2] if matches(i, j - 1): f[i][j] |= f[i - 1][j] else: if matches(i, j): f[i][j] |= f[i - 1][j - 1] return f[m][n] 0x07 T11 盛最多水的容器 标签：贪心、数组、双指针 难度：中等 给定一个长度为 n 的整数数组 height 。有 n 条垂线，第 i 条线的两个端点是 (i, 0) 和 (i, height[i]) 。 找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。 返回容器可以储存的最大水量。 说明：你不能倾斜容器。 123456789101112131415class Solution: def maxArea(self, height): # 找出其中的两条线，找出其中与x轴构成可以容纳最多的水 left=0 right=len(height)-1 result=0 while left &lt; right: result=max(result,min(height[right],height[left])*(right-left)) # 更新right和left # 提升的意义，在于删除小于当前值 if height[right]&gt;height[left]: left=left+1 else: right=right-1 return result 0x08 T15 三数之和 标签：数组、双指针、排序 难度：中等 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。 12345678910class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: hashtable=dict() # 新建一个哈希表，来记录每个数字它对应的补数 for i in range(len(nums)): if target-nums[i] in hashtable: # 在这个哈希表中就OK了，而且这个时间复杂度并不高 return [hashtable[target-nums[i]],i] hashtable[nums[i]]=i return [] 0x09 T17电话号码的字符组合 标签：字符串、哈希表、回溯 难度：中等 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。 1234567891011121314151617181920212223class Solution: def letterCombinations(self, digits: str) -&gt; List[str]: if not digits: return [] phone = &#123;&#x27;2&#x27;:[&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;], &#x27;3&#x27;:[&#x27;d&#x27;,&#x27;e&#x27;,&#x27;f&#x27;], &#x27;4&#x27;:[&#x27;g&#x27;,&#x27;h&#x27;,&#x27;i&#x27;], &#x27;5&#x27;:[&#x27;j&#x27;,&#x27;k&#x27;,&#x27;l&#x27;], &#x27;6&#x27;:[&#x27;m&#x27;,&#x27;n&#x27;,&#x27;o&#x27;], &#x27;7&#x27;:[&#x27;p&#x27;,&#x27;q&#x27;,&#x27;r&#x27;,&#x27;s&#x27;], &#x27;8&#x27;:[&#x27;t&#x27;,&#x27;u&#x27;,&#x27;v&#x27;], &#x27;9&#x27;:[&#x27;w&#x27;,&#x27;x&#x27;,&#x27;y&#x27;,&#x27;z&#x27;]&#125; def backtrack(conbination,nextdigit): if len(nextdigit) == 0: res.append(conbination) else: for letter in phone[nextdigit[0]]: backtrack(conbination + letter,nextdigit[1:]) res = [] backtrack(&#x27;&#x27;,digits) return res 0x10 T19 删除链表的倒数第N个节点 标签：链表，双指针 难度：中等 给你一个链表，删除链表的倒数第 n 个结点，并且返回链表的头结点。 1234567891011121314151617181920# Definition for singly-linked list.# class ListNode:# def __init__(self, val=0, next=None):# self.val = val# self.next = nextclass Solution: def removeNthFromEnd(self, head: ListNode, n: int) -&gt; ListNode: dummy = ListNode(0, head) first = head second = dummy for i in range(n): first = first.next while first: first = first.next second = second.next second.next = second.next.next return dummy.next 0x11 T20 有效的括号 标签：栈、字符串 难度：简单 给定一个只包括 ‘(’，‘)’，‘{’，‘}’，‘[’，‘]’ 的字符串 s ，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 1234567891011121314151617class Solution: def isValid(self, s: str) -&gt; bool: stack = [] for item in s: if item == &#x27;(&#x27;: stack.append(&#x27;)&#x27;) elif item == &#x27;[&#x27;: stack.append(&#x27;]&#x27;) elif item == &#x27;&#123;&#x27;: stack.append(&#x27;&#125;&#x27;) elif not stack or stack[-1] != item: return False else: stack.pop() return True if not stack else False","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://blog.tjdata.site/tags/LeetCode/"}]},{"title":"数据结构与算法03-搜索树","slug":"数据结构与算法03-搜索树","date":"2022-05-08T09:45:56.000Z","updated":"2023-05-13T13:52:42.043Z","comments":true,"path":"posts/1866a43d.html","link":"","permalink":"https://blog.tjdata.site/posts/1866a43d.html","excerpt":"二叉树中三种遍历方式：前序遍历、后序遍历和中序遍历；在普通二叉搜索树中的搜索search、插入insert、删除remove中的算法效率或者说复杂度和树的深度有关。因此在树的等价交换和基本操作的基础上，提出了平衡二叉树（BBST，Balanced binary search tree）的概念，由此延伸得到AVL、伸展树（Splay tree）、B树、红黑树、KD-树的概念，并可以看到这些在实际生活中的应用。","text":"二叉树中三种遍历方式：前序遍历、后序遍历和中序遍历；在普通二叉搜索树中的搜索search、插入insert、删除remove中的算法效率或者说复杂度和树的深度有关。因此在树的等价交换和基本操作的基础上，提出了平衡二叉树（BBST，Balanced binary search tree）的概念，由此延伸得到AVL、伸展树（Splay tree）、B树、红黑树、KD-树的概念，并可以看到这些在实际生活中的应用。 0x01 二叉树的遍历traversal 对二叉树的访问可以抽象为如下形式：按照某种约定的次序，对节点访问且仅一次。遍历之于二叉树的意义，同样在于为相关算法的实现提供通用的框架，此外这一过程等效于将半线性的树形结构转换为线性结构，但是二叉树不在属于线性结构，因此遍历过程更为复杂。 1.1 递归式遍历 recursively traversal 二叉树本身并不具有天然的全局次序，故为实现遍历，首选需要在各节点与其孩子之间约定某种局部次序，从而间接定义全局次序。分为左（L，left）、右（R，right）、节点（R，root），因此分为VLR、LVR、LRV三中心选择，也就是先序遍历（preorder）、中序遍历（inorder）、后序遍历（postorder） 先序遍历（preorder） 首先核对X是不是空集，若x为空则直接退出 若x非空，则按照先序遍历，优先访问根节点，然后访问左子树和右子树 12345def travPre_R(set,visit): if(!x) return; visit(x.data); travPre_R(X.lc,visit) travPre_R(x.rc,visit) 中序遍历（inorder） 各节点在中序遍历序列中 后序遍历（postorder） 递归遍历算法和迭代遍历算法都需要渐进的线性时间，而且相对而言，前者更加简明；但是迭代算法的时间和空间复杂度的常系数相比较递归更小，同时从迭代遍历完成可以加深对相关过程和技巧的理解 1.2 递归式遍历 recursively traversal 比较难，但可以加深理解 先序遍历可以分解为两段，沿着最左侧通路自上而下的访问各节点，以及自底向上遍历的对应右子树 1.3 一些算法的实现 123456789101112131415161718192021222324252627282930313233343536373839404142# Definition for a binary tree node.class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right# 题目debug地址：https://leetcode-cn.com/problems/binary-tree-inorder-traversal/class Solution: def inorderTraversal(self, root): &#x27;&#x27;&#x27; 题目描述：给定一个二叉树的根节点root，返回它的中序遍历 二叉树的遍历分为深度遍历和广度遍历 深度遍历分为前序、中序和后序三种遍历方法 - 前序，根节点、左子树、右子树 - 中序，左子树、根节点、右子树 - 后序，左子树、右子树、根节点 广度遍历就是常说的层次遍历的方法 :param root: :return: &#x27;&#x27;&#x27; stack,ret=[],[] # 设计一个栈作为中间变量 # ret为最终结果 cur=root # 初始化最初的值为cur while stack or cur: # 当stack为空并且cur为空停止，也就是所有都遍历完，同时也不存在左子树 if cur: # 如果当前节点非空，则取这个节点到stack中 # 将当前节点设置为节点的left node stack.append(cur) cur=cur.left else: # 如果stack非空，但是当前节点为空。说明遍历到最左边的 # 取当前节点的上一个 cur=stack.pop() ret.append(cur.val) cur=cur.right return ret 0x02 二叉搜索树（Binary Search tree) 二叉搜索树是满足顺序性的二叉树 任一节点r的左右子树中，所有的节点（若存在）均不大于（不小于）r 为回避边界情况，暂定假设所有节点不想等，因此可以简化为 任意节点r的左（右）子树中，所有的节点（若存在）均小于（大于）r 从本章开始，讨论的重点将逐步转向查找技术，实际上在之前的章节已经就此做过一些讨论，比如在vector和list等结果中，已经给出了对应的ADT结构，但是遗憾的是这种接口的效率无法令人满意。 比如vector向量模版，针对无序和有序向量的查找提供了find()和search（）接口。前者的实现策略是将目标对象与向量存放的对象逐个对比，硬刺需要O(n)时间，后者利用二分查找策略可以确保O(logN)时间内完成单次查找，但是一旦向量本身需要修改，无论是插入还是删除，在最坏情况下每次需要O（n）的时间。 所以对于线性结构来说，既要求对象集合的组成可以高效率地动态调整，同时也要求能够高效率查找，lInear data structure很难胜任，那么高效率的动态修改和高效率的静态查找能否同时兼顾，如有可能又应该采用什么样的数据结构？ 之后两章希望逐步了解其中的故事，涉及到的数据结构种类比较多，按照基本和高级两章分别进行讲解 本章首先介绍树式查找的总体构思、基本算法以及数据结构，通过对二分查找策略的抽象与推广来定义并实现二叉搜索树（Binary search tree)结构，虽然在最坏情况下渐进时间复杂度与之前并无实质性改变，但是这给出来一种基于半线性的树形结构。 之后提出理想平衡和适度平衡等概念，并相应引入和实现AVL树这种典型的平衡二叉搜索树（Balanced binary search tree)，借助精巧的平衡调整算法，AVL树可以保证即使在最坏情况下，单次动态修改和静态查找也可以在O(logN)的时间内完成，在之后的选择中给出balanced m-way search trees 2.1 查找算法（Search） 采用减而治之的思路与策略，执行的过程可以描述为 从树根出发，逐步缩小查找范围，直到发现目标或缩小到空树。节点的插入和删除操作，都需要首先调用查找算法，并根据查找结果确定后序的处理方式，因此这里引用方式传递子树根节点，为后续操作提供必要的信息 效率：在二叉搜索树的每一层，查找算法至多访问一个节点，且只需常数时间，因此总体所需要时间应线性正比于查找路径的长度，或最终返回节点的深度，在最坏的情况下可以达到\\omiga n的复杂度；由此我们得到汽水，若要控制单次查找在最坏情况下的运行时间，需要从二叉搜索树的高度入手，后面讨论的平衡二叉搜索树正是基于这个思路的改进 2.2 插入算法（Insert） 一般在二叉搜索树中插入新节点e的过程，可以描述为函数insert(): 它的过程是首先调用search() 查找e，如果返回位置非空，则说明已有雷同节点从，插入操作失败，否则x必然是_hot节点的某一个空孩子，于是创建这个孩子并存入e，之后更新全树的规模记录，并调用updateHeightAbove（）来更新x和历代祖先的高度 效率： 主要小孩在对算法search()和updateHeightAbove()的调用，时间复杂度同样取决与新节点的深度，在最坏情况下不超过全树的高度 2.3 删除算法（Remove） 从二叉搜索树中删除节点，首先需要调用BST::search（）来判断目标点是否的确存在树中，如果存在则需要返回其位置，方能对其进行具体实施删除操作，在删除的过程中分为单分支情况和双分支情况 效率： 删除操作所需要的时间主要消耗在对search()、succ（）和updateHeightAbove（） 的调用，在树中的任何高度，它们都至多消耗O（1）时间，故总体的渐进时间复杂度也不会超过全树的高度 0x03 平衡二叉搜索树（Balanced binary search tree） 3.1 树高和性能 根据对二叉搜索树的实现与分析，search()、insert()和remove（）等主要接口的运行时间，均线性正比于二叉搜索树的高度，在最坏情况下，二叉搜索树可能彻底退化为列表，此时查找效率甚至会降低O(n)，因此如果不能有效控制树高，实际性能比之前的向量和列表并没有明显的区别。 为了描述出现这种最坏的情况的概率，这里使用平均复杂度的概念来看二叉搜索树的性能，使用两种常见的随机统计口径来进行分析 随机生成(randomly generated)，在这种情况下可以看出二叉搜索树的平均高度为\\Omega(LogN) 随机组成(randomly composed)， 平均查找长度为 \\Omega(\\Sqrt(N)) 对比两种情况，可以看出两种不同的统计口径中对于平衡二叉树的统计次数的重叠，在第一种平衡中会越是平衡的树越会被统计多次，因此相对而言，按照后面口径多得到的估计值更加可信。 3.2 理想平衡和适度平衡 在之前看对于二叉树（Binary tree）的基本操作，比如search()、insert（）、remove（）的性能主要取决与树的高度，因此在节点数目固定的情况下，应当尽可能的降低高度，也就是尽可能的让兄弟子树的高度彼此接近，让全树更加平衡，比如对于包含n节点的二叉树，最理想的情况是高度为log_2N,这种就是理想平衡的情况；但是适当放松要求可以让我们得到比较好的效果，也就是适度平衡。 比如将树高限制在渐进不超过O(logN),相比较严格的理想平衡二叉树会更加放松，这里介绍的AVL树、伸展树、红黑树、KD树等都属于适度平衡的类别，因此也可以归纳为平衡二叉搜索树（Balanced binary search tree） 平衡二叉搜索树的适度平衡性就是通过对树中每一个局部增加某种限制条件来保证的， 比如在红黑树中，从树根到叶节点的通路总是包含一样多的黑节点； 比如在AVL树中，兄弟节点的高度相差不过1 这种限制条件设定是非常精妙的，除了适度平衡性，还具有局部性 经过单次动态修改操作后，至多之后O（logN）处局部不在满足限制条件 可以在O(logN)的时间内，让这O（logN）处局部乃至全树重新满足限制条件 由此来让失去平衡的二叉搜索树，必然可以迅速转换称为一颗等价的平衡二叉搜索树，等价二叉搜索树之间的转换过程称为等价交换 3.3 等价交换 首先定义等价，也就是中序遍历相同的二叉树之间是等价的，这种特点可以概括为“上下可变，左右不乱” 虽然二叉搜索树可以转换为理想平衡的完全二叉树，但是这种转换也是需要时间的，如何实现这种局部失衡的调整的同时来保证修复的速度？ 3.4 旋转调整 最基本的修复手段就是通过围绕特定节点的选装来实现等价前提下的局部拓扑调整，也就是单旋和双旋，zig和zag zig和zag均属于局部操作，仅涉及常熟个节点及其之间的链接关系，故可以在常数时间内完成，在后面实现各种二叉搜索数平衡化算法是支撑性的基本操作。 0x04 平衡二叉搜索树（BBST，Balanced binary search tree）的总结 本来直接看AVL的，但是由于太难了，不如在此对这一类的平衡二叉搜索树做一个总结，防止以后概念的混淆，同时在学习这些BBST的时候要注意基本概念产生的树的深度和算法（基本操作insert()、remove()、search() 之间的关 AVL树，平衡二叉树之一，应用相对其他数据结构比较少，windows对进程地址空间的管理用到了AVL；由G. M. Adelson-Velsky和E. M. Landis不1962年収明[36] ，并以他们名字的首字母命名 伸展树（Splay tree），按照“最常用者优先”的启发式策略，引入并实现伸展树，；由D. D. Sleator和R. E. Tarjan亍1985年发明 B、B-、B+树，平衡多路查找树（查找路径不只两个），主要用在文件系统以及数据库中做索引等 红黑树，广泛应用在C++STL中，比如map和set、Java的TreeMap KD-树结构，在四叉树（quadtree）和八叉树（octree）的一般性推广，是在计算几何类问题的求解的模式 4.1 AVL树 在二叉查找树中，任一节点对应的两棵子树的最大高度差为 1，这样的二叉查找树称为平衡二叉树 特点： 尽管可以保证最坏情况下的单次操作速度，但需在节点中嵌入平衡因子等标识；更重要的是，删除操作之后的重平衡可能需做多 达(logn)次旋转，从而频繁地导致全树整体拓扑结构的大幅度变化。 保持树平衡的目的是可以控制查找、插入和删除在平均和最坏情况下的时间复杂度都是O(log n)，相比普通二叉树最坏情况的时间复杂度是 O(n) ，AVL树把最坏情况的复杂度控制在可接受范围，非常合适对算法执行时间敏感类的应用。 4.2 伸展树（Splay tree） 1）刚刚被访问过的节点，极有可能在不久之后再次被访问到 2）将被访问的下一节点，极有可能就处于不久之前被访问过的某个节点的附近 特点： 伸展树实现简便、无需修改节点 结构、分摊复杂度低，但可惜最坏情况下的单次操作需要(n)时间，故难以适用于核电站、医 院等对可靠性和稳定性要求极高的场合。 4.3 B、B-、B+树 为此，需要充分利用磁盘之类外部存储器的另一特性：就时间成本而言，读取物理地址连续 的一千个字节，与读取单个字节几乎没有区别。既然外部存储器更适宜于批量式访问，不妨通过 时间成本相对极低的多次内存操作，来替代时间成本相对极高的单次外存操作。相应地，需要将 通常的二叉搜索树，改造为多路搜索树在中序遍历的意义下，这也是一种等价变换。 特点： B树是所有节点的平衡因子均等于0的多路查找树（AVL树是平衡因子不大于 1 的二路查找树）。B 树节点可以保存多个数据，使得 B 树可以不用像 AVL 树那样为了保持平衡频繁的旋转节点。B树的多路的特性，降低了树的高度，所以B树相比于平衡二叉树显得矮胖很多。B树非常适合保存在磁盘中的数据读取，因为每次读取都会有一次磁盘IO，高度降低减少了磁盘IO的次数。 4.4 红黑树 为此首先需在AVL树“适度平衡”标准的基础上，进一步放宽条件。实际上，红黑树 所采用的“适度平衡”标准，可大致表述为：任一节点左、右子树的高度，相差不得超过两倍 特点： 而节点的路径长度决定着对节点的查询效率，这样我们确保了，最坏情况下的查找、插入、删除操作的时间复杂度不超过O(log n)，并且有较高的插入和删除效率。 4.5 KD-树结构 需要在理解多维查询的基础上查询 循着上一节采用平衡二叉搜索树实现一维查询的构思，可以将待查询的二维点集组织为所谓 的kd-树（kd-tree）⑥结构。在任何的维度下，kd-树都是一棵递归定义的平衡二叉搜索树。","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"TsinghuaBook","slug":"TsinghuaBook","permalink":"https://blog.tjdata.site/tags/TsinghuaBook/"}]},{"title":"操作系统-01--基本概念","slug":"操作系统-01--基本概念","date":"2022-05-01T13:52:42.000Z","updated":"2023-05-13T13:52:26.079Z","comments":true,"path":"posts/ac6f4ba.html","link":"","permalink":"https://blog.tjdata.site/posts/ac6f4ba.html","excerpt":"希望跟着李老师来了解一下，嵌入式系统和微机原理没有了解的地方，来见证计computer是如何从计算机变成电脑的。可能需要看一下&lt;计算机组成原理&gt;,但是因为太下饭了，就看一下这个吧,掌握概念就好。Learning OS concepts by coding them!","text":"希望跟着李老师来了解一下，嵌入式系统和微机原理没有了解的地方，来见证计computer是如何从计算机变成电脑的。可能需要看一下&lt;计算机组成原理&gt;,但是因为太下饭了，就看一下这个吧,掌握概念就好。Learning OS concepts by coding them! 0x01 什么是操作系统 计算机是用来帮助人们解决一些实际问题的，它需要通过总线来连接输入输出设备、存储、CPU和内存等设备。其中最重要的CPU（Central Processing Unit，中央处理器）主要是解释计算机中的指令并处理数据的单元。 比如计算机在终端输入hello的过程 cpu发出指令，取内存 内存取对应地址的内容 通过控制器、总线来传递到图形控制器 操作系统（operation system）将计算机硬件设备管理，在这个基础上实现应用软件。基本的软件包括CPU、内存、终端、磁盘、文件；在之外的高级操作系统中添加不同计算机之前的使用。 我们需要学习 从应用软件出发看操作系统，只能是仅仅停留在操作系统的接口 从应用软件出发进入到操作系统，理解其中命令的过程，理解量才能知道背后的功能并开发 从硬件出发设计并实现操作系统 希望了解操作系统是如何运转的，八个实验 0x02 bootsect.s 2.1 计算机发展的历史 从白纸到图灵机，1936年，通过模拟人对计算过程得到计算模型 从图灵机到通用图灵机的过程 从通用图灵机到计算机（1946年，冯·洛依曼） 2.2 计算机开机的过程 计算机中开始电源的最初的IP是由硬件设计者决定，比如x86的开机CS=0xffff，ip=0x0000，以及寻址（Bios映射区），检查RAM、键盘、显示器和软硬磁盘，汇编中的每一条指令中有着操作 BIOS的引导扇区代码（bootsect.s） 0x03 setup.s and head.s 在上述bootsec.s运行完之后，可以是导入setup.s，它主要做了两件事情 添加操作系统代码到内存中，并为了保证操作系统的完整性，移动到0地址,第一个代码是head.s 读取硬件信息并初始化，mem_init 运行setup.s的过程中会短暂的定义GDT和IDT表格，之后系统会进行模式的转换，将16位模式来变为32位模式，提高对内存使用的权限 16位模式的寻址解析电路：CS&lt;&lt;4+ip （称为实模式） 32位模式的寻址解析电路：根据CS查表+IP（称位保护模式） 在运行完head.s之后便可以孩子选哪个main.c,这里是根据栈来进行处理的，也就是内存中函数的记录和返回 0x04 Interface 接口就是系统提供的一些可以调用的函数，因为接口是函数，函数是通过调用实现的，因此也称为系统调用 在具体到操作系统中，系统的接口需要一些统一的规范，最基本的是POSIX中的接口列表","categories":[{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"}],"tags":[{"name":"蘑菇书","slug":"蘑菇书","permalink":"https://blog.tjdata.site/tags/%E8%98%91%E8%8F%87%E4%B9%A6/"}]},{"title":"优化算法-01--pyomo的简单学习","slug":"优化算法-01--pyomo的简单学习","date":"2022-05-01T13:24:56.000Z","updated":"2023-05-13T13:51:27.233Z","comments":true,"path":"posts/903b7e5.html","link":"","permalink":"https://blog.tjdata.site/posts/903b7e5.html","excerpt":"pyomo是Python中的一个建模求解语言 Pyomo(Python Optimization Modeling Objects):优化建模对象，支持复杂优化应用的数学模型的建立和分析,是一种功能齐全的高级编程语言，包含一组丰富的支持库；建模的过程是科学研究、工程和商业许多方面的基本过程，建模涉及系统或现实世界对象的简化表示的制定。可以调用cplex这样的求解器来进行计算。","text":"pyomo是Python中的一个建模求解语言 Pyomo(Python Optimization Modeling Objects):优化建模对象，支持复杂优化应用的数学模型的建立和分析,是一种功能齐全的高级编程语言，包含一组丰富的支持库；建模的过程是科学研究、工程和商业许多方面的基本过程，建模涉及系统或现实世界对象的简化表示的制定。可以调用cplex这样的求解器来进行计算。 Cplex12.10–Linux–(Py3~Py38安装过程（附安装包）) 因此像Pyomo的建模工具可以用于： 解释系统中出现的现象 预测系统的未来状态 识别系统中可能的最坏情况或者最低成本的极值点 分析权衡来给予决策者支持 常见的求解器： CBC，开源求解器（COIN-OR）开发的线性规划求解器，性能不足 GLPK（GNU Linear Programmed Kit）是GNU维护一个线形规划工具包，对于求解大规模的额线性规划问题速度缓慢 CPLEX，是IBM开发的商业线性规划求解器，可以求解LP,QP,QCQP,SOCP等四类基本问题和对应的MIP，社区版仅支持低于1000变量的使用，教育版无限制，建模时间长，但是求解速度非常快 Gurobi，是CPLEX团队创始人重新创建的商业求解器，和cplex速度差别不大，相对来说比Cplex好一点 Pyomo的学习网站 Installation - Pyomo 6.4.0 documentation 0x01 Pyomo overview 1.1 Mathematical modeling 数学建模 数学模型是用形式化的语言表示系统只是，以下数学概念是现代建模活动的核心 变量variable，变量代表模型的未知或变化部分，（例如是否做出决定，或系统结果的特征），变量所取的值通常称为解，通常是优化过程的输出 参数parameters，参数表示为执行优化必须提供的数据，实际上在某些设置中data用来代替parameters 关系relations，这里是在定义模型的不同部分如何相互链接的方程、不等式或者其他的数学关系 目标goal，反应被建模系统的目标和功能 在计算机求解的过程中可以分为建模和求解两个方面，计算性能的替僧是的数学模型的数值分析称为一项司空见惯的活动，但是如果没有建模语言，设置输入文件、执行求解器以及从求解器中输出中提取结果的过程即繁琐又容易出错，在发生错误时难以调试，在大规模的实际应用程序中这种困难更加复杂，此外优化软件包使用的格式很多，而许多优化器实际识别的格式很少，因此应用多个优化器求解来分析模型会带来额外的复杂性 在这个过程中pyomo希望拓展用于python的数学建模，并调用对应的优化求解器来辅助求解，在这个过程中其具有的特征有 开源 可定制 求解器集成 具有非常robust的语言、广泛的文档、丰富的标准库集，对现代编程中类和函数的支持 1.2 Overview of modeling components and processes建模组建和过程描述 简单建模过程的基本步骤 创建模型并声明组建 实例化模型 应用求解器 询问求解器结果 在整个过程中pyomo的建模组件定义来模型的不同方面，包括现代AML通常支持的建模组件， sets, symbolic parameters, decision variables, objectives，constraints 在pyomo中定义相关的python类 Set，用于定义模型实例的数据 Param，用于定义模型实例的参数数据 Var。模型中的决策变量 Objective，模型中最小化或最大化的目标函数 Constraint，对模型中的Var施加约束限制的表达式 0x02 Abstract versus concrete models抽象模型和具体模型 使用类AbstractModel（）可以使用表示数据值的符号来定义数学模型，，例如下列表示一个线性程序，用于找到向量的最优值x，包括参数n和b，和参数向量a和c 使用类ConcreteModel（）来建立具体模型 python程序可能更喜欢 编写具体模型，而其他的一些代数建模语言的用户可能更喜欢编写抽象模型 2.1 Simple models简单模型 12345import pyomo.environ as pyomodel=pyo.ConcreteModel()model.x=pyo.Var([1,2],domain=pyo.NonNegativeReals)model.Obj=pyo.Objective(expr=2*model.x[1]+3*model.x[2])model.Constraint1=pyo.Constraint(expr=3*model.x[1]+4*model.x[2]&gt;=1) 虽然规则函数也可以用于指定Constraint和Objective，但是在此示例中使用expr来仅在具体模型中可用的选项，来直接指定表达式 2.2 Abstract Models抽象模型 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from _future_ import divisionimport pyomo.environ as pyomodel=pyo.AbstractModel()// 定义一些参数的集合// within 用于验证分配给参数数据值的选项的使用model.m=pyo.Param(within=pyo.NonNegativeReals)model.n=pyo.Param(within=pyo.NonNegativeReals)// 使用rangeset来声明集合是一个整数序列Model.I=Pyo.RangeSet(1,model.m)Model.J=Pyo.RangeSet(1,model.n)// 当集合Set作为Param的组件参数给出之后，表明该集合将索引参数model.a=pyo.Param(model.I,model.J)model.b=pro.Param(model.I)model.c=pyo.Param(model.J)//根据参数j定义变量，第二个参数表示Variable指定的参数域model.x=pyo.Var(model.J,domain=pyo.NonNegativeReals)/*在抽象模型中，promo表达式通常通过def来定义函数给定目标和约束声明，该def为函数及其参数建立一个名称，当pyomo使用函数来获取objective或者constraint时候，总是将模型作为第一个参数输入因此在pyomo中声明此类函数时，模型始终是第一个形式参数，如果需要请遵循其他参数定义的过程中有，常见的sum函数，来表示求和summation（）表示两个参数在他们的索引的乘积之和，默认最小化，如果希望最大化需要加入senese=pyo.maximize*///定义目标函数def obj_experssion(m): return pyo.summation(m.c,m.x)//??这里应该是矩阵相乘model.OBJ=pyo.Objective(rule=obj_experssion)//？？这里的参数输入为什么是ruledef ax_constraint_rule(m, i): # return the expression for the constraint for i return sum(m.a[i,j] * m.x[j] for j in m.J) &gt;= m.b[i]/*从抽象模型中可以看出，我们需要为每个值设置一个约束i从1到m为参数化表达式i，我们将它作为形式参数包含在声明约束表达式的函数中，使用pyomo.constraint参数因为我们模型具有许多相同形式的约束，并且我们创建来一个集合，model.I这些约束可以在其上被索引，因此这是约束声明的第一个参数，下个参数给出来将用于生成约束表达式的规则，这个约束声明model.I将创建一个由集合索引的约束列表，并且对于每个成员model.I都会调用函数ax-constraint-rule并传递给模型对象以及成员model.I*/# the next line creates one constraint for each member of the set model.Imodel.AxbConstraint = pyo.Constraint(model.I, rule=ax_constraint_rule) 为了使用这个模型，必须给出参数值的数据，可以提供数据的文件，格式为dat 0x03 Pyomo model setting Any= 所有可能的值 Reals= 浮点值 PositiveReals= 严格的正浮点值 NonPositiveReals= 非正浮点值 NegativeReals= 严格的负浮点值 NonNegativeReals= 非负浮点值 PercentFraction= 区间 [0,1] 中的浮点值 UnitInterval= PercentFraction 的别名 Integers= 整数值 PositiveIntegers= 正整数值 NonPositiveIntegers= 非正整数值 NegativeIntegers= 负整数值 NonNegativeIntegers= 非负整数值 Boolean 布尔值，可以表示为 False/True、0/1、‘False’/‘True’ 和 ‘F’/‘T’ Binary= 整数 {0, 1} 3.1 Sets 1234567891011pyo.Set()* dimen,集合参数的维度* doc，描述集合的字符串* filter，在构造过程中使用布尔函数* initialize，包含set的初始成员的可迭代对象* ordered，一个bool来表示集合是有序的* validate，验证新成员数据的bool* within，用于验证的集合pyo.rangeSet()生成一个【min,max,step】 3.2 Parameters 使用该词表示必须提供的数据，以便为决策变量找到最佳的分配 1234567pyo.Param()* default* doc* initialize 返回用于初始化参数值的数据函数* mutable，bool来设置是否允许在param初始化后更改值* validate，一个回调函数，接受模型、建议值和建议值的索引* within，用于验证的集合，指定有效参数值的域 3.3 Varibles 1234pyo.Var()* bounds* domain* initialize,为变量提供初始值，或者提供初始索引值 3.4 Objectives 返回试图最大化或最小化值的变量函数，可以构建一个默认参数位model的函数来作为输入 123def ObjRule(model): return 2*model.x[1] + 3*model.x[2]model.obj1 = pyo.Objective(rule=ObjRule) 可以使用sense参数来最大化 3.5 Constraints 大多数约束是使用规则创建的等式或不等式指定表达的 约束可以通过列表或集合来索引，当声明中包含列表或集合作为参数，元素会迭代传递给规则函数 123456model.A = RangeSet(1,10)model.a = Param(model.A, within=PositiveReals)model.ToBuy = Var(model.A)def bud_rule(model, i): return model.a[i]*model.ToBuy[i] &lt;= iaBudget = Constraint(model.A, rule=bud_rule) 求解实例 123456789101112131415161718# 学习promo中建模的基本过程# min 2*x+3*y# s.t. 3x+4y&gt;=1# x,y&gt;=0# 尝试构建模型，求解并得到最终的结果from pyomo.environ import *import pyomo.environ as pyo# 建立实际模型model=ConcreteModel()model.x=Var([1,2],domain=pyo.NonNegativeReals)model.Obj=Objective(expr=2*model.x[1]+3*model.x[2])model.Constraint1=Constraint(expr=3*model.x[1]+4*model.x[2]&gt;=1)opt=pyo.SolverFactory(&#x27;cplex&#x27;)opt.solve(model)print(pyo.value(model.x[1]))print(pyo.value(model.x[2]))","categories":[{"name":"Baseline","slug":"Baseline","permalink":"https://blog.tjdata.site/categories/Baseline/"}],"tags":[{"name":"Pyomo","slug":"Pyomo","permalink":"https://blog.tjdata.site/tags/Pyomo/"}]},{"title":"数据结构与算法02-图","slug":"数据结构与算法02-图","date":"2022-04-23T09:26:05.000Z","updated":"2023-05-13T13:52:38.812Z","comments":true,"path":"posts/36d150d2.html","link":"","permalink":"https://blog.tjdata.site/posts/36d150d2.html","excerpt":"这里主要借鉴Tsinghua的2020fall&lt;数据结构与算法&gt;这本书，包含对于一些基本数据结构的探索，先从定义梳理，在整理题目，之后是实际训练。结合之前在程序设计或嵌入式中对于数据在实际存储的例子来学习可能会更好。从中也能体悟到算法一些含义 本次主要对图（Graph）的基本知识点，和一些实际应用的算法进行描述，但是在另外一方面，图也不仅仅存在于数据结构中，在运筹学中对图也有相关的描述，因此希望在这里整合两者之间的概念，并分别介绍两者的应用，挺有意思的。","text":"这里主要借鉴Tsinghua的2020fall&lt;数据结构与算法&gt;这本书，包含对于一些基本数据结构的探索，先从定义梳理，在整理题目，之后是实际训练。结合之前在程序设计或嵌入式中对于数据在实际存储的例子来学习可能会更好。从中也能体悟到算法一些含义 本次主要对图（Graph）的基本知识点，和一些实际应用的算法进行描述，但是在另外一方面，图也不仅仅存在于数据结构中，在运筹学中对图也有相关的描述，因此希望在这里整合两者之间的概念，并分别介绍两者的应用，挺有意思的。 0x01 数据结构中的 图 Graph 例如之前例子中的迷宫，借助绳索掌握迷宫内各通道之间的相互关系，在很多应用中我们需要准确有效描述和利用这类信息，这类信息往往可以表述为定义与一组对象之间的二元关系，比如城市交通图、比如互联网中的IP地址，尽管上一章的树 Tree结构也可以用来表示这种二元关系，但是仅限与Parent Node 和Child Node之间，这种一般性的二元关系属于图论 Graph Theory的范畴 本章的主要目的 简要介绍图（Graph）的基本概念和术语 如何实现作为抽象数据类型（ADT）的图结构，主要讨论邻接矩阵（Adjacent matrix），和邻接表（Adjacent list）两种实现方式 从遍历（traverse）的角度介绍将图（Graph）转换为树（Tree）的典型方法，包括广度优先搜索（BFS）和深度优先搜索（DFS） 分别以拓扑排序和双连通域分解为例子，介绍利用基本数据结构并基于遍历模式，设计图算法的主要方法 （数据结构决定遍历次序）的观点出发，将遍历算法概括并统一为最佳优先遍历这一模式，如此来更加准确和深刻理解不同图算法之间的共性与联系，更可以学会通过选择和改进数据结构，高效设计并实现各种图算法 1.1 概述 图（Graph）定义为G=（V，E）。集合V中的元素为顶点（Vertex），集合E中的元素分别对应于V总的某一对顶点（u,v），表示它们之间存在的某种关系，因此可以称为边（Edge），从计算需求的角度约定都是有限集，规模分别记为n和e 无向图（undirected graph），若边(u,v)所对应顶点的u和v的次序无所谓，称作无向边（undirect edge）； 有向图（directed graph）。如果不对等，称为directed edge，如果从u指向v，则其中u是该边的origin或者尾顶点tail，v是该边的终点destination或头顶点head 如果包含有向边和无向边，可以称为混合图mixed graph 度（Degree），对于任何一边e=&lt;u,v&gt;，可以称顶点u和v彼此邻接（adjacent），同时与边e彼此关联（incident）。在无向图中，与顶点v关联的边数称为v的度数（degree），记deg（v）；在有向图中，出边总数称为出度（out-degree）、入边总数称为（in-degree） 简单图（Simple Graph），指的是不包含任何自环的图（Self-loop），自环指的是联接与同一顶点之间的边，在某些场景中具有特定意义，但在简单图中不讨论。 通路（path）就是由m+1个顶点于m条边交替而成的一个序列，也就是说这些边依次首尾相连，其中沿途的边的总数m是通路的长度。注意通路中的边必须互异，但是顶点可能重复，当顶点都不相同称为简单通路（Simple path） 环路（cycle）就是在通路的基础上加上起止顶点相同，对于不包含任何环路的有向图称为有向无环图（directed acrylic graph，DAG），如果环路中除了起点和终点的顶点相同，其他都是一样的称为简单环路（Simple cycle）。一些特殊的环路，欧拉环路（Eulerian tour）是图中各边一次且恰好一次的环路；对偶的，哈密尔顿环路（Hamiltonian tour）是经过图中各顶点一次且恰好一次的环路 带权网络（weighted network，G（V，E，wt（）））需要通过一个权值函数，为每一边e指定一个权重weight，wt（e）指定边e的权重 复杂度（complexity），在这个过程中n各顶点，最多有e=O（n^2)来进行描述 1.2 抽象数据类型的实现 也就是图（Graph）操作的一些方法，一般常见的实际方法，具体实现过程略过（看不懂，暂时觉得没必要） 1.3 邻接矩阵 Adjacent matrix 邻接矩阵是图（Graph）的ADT（Abstract Data Type），使用方阵A[n][n] 表示由n顶点构成的图，其中的每个单元负责描述顶点之间可能存在的邻接（Adjacent）关系 对于无权图，存在和不存在使用0-1来表示 对于带权网络，此时可以将矩阵中各单元从bool转换为int或者float类型，对于不存在的边使用0或者∞来代替 代码实现过程略过 1.3.1 时间性能 各顶点编号可以直接转换为其Adjacent matrix中对应的Rank，从而使得ADT中所有的静态操作接口的时间只需要O（1）时间 另外边的静态和动态操作只需要O（1）的时间，代价是Adjacent matrix的空间冗余 但是这种方法并非完美无缺，不足点在于顶点的动态操作接口十分耗费时间，为来插入新的顶点，V[]中需要添加一个元素，同时边集向量E[][]也需要增加一行，且每行都需要添加一个元素，顶点的删除操作也是类似；在通常的算法中顶点的动态操作远少于其他操作，而且计入向量扩容的代价，单次操作的耗时不过O（n） 1.3.2 空间性能 对于无向图而言，邻接矩阵必须为对称阵，其中除自环以外的每条边都被重复存放来两次，因此有一半的单元都是冗余的，也就是O（n^2） 1.4 邻接表（adjacent list） 在上述邻接矩阵（Adjacent matrix）的空间解释中可以看出其空间的仍存在改进的余地，在实际应用中处理的图所含有的边通常远远少于O（n^2)，比如在平面图之类的稀疏图（sparse graph）中，边数渐进不超过O（n），仅仅与顶点总数大致相当 为了完善这种静态空间管理策略所导致的问题，因此可以使用图结构的另外一种表示与实现方式，可以将邻接矩阵转换称邻接表的方式，分别记录每个顶点的关联边（或者等价的邻接顶点）来构成邻接表（adjacent list） 1.4.1 时间复杂度分析 复杂度分析，adjacent list中的列表等于顶点总数N，每条边在其中仅存放一次（for direct graph）或者两次（for undirected graph），因此空间总量为O(n+e),与图自身的规模相当，相比较adjacent matrix有很大的改进 在空间性能的改进，相对应的是时间性能的降低为代价，比如判断顶点v与顶点u的边是否存在，需要O(n)时间 与顶点相关的动态操作，顶点的插入操作可以在O（1）的时间内完成，顶点的删除操作需要遍历所有的adjacent list，需要O（e）时间 1.4.2 空间复杂度分析 adjacent list在访问单条边的效率并不算高，但是适合用循环的额方式，处理同一顶点的所有关联边比如为了枚举从顶点v出发的所有边，仅需要theta(1+outdegreee(v))而不是theta(n)的时间 1.5 图（Graph）遍历算法概述–BFS和DFS 图算法中大部分成员的主体框架都归结于图的遍历，与树的遍历相似，图的遍历需要访问所有顶点一次且仅有一次，此外图遍历同时还需要访问所有的边一次且仅一次 同时无论采用何种策略和算法，图遍历都可以理解为将非线性结转化为半线性结构的过程，经遍历而确定的边类型中，最重要的一类就是所谓的树边，它们与所有顶点共同构成来原图的一颗支撑树，称为遍历树traversal tree 图中顶点之间可能存在多条通路，为来避免对顶点重复访问，在遍历的过程中，通常还需要动态设置不同顶点的状态，并随着遍历的进程不断转换状态，直至最后的“访问完毕”，图的遍历更加强调对处于特定状态顶点的甄别与查找，因此也称为图搜索（Graph search） 深度优先搜索、广度优先搜索、最佳优先等基本而典型的图搜索，都可以在线性时间内完成，也就睡这些算法仅需要O（n+e）的时间来访问所有的顶点和边 各种图搜索之间的区别体现在边分类结果的不同，以及所得遍历树的结构差异，其决定因素在于搜索过程的每一步迭代，将依照何种策略来选取下一接受访问的顶点 1.5.1 广度优先搜索 breadth-first-search BFS 越早被访问到的顶点，其邻居被优先选用 搜索的过程：反复从前沿集（frontier）中找到最早被访问到顶点v，若其邻居均已访问到，则将其逐出前沿集，否则随意选出一个尚未访问到的邻居，并将其加入到前沿集（frontier） 由于每一步迭代都有一个顶点被访问，因此最多迭代O（n），另一方面因为不会泄漏每个刚被访问顶点的任何邻居，因此对应无向图（undirected graph）必能覆盖s所属的连通分量（connected component），对于有向图必能覆盖以s为起点的可达分量（reachable component） 123456789101112131415161718192021222324252627282930// 图的广度优先搜索算法void Graph::bfs(int s)&#123; //assert 0,nreset();int clock=0;int v=s; //初始化do if (UNDISCOVERED == status(v))// 一旦遇到尚未发现的顶点 BFS(v,clock);while (s !=(v=(++v %n))// 按照序号检查void Graph::BFS(int v, int&amp; clock)&#123; Queue Q;//辅助队列 status(V)=DISCOVERED; Q.enqueue(v);//初始化起点 while(!Q.empty())&#123; int v=Q.dequeue(); dTime(v)=++clock;//取出队首顶点v for(u=firstNbr(v);-1&lt;u;u=nextNbr(v,u)) if(status(u)==UNDISCOVERED)&#123; status(u)=DSICOVERED; Q.enqueue(u);//发现顶点 type(v,u)=TREE; parent(u)=v; &#125;else type(v,u)=CROSS; &#125; status(v)=VISITED&#125;&#125; 1.5.2 深度优先搜索 depth-first-search，DFS 优先选取最后一个被访问到的顶点的邻居 以顶点s为基点的DFS搜索，首先访问顶点s，再从s所有尚未访问到的邻居中任取其一，并以之为基点，递归地执行DFS搜索，故各顶点被访问到的次序，类似与树的先序遍历，而各顶点被访问完毕的次序，则类似于树的后序遍历 0x02 交通运筹学中的图 2.1 交通中图的例子 轨道交通中的图 18世纪哥尼斯堡城的，普雷格尔的两岸和河中两个岛之前有七座桥 经典的收发问题 2.2 基本概念–无向图G 无向图，设 V 是一个有n顶点的非空集合：V={v1，v2，v3，…，vn}；E是一个有m条无向边的集合：E={e1，e2，…，em}，则称V和E这两个集合组合一个无向图，记做G=（V，E） 基于无向图的G的结构特点，给出下列术语 平行边，如果两条不同的边具有相同的端点，称为e和e‘是G的平行边 简单图，如果图G中没有平行边则为简单图（！！有点不一样） 完备图，若图G中任何两个顶点之间恰好有一条边相关联，则称图G是完备图 子图，G1=（V1，E1）并且V1属于V、E1属于E 生成子图，G1是G的子图，并且V1=V，则称G1是G的生成子图 导出子图，若非空E1属于E，则E1及包含的顶点时G的导出子图 链，无向图中一个由顶点和边交替而成的非空有限序列，Q=v0e0v1e1v2，如果起始点相同是闭链，不想等位开链 初等链，若开链Q中诸顶点都不相同，则称Q为一条初等链 回路，若一个闭链除链第一个顶点和最后一个顶点相同之外，没有其他相同的顶点和相同的边则称为回路 连通图，若图G中任意两顶点u和v之间存在一条链，则称为图G为连通图。 否则被称为分离图 割边，若G为连通图，将G中边e取走后所得图为分离图，则称e为图G的割边 2.3 基本概念–有向图D 有向图，设 V 是一个有n顶点的非空集合：V={v1，v2，v3，…，vn}；E是一个有m条有向边的集合：E={e1，e2，…，em}，则称V和E这两个集合组合一个有向图，记做D=（V，E） 类似的有向图D也有术语 平行边，不同有向边的e与e‘的起点与终点相同 孤立点，V中不与E任一条边关联的点称为D的孤立点 简单图，无平行边的称为简单图 完备图，图中任何两个顶点，存在有向边（u，v）和（v，u），则该有向图D为完备图 基本图，将有向图D的每条边除定向就得到一个相应的无向图G，则G位D的基本图 子图，同上 导出子图，同上 导出生成子图，同上 同构图，如下图，顶点和边是相等的，由于同构图被认为是相同的，这就给我们在网络规划中建立网络模型带来许多方便，当我们使用几何图来构建网络模型时，点的位置可以任意布置。边的长短曲直可以任意，因此需要尽量设计这种反应问题清晰、简练的几何图 链，若Q是有向图D的基本图G中的一条链，则Q为D的一条链 初等链，若Q是有向图D的基本图G的一条初等链，则Q被称为D的一条初等链 路，若Q是有向图D的基本图G中一条链 路径 回路，第一个顶点和最后一个顶点相同 2.4 基本概念–矩阵表示 关联矩阵，行表示顶点，列表示边，使用1表示是否链接 邻接矩阵，行表示顶点，列表示顶点，使用数目表示两个顶点之间的链接数量 2.5 树 不做赘述 0x03 数据结构中图的应用 3.1 拓扑排序（topological sorting） 以教材的编写实际问题为例子，作者可以借助有向图的结构整理出相关知识点之间的依赖关系，因向量是散列表和查找表的基础知识点，等等得到一份有向图，在这个基础上如何将这个有向图（undirected graph）来得到具有前端的顺序的额拓扑排序（topological sorting） 相容：每一个顶点都不会通过边，指向其在此序列中的前驱顶点，这样的一个线性序列，称作原图的拓扑序列 针对有向无环图（directed noloop graph），问题在于topological sorting是否必然存在，如果存在是否唯一？ 同理，有限偏序集中也必然存在极小元素（同样，未必唯一）。该元素作为顶点，出度必然 为零比如图6.10(b)中的顶点D和F。而在对有向无环图的DFS搜索中，首先因访问完成而转 换至VISITED状态的顶点m，也必然具有这一性质；反之亦然。 166 进一步地，根据DFS搜索的特性，顶点m（及其关联边）对此后的搜索过程将不起任何作用。 于是，下一转换至VISITED状态的顶点可等效地理解为是，从图中剔除顶点m（及其关联边）之 后的出度为零者在拓扑排序中，该顶点应为顶点m的前驱。由此可见，DFS搜索过程中各顶 点被标记为VISITED的次序，恰好（按逆序）给出了原图的一个拓扑排序。 此外，DFS搜索善于检测环路的特性，恰好可以用来判别输入是否为有向无环图。具体地， 搜索过程中一旦发现后向边，即可终止算法并报告“因非DAG而无法拓扑排序”。 3.2 双连通域分解 考查无向图G。若删除顶点v后G所包含的连通域增多，则v称作切割节点（cut vertex）或 关节点（articulation point）。如图6.13中的C即是一个关节点它的删除将导致连通域 增加两块。反之，不含任何关节点的图称作双连通图。任一无向图都可视作由若干个极大的双连 通子图组合而成，这样的每一子图都称作原图的一个双连通域（bi-connected component）。 例如图6.14(a)中的无向图，可分解为如图(b)所示的三个双连通域。 3.3 优先级搜索 上面的图搜索应用虽然各有特点，但是其基本框架缺基本相似，总体而言都是通过迭代逐步发现各顶点，将其纳入遍历树中并做相应处理，同时根据应用问题的需求适当给出解答，各算法在功能上的差异，主要体现在每一步迭代中对新顶点的选取策略不同，比如BFS搜索会优先考察更早被发现的顶点，而DFS会更侧重于最后被发现的顶点 总结上述策略，可以看出其本质上是给所有顶点赋予不同的优先级，随着算法的推进不断调整，而每一步迭代所选取的顶点都是当时的优先级最高者，按照这样的理解，可以将BFS和DFS纳入统一的框架，称为PFS（priority-first search） 在实际应用中，引导优化方向的指标，往往对应于某种有限的资源或成本（比如通讯带宽、机票价格等）因此这里不妨约定优先级越大顶点的优先级越低 通过最小支撑树和最短路径这两个经典的图算法深入介绍这个框架的具体应用，在复杂度的分析中，PFS由两层循环构成，其中内层循环又含并列的两个循环，采用邻接表的方式，总体的复杂度为O（n^2) 3.4 最小支撑树 连通图G的某一无环连通子树T若覆盖G中所有的顶点，则称为G的一颗支撑树或生成树（spanning tree） 就保留原图中边的数目而言，支撑树是禁止环路前提下的极大子图，也是保持连通前提下的最小子图，其往往对应系统中最经济的连接方案 3.4.1 蛮力算法 3.4.2 prim算法（属于PFS的特例，时间复杂度为O（n^ 2） 3.5 最短路径树 可以看下面问题描述 Dijkstra算法（时间复杂度O(n^2) ![image-20220423203235868](/Users/chenxia/Library/Application Support/typora-user-images/image-20220423203235868.png) 0x04 交通运筹学中的图的应用 4.1 最短路径问题 在生产实践、运输管理和工程时间的很多活动中都需要面临寻找“图的最短路径”，这是网络规划中的一个基本问题 假设对于有向图D=（V，E），设图D的每条边(u,v)都和一个实数权重W（e）=W（u，v）对应，则称为赋权图。这里所说的权是与边有关的数量指标，可以根据问题的需要不同的含义，比如距离、时间和费用等 W（P）=\\Sigma W(e) 常见的解决方法 4.1.1 Dijkstra算法(略) 4.1.2 Bellman-Ford算法（略 4.2 最长路径问题 4.3 第k短路径问题 在最短路径的基础上，考虑第k路径感兴趣 4.4 最小生成树 给定连通赋权无向图G=（V，E），若T为G的生成树，T中边e的权 W(T)=ΣW(e)W(T)=\\Sigma W(e)W(T)=ΣW(e) 其中最小的称为最小生成树，一些常见的算法 4.4.1 Prim算法（略） 4.4.2 Kruskal 算法（略） 4.5 中国邮路问题 ![image-20220423194702621](/Users/chenxia/Library/Application Support/typora-user-images/image-20220423194702621.png) 4.6 运输网络 许多系统中存在流的问题，运输系统有物资流、公交系统中有车辆流、供水系统中存在水流，因此可以用图来描述网络，因此给定一些数学定义 运输网络 ![image-20220423195949264](/Users/chenxia/Library/Application Support/typora-user-images/image-20220423195949264.png) 网络流 割 最小割 最大流 4.7 最大流（4.6） 4.8 最小代价流问题（4.6）","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"TsinghuaBook","slug":"TsinghuaBook","permalink":"https://blog.tjdata.site/tags/TsinghuaBook/"}]},{"title":"数据结构与算法01-向量｜列表｜栈与队列｜树","slug":"数据结构与算法01-向量｜列表｜栈与队列｜树","date":"2022-04-16T15:10:37.000Z","updated":"2023-05-13T13:52:35.227Z","comments":true,"path":"posts/d1d898bf.html","link":"","permalink":"https://blog.tjdata.site/posts/d1d898bf.html","excerpt":"这里主要借鉴Tsinghua的2020fall&lt;数据结构与算法&gt;这本书，包含对于一些基本数据结构的探索，先从定义梳理，在整理题目，之后是实际训练。结合之前在程序设计或嵌入式中对于数据在实际存储的例子来学习可能会更好。从中也能体悟到算法一些含义 本次主要对绪论、线性结构的数组（Array）为基础的向量（Vector）、以链表（Link）为基础的列表（List）、栈（Stack）与队列（Queue）；半线性结构的数（Tree）做定义的记录和梳理。","text":"这里主要借鉴Tsinghua的2020fall&lt;数据结构与算法&gt;这本书，包含对于一些基本数据结构的探索，先从定义梳理，在整理题目，之后是实际训练。结合之前在程序设计或嵌入式中对于数据在实际存储的例子来学习可能会更好。从中也能体悟到算法一些含义 本次主要对绪论、线性结构的数组（Array）为基础的向量（Vector）、以链表（Link）为基础的列表（List）、栈（Stack）与队列（Queue）；半线性结构的数（Tree）做定义的记录和梳理。 Chapter01 绪论 1.1 瞎说 计算机是人类从事计算的工具，也是抽象计算模型的具体物化，基于图灵模型的现代计算机，即是人类现代文明的标志与基础，更是人脑思维的拓展与延伸。尽管计算机的性能日益提高，但是这种能力在解决实际应用问题能够真正得到发挥，决定性的因素在于人类如何深入思考与分析获得对问题本质的透彻理解， 需要按照长期积淀的框架和模式来设计出合乎问题内在规律的算法， 选用、改进或者定制足以支撑算法高效实现的数据结构， 并在真实的应用环境中充分测试、调试和改进 那么什么是算法？ 埃及人的绳索是算法 尺规作图是算法 冒泡排序bubble sort也是算法 宏观的定义是基于特定的计算模型，在解决某一信息处理问题而设计的一个指令序列，本书所说的算法还需要具有以下的特点 有input和output 可操作、确定性与可行性 有穷性和正确性，finiteness and correctness 退化与鲁棒性，degeneracy and robustness 重用性，reuse 如何评价一个算法呢？ 可计算性computability 难解性 intractability，本书将更多的关注于非“不可解和难解”的一般性问题，并讨论如何效率的解决这一层面的计算问题，因此需要确定一种尺度，从时间和空间方面度量算法的计算成本，并由此对不同算法进行比较和评判，当然最重要的是在研究和归纳算法设计月实现过程中的一般性规律与技巧，以编写出效率更高、能够处理更大规模数据的程序，这是本书的基本主题也是贯穿主题的脉络 计算效率 数据结构 1.2 复杂度complexity度量 💡 时间复杂度（Time complexity），运行时间是由多种综合因素作用而决定的，因为对于同种算法，对于不同的输入所需的运行时间并不相同，比如对于排序问题，输入序列的规模其中各元素的元素以及次序均不确定，这些因素都将影响到排序算法最终的运行时间，因此**为来运行时间建立一种可行、可信的评估标准，需要考虑其中的关键因素 因此可以将这个问题转化成为：随着输入模式的扩大，算法的执行时间将如何增长？执行时间的这一变化趋势可表示为输入模式的一个函数，可以讲起称为时间复杂度time complexity，对于特定算法处理规模为n的问题所需要的时间可以作T(n)** 💡 渐进复杂度（asymptotic analysis），一些算法适用于小规模输入，一些算法适用于大规模输入，在评价算法运行效率时，我们往往可以忽略其处理小规模问题的差异，转而关注在处理更大规模问题时的表现，在其中我们可以尝试用一些方法，1. 大O记号 2 大Omega记号 3 大Theta记号 渐进上界 ，也就是最差情况big-O notation，对于规模为n的任意输入，算法的运行时间都不高于O（f（n）） 渐进下界，也就是最好情况big-Omega-Notation，对于规模为n的任意输入，算法的运行时间都不低于Omega（g（n）） 如果恰好渐进上界和渐进下界之间先等，O=Omega，因此可以使用big-theta-notation做记号 💡 空间复杂度（space complexity），为了更加客观地评价算法性能的优劣，除非特别申明，空间复杂度通常并不原始输入本身所占用的空间，对于同一问题，这一指标对任何算法都是相同的，反之其他的各种方面所小孩的空间都应该计算 另外在很多时候我们都是更好甚至仅仅关注于算法的时间复杂度，而不必对空间复杂度多专门的考察，这种简单评测方式的一句都来自于一下事实：就渐进复杂度的意义而言，在任一算法的任何一次运行过程中所消耗的存储空间都不会多余期间所执行基本操作的累计次数；但是空间复杂度的分析的意义在于对空间效率非常在乎的应用场合中，当问题的输入规模极为庞大时，由时间复杂度所确立的平凡上界已经难以令人满意 1.3 复杂度分析 在1.2 中确定算法复杂度的度量标准，分析算法的复杂度，可一般使用大O算法，来将各种算法的复杂度从低到高划分为不同的级别 常数O（1） 对数O(log N) 线性 O（n） 多项式 O（polynomial（n）） 指数O（2^n） 1.4 递归recursive 递归的价值在于，许多应用问题都可以简介而准确地描述为递归形式，同时也是一种基本而典型的算法设计模型，这模式可以对实际问题中反复出现的结构和形式loop variant进行高度概括，并从本质层面加以描述与刻画，进而导出高效的算法 本篇文章从递归的基本模式入手，循序渐进介绍如何选择和应用（线性递归、二分递归和多分支递归等）不同的递归形式，来实现（遍历、分治等）算法策略，以及如何利用递归跟踪和递推方程等方法分析递归算法的复杂度 线性递归，base case of recursion，避免因无限递归导致系统溢出，往往对应减而治之decrease and conquer的算法策略，递归每深入一层，待求解问题的规模都缩减一个常熟，直至最终蜕化为平凡的简单问题 递归分析，可以使用递归跟踪与递归方程两种主要的方法 算法的每一个递归实例都表示为一个方框，其中著名该实例调用的参数 若实例M调用实例N，则在M与N对应的方框之间添加一条有向联线 递归模式 递归消除 二分递归 divide-and-conquer Chapter02 （Static）向量vector 数据结构是数据项的结构化集合，其结构表现为数据项之间的相互系列与作用，也可以理解为定义与数据项之间的某种逻辑次序，根据这种逻辑次序的复杂程度，可以将数据结构划分为线性结构、半线性结构和非线性结构三个部分 在线性结构中，数据项按照一个线性次数构成一个整体，其中最基本的线性结构为sequence，根据数据项的逻辑次序和物理存储地址的不同可以区分为向量vector和列表list 本章的讲解将围绕向量结构的高效实现而逐步展开，包括作为抽象数据类型的接口规范以及对应的额算法，尤其是高效维护动态向量的技巧 2.1 从数组和向量 💡 数组 Array 若集合S由n个元素组成，且各元素之间具有一个线性次序，则可以将他们存在在开始地址A、物理位置连续的一段存储空间， A=[a0,a1,...,an−1]A=[a_0,a_1,...,a_{n-1}]A=[a​0​​,a​1​​,...,a​n−1​​] q其中i小于j，A[i]都是A[j]的predecessor，后者是successor，相邻的成为immediate predecessor；immediate successor，元素的所有前去构成前缀prefix，所有的后继构成suffix 采用这样的元素规范，不仅使得每个元素都通过下标唯一指代，而且可以让我们直接访问任何元素，这里所说的访问包括 读取和修改等基本操作，“直接”的意思是这些操作可以在常数时间内完成 在其中元素的物理地址与其下标之间满足这种线性关系，因此被称作Linear Array 💡 向量Vector 对数组array基础上做一般性的推广。也是具有线性次序的一组元素构成的集合 V=[v0,v1,...,vn−1]V=[v_0,v_1,...,v_{n-1}]V=[v​0​​,v​1​​,...,v​n−1​​]其中的元素分别由Rank秩相互区分 在这样抽象之后，我们不在限定同一个向量中的元素都属于同一基本类型，本身可以是来自于更具一般性的某一类的对象，另外各元素也不见得同时具有某一数值属性，故并不保证之间可以相互比较大小 2.2 Interface接口 操作接口 具有一些基本操作， 介绍其中某些操作，比如size（）、get（）等静态操作可以在常数时间内完成 insert（）、remove（）等动态操作可能需要线性时间 Chapter03 （Dynamic）列表List 上一个章节中的元素访问为call-by-rank访问 另外一种形象的元素访问时间可以是call-by-link 不同数据结构内部的存储与组织方式差异，其操作接口的作用方式和时空性能也不相同，在设计和选用数据结构时，应该从实际应用的需求出发，先确定功能规范及性能指标，比如引入LIst的目的就是为了弥补Vector在解决某些应用问题的功能和性能方面的不足，两者之间的差异体现在对外的操作不同，根源在于内部存储方式的不同 3.1 从Vector到List 这也代表这从Static到Dynamic之间的转变 Static Storage Policy 静态存储策略 之前的Vector采用的就是静态存储的策略，“各元素物理地址连续”，由此导致的size（）get（）静态操作均可以在常数时间完成，而insert（）、remove（）等动态操作却都可能需要线性时间；得益于这种策略，我们可以O（1）时间内由Rank确定向量元素的物理地址，但是反过来在insert和remove的 过程中又不得不移动 O（n）元素，可以看出静态存储策略的静态操作的效率达到了极致，但是动态操作，局部的修改会引起整个范围甚至整个数据结构的调整 Dynamic Storage Policy 动态存储策略 List作为代表，尽管要求元素在逻辑上具有线性次序，但对物理地址并未做出任何限制，具体的是在生命周期内，此类数据结构将随着内部数据的需要，相应分配或回收局部的数据空间，如此元素之间的逻辑关系得以延续，却不必与物理次序相关，作为补偿，这类结构将通过指针或引用等机制来确定各元素的实际物理地址 比如链表（Linked list）就是一种典型的动态存储结构，其中的数据分散为一系列称为节点（Node）的单位，节点之间通过指针相互索引和访问，引入新的节点就可以删除原有的节点，在局部调整少量相关节点之间的指针 但是这样并不是没有问题 在提高动态动态操作效率的同时，却不不得不舍弃原静态存储策略中使用Rank访问的方式，从而造成来静态操作性能的下降，虽然Link list的访问可以通过Rank来查询，但是其本质上是通过多次的指针递归得到的，因此平均访问时间为O（n） Chapter04 （更基本）栈Stack 与队列Queue 本章的目标是实现更加基本，也更加常用的两类数据结构—栈和队列，属于线性序列结构，古其中存放的数据对象之间也具有线性次序，相对于一般的序列结构，栈与队列的数据操作范围仅限于逻辑上的特定某段，得益于其简洁行于规范性，他们可以构建更复杂、更高级数据结构的基础，也是算法设计的基本方法 相对于向量和列表，栈于队列的外部接口更为简化和紧凑，得益于此，本章的重点将不在拘泥对数据结构内部实现机制的展现，并转而更多从外部特性出发，结合若干典型的实际问题介绍栈和队列的具体应用 在队列的应用方面，贲张将介绍如何实现基于轮值策略的通用循环分配器，并以银行窗口服务为例实现基本的调度算法 4.1 栈（Stack） 栈是存放数据对象的一种特殊容器，其中数据元素按照线性逻辑次序排列，因此可以定义首、末元素，不过尽管栈结构也支持对象的插入和删除操作，其操作的范围仅限于栈的某一特定端，也就是说，若约定的元素只能从某一端插入其中，则反过来也只能从这一端删除已有的元素 类似于这种操作，栈中可以操作的一段成为栈顶Stack Top，另一段无法直接操作的盲端称为Stack Bottom，最常用的插入和删除操作分别称为入栈Push和出栈Pop 4.2 栈与递归 递归算法所需的空间量主要决定于最大递归深度，在达到这个深度的时刻，同时活跃的递归实例达到最多， 关于操作系统是如何实现函数递归调用的？如何记录调用与被调用函数（递归）之间的关系？如何实现函数（递归）调用的返回？又是如何维护同时活跃的所有函数（递归）实例的实现的？ 这些所有问题的答案，都可以归结于栈Stack 在windows操作系统中，每个运行中的binary executable的二进制程序都配有一个调用栈（call stack）或执行栈execution stack，借助调用栈可以跟踪属于同一程序的所有函数，记录它们之间的相互调用关系，并保证在每一调用实例执行完毕之后，可以准确返回 函数调用 Call Stack的基本单位是帧（Frame）、以及局部变量、输入参数，并将该栈Push调用栈，并在该函数返回之前发生新的调用，同样将与新函数对应的一帧Push栈顶，函数一旦运行完毕，对应的帧随即弹出，运行控制权将被交还给该函数的上层调用，并按照Frame记录的返回地址确定二进制程序中继续执行的位置，当位于栈底的main（）被弹出意味着整个程序的运行结束，此后控制权将交还给OS CPU眼里的：{函数} | 栈帧 | 堆栈 | 栈变量 | 调用栈_哔哩哔哩_bilibili 递归 作为函数调用的特殊形式，递归也可以借助上述调用栈得以实现，可以看出同一函数可能同时拥有多个实例，并在调用栈中各自占有一栈，这些栈的结构完全相同 一些没有用的建议 4.3 栈的典型应用 4.3.1 逆序输出 逆序输出中的共同特征：首先，虽有明确的算法，但解答却以线性序列的形式给出，其次无论是递归还是迭代实现，该序列都是按照逆序计算输出的，最后输入和输出规模不确定，事先难以确定盛放输出数据的容器大小，因此具有特有的“后进先出”的特点，以及在容量方面的自适应性，因此可以使用Stack来解决这类问题 💡 进制转换问题，可以将十进制整数n转换为lambda进制的表现形式 比较简单的除呗 12345678void convert(S,int：n,base)&#123; static char digit[]=&#123;&#x27;0&#x27;,&#x27;1&#x27;,...,&#x27;E&#x27;,&#x27;F&#x27;&#125;; if (n&gt;0)&#123; S.push(digit[n%base]&#125; convert(S,n/base,base)//在C中这里的n/base会自动输出为整数&#125;&#125;//新的base进制下由高到低的各数位，自顶而下保存与栈S中 4.3.2 递归嵌套 具有自相似性的问题可以用多嵌套递归描述，但因为分支位置和嵌套深度并不固定，其递归算法的复杂度不易控制，栈结构及其操作天然具有递归嵌套性，因此可用于高效解决这类问题 栈混洗（Stack Permutation） 假设三个栈A、B、S，其中BS开始为空，A中包含n元素，S作为中间转移栈，将A中元素转移到B中，其中仅允许 S.Push(A.Pop()) B.Push(S.Pop()) 💡 括号匹配问题，对源程序的检查是代码compile中重要而基本的一个步骤，而对表达式括号匹配的检查又是语法检查中必需的一个环节 其任务是，对任何一个程序块，需要判断其中的括号是否在嵌套的意义下完全匹配， 4.4 试探回溯法（Probing and BackTracking） 古希腊神话中半人半牛的怪物弥诺陶洛斯（Minotaur），藏身于一个精心设计、结构极其 复杂的迷宫之中。因此，找到并消灭它绝非易事，而此后如何顺利返回而不致困死更是一个难题。 不过，在公主阿里阿德涅（Ariadne）的帮助下，英雄忒修斯（Theseus）还是想出了个好办法， 他最终消灭了怪物，并带着公主轻松地走出迷宫。 实际上，忒修斯所使用的法宝，只不过是一团普通的线绳。他将线绳的一端系在迷宫的入口 处，而在此后不断检查各个角落的过程中，线团始终握在他的手中。线团或收或放，跟随着忒修 斯穿梭于蜿蜒曲折的迷宫之中，确保他不致迷路。 忒修斯的高招，与现代计算机中求解很多问题的算法异曲同工。事实上，很多应用问题的解， 在形式上都可看作若干元素按特定次序构成的一个序列。 以 经典 的旅行商问题（ traveling salesman problem, TSP）为例，其目标是计算出由给定的n个城市构成的一个序列，使得按此 序列对这些城市的环游成本（比如机票价格）最低。尽管此类问题本身的描述并不复杂，但遗憾 的是，由于所涉及元素（比如城市）的每一排列都是一个候选解，它们往往构成一个极大的搜索 空间。通常，其搜索空间的规模与全排列总数大体相当，为n! = O(nn )。因此若采用蛮力策略， 逐一生成可能的候选解并检查其是否合理，则必然无法将运行时间控制在多项式的范围以内。 这样的算法对应这样的模式： 从零开始，尝试逐步增加候选解的长度，更准确地是在这个过程中成批的考察具有特定前缀的所有候选解，这种从长度上逐步向目标解靠近的尝试，成为试探 Probing 作为解得到局部特征，特征前缀在试探的过程中一旦被发现与目标解不适合，则收缩到此前一步的长度，然后试探下一可能的组合，特征前缀长度缩减的这类操作成为，回溯BackTracking，其效果等同于剪枝Pruning 在上述的故事中，这种方法依赖于有型的物质基础，也就是需要保证搜索过的过程不被重复搜索，办法就是在剪枝的位置留下某种标记 💡 八皇后，国际象棋中皇后的势力范围覆盖所在的水平线、垂直线和两条对角线，现在考察如下的问题 在n*n的棋盘中，如何使得她们之间彼此互不攻击， 此时称她们构成一个可行的棋局，对于任何整数n大于等于4 首先分析问题可以看出，n皇后可以在n*n的棋盘上可行，首先需要设计Queen这个类，也就是坐标，通过重载判断等操作符来实现对皇后位置是否相互冲突的便捷判断 若每行能且只能放置一个皇后，不妨首先将每个皇后分配给每一行，然后从空棋盘开始逐个尝试将她们放置到无冲突的某列，没放置好一个皇后才继续试探下一个，若当前皇后在任何列都会造成冲突，则后续皇后的试探都是徒劳的，因此应该回溯到上一皇后 可以借助栈solu来动态记录各皇后的列号，当该栈的规模增至N得到全局解 💡 迷宫寻路，要求依照预定的行进规则，在具有特定集合结构的空间区域内，找到从起点到终点的一条通路，这样的简化版本 在空间区域限定为由n*n的方格组成的迷宫，除来四周的围墙，还有分布其间的若干障碍物，只能水平或垂直移动 我们的任务是在任意制定的Origin和Des中找到一条通路 4.5 队列Queue 与栈Stack一样，队列Queue也是存放数据对象的一种容器，其中的数据对象也按照线性的逻辑次序排列，队列结构同样支持对象Insert和delete，但是两种操作的范围分别被限制于队列的两端（若约定新对象只能从某一端插入其中，则只能从另一端删除已有的元素，允许取出元素的一端成为队头Front，而允许插入元素的另一端成为队尾Rear 对于的插入和删除操作，从队的角度可以称为enqueue和dequeue的操作 对应的一些基本操作 💡 循环分配器，为在客户client群体共享某一资源，比如共享CPU，一套公平且高效的分配规则必不可少，而队列结构则非常适于定义和实现这样的一套分配规则 可以使用所谓的轮值round robin算法中，首先令所有参与资源分配的客户组成一个队列Q，接下来是一个反复轮回式的调度过程 这里，每位用户持续占用资源的时间对算法的成败至关重要，一方面，未来保证响应速度，这个时间值通常不能过大；另一方面，因占有权限的切换也需要消耗一定时间，因此这个时间取的过小，切换过于频繁也会造成整体效率的下降 💡 银行服务模拟，介绍如何使用Queue结构实现顾客服务的调度于优化， Chapter05 二叉树 Tree 如果以平衡二叉搜索数为例子，若其中包含n个元素，则每次查找、更新、插入和删除操作等都可以在O(log N)的时间内完成 数结构有不计其数的变种，在算法理论以及实际应用中扮演着最为关键的角色，得益于独特而又普适的逻辑结构。树作为一种分层结构，而层次化这个特征几乎蕴含在所有食物及其联系之中 作为树的特例，二叉树实际上并不失其一般性，就本章而言，无论是逻辑结构还是算法功能来说，任何有跟有序的多叉树都可以等价转化并实现为二叉树，本章的终点在二叉树中，我们将用通讯编码算法的实现这个应用实例作为线索贯穿全章 5.1 二叉树及其表示 5.1.1 树（Tree） 从图论的角度来看，树等价于连通无环图，因此与一般的图相同，树可以用 一组定点Vertex，及其连接与其间的若干条边edge组成 在计算机科学，在这个基础上在制定某一特定定点成为根root，实现rooted tree 在程序实现的角度上，更多将定点vertex称做节点node 由于树的连通性，每个节点与根之间都有一条路相连，而根据树的无环性，由根通往每个节点的路径必然唯一，因此在每个节点vertex到根root的唯一通路所经过边的数目，称作的深度depth，依据深度排序可以对所有节点做分层归类 depth；沿每个节点vertex到根root的唯一通路所经过边的数目成为该节点的深度 祖先ancestor/后代descendant；这个是包含vertex节点本身 真祖先proper ancestor/真后代proper descendant；不包含vertex节点本身 parent/child；相邻的成为父母节点，和孩子节点 degree，vertex的孩子总数称为度树或者度，记做deg（v） leaf，无孩子的节点被成为叶节点，包括根在内的其余节点都被称内部节点internal node subtree；vertex的所有后代及其之间的联边称作子树，subtree（v） 5.1.2 二叉树 （Binary Tree） 二叉树中的每个节点的degree均不超过2，因此在Binary Tree中同一父节点中的汉子都可以使用左、右相互区分，因此可以被称为有序二叉（Ordered Binary Tree）；特别的，不包含一度节点的二叉树称为真二叉树（Proper Binary Tree） 5.1.3 多叉树（K-ary Tree） 一般来说，树中各节点的degree的数目并不确定，每个节点的degree均不超过k个的有根树，称为K叉树 在这个过程过，多叉树的表现方式有多种 父节点表示方法 孩子节点表示方法 父节点和孩子节点表示方法 有序多叉树=二叉树 长子和兄弟 父节点表示方法 可以将各节点组织为向量Vector或列表List，其中每个元素除保存节点本身的信息Data之外，还需要保存父节点Parent的Rank或Position 特别的，可以为Root指定一个虚构的父节点-1或Null，便于统一判断 如此，所有向量或列表所占的空间总量为O（N），线性正比于节点总数N，时间方面，仅需常数时间就可以确定任一节点的父节点Parent；但是反过来，孩子节点的查找却不得不花费O（n）时间访遍所有节点 孩子节点表示方法 可以让每个节点将其所有的孩子组织为一个向量或列表，由此对于拥有r个孩子的节点，可以在O（r+1）的时间内列举出其所有的孩子 父节点和孩子节点 上面两种方式各有所长，也各有所短，为了综合两者之间的优势，消除缺点，可以使用各节点记录父节点，也记录序列保存所有孩子 但是这种方法并不是没有缺点；尽管如此可以高效兼顾对父节点和孩子定位，但在节点插入与删除操作频繁的场合，为了动态维护和更新树的拓扑结构，不得不反复遍历和调整一些节点所对应的孩子序列，然而Vector和List等线性结构的此类操作都需要耗费大量时间，势必影响到整体的效率 有序多叉树和二叉树 采用从支持高效动态调整的二叉树结构，为此必须首先建立从多叉树到二叉树之间的某种转换关系，在这种转换的意义下，任何多叉树都等价与某颗二叉树 长子和兄弟 多序多叉树中任一非叶节点都有唯一的长子，而且可以该长子出发，按照约定或指定的次序遍历所有的孩子节点 一个非常有趣的现象出现：尽管二叉树只是多叉树的一个子集，但是对应用问题的描述和刻画能力并不低于后者，实际上以下我们还能进一步发现，即便就计算效率而言，二叉树也并不逊色一般意义上的树，反过来，得益与定义的简洁性以及结构的规范性，二叉树所所支撑的算法往往可以更好地得到描述，更加便捷实现 5.2 编码树 通过将通讯编码算法的实现作为二叉树的应用实例，通讯理论的基本问题是在尽可能低的成本下，用最高的速度来真实的实现信息在空间和时间上的复制和转移；在信道转移的信息大多按照二进制比特形式表示和存在，而每一个具体的编码方案都对应一颗二叉编码树 讲解的不深，不值得看，可以去看《信息传输远离》 5.3 二叉树的实现 作为图（Graph）的特殊形式，二叉树的基本组成单元是节点与边，作为数据结构，其基本的组成实体是二叉树节点（Binary Tree Node），边作用与节点之间的相互作用","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"TsinghuaBook","slug":"TsinghuaBook","permalink":"https://blog.tjdata.site/tags/TsinghuaBook/"}]},{"title":"PAPER01","slug":"PAPER01","date":"2022-04-08T06:58:34.000Z","updated":"2023-05-13T13:50:03.168Z","comments":true,"path":"posts/fc444d3.html","link":"","permalink":"https://blog.tjdata.site/posts/fc444d3.html","excerpt":"在疫情和定制公交的背景下，探讨如何促进人们可持续出行，也就是尽可能的转向定制公交，做出的主要贡献是研究了 通勤者在疫情中转向定制公交服务的意愿 根据问卷调查的方法确定了不同群体的模型偏好 为在疫情中促进公交服务提供潜在的政策建议 论文链接","text":"在疫情和定制公交的背景下，探讨如何促进人们可持续出行，也就是尽可能的转向定制公交，做出的主要贡献是研究了 通勤者在疫情中转向定制公交服务的意愿 根据问卷调查的方法确定了不同群体的模型偏好 为在疫情中促进公交服务提供潜在的政策建议 论文链接 01 引言和文献综述 首先大的背景是疫情，在疫情初期人们不可避免的受到政策和居家办公等影响在家，但是随着疫情慢慢结束，人们有着不可避免的出行需求，根据前人的研究，疫情前后出行的特点包括 客流需求降低、货运需求提升 出行使用私家车、自行车和步行升高；使用其他公共交通方式降低 但是过度的私家车出行会具有交通拥堵、环境污染等问题，因此促进疫情可持续出行是十分有必要的，而定制公交（customized bus，CB）是典型的需求响应式公交（demand response transit，DRT），利用类似公交服务于具有相同出行点和目的地的乘客，它具有比私家车更环保、比传统公共交通成本更低、同时具有私密、灵活和接驳的特点，从疫情的角度可以有效的避免路上的交叉感染， 从定制公交和疫情中人们出行行为变化的发展来看 定制公交的文献主要研究如何提升其服务水平，包括路径规划、车辆调度、服务质量等，没有研究定制公交具有吸引力的原因；因此可以研究疫情中定制公交如何影响人们的出行行为选择 在疫情前后，人们的出行方式可能发生变化，其中设计到人口特征、政策和个人观念，因此研究疫情汇总人们出行行为偏好的改变 02 方法和实验 因此本文使用调查问卷的方式，在问卷调查中主要分为三个部分： RP调查，是针对用户的真实场景进行提问，利用百度API爬取的通勤起终点步行、骑行、私家车、公交车、地铁和定制公交的时间、距离和费用等特征 SP调查时在给定场景中对用户的行为进行判断，对调查用户在收费和速度不同的四种场景下转向定制公交的意愿特征分析；四种正交场景包括票价和旅行速度的差异 基本的属性和社会学特征，包括性别、年龄、受教育程度、收入、是否有驾照、是否有私家车、是否有自行车/摩托车 之后使用多类别逻辑回归和嵌套逻辑回归分析，它们于逻辑回归的区别在于， 逻辑回归 假设 成本函数 多类别逻辑回归 （ps：我觉得就是softmax regression），它受到不相关替代方案的独立性影响，会导致不同类别之间具有互斥性，因为我们暂时还不知道CB与其他交通方式是否具有相似性，导致不同类别之间具有互斥性 嵌套逻辑回归 允许某些备选模式之间存在相关性，放宽了不同类别之间的独立同分布的假设 03 结果和讨论 建立的模型为 根据假设检验判断NL并不显著，说明CB和其他交通方式有明显的差异，因此主要看MNL的结果就行 单程客制化票价系数为负（-0.1141）；定制巴士的出行时间对通勤者的出行方式选择概率产生负面影响（-1.3966） 大多数模式的旅行时间系数为负。汽车的出行时间系数分别是步行和乘坐公共汽车的2.41倍和2.16倍 受访者对公共汽车的进出距离和地铁的出口距离很敏感。地铁的出口距离影响较大（-1.12），而公交车的出口距离不明显（-0.3321）。 之后根据ASC，也就是受访者在不采取任何措施时候的取值，反映保持现状受访者的基准效用 Ø年轻人更愿意乘坐地铁和公共汽车通勤，对定制公交比较积极 Ø中年人更喜欢乘坐定制公交出勤 Ø中等收入倾向于不步行通勤 Ø较高收入对私家车表现更高的偏好 Ø高等教育对定制公交具有强烈的偏好 Ø女性出行者更倾向于使用定制公交服务，比男性更讨厌步行和骑自行车 Ø男性对不同通勤方式的偏好没有显著差异 Ø无驾照人群更倾向于定制公交，同时对私家车出行消极 Ø有驾照人群对私家车出行和定制公交都积极 Ø有车群体愿意开车通勤，但比没有车的人更愿意改乘定制巴士 Ø有自行车的受访者使用自行车上班的可能性更高，但是定制公交对他们也很有吸引力 Ø有自行车的受访者使用自行车上班的可能性更高，但是定制公交对他们也很有吸引力 由上述给出的建议 从短期来看，公众愿意接受具有个人防护设备和疫情防控的基本用品的定制公交服务 从长远来看，由于后 COVID-19 时期的汽车通勤者更愿意使用定制巴士，而定制巴士的出行时间是一个重要变量，政府应实施相关政策来推动这一转变。 关于每个群体的特点，重要的是要考虑中年（31 至 36 岁）或受过高等教育（硕士和博士学位）/中等收入/没有执照或同伴，并拥有汽车和自行车。应该为这些群体设计具体的政策。票价折扣和补贴可以被认为是一个起点。","categories":[{"name":"Trans","slug":"Trans","permalink":"https://blog.tjdata.site/categories/Trans/"}],"tags":[{"name":"paper_reading","slug":"paper-reading","permalink":"https://blog.tjdata.site/tags/paper-reading/"}]},{"title":"Single01-设计模式","slug":"Single01-设计模式","date":"2022-04-08T06:58:34.000Z","updated":"2023-05-13T13:51:09.687Z","comments":true,"path":"posts/4de165f7.html","link":"","permalink":"https://blog.tjdata.site/posts/4de165f7.html","excerpt":"读书笔记","text":"读书笔记 0x01 基础知识 模式：每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心，通过这种方式，我们可以无数次重用那些已有的成功的解决方案，无须重复相同的工作 a pattern is a successful or efficient solution to a recurring problem within a context! 设计模式 一般包含模式名称、问题、目的、解决方案和效果等组成要素，其中关键要素是模式名称、问题、解决方案和效果 pattern name：通过一两个词来描述模式的问题、解决方案和效果，便于更好的理解模式并方便开发人员之间的交流 Problem：描述了应该在何时使用模式，包含了在设计中存在的问题以及问题存在的原因 Solution：描述设计模式的组成成分，以及这些组成成分之间的相互关系，各自的职责和协作方式，通常解决方案通过UML类图和核心代码来进行描述 Consequences：描述了模式的优缺点以及在使用模式应该权衡的问题 模式的分类主要分为creational、structural、behavioral三种 creational：描述如何创建对象 structural：主要用于描述如何实现类或对象的组合 behavioral：描述类或对象怎么交互以及怎么分配职责 设计模式的作用 可以实现可维护复用的设计方案，使用这些方案可以让我们避免做一些重复性的工作，有助于帮助我们提高开发和设计效率，同时提供了一套通用的设计词汇和一种通用的形式来方便开发人员之间沟通和交流、使得设计方案更加通俗易懂，大部分设计模式都兼顾了系统的可重用性和可拓展性，这使得我们可以更好地重用一些已有的设计方案、功能模块甚至一个晚还在呢个的软件下系统，避免做一些重复的设计（donnot repeat your code) 面向对象 面向对象的软件系统的设计，在支持可维护性的同时，提高系统的可复用性是一个至关重要的问题，如何同时提高一个软件系统的可维护性和可复用性是面向对象设计需要解决的核心问题之一，常见的面向对象的具有一下的设计原则 单一职责原则 single responsibility principle 一个类之负责一个功能领域总的相关职责，或者可以定义为，就一个类而言，应该只有一个引起他变化的原因；在软件系统中，一个类承担的职责越多，它被复用的可能性就越小 开闭原则 open closed principle 一个软件实体应该对拓展开发，对修改关闭，软件实体应尽量在不修改原有代码情况下进行拓展 为了满足开闭原则饿，需要对系统进行抽象化设计，抽象化是开闭原则饿的关键 12345678910111213// display 方法if(type.equals(&#x27;pie&#x27;)&#123;pieCHart chart=new PieChart()chart.display();&#125;else if (type.equals(&#x27;bar&#x27;))&#123;barChart chart=new BarChart();chart.dispaly();&#125;)// 但是这种方法中，如果需要增加一个新的图表类，比如折线图lineChart，就需要修改chartdisplay的源代码，增加判断逻辑违反了开闭原则//重构代码，需要通过抽象化的方式来对系统进行冲个，使之增加新的图表时不需要修改源代码1. 增加一个抽象图表类AbstractChart 将使用各种具体图表类作为子类2. chartdisplay类针对抽象图表类进行编程，由客户端来决定使用那种具体图表 里氏代换原则 liskov substitution principle 所有引用父类的地方必须能透明地使用其子类的对象 里氏代换原则是实现开闭原则的重要 在软件中将一个基类对象替换成为子类对象，程序将不会出现任何错误和异常，需要注意的问题有 子类的所有防范必须在弗雷中生命，为了保证系统的拓展性，在程序通常使用parent class来进行定义 尽量把parent class设计为抽象类或者借口，让sub class继承parent class或者实现parent class借口 依赖倒转原则 dependence inversion principle 抽象不应该依赖于细节，细节应当以来于抽象 要求我们在程序代码中传递参数或者在关联关系汇总，尽量引用层次高的抽象层类，使用接口和抽象类进行变量类型生命、参数类型生命、方法返回类声明以及数据类型的转换，而不是要用具体类来做这些事情 接口隔离原则 interface segregation principle 使用多个专门的接口，而不是使用单一的总结口 接口不能太小，太小造成数量太多难以维护，接口不能太大，太小违反接口隔离的原则 合成复用原则 composite reuse principle 尽量使用对象组合，而不是继承来达到复用的目的，是在一个新的对象例通过关联关系来使用一些已有的对象，使之成为新对象的一部分，新对象通过委派调用已有对象的方法达到复用功能的目的 迪米特法则 law of Demeter 一个软件实体应该尽可能减少和其他实体发生相互作用 0x02 六种 创建模式 2.1 简单工厂模式 首先将需要创建的各种不同对象的相关代码封装到不同的类中，这种类称之为具体产品类，而 将他们的公共的代码进行抽象和提取后封装在一个抽象产品类中，每一个具体产品类都是抽象产品类的子类，然后提供一个工厂类用于创建各种产品，在工厂类中提供一个创建产品的工厂方法，该方法可以根据所传入的参数不同创建不同的具体产品对象，客户端只需要调用工程类的工厂方法并传入响应的参数就可以得到一个产品对象 0x03 七种 结构模式 0x04 十一种行为模式","categories":[{"name":"Baseline","slug":"Baseline","permalink":"https://blog.tjdata.site/categories/Baseline/"}],"tags":[{"name":"Single","slug":"Single","permalink":"https://blog.tjdata.site/tags/Single/"}]},{"title":"CS229-09--学习理论终章","slug":"CS229-09--学习理论终章","date":"2022-04-03T08:56:49.000Z","updated":"2023-05-13T13:47:39.675Z","comments":true,"path":"posts/be2cd4f6.html","link":"","permalink":"https://blog.tjdata.site/posts/be2cd4f6.html","excerpt":"在目前没有足够做的经验或者说是机器学习素养的情况下来看这种文章无疑是一种折磨，因此过一遍概念就over惹，同时记录一下文献管理中的一些经验","text":"在目前没有足够做的经验或者说是机器学习素养的情况下来看这种文章无疑是一种折磨，因此过一遍概念就over惹，同时记录一下文献管理中的一些经验 01 计算学习理论 计算学习理论希望回答 在什么样的条件下成功的学习是可能的 在什么条件下某个特定的学习算法可以保证成功运行 在可能近似正确（probably approximately correct，PAC）下，我们确定若干假设类别，判断它们能否从多项式数量的训练集中得到，同时对假设空间的自然度量来界定归纳学习所需的样例的训练数目 1.1 问题和错误率 我们具有数据集合(x^{(i)},y^{(i)}），以及做出的假设的集合H和学习算法L，在这个问题中，我们感兴趣的是刻画不同的学习器L的性能，这些学习器使用不同假设空间H来学习不同类别的C中的目标概念 为了描述学习器L输出的假设h对真实目标的逼近成句，我们定义真实错误率（true error）,注意这里的真实错误率的定义是在整个实例的分布上，而不只是训练样例上，因为它是在实际应用此假设h后遇到的真实错误率 error(h)=Pr[c(x) =h(x)]error(h)=Pr[c(x)~=h(x)]error(h)=Pr[c(x) =h(x)] 这个错误率的分布依赖于未知的概率分布，这个概率分布是和假设空间相关的；另外一方面h对于c的错误率不能直接由学习器观察到 我们的目的是刻画一个：能够从合理数量的随机抽样训练样例中通过合理的计算来得到一个可靠的假设，那我们如何来描述这种可学习性？我们当然希望所有的真实错误率都为0，但是这样是不现实的（思维辩证就知道不合适），因此我们可以从这两个角度看 将真实错误率限定在一个常数范围内，同时让这个常数可以任意小ϵ\\epsilonϵ 并不要求对所有的随机抽样序列都能成功，只要求其实拍的概率在某个常数σ\\sigmaσ 一些PAC的定义： 在PAC学习定义之外，我们可以看出模型的可学习性很大程度由所需要的数据集数量确定，随着问题规模的增长所需要的训练样例的增长被称为该学习问题的样本复杂度（sample complexity） 对于一个假设空间如何确定和数据集之间的关系，可以用ϵ−exhousted\\epsilon-exhoustedϵ−exhousted来刻画，表示于训练样例一致的所有假设的真实错误率都恰好小于ϵ\\epsilonϵ 由此计算的得到需要的训练实际例子 m&gt;=1/(ϵ)(In∣H∣+in(1/σ))m&gt;=1/(\\epsilon)(In|H|+in(1/\\sigma ))m&gt;=1/(ϵ)(In∣H∣+in(1/σ)) 同样对于一个假设空间的复杂程度，可以使用Vapnik-Chervonenkis维度来证明模型的相关复杂程度 常见模型的复杂程度 神经网络的复杂程度 02 基于实例学习 一个很简单的思路，通过强大的计算能力，我们可以比较希望预测的值和数据集中所有实例，当从这些实例中泛化的工作被推迟到必须分类新的实例时，每当学习器遇到一个新的查询实例就分析这个实例与之前存储的的关系，来由此区分目标函数的值，这样的方法包括： 最近邻方法 nearest neighbor 局部加权回归 locally weighted regression 03 增强学习 大坑，不学，死都不学 04 文献管理 这里就是作为一个简单的记录，看文献中可能的应用场景 日常泛读来了解自己的研究现状（对于学术小白鼠不考虑555，所以没有这种需求） 文献综述 组会汇报的工作 因此需要对论文整理成一个一个项目来管理，同时需要对其做笔记，更重要的是可以方便引用， 第一部分查找： 单纯的找论文和管理的话，google scholar+sci-hub感觉就够了 在自己的google账号账图书馆中新建自己的文章档案库，这样可以方便管理 第二部分阅读： 可以在文档下载导入到zotero，再链接到notion，利用notion来做笔记和一些comment 作为一个文献管理的过程 第三部分引用： 可以利用zotero配合word的插件 也可以google scholar中导出apa格式 也可以使用latex中的texbib格式","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"CS229-08--集成学习","slug":"CS229-08--集成学习","date":"2022-03-28T13:25:01.000Z","updated":"2023-05-13T13:47:36.672Z","comments":true,"path":"posts/2cac3df3.html","link":"","permalink":"https://blog.tjdata.site/posts/2cac3df3.html","excerpt":"集成学习是通过构建并结合多个学习器来完成学习任务，有时候也被称为多分类系统（multi- classifier system）、基于委员会的学习（committee based learning）等等之类的，在其中主要面临基本学习器的选择和训练过程，我们希望学习器可以在相同的数据集上训练，但是得到的最终的弱学习器最好的是相互独立的，这样才能提高我们最高算法的准确程度。 集成学习成立的基础是：基学习器的误差相互独立，因此这也是我们在集成方法中需要尽可能的去实现的，因此本文从基本的方法和以决策树作为一系列基学习器开始","text":"集成学习是通过构建并结合多个学习器来完成学习任务，有时候也被称为多分类系统（multi- classifier system）、基于委员会的学习（committee based learning）等等之类的，在其中主要面临基本学习器的选择和训练过程，我们希望学习器可以在相同的数据集上训练，但是得到的最终的弱学习器最好的是相互独立的，这样才能提高我们最高算法的准确程度。 集成学习成立的基础是：基学习器的误差相互独立，因此这也是我们在集成方法中需要尽可能的去实现的，因此本文从基本的方法和以决策树作为一系列基学习器开始 0x01 引言 在任何应用中，我们都可以使用多个学习算法汇总的一个，使用确定的算法都在一组基本假设，并训练得到影响最终学习器的超参数，因此可以尝试使用构建多个彼此不同的学习器，尽可能的减少它们之间误差的相关性来通过某种策略的组合来提升模型的效果，如何构建不同的学习器？ 使用不同的算法和数据集，比如使用参数化的逻辑回归和非参数化的决策树模型，这样多算法的学习器之间的误差是可能独立的；对于相同的参数化的模型也可以采用不同的超参数，比如对于K-means算法可以在不同的算法选择不同的k值；同样对于不同的算法模型中选择不同的数据集是也可以产生不同的学习器，因此可以使用自助法等构建彼此相互独立数据集的基础上来训练得到不同的算法模型 使用一些特殊的策略，包括但不限于：平均法（averaging）、投票法（voting）、学习法（learning） 使用一些特殊的策略，包括但不限于：bagging（典型模型：随机森林random forest）和boosting（典型模型：Adaboost、GB） 0x02 集成学习 – 不同的模型 比较简单，看0x01引言–第一点 0x03 集成学习-- 不同的策略 3.1 平均法averaging（回归器） 对于数值型常用的结合策略是平均法，又可以分为简单平均法（simple average）和加权平均法（weighted average） 虽然看名字可能就知道这个代表是什么，但是对于加权平均法其中最重要的是权重的确定，或许可以根据多元高斯分布来确定由近及远的权重、可以根据专家打分的德尔菲法、可以有迷糊的一致性矩阵计算得到的AHP、Kalman filter中检测和状态转移的估计等得到的权重，无论是何种方法最重要的是可以得到一个令自己满意、顶得住别人argue的处理方法 加权平均方法被用于集成学习可以被看作是集成学习研究的基本出发点，对给定的基学习器，不同的学习方法可以视作通过不同的方式来确定加权平均法中的基学习器的权重。 3.2 投票法voting（分类器） 投票的方式本质上和回归的平均法是类似的，但是因为class是可以数清楚的，因此可以分为绝对多数投票法（majority voting）、相对多数投票法（plurality voting）、加权投票法（weighed voting）、 3.3 学习法 当训练数据很多的时候，一种更为强大的结合策略是使用学习法，通过另外一种学习器来进行结合 stacking是学习法的典型代表，在这里将个体学习称为初级学习器，用于结合的学习器称为次级学习器或者元学习器（meta- learner），stacking先从初始数据集和中训练得到初级学习器，然后“生成“一个新的数据集来训练次级学习器，在这个新的数据集中，初级学习器的输出被当作样例来输入特征，而初始样本的标记被当作样例标记，这里的假设是初级学习器是使用不同学习算法得到的不同的模型，参考周志华-《机器学习》代码 可以看出，其中的次级学习算法可以看出是一种自适应adaptive的权重调整方法，同时这种权重是通过一个学习器来训练得到的，抛弃其中的数学原理不谈，这里常用的包括多响应线性回归Multi- response Linear regression和贝叶斯模型平均Bayes Model AVeraging BMA等效果较好 0x04 集成学习-- 特殊的概念 在集成学习中最晦涩的就是boosting和bagging（bootstrap aggregating）两种方法 4.1 bagging（有放回称为bagging、无放回的称为pasting） 同样是根据希望的得到不同基训练模型，因此我们可以对相同的学习器来赋予不同的训练集来得到不同的模型，但是由于数据集是有限的，因此如果数据集完全隔离开，这样训练得到的学习器必然是不好的（或者说是不够好的），如果我们想尽可能的好的得到独立同时效果也好的学习模型，可以参考之前对模型评估中的样本的自助法选择（bootstrap sampling）来得到相互独立数据集得到的不同学习模型；在此基础上得到的结果可以使用简单平均策略或者简单投票来得到最终的结果 从bias=variance的角度来看，bagging主要集中在降低方差 4.2 boosting 是一类可以将弱学习器提升为强学习器的算法，这种算法的工作机制类似：先从初始训练集训练得到一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本再后续受到跟多关注，然后基于调整后的样本分布是的先前基学习器做错的训练样本再后续收到更多的关注，然后使用基于调整后的样本分布来训练下一个基学习器，如此重复进行，直到基学习器数目达到来事先制定的值，最终将这些基学习器进行加权结合 从bias- variance的角度来看，boosting主要集中在降低偏差 （这里感觉书上讲的还是比较模糊的，主要在后面的实际例子中看） 4.3 bagging和boosting的区别 从样本选择角度 从样本的权重 从预测函数的权重 从计算的角度 0x05 实际例子 5.1 投票法 一个比较简单的例子 1234567891011121314151617181920212223242526272829## 集成学习需要得到的是不相关的预测器# 可以使用不同的学习器# 可以使用不同的数据来训练得到不同的学习器# 一些特殊的方法bagging和boosting#%%from sklearn.datasets import make_moonsfrom sklearn.model_selection import train_test_splitx,y=make_moons(n_samples=100,noise=0.25)x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.2)#%%## votefrom sklearn.ensemble import RandomForestClassifierfrom sklearn.ensemble import VotingClassifierfrom sklearn.linear_model import LogisticRegressionfrom sklearn.svm import SVC#%%lr_clf=LogisticRegression()rnd_clf=RandomForestClassifier()svm_clf=SVC()#%%voting_clf=VotingClassifier(estimators=[(&#x27;lr&#x27;,lr_clf),(&#x27;rf&#x27;,rnd_clf),(&#x27;svc&#x27;,svm_clf),],voting=&#x27;hard&#x27;)#%%voting_clf.fit(x_train,y_train)from sklearn.metrics import accuracy_scorefor clf in (lr_clf,rnd_clf,svm_clf,voting_clf): clf.fit(x_train,y_train) y_pred=clf.predict(x_val) print(accuracy_score(y_val,y_pred)) 5.2 随机森林 random forest（based on bagging） 随机森林就是使用许多个决策树来集成得到最终的结果，论文最早发布与1997年的如下，他是如何将有放回的抽样应用到决策树CART中的呢？（这或许是随机森林学习的重点），以及具体的实践方法，其中的数学原理可能比较困难 Paper：Amit, Y., &amp; Geman, D. (1997). Shape quantization and recognition with randomized trees. Neural computation, 9(7), 1545-1588. API:sklearn.ensemble.RandomForestClassifier 回顾之前关于实现决策树模型的过程，它是一个很简单的过程，一种采用递归思想的算法，在不考虑最终停止的条件，它总是从现有的特征集中选择最好的特征来进行模型的分割，然后删除这个特征进行下一次递归，那么随机森林在这个过程中做了什么优化呢？ 样本的角度，在训练决策树中并不选择所有的样本训练，利用bootstrap的方法来有放回的抽取数据集来训练不同的决策树（decision tree） 特征的角度，传统的decision tree由上述的描述可以看出它实际上是一种没有放回抽样（why？），那么随机森林的改进就是每次不删除特征集，而是随机选择一定属性的特征（比如原始特征集的10%）来选择其中最佳的特征来进行模型的分割一直到不能再分裂为止 模型的优点 有可以做出高纬度的数据、并且不用降纬，不需要做特征选择 可以判断特征的重要程度、特征之间的相互影响 训练速度可以很快，做成一种并行处理的方法 对于不均衡的数据可以平衡误差 模型的缺点 被证明在某些noise比较大的分类或回归问题中会产生过拟合 对于不同取之的属性的数据，取值划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产生的属性权重是不可信的 5.3 Adaboost（based on boosting，short for adaptive boosting） 自适应增强学习Adaboost是如何将boosting的方法使用在训练的过程中呢？总的来看它考虑如何通过更加规则（而不是随机）的方式来得到更加有效的基学习器的训练，并采用一定的策略来加权所有的预测 Paper：Freund, Y., &amp; Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1), 119-139. API：sklearn.ensemble.AdaBoostClassifier Adaboost的算法可以简述为三个步骤： 初始化数据集，这里保证数据集中的每个样本的数据的权重是相同的 在第N次的训练中，得到原始标签和模型的输出，如果预测是正确的那么在下一次训练中需要降低它的权重、如果预测是错误的则需要提升它的权重，在进行N+1学习器的训练 在综合最终的结果就是对每个阶段的学习器进行加权平均，如何加权呢？根据正确率来判断，正确率高的权重大 模型的优点：这里参考https://zhuanlan.zhihu.com/p/41536315 很好的利用弱分类器进行级联cascade 可以将不同的分类算法作为弱分类器 AdaBoost具有很高的精度 可以充分考虑每个分类器的权重（也就是加权平均中权的选择合理） 模型的缺点： 模型的迭代次数不好设计，可以使用交叉验证来进行确定 数据不平衡导致分类精度下降 由于不能并行训练，因此计算时间比较长 5.4 GB（gradient boosting，based on boosting and slightly bagging） 有一点复杂2022-03-28还没有完全搞清楚梯度提升（gradient boosting），其算法实现主要分为XGBoost和LightGBM，从boosting算法的角度是必须串行计算的，但是在工程的实际应用中可以使用一些稀奇古怪 的方法来反复使用其中的一些东西来并行计算提高计算效率 Paper：Friedman, J. H. (2001). Greedy function approximation: a gradient boosting machine. Annals of statistics, 1189-1232. 一些工业化的实现： lightGBM：https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf XGBoost：Chen, T., &amp; Guestrin, C. (2016, August). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining (pp. 785-794). 存疑：GBDT（采用decision tree作为基学习器的GB算法）的核心是学习之前每棵树结论和的残差，这个残差就是一个加预测值后能得到的真实值的累加量，这里相比Adaboost的优点 与Adaboost算法不同的是，梯度提升在迭代每一步构建一个能够沿着梯度最陡的方向降低损失来弥补现有模型的不足 经典的Adaboost的算法只能采用指数损失函数的二分类学习任务，而梯度提升可以通过不同的可微损失函数来处理各类学习任务（multi-class、regression、rank） Adaboost中对异常点比较敏感，而梯度提升算法通过引入bagging的思想、正则化可以提升robust","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"CS229-07--贝叶斯学习（暨基本理论开篇）","slug":"CS229-07--贝叶斯学习（暨基本理论开篇）","date":"2022-03-19T13:44:12.000Z","updated":"2023-05-13T13:47:33.880Z","comments":true,"path":"posts/6378bc30.html","link":"","permalink":"https://blog.tjdata.site/posts/6378bc30.html","excerpt":"","text":"0x00 计算学习理论的开篇 贝叶斯学习，贝叶斯推理提供来一种推理的概率方法，基于待考察的量遵循某种概率分布，且可根据这些概率及已观察到的数据进行推理得到最优的决策 集成学习，从多个弱学习器中得到一个较好的学习器 计算学习理论，致力于回答“在什么养的条件下成功的学习是可能的》”和“在 什么条件下某个特定的学习算法可保证成功运行？”，从近似正确（PAC）和对假设空间的自然度量两个角度来分析学习算法，在出错界限的框架下考察一个学习器在确定正确假设前可能产生的训练错误数量 基于实例的学习，每当学习器遇到一个新的实例，通过分析这个例子和之前存储的实例关系来将这个目标函数赋值给新的实例 基于解释的学习，先验知识用于分析观察到的学习样例是怎样满足目标概念的，然后这个解释被用于区分训练样例中哪些是相关的特征、哪些是不相关的，这样就可以基于逻辑推理进行泛化，而不是基于统计推理 增强学习，用来确定最优控制策略 0x01 贝叶斯学习简介 贝叶斯学习具有两个特点：第一，贝叶斯学习算法能够计算显始的假设概率，比如朴素贝叶斯分类器，是解决相应学习问题的最实际的方法之一；第二，为理解多数学习算法提供了一种有效的手段，这些算法不一定直接操纵概率数据 在机器学习中，通常最感兴趣是在给定训练数据D的时候，确定假设空间H中最可能的假设： 使用P(h)P(h)P(h) 来代表没有训练数据前假设h拥有的概率，通常被称为prior probability（先验概率） P(D)P(D)P(D) 代表将要观察的训练数据D的先验概率，也就是在没有某一假设成立时D的概率 P(h∣D)P(h|D)P(h∣D) 代表的是看到训练数据D后h成立的置信度，这里是posterior probability（后验概率） P(h∣D)=P(D∣h)P(h)P(D)P(h|D)=\\frac{P(D|h)P(h)}{P(D)}P(h∣D)=​P(D)​​P(D∣h)P(h)​​ 极大后验（maximum a posterior，MAP）：maxP(D∣h)P(h)max P(D|h)P(h)maxP(D∣h)P(h) 极大似然估计（maximum likelihood，MLE）：maxP(D∣h)max P(D|h)maxP(D∣h) example：考虑一个医疗诊断问题，这里是h是是否患有癌症，这里是的数据是检测结果是正例+还是负例- 我们知道人群中患有癌症的概率是0.008；也就是没有患有癌症的概率是0.992 同时我们知道对于患有癌症的患者返回检测结果，0.98是+、0.02是- 对于没有患有癌症的患者，返回检测结果，0.03是+，0.97- 如果现在来了一个病人的检测结果是+，那么患有癌症的概率是多少 P(h=患有癌症｜D=检测结果+)=\\frac{P（D=+｜h=患有癌症）P（h=患有癌症）}{p（D=+|h=患）p（h=患）+p（D=+｜h=不患）p（不患）}=0.21 example02～example03: 线性回归中极大似然和最小误差平方假设 逻辑回归中极大似然和交叉熵 0x02 贝叶斯分类器 基于一个简单而又强大的假设：在给定目标值事，属性值之间的相互条件独立，该假定说明在给定实例的目标值情况下，观察到的联合属性a1、a2、a3… 的概念等于单个属性的概率乘积： P（a_1,a_2,...,a_n|h）=\\prod P(a_i|h) example： 我们是数据集和知道了关于一个🍉是否好坏的颜色和大小的属性： 对一个红色，大的🍉判断是否好坏： P（好）=0.8 P（坏）=0.2 P（红色｜好）=0.8， P（红色｜坏）=0.1， P（大｜好）=0.9 P（大｜坏）=0.4 P（好）*P（红色｜好）*P（大｜好）=0.576 同理，观察到数据中坏的可能行=0.008 所以为好🍉 半进阶，需要考虑到独依赖估计（semi- naive bayes classifiers） 进阶：贝叶斯信念网 留个坑：贝叶斯分类器的文本估计 0x03 期望最大化算法（EM） 在讨论中，一直假设训练样本所有属性变量的值度可以被观测到，但是在实际中往往会遇到特征只有一部分可以观察到，EM算法可以用于变量从来没有被直接观察到的情况，只要这些变量所遵循的概率分布的一段形式 example：理解EM算法可以从一个实际的例子推导来得到，假设一个数据是从k个高斯分布混合而得到的，注意这个k未知，但是这个k个高斯分布的方差是σ2\\sigma ^2σ​2​​ 知道，现在需要预测是k个均值&lt;μ1,μ2,,,μk&gt;&lt;\\mu_1,\\mu_2,,,\\mu_k&gt;&lt;μ​1​​,μ​2​​,,,μ​k​​&gt;,我们需要先假设均值的值，在重新估计隐藏变量的值来重新计算极大似然假设 Step01:当前的假设为&lt;μ1...,μk&gt;&lt;\\mu_1...,\\mu_k&gt;&lt;μ​1​​...,μ​k​​&gt; 的值，计算属于每个类别的期望值 E(z=k∣D)=p(x=xi∣μ=μi)/P(x=xi)E(z=k|D)=p(x=x_i|\\mu=\\mu_i)/P(x=x_i)E(z=k∣D)=p(x=x​i​​∣μ=μ​i​​)/P(x=x​i​​) Step02: 计算一个新的极大似然假设，计算每个点属于每周类别的最大概率来更新均值，来替换称为新的假设 理论推导 对于n个样本观察数据{xi}i=1m\\{x^i\\}_{i=1}^m{x​i​​}​i=1​m​​ 我们需要找到样本的模型参数θ\\thetaθ 来最大对数似然函数，其中包含没有观察到的隐含数据Z \\bar \\theta=argmax \\Sigma log p(x^i;\\theta)\\\\ \\bar \\theta=argmax \\Sigma log p(x^i,z^i;\\theta)\\\\ =\\bar \\theta=argmax \\Sigma log \\Sigma_{z^i}\\ p(x_i,z^i;\\theta)\\\\ =\\bar \\theta=argmax \\Sigma log Q_i(Z^i) \\Sigma_{z^i}\\ \\frac{p(x^i,z^i;\\theta)}{Q_i(z^i)}引入一个新的分布\\\\ >=\\Sigma\\Sigma Q(Z_i) *log\\frac{p(x_i,z_i;\\theta)}{Q(z_i)}根据Jensen不等式 我们有许多的选择，但是这样Jesen会在后面的取常数的时候手链 \\frac{p(x^i,z^i;\\theta)}{Q_i(z^i)}=c\\\\ 同时\\Sigma Q_i(Z^i)=1 由此可以看出 Qi(zi)=p(xi,zi;θ)/Σ(p(xi,zi;θ))=p(zi∣xi,θ)Q_i(z^i)=p(x^i,z^i;\\theta)/\\Sigma(p(x^i,z^i;\\theta))=p(z^i|x^i,\\theta) Q​i​​(z​i​​)=p(x​i​​,z​i​​;θ)/Σ(p(x​i​​,z​i​​;θ))=p(z​i​​∣x​i​​,θ) E: 计算Qi(Zi)Q_i(Z^i)Q​i​​(Z​i​​) M: argmaxΣΣQi(Zi)log(p(xi,zi;θ)/Qi(Zi))argmax\\Sigma\\Sigma Q_i(Z^i)log(p(x^i,z^i;\\theta)/Q_i(Z^i))argmaxΣΣQ​i​​(Z​i​​)log(p(x​i​​,z​i​​;θ)/Q​i​​(Z​i​​)) EM算法的例子 更实际的例子：假设AB用相同的概率选择一个硬币，进行实验，每次都是独立的，请问如何估计两个硬币正面出现的概率？（a情况是知道选择硬币A还是B；b情况不知道选择硬币A还是B） E：我们假设A的概率是0.6；假设B的概率是0.5，这里仅仅是初始化的值，同时根据观测的数据来计算期望的分布 Q_i(Z^i=A)=P（Z=A｜y_i,\\bar\\theta_A）=\\frac{P（Z=A,y_i|\\bar\\theta_A）P(A)}{P（Z=A,y_i|\\bar\\theta_A）P(A)+P（Z=B,y_i|\\bar\\theta_A）P(B)}\\\\ =[0.45,0.80,0.73,0.35,0.65] Q: 其中的Q函数形式为 Q(θ,θi)=∑j=1N∑zP(z|yj,θi)logP(yj,z|θ)=∑j=1Nμjlog(θyjA(1−θA)10−yj)+(1−μj)log(θyjB(1−θB)10−yj)] Q ( θ , θ i ) = ∑ j = 1 N ∑ z P ( z | y j , θ i ) l o g P ( y j , z | θ ) = ∑ j = 1 N μ j l o g ( θ A y j ( 1 − θ A ) 10 − y j ) + ( 1 − μ j ) l o g ( θ B y j ( 1 − θ B ) 10 − y j ) ] 求导来得到更新的θA,θB\\theta_A,\\theta_Bθ​A​​,θ​B​​ 比如混合高斯模型GMM、K-means聚类的方法 0x04 卡尔曼滤波","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"CS229-04--常见模型总结","slug":"CS229-04--常见模型总结","date":"2022-03-11T01:37:48.000Z","updated":"2023-05-13T13:47:24.382Z","comments":true,"path":"posts/61a92f70.html","link":"","permalink":"https://blog.tjdata.site/posts/61a92f70.html","excerpt":"在机器学习看到一半的过程中，对于之前学习的广义线性模型、高斯判别分析、支持向量机、决策树、多层感知器进行阶段性的总结，并尝试使用过去课程中可能存在例子来进行展示，最后利用Kaggle的实验来进行展示 如有侵权，可以删除；如有错误，欢迎提出","text":"在机器学习看到一半的过程中，对于之前学习的广义线性模型、高斯判别分析、支持向量机、决策树、多层感知器进行阶段性的总结，并尝试使用过去课程中可能存在例子来进行展示，最后利用Kaggle的实验来进行展示 如有侵权，可以删除；如有错误，欢迎提出 0x01基本模型 1.1 GLM（logistic regression、linear regression、softmax regression） 之前的blog，关于GLM 吐槽： 明明是discriminate的模型，却叫广义线性模型（generative linear model）；明明是generative的模型，却叫高斯判别分析（gaussian discriminat analysis） 广义线性模型中的步骤是，对于一群i.i.d（独立同分布）的数据集X，通过学习算法得到一个关于输出预测y的P(y^∣X)P(\\hat y|X)P(​y​^​​∣X),再每次输出中将期望值作为最终的输出，使得其的概率可以最大。其中做出三个基本假设 X～Exponential\\ Family(\\eta)=b(y)exp(\\eta^TT(y)-a(\\eta)) 输出的预测值y^=hθ(x)=E(y∣x)\\hat y=h_{\\theta}(x)=E(y|x)​y​^​​=h​θ​​(x)=E(y∣x) 由于是线性模型，最强的假设是η=θTx(i)\\eta =\\theta^T x^{(i)}η=θ​T​​x​(i)​​ 可以从三个例子来看出推导过程： example01:逻辑回归（y=「0，1」,ps：y=[-1,1]不一样） GLM分析： hθ(x)=E(y∣x,θ)h_{\\theta}(x)=E(y|x,\\theta)h​θ​​(x)=E(y∣x,θ),这里的分布假设是Bernoulli（伯努利分布），因此 hθ(x)=ϕ=1/(1+e−η)=1/(1+e−θTx)h_{\\theta}(x)=\\phi=1/(1+e^{-\\eta})=1/(1+e^{-\\theta^Tx})h​θ​​(x)=ϕ=1/(1+e​−η​​)=1/(1+e​−θ​T​​x​​) 数据集和假设（x^{(i)},y^{(i)}）,y\\in\\{0,1\\},h_{\\theta}(x)=g(z),g(z)=\\frac{1}{1+e^{-z}} 由此推导得到预测值的输出的损失函数:P(y∣x)=∏hθ(x)y∗(1−hθ(x)1−yP(y|x)=\\prod h_{\\theta}(x)^y*(1-h_{\\theta}(x)^{1-y}P(y∣x)=∏h​θ​​(x)​y​​∗(1−h​θ​​(x)​1−y​​ 之后为了利用梯度下降Gradient Descent下降的方式需要计算∂l∂θ\\frac{\\partial l}{\\partial\\theta}​∂θ​​∂l​​,同时为了简便计算 ∂l∂θ=∂In(P)∂θ=Σ(y−hθ(x).∗x)\\frac{\\partial l}{\\partial\\theta}=\\frac{\\partial In(P)}{\\partial\\theta}=\\Sigma (y-h_{\\theta}(x).*x)​∂θ​​∂l​​=​∂θ​​∂In(P)​​=Σ(y−h​θ​​(x).∗x) example02: 线性回归 GLM分析： hθ(x)=E(y∣x,θ)h_{\\theta}(x)=E(y|x,\\theta)h​θ​​(x)=E(y∣x,θ),这里的分布假设是高斯分布 hθ(x)=ϕ=η=θTxh_{\\theta}(x)=\\phi=\\eta=\\theta^Txh​θ​​(x)=ϕ=η=θ​T​​x 数据集和假设（x^{(i)},y^{(i)}）,h_{\\theta}(x)=\\theta^Tx 由此推导得到预测值的输出的损失函数:P(y∣x)=N(θTx,σ2)P(y|x)=N(\\theta^Tx,\\sigma^2)P(y∣x)=N(θ​T​​x,σ​2​​) 之后为了利用梯度下降Gradient Descent下降的方式需要计算∂loss∂θ\\frac{\\partial loss}{\\partial\\theta}​∂θ​​∂loss​​,同时为了简便计算 In(p)=Σi=1m[In(1σ∗(2∗π))+−(y^i−hθ(X))22∗σ2]In(p)=\\Sigma_{i=1}^m[In(\\frac{1}{\\sigma*\\sqrt(2*\\pi)})+-\\frac{(\\hat y^i-h_\\theta(X))^2}{2*\\sigma^2}]In(p)=Σ​i=1​m​​[In(​σ∗√​(​​​2∗π)​​1​​)+−​2∗σ​2​​​​(​y​^​​​i​​−h​θ​​(X))​2​​​​] 等价于loss=Σ−(y^i−hθ(X))22loss=\\Sigma-\\frac{(\\hat y^i-h_\\theta(X))^2}{2}loss=Σ−​2​​(​y​^​​​i​​−h​θ​​(X))​2​​​​ ∂loss∂θ=Σ(y−hθ(x).∗x)\\frac{\\partial loss}{\\partial\\theta}=\\Sigma(y-h_{\\theta(x)}.*x)​∂θ​​∂loss​​=Σ(y−h​θ(x)​​.∗x) example03: softmax 回归 GLM分析： hθ(x)=E(y∣x,θ)h_{\\theta}(x)=E(y|x,\\theta)h​θ​​(x)=E(y∣x,θ),这里我们不知道具体的概率分布是什么，只能假设每一类的输出是ϕk\\phi_kϕ​k​​,得到概率分布函数 p(y;ϕ)=ϕ11,y=1∗ϕ21,y=1...∗ϕk1,y=k=ϕ1T(y)1∗ϕ2T(y)2∗...∗ϕkT(y)k=b(y)exp(ηT(y)−a(η))p(y;\\phi)=\\phi_1^{1,y=1}*\\phi_2^{1,y=1}...*\\phi_k^{1,y=k}=\\phi_1^{T(y)_1}*\\phi_2^{T(y)_2*...*\\phi_k^{T(y)_k}}=b(y)exp(\\eta^T(y)-a(\\eta))p(y;ϕ)=ϕ​1​1,y=1​​∗ϕ​2​1,y=1​​...∗ϕ​k​1,y=k​​=ϕ​1​T(y)​1​​​​∗ϕ​2​T(y)​2​​∗...∗ϕ​k​T(y)​k​​​​​​=b(y)exp(η​T​​(y)−a(η)) 经过化简可以得到 η=[log(ϕ1/ϕk),...,log(ϕk−1/log(ϕk))]\\eta=[log(\\phi_1/\\phi_k),...,log(\\phi_{k-1}/log(\\phi_k))]η=[log(ϕ​1​​/ϕ​k​​),...,log(ϕ​k−1​​/log(ϕ​k​​))] 同时 Σϕj=1\\Sigma \\phi_j=1Σϕ​j​​=1 可以得到 ϕk=1/Σeηi=1/ΣeθiTx\\phi_k=1/\\Sigma e^{\\eta_i}=1/\\Sigma e^{\\theta^T_i x}ϕ​k​​=1/Σe​η​i​​​​=1/Σe​θ​i​T​​x​​ 因此对于 ϕi=eηi/Σ(eηj)=eθiTx/Σ(eθjTx)\\phi_i=e^{\\eta_i}/\\Sigma(e^{\\eta_j})=e^{\\theta^T_ix}/\\Sigma(e^{\\theta_j^T x})ϕ​i​​=e​η​i​​​​/Σ(e​η​j​​​​)=e​θ​i​T​​x​​/Σ(e​θ​j​T​​x​​) 在得到分布函数的基础上，我们就可以计算期望值 hθ(x)=E(y∣x;θ)=[ϕ1,...,ϕk−1]h_{\\theta}(x)=E(y|x;\\theta)=[\\phi_1,...,\\phi_{k-1}]h​θ​​(x)=E(y∣x;θ)=[ϕ​1​​,...,ϕ​k−1​​] 损失函数就是我们最初定义的： loss=ϕ1T(y)1∗ϕ2T(y)2∗...∗ϕkT(y)kloss=\\phi_1^{T(y)_1}*\\phi_2^{T(y)_2*...*\\phi_k^{T(y)_k}}loss=ϕ​1​T(y)​1​​​​∗ϕ​2​T(y)​2​​∗...∗ϕ​k​T(y)​k​​​​​​ 1.2 GDA（Gaussian Discriminat Analysis） 与判别式模型（GLM）想比较p(y∣x)p(y|x)p(y∣x)，生成式模型generative用于生成p(x∣y)p(y)p(x|y)p(y)p(x∣y)p(y)来对每一种类别建模，寻找每个类别的特征，也就是比如输出多种类别，同时假设每个类别都是高斯分布，则可以计算两个类别的高斯分布参数，这样在得到输入可以直接使用分布函数来得到输出 p(x∣y)=1(2∗π)n/2∗∣Σ∣1/2∗exp(−1/2∗(x−μT)Σ−1(x−μ)))p(x|y)=\\frac{1}{(2*\\pi)^{n/2}*|\\Sigma|^{1/2}}*exp(-1/2*(x-\\mu^T)\\Sigma^{-1}(x-\\mu))) p(x∣y)=​(2∗π)​n/2​​∗∣Σ∣​1/2​​​​1​​∗exp(−1/2∗(x−μ​T​​)Σ​−1​​(x−μ))) 计算就好了蛮 1.3 SVM(Support Vector Machine) 支持向量机是最大边缘方法，允许把模型表示为训练实例的一个子集的影响之和，这些影响用面向应用的相似性核给出，采用：不要在解决实际问题之前把解决一个更复杂的问题作为第一步；在训练过程中希望找到的是那个最佳分离平面hyperplane：wTx+bw^Tx+bw​T​​x+b中的两个参数 模型的输入是(x(i),y(i)),y∈{−1,+1}(x^{(i)},y^{(i)}),y\\in\\{-1,+1\\}(x​(i)​​,y​(i)​​),y∈{−1,+1},希望找到的是可以讲数据集可以正确区分开的参数w bw\\ bw b Ps:为了简单起见，可以从线性可分的情况来谈论，再拓展到非线性可分的情况 通过定义functional margin和geometry margin，我们可以建立最符合直觉的模型为： target:max\\ \\gamma=min[y^{(i)}(w^Tx^{(i)}+b)]\\\\ subject\\ to:y^{(i)}(w^Tx^{(i)}+b)>\\gamma\\\\ ||w||=1 经过凸优化中的相关变化，使其变成可以求解的形式 min:\\frac{1}{2}||w||^2\\\\ s.t.:y^{(i)}(w^Tx^{(i)}+b)>=1 对于这种类型的凸优化问题，可以采用拉格朗日方法或者其他方法直接进行求解；也可以将其转换为对偶问题dual problem，再利用拉格朗日算法或者其他方法来求解，⚠️我们希望求解的是w和b！！ L=12∣∣w∣∣2+αi(1−y(i)(wTx(i)+b))[α&gt;=0]L=\\frac{1}{2}||w||^2+\\alpha_i(1-y^{(i)}(w^Tx^{(i)}+b))[\\alpha&gt;=0]L=​2​​1​​∣∣w∣∣​2​​+α​i​​(1−y​(i)​​(w​T​​x​(i)​​+b))[α&gt;=0] 对于这个函数求极值，就是希望 ∂L∂w\\frac{\\partial L}{\\partial w}​∂w​​∂L​​和∂L∂b\\frac{\\partial L}{\\partial b}​∂b​​∂L​​等于0 ∂L∂w=w−Σαiy(i)x(i)\\frac{\\partial L}{\\partial w}=w-\\Sigma\\alpha_iy^{(i)}x^{(i)}​∂w​​∂L​​=w−Σα​i​​y​(i)​​x​(i)​​ ∂L∂b=Σαiy(i)\\frac{\\partial L}{\\partial b}=\\Sigma\\alpha_iy^{(i)}​∂b​​∂L​​=Σα​i​​y​(i)​​ 将这个带入到L中，化简得到 L=Σαi−1/2ΣΣαiαjy(i)y(j)x(i)x(j)L=\\Sigma\\alpha_i-1/2\\Sigma\\Sigma\\alpha_i\\alpha_jy^{(i)}y^{(j)}x^{(i)}x^{(j)}L=Σα​i​​−1/2ΣΣα​i​​α​j​​y​(i)​​y​(j)​​x​(i)​​x​(j)​​ 构建对偶问题，等价于 max Lmax\\ Lmax L s.t. \\alpha_i>=0\\ 并且 \\Sigma\\alpha_i*y^{(i)}=0 其中需要满足KKT条件： αi&gt;=0\\alpha_i&gt;=0α​i​​&gt;=0 y(i)(wTx(i)+b)−1&gt;=0y^{(i)}(w^Tx^{(i)}+b)-1&gt;=0y​(i)​​(w​T​​x​(i)​​+b)−1&gt;=0 αi(y(i)(wTx(i)+b)−1&gt;=0)=0\\alpha_i(y^{(i)}(w^Tx^{(i)}+b)-1&gt;=0)=0α​i​​(y​(i)​​(w​T​​x​(i)​​+b)−1&gt;=0)=0 通过某种算法SMO可以很轻松的求解上述对偶问题，得到αi\\alpha_iα​i​​并根据KKT条件可以确定支持向量（support vector）,由此计算得到w和b，这样就可以判断正例还是反例 SMO算法？以后才知道吧 在线性不可分的情况，可以使用核机器（kernel function）来进行重新度量向量之间的非相似性 在间隔划分中，可以通过设置软间隔的方式来允许有部分噪声点发生 同时为了过拟合的风险，依旧可以增加模型复杂程度的项（term） 1.4 CART（Classfication and regression tree） 1.5 ANN（Artificial Neural Network） 对于每个神经元包括两个部分，一个是接受前端的激活权重，另外一方面是自身的激活函数的选取 线性连接：z^i=w^ia^{i-1}+b^i 激活输出：a^i=g(z^i) 假设对于这样的一个函数： 前向传递： Z1=W1∗X+b1Z^1=W^1*X+b^1Z​1​​=W​1​​∗X+b​1​​ A1=g(Z1)A^1=g(Z^1)A​1​​=g(Z​1​​) Z2=W2∗A1+b2Z^2=W^2*A^1+b^2Z​2​​=W​2​​∗A​1​​+b​2​​ A2=g(Z2)A^2=g(Z^2)A​2​​=g(Z​2​​) Z3=W3∗A2+b3Z^3=W^3*A^2+b^3Z​3​​=W​3​​∗A​2​​+b​3​​ A3=g(Z3)A^3=g(Z^3)A​3​​=g(Z​3​​) 梯度下降来更新参数： ps：解决问题要从源头一步一步解决 可以选取交叉熵作为误差函数 L=−(ylog(y^)+(1−y)log(1−y^))L=-(ylog(\\hat y)+(1-y)log(1-\\hat y))L=−(ylog(​y​^​​)+(1−y)log(1−​y​^​​)) ∂L/∂W3=∂L/∂A3∗∂A3/∂W3=(y^−y)A2\\partial L/\\partial W^3=\\partial L/\\partial A^3*\\partial A^3/\\partial W^3=(\\hat y-y)A^2∂L/∂W​3​​=∂L/∂A​3​​∗∂A​3​​/∂W​3​​=(​y​^​​−y)A​2​​ 很amazing，在于输出的梯度下降可以和前一个节点的激活有关，如果使用内存把这些记录下来，可以大幅度的降低训练的时间，同时可以并行的计算一些参数 在定义好一个网络结果只是一个基础，还需要确定网络中的激活函数，定义好网络中训练的基本参数初始化、参数的随机选择、以及采用比较好的优化求解算法 激活函数 softmax、tanh、logistic、ReLu等等 参数归一化 min-max归一化、z-score、均值方差归一化 参数初始化 在网络层数变多的情况下，梯度会出现爆炸或者变小的情况，因此可以采用的随机化包括：均值、xvaier initiation、he initialization、np.random .randn(shaope)*np.sgrt(1/n[z-1]) simoid 用1比较好、relu用2比较好等等不知名的参数初始化 优化方法 GD、SGD、BGD、动量算法、Adam、启发式算法（模拟退火、遗传算法）等等 常见的网络 RBF（radial basis function，径向基网络） ART（adaptive resonance theory，自适应谐振理论） SOM（self- organizing map ，自组织映射） CC（cascade- correlation，级联相关网络） Elamn网络 Boltzmann机 0x02实验 一些比较简单的codebase GLM 决策树CART在IRIS tensorflow实现的人工神经网络 支持向量机 0x03Kaggle- Titanic 草率的花了一晚上了解了一下kaggle的流程，有点拉胯，一万多 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495001 数据集的导入和基本信息train数据集中包括的特征有： PassengerId：乘客的编号 Survived：是否存活 Pclass：票的类型，1是最好的、3是最差的 Name:性命 Sex:年龄 Age:年龄 SibSp:相伴的兄弟姐妹以及配偶 Parch：相伴的父母或者孩子 Ticker：乘客的票号 Fare:乘客的票价 Cabin：机舱号码 Embarked：下车地点import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snstrain_data=pd.read_csv(&#x27;../titanic/train.csv&#x27;)test_data=pd.read_csv(&#x27;../titanic/test.csv&#x27;)train_data.head()# 和交通数据中一样拿到数据需要考虑数据是否存在缺失、异常、或者是重复等等train_data.info()# 可以看出数据中存在缺失的特征包括：Age、Cabin、Embarked## 缺失值的修补#Embarked 上船地点中缺少两个数，对于之后并没有太大的影响，可以使用众数进行修补train_data.Embarked.fillna(value=train_data.Embarked.dropna().mode().values[0])data_test=test_data.Fare.fillna(value=test_data.Fare.dropna().mean())test_data.loc[:,&#x27;Fare&#x27;]=data_test# 从直觉上来看，年龄对于之后是否坠船有相关的影响，因此在这里选择对应的非空特征进行绚练feature_name=[&#x27;Pclass&#x27;,&#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;,&#x27;Fare&#x27;,&#x27;Embarked&#x27;,&#x27;Survived&#x27;]# cabin 的机场缺失太多，这里就不作为训练来# 对性别进行编码train_data_copy=train_data[feature_name]from sklearn.preprocessing import LabelEncoderlabel=LabelEncoder()train_data_copy.loc[:,&#x27;Sex&#x27;]=label.fit_transform(train_data_copy.Sex)train_data_copy.loc[:,&#x27;Embarked&#x27;]=label.fit_transform(train_data_copy.Embarked)test_data.loc[:,&#x27;Sex&#x27;]=label.fit_transform(test_data.Sex)test_data.loc[:,&#x27;Embarked&#x27;]=label.fit_transform(test_data.Embarked)## 尝试使用SVMimport numpy as npfrom sklearn.pipeline import Pipelinefrom sklearn.preprocessing import StandardScalerfrom sklearn.preprocessing import PolynomialFeaturesfrom sklearn.svm import LinearSVCp_s_c=Pipeline([ (&#x27;poly_features&#x27;,PolynomialFeatures(degree=3)), (&#x27;scaler&#x27;,StandardScaler()), (&#x27;svm_clf&#x27;,LinearSVC(C=10,loss=&#x27;hinge&#x27;))])p_s_c.fit(train_data_copy.loc[:,(&#x27;Pclass&#x27;,&#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;,&#x27;Fare&#x27;,&#x27;Embarked&#x27;)],train_data_copy.iloc[:,-1])from sklearn.metrics import accuracy_scoreresult=p_s_c.predict(test_data.loc[:,(&#x27;Pclass&#x27;,&#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;,&#x27;Fare&#x27;,&#x27;Embarked&#x27;)])submisstion=pd.DataFrame(&#123; &#x27;PassengerId&#x27;:test_data[&#x27;PassengerId&#x27;], &#x27;Survived&#x27;:result&#125;)submisstion.to_csv(&#x27;submission.csv&#x27;,index=False)","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"基于Django的个人博客网站设计","slug":"基于Django的个人博客网站设计","date":"2022-03-04T07:04:54.000Z","updated":"2022-10-17T08:18:08.951Z","comments":true,"path":"posts/237951b2.html","link":"","permalink":"https://blog.tjdata.site/posts/237951b2.html","excerpt":"文本希望根据Django作为框架，前端利用Vue来实现个人博客网站的开发 作为一个外行人看专门的Django的书本会被一些基础知识所拖累，比如HTML中的一些基本概念，然而抛去细节，用自己的方式来完成一个比较难的（难度不会特别高，但是又会比官方教程学习）的多一些，这可能是本教程的意义在此","text":"文本希望根据Django作为框架，前端利用Vue来实现个人博客网站的开发 作为一个外行人看专门的Django的书本会被一些基础知识所拖累，比如HTML中的一些基本概念，然而抛去细节，用自己的方式来完成一个比较难的（难度不会特别高，但是又会比官方教程学习）的多一些，这可能是本教程的意义在此 0x00 基础知识 网站上是后端服务器生成视频、文字、图片、数字等等数据，通过HTTPS或者各种网络通信协议来传递到前端浏览器中进行显示（B-S框架），这涉及三个方面： 服务端（server）需要什么逻辑处理程序语言？需要什么数据存储语言？ 之间通信如何安排？ 前端显示的格式是什么？ 幸运的是，这里我们有一套标准，前端显示是HTML（html+css+js），在此基础上有也有一些框架如Vue、React来讲一些漂亮的格式固定化方便调用，通信中Django作为框架已经处理好了，所以我们用它就ok了！，服务端逻辑处理程序语言中python、C、Java等等都可以，重要的是要处理逻辑，这里使用python就好，数据管理可以使用MySQL 其中再拿出Django单独说，它不仅仅服务于网络通信，也可以帮助后台网站模版的组织、帮助利用python语言来控制服务库，同时将前后端开发中复杂的文件关系使用MVC模式 model：处理与数据相关的业务（人话：可以用python语言来增删改查mysql，所以不用学mysql具体语句） template：处理与表现相关的决定（也就是前端的网页是如何显示的） view：存取模型及调用恰当模版的相关逻辑（也就是程序的本质，比如前端点击一个按钮，后端需要运算一段程序，来返回结果，这就是需要的工作） 在此基础上，我们希望搭建自己的个人博客系统，主要参考别人的文章，分析个人博客的逻辑其实比较简单： 服务端存储博客的原始数据、前端中显示博客页面，使用view来实现一些功能，使用template来实现原始博客的美观并在前端生成，利用model来保存博客数据 在一个博客应用中，需要创建的逻辑包括 博客首页、用来展示最近的几项内容 内容详情页，用来详细展示某项内容 评论处理器用来响应为一项内容添加评论的操作 无论做什么，都需要在coding之前认清楚自己想做什么，当然跟着别人的教程做不用考虑这些 开发环境：python3.7+Django 2.2（centOS），利用conda安装环节 conda create -n djangoblog python=3.7 // 用来生成python的环节，-n后面代表是djangoblog名称，后续从大 activate djangoblog就行了 conda acticate djangoblog Pip install django==2.2 本文借鉴了很多网上的教程，若侵删 Django搭建个人博客-杜塞 廖雪峰个人网站 菜鸟教程 W3School Django文档 0x01 使用Django 1.1 创建APP // cd到对应的目录，并激活对应的conda django-admin startproject my_blog 由此创建的网站文件夹(由于是Linux系统没有db.sqlite3,奇怪) 之后 cd my_blog python manage.py runserver 0.0.0.0:80 // 后面是设置ip地址和域名，当然可以不设置 然后创建APP，在Django中每个app代表一个功能模块，开发者可以将不同功能的模块放到不同的app中，方便代码的复用，app就是项目的基石，因此开发博客的第一步就是创建新的app python manage.py startapp article 每个文件夹的简单功能； /my_blog/db.sqllite3 是轻量级的数据库文件；/my_blog/manage.py 是项目执行文件的入口 /my_blog/article 是 刚创建的app，用来防治博客文章相关的代码，后台管理文件admin、数据模型文件models、视图文件view、存放数据迁移文件migrations /my_blog/my_blog 其中setting.py包含项目的配置参数，urls.py 包含项目的根路由文件 新建app需要做的简单的事情 注册app 在setting里面添加就行 修改项目的中的urls.py，这里将根路由转发到app的路由（这里转发到article的urls）这里的路由配置比较复杂，后续需要深入了解 来看path中相关的参数 article/ 表示app的访问路径 include 将路径分发到下一步处理 namespace 保证反查到唯一的url 修改app中的urls 12345678from django.urls import path# 正在部署的应用的名称app_name = &#x27;article&#x27;urlpatterns = [ # 目前还没有urls] 这里暂时还是空的 1.2 创建model 数据库的基本概念，数据库是存储电子文件的场所，存储单独的数据集合，一个数据库由多个数据表构成，在数据库中通常使用标准的SQL语句来进行增删改查，这里是一个新的内容，在面对新的内容总会出现一定的困难，因此： Django使用对象关系映射（object relational mapping，ORM）来实现面向对象编程语言中不同类型系统的数据之间的转换 意味着不要学习如何使用SQL，学会如何配置models.py就行 对于博客后台的数据库中，我们设想如何描述文章这个对象“ 需要有文章作者author、需要有文章标题title、需要有文章正文body、需要有文章的创建时间created、需要有文章更新时间update，这里的数据类型由Django自己定义，这里每个模型都被表示为Django.db.models.Model的类，需要用法可以直接去查 Django本身具有一个简单的user账号系统，因此这里定义foreignkey可以包含与外部的环境 12345678910111213141516171819202122232425262728293031323334# Create your models here.from django.db import models# 导入内建的User模型。from django.contrib.auth.models import User# timezone 用于处理时间相关事务。from django.utils import timezone# 博客文章数据模型class ArticlePost(models.Model): # 文章作者。参数 on_delete 用于指定数据删除的方式 author = models.ForeignKey(User, on_delete=models.CASCADE) # 文章标题。models.CharField 为字符串字段，用于保存较短的字符串，比如标题 title = models.CharField(max_length=100) # 文章正文。保存大量文本使用 TextField body = models.TextField() # 文章创建时间。参数 default=timezone.now 指定其在创建数据时将默认写入当前的时间 created = models.DateTimeField(default=timezone.now) # 文章更新时间。参数 auto_now=True 指定每次数据更新时自动写入当前时间 updated = models.DateTimeField(auto_now=True) # 内部类 class Meta 用于给 model 定义元数据 class Meta: # ordering 指定模型返回的数据的排列顺序 # &#x27;-created&#x27; 表明数据应该以倒序排列 ordering = (&#x27;-created&#x27;,) # 函数 __str__ 定义当调用对象的 str() 方法时的返回值内容 def __str__(self): # return self.title 将文章标题返回 return self.title ForeignKey： 数据库中多种多样的数据表，有时候数据表的数据是相互关联的，因此这两张表之间就产生了关系，外健就是用来表示这种关系的，（本文中user由Django自己生成），当然也有一对多onetoonefield、多对多manytomanyfield 内部类: 内部类class-meta提供模型的元数据，任何不是字段的东西，比如ordering、数据库名称、单数和复数名称 创建数据库之后需要数据迁移，迁移时Django模型所做的更改传递到数据库中的方式，Django的前一代码时由模型文件自动生成，本质上是一个历史记录，可以勇气可嘉进行数据库的滚动更新，通过这种方式使其能够和当前的模型匹配 1python manage.py makemigrations 1.3 编写view Django中试图的概念是一类具有相同功能和模版的网页的集合，通常需要使用通过view来处理前端的请求，在数据库中增删改查来返回给前端显示，写好一个view函数后，还需要配置路由来讲用户请求和视图链接起来 demo 在article/view.py 123456# 导入 HttpResponse 模块from django.http import HttpResponse# 视图函数def article_list(request): return HttpResponse(&quot;Hello World!&quot;) 之后配置路由URL 12345678910from django.urls import pathfrom . import views# 正在部署的应用的名称app_name = &#x27;article&#x27;urlpatterns = [ # path函数将url映射到视图 path(&#x27;article-list/&#x27;, views.article_list, name=&#x27;article_list&#x27;),] 在浏览器输入 1http://101.43.56.17/article/article-list/ view和model之间的连接 Model中虽然定义了数据表，但是这个表是空的，不方便展示view调取数据的效果，因此需要向数据表中记录一些数据 创建管理员账号superuser 1python manage.py createsuperuser 将articlepost（之前数据表）注册到后台 在admin.py中 12345678from django.contrib import admin# Register your models here.# 别忘了导入ArticlerPostfrom .models import ArticlePost# 注册ArticlePost到admin中admin.site.register(ArticlePost) 这样就可以在后台自己上传文章啦（如何支持markdown语法？？） 利用view 上述我们可以增加model中的数据，后续需要增加将数据库的数据显示在前端是view的工作，如何美观的现实是template的事情 在article/views.py内 12345678910111213141516from django.shortcuts import render# Create your views here.from django.http import HttpResponse# 导入数据模型ArticlePostfrom .models import ArticlePost# 视图函数def article_list(request): # 取出所有博客文章 articles = ArticlePost.objects.all() # 需要传递给模板（templates）的对象 context = &#123; &#x27;articles&#x27;: articles &#125; # render函数：载入模板，并返回context对象 return render(request, &#x27;article/list.html&#x27;, context) 之后配置模版存放的路径，在setting文件夹内 12345678910111213141516// 55行TEMPLATES = [ &#123; &#x27;BACKEND&#x27;: &#x27;django.template.backends.django.DjangoTemplates&#x27;, &#x27;DIRS&#x27;: [os.path.join(BASE_DIR, &#x27;templates&#x27;)], &#x27;APP_DIRS&#x27;: True, &#x27;OPTIONS&#x27;: &#123; &#x27;context_processors&#x27;: [ &#x27;django.template.context_processors.debug&#x27;, &#x27;django.template.context_processors.request&#x27;, &#x27;django.contrib.auth.context_processors.auth&#x27;, &#x27;django.contrib.messages.context_processors.messages&#x27;, ], &#125;, &#125;,] 之后在模版中list.html中加入 123&#123;% for article in articles %&#125; &lt;p&gt;&#123;&#123; article.title &#125;&#125;&lt;/p&gt;&#123;% endfor %&#125; 这样就可以查看到生成了最新的模版 阶段总结 在上述走过了Django的model数据库的建立和admin管理、view函数对前端的请求响应、templates中关于模版的使用，完整的学习了Django的MVT模式，在之后还需要改进的地方有： 数据层面，数据库的建立。整个数据库系统中多个表格的使用，model建立过程中关键字的定义，变量类型的定义 view中数据逻辑，如果是个人博客系统需要考虑到网站整体的需求，然后在view函数中进行解析，需要设计具体的功能和具体功能的流程，最后反映到编程之中，比如页面的排名、页面的详细信息、页面的浏览等等 模版和网页前端的交互，模版中规定了基础的Django数据的传输方式，还有网页中通常使用的Ajax通信来传递相关信息，以及如何使用脚手架来使得前端页面更加好看，利用HTML中特殊属性来添加元素、利用CSS来规定元素的格式、利用JS来设置页面的动态效果 整体管理，包括路由配置、包括实际部署、包括变量的管理等等","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"Django","slug":"Django","permalink":"https://blog.tjdata.site/tags/Django/"}]},{"title":"CS229-06---机器学习的实验设计","slug":"CS229-06---机器学习的实验设计","date":"2022-02-25T09:13:08.000Z","updated":"2023-05-13T13:47:30.890Z","comments":true,"path":"posts/39e00dd8.html","link":"","permalink":"https://blog.tjdata.site/posts/39e00dd8.html","excerpt":"非常喜欢《机器学习导论》中关于感知器的一句话：“神经网络的目的不是为了研究人脑的内部结构和运行机理，而仅仅是模仿来作为一个学习罢了”，通过这句话可以看出机器学习作为一门工程类的学科，本质目的还是为了寻找一种好的方法，在此过程中就要思考需要用什么样的标准来评价好坏？这是一个曾经观察高中物理、高中化学、高中生物中的实验科学，更进一步，我们更有着统计的知识来指导我们更近一步地正确设计实验。","text":"非常喜欢《机器学习导论》中关于感知器的一句话：“神经网络的目的不是为了研究人脑的内部结构和运行机理，而仅仅是模仿来作为一个学习罢了”，通过这句话可以看出机器学习作为一门工程类的学科，本质目的还是为了寻找一种好的方法，在此过程中就要思考需要用什么样的标准来评价好坏？这是一个曾经观察高中物理、高中化学、高中生物中的实验科学，更进一步，我们更有着统计的知识来指导我们更近一步地正确设计实验。 0x01 引言 机器学习中，实现一个目标中可以有很多中不同的学习算法，来么： 如何评估一个学习算法在给定问题上的期望误差？ 对于同一个目标的不同学习算法，我们如何证明一个算法比另外一个算法误差更低？ 我们不能只看训练集上的误差来作为判断，因为具有更复杂度的模型的误差总是比简单模型小 同样在不同与训练及的验证集中一轮运行也不够，因为可能会有噪声和离群点的影响，同样具有超参数的算法的泛化过程中会有这其他的随机因素。我们通过运行learning algorithm来得到一个leaner；如果我们只训练一次只得到一个leaner和一个validation error，为了平均各种随机性，我们需要产生多种leaner，进而在多个验证集上评估，我们对learning algorithm的评估是应该是基于这些validation error的distribution来的，通过评估expected error或者是variance来进行比较。 总结上述，可以看出我们的目标是规划和设计机器学习实验，来分析实验产生的数据，以便能够排除随机性的影响，得到统计显著的结论，在机器学习中，我们的目标是得到具有最高的泛化准确率、最小复杂度的学习器，并且该学习器是robust 我们在实验设计中需要设计的3项基本原则： randomization随机化，要求实验运行的次序应该是随机确定的，这样使得结果是独立的 replication重复，因为这应该对可控因素的相同配置多次实验，以便平均不可控因素的影响，通常在相同数据集上再抽样的版本上叫做交叉验证（cross- validation） blocking阻止，用来降低或消除有害因素导致的可变性，准确率的差异不仅取决于不同的算法还取决于不同的子集，因此为了度量仅由算法导致的差别，重复运行的不同训练集应该是相同的，在统计中常有配对检验（pairing test） 0x02 实验设计的基本策略 strategy of experimentation 这里感觉更多是关于如何调参的选择，如何设计对比出不同算法优劣，比如消融实验之类的还是依靠实践 最佳猜测 best- guess 从某个我们相信是好配置的因素设置开始，在此检验响应之前，每次稍微改动一个或者少量因素，来检验每个组合指导得到一个足够好的状态 一次一个因素 one factor at a tiem 我们为每个因素确定一个基线的抹额认知，然后对一个因素尝试不同水平而令其他因素保持在极限上，这种方法的缺点是假设因素之间不相互影响 因素设计 factorial design 通常也被称为网格搜索grid search，其中因素一起变化而不是单因素变化 响应面设计 response surface design 通过设计合理的有限次数试验，建立一个包括各显著因素的一次项、平方项和任何两个因素之间的一级交互作用项的数学模型，精确研究各因素与响应值之间的关系，快速确定多因素系统的最佳条件，常用具体方法有：中心复合试验设计（central composite design CCD）和Box-Behnken试验设计（DDB） 0x03 模型选择–重复样本 hold-out 通常对获得数据集之后，会将其划分出来一部分不会使用的test set；在训练过程中的会用到的有train set和validation set 通常train set和validation set之间的比例可以为10或者30，但是不幸的是样本通常没有这么多，因此我们应该在小数据集上尽力而为，其方法是以不同划分来重复使用它，这种称为交叉验证cross- validation，但是潜在的问题有交叉验证使得错误率是相互依赖的，因为这些不同集合共享数据 在重复爱漾中要尽可能的保持分层stratification，我们希望保证误差估计的鲁棒性，同时要保持不同集合间的重叠尽可能的小，还不能扰乱类的先验概率 3.1 K- fold CV 将训练的书籍划分为K等分，将K份数据集中的一份划分为验证集，其他作为验证集，在较为极端的医疗中可能会有leave-one-out 3.2 5x2 CV 很神奇而让人不想去了解 3.3 bootstrapping（自助法） 采用从原始样本中以有放回地抽取实例的方法来产生新的样本，自助样本可能比交叉验证有更多的重叠，因而其估计可能更相互依赖 （1-\\frac{1}{N})^N=1/e=0.368 意味训练集中包含63.2%的实例，将原始数据集作为验证集 0x04 模型选择–性能度量 4.1 分类 二分类的混淆矩阵confusion matrix 预测positive 预测negative 正例positive TP FN 负例negative FP TN 误差：(FP+FN)/N\\\\ 准确率：(TP+TN)/N\\\\ 精度：TP/（TP+FP）\\\\ 召回率：TP/（TP+FN）\\\\ 灵敏度：召回率\\\\ 特效性：TN/fp+tn\\\\ tp-rate:tp/p\\\\ fp-rate=fp/(tn+fp) 关于假正和假负，例如一个用户希望登陆另外一个用户的账户，假正是允许顶替，假负是正常用户登陆不了，显然前者危害会更高 tp-rate：衡量通过身份认证合法用户的比例 FP-rate：错误接受顶替的比例 （tp-rate，fp-rate）得到ROC（receiver operating characteristic），该曲线下面的（area under the curve AUC）可以来比较不同损失条件下平均的整体性能 可以参考科技文献检索中的查全率和查准率 class confusion matrix 4.2 回归 mean square error RMSE之类的 0x05 模型选择 – 结果可靠性（看不懂，统计功底不够） 5.1 区间估计 interval estimation 《概率论》 5.2 假设检验 hypothesis testing 《概率论和数理统计》 5.3 结合评估性能 一下用于对分类问题中的错误率进行分析，同样可以适用于回归的就放误差、非监督学习的对数似然、增强学习的期望奖励等 单个学习器的错误率衡量 二项检验 近似正态检验 t检验（K-fold） 比较两个分类算法错误率 McNemar检验 K折+t检验 比较多个分类的错误率同时分析方差 在多个数据集上比较多个算法的错误率 比较多个算法的不同指标","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"Experiment","slug":"Experiment","permalink":"https://blog.tjdata.site/tags/Experiment/"}]},{"title":"CS229-03--决策树CART","slug":"CS229-03--决策树CART","date":"2022-02-20T14:37:46.000Z","updated":"2023-05-13T13:47:21.454Z","comments":true,"path":"posts/a32aa49a.html","link":"","permalink":"https://blog.tjdata.site/posts/a32aa49a.html","excerpt":"决策树可以看作是一个基学习器，同样在这个例子中需要了解到相关机器学习中相关基本概念、模型评估和选择的过程中才能更好的继续下去，因为本人觉得ML在除了统计理论推导之外，实验的设计与验证也是非常重要 同样在CART的基础上，结合集成学习：Bagging、Boosting等可以更加优化决策树的性能进而推出更好的模型，但是最基本的东西还是来源于决策树的流程，本文将介绍决策树的基本流程以及代码实现","text":"决策树可以看作是一个基学习器，同样在这个例子中需要了解到相关机器学习中相关基本概念、模型评估和选择的过程中才能更好的继续下去，因为本人觉得ML在除了统计理论推导之外，实验的设计与验证也是非常重要 同样在CART的基础上，结合集成学习：Bagging、Boosting等可以更加优化决策树的性能进而推出更好的模型，但是最基本的东西还是来源于决策树的流程，本文将介绍决策树的基本流程以及代码实现 0x01 决策树（Decision tree）的基本流程 介绍 决策树是一种实现分治策略的层次数据结构，是一种有效的非参数方法，可以用于分类与回归 关于分治法，divide and conquer Divide the problem into a number of subproblems that are smaller instances of the same problem Conquer the subproblems by solving them recurisvely. If the problem sizes are small enough, however,just solve the subproblems in a straightforward manner. Combine the solutions to the subpoblems into the solution for the original problem (1)对于一个规模为N 的问题，若该问题可以容易地解决，则直接解决,否则执行下面的步骤。 (2)将该问题分解成若干个规模较小的子问题，这些子问题互相独立，并且原问题形式相同。 (3)递归recursively地解子问题。 (4)然后，将各子问题的解合并得到原问题的解 对于参数估计，我们定义整个输入空间上的模型，并使用所有的训练数据学习它的参数，然后对于任意的检验输入使用相同的模型和参数 对于非参数估计，我们将输入空间划分为利用欧几里得范数这样定义的距离度量的局部模型，并对每个输入使用由该区域的训练数据计算得到的对应的局部模型中，在非参数模型汇总给定一个输入，识别定义局部模型的局部数据的开销很大，需要计算从给定的输入到所有训练实例的距离。 决策树是一种用于监督学习的层次模型，局部区域通过少数几步递归分类确定，决策树又一些内部决策节点和终端树叶组成，每个决策节点decision node实现一个具有离散输出的测试函数，由此到达一定条件后形成一个树叶节点leaf node，形成最终的值并输出。 在决策树的实现当中，可以从单个输入变量的单变量树开始（考虑如何使用分类或者回归的方式构造这样的树），之后将这种树推广到所有输入的多变量树的内部节点 参考西瓜书中的算法为代码： 将决策树生成的整个过程分解，本质上是从父节点向下分解的过程，在其中回出现三种情况： 划分前，父节点全部属于一类； 划分中，父节点样本中特征结合为空集或者所有取值相同 划分后，有一个分支为空集，则与另外一个分支合并，将其类别标记为样本最多的类 在正常划分中，区分分类情况和回归情况（即离散值和连续值的划分方法） 单变量分类（classfication）情况 在分类树 classfication tree中，划分的优劣用不纯度度量（impurity measure）分析： 如果对于所有分支，划分后选择相同分支的所有实例都属于相同的类，对于节点m，令N_m为到达节点m的训练实例\\\\数，N_m个实例中N_m^i都属于C_i类，则对于一个实例x到达节点m，属于C_i类的概率估计为\\\\ \\bar p(C_i|X,m)=N_m^i/N_m\\\\ （def）节点m是纯的，如果对于所有的i，p_m^i为0或1，当到达节点m的所有实例都不属于C类时，p_m^i为0，\\\\而当所有节点到达m的所有实例都属于C_i类时候，为1\\\\ 在不纯性度量划分的依据中，需要满足一下基本的性质且需要大于0 1. 对于任意p\\in [0,1],\\phi(1/2,1/2)>=\\phi(p,1-p)\\\\ 2.\\phi(0,1)=\\phi(1,0)=0\\\\ 3. 在[0,1/2]上\\phi(p,1-p)是递增的，当p在[1/2，1]上\\phi(p,1-p)是递减的 例如常见的不纯性度量函数包括： 信息熵 Information Entropy Gain=Gain（DataSet_{parent}）-\\Sigma N(sub)/N(Dataset_{parent})*Gain(SubDataSet) 增益率 Gain ratio: 降低分支过多带来的影响，相当于加了一层罚函数在分母 Gain_{ratio}=Gain(DataSet_{parent})/IV(a)\\\\ IV(a)=-\\Sigma|D^v|/|D|*log_2|D^v|/|D| \\ ~ 是该属性的固有值 基尼指数 gini index 误分类函数 等等 单变量回归(regression)情况 回归树可以使用几乎与分类书完全相同的方法构造，唯一不同是适合分类的不纯性度量用适合回归的不纯性度量取代，相比较回归分析之前的差别可能是： 节点的分类不按照特征集中的类别直接分类，而是按照均值或者中值（noise大的时候用中值） 节点的不纯度量利用均方误差或者最大误差来实现，当误差小于设定threshold时生成树叶，否则继续分类 threshold的设置中，可以使用复杂度函数来设置，值越小产生的树会越大导致过拟合分线越大，这里同样引入惩罚的概念 同样的，不利用均值或者中值，可以使用线性回归拟合选定树叶上的实例，但是这样计算开销会比较大 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134from math import logimport operatorimport numpy as npclass decisionTree(): def dataLoader(self,filename): dataSet = []; labels = [] i=1 fr = open(filename) for line in fr.readlines(): # 逐行读取，滤除空格等 lineArr = line.strip().split(&#x27;,&#x27;) if i==1: labels=lineArr[1:(len(lineArr)-1)] i=i+1 else: dataSet.append(lineArr[1:]) return dataSet,labels def createExampleDataset(self): &#x27;&#x27;&#x27; 返回示例数据，包括dataset、labels &#x27;&#x27;&#x27; dataSet = [[&#x27;白&#x27;, &#x27;高&#x27;, &#x27;男&#x27;], [&#x27;黑&#x27;, &#x27;高&#x27;, &#x27;男&#x27;], [&#x27;白&#x27;, &#x27;高&#x27;, &#x27;男&#x27;], [&#x27;黑&#x27;, &#x27;低&#x27;, &#x27;女&#x27;], [&#x27;黑&#x27;, &#x27;低&#x27;, &#x27;女&#x27;], [&#x27;黑&#x27;, &#x27;高&#x27;, &#x27;女&#x27;], [&#x27;白&#x27;, &#x27;低&#x27;, &#x27;女&#x27;], [&#x27;黑&#x27;, &#x27;高&#x27;, &#x27;女&#x27;]] labels = [&#x27;颜色&#x27;, &#x27;身高&#x27;] # 两个特征 return dataSet, labels def calcCrossEntropy(self, dataSet): &#x27;&#x27;&#x27; 计算数据集合中的数据熵 return crossEntropy &#x27;&#x27;&#x27; classList = [example[-1] for example in dataSet] unique,counts=np.unique(classList,return_counts=True) crossEntropy=0 for count in counts: crossEntropy+=-float(count/len(classList))*log(float(count/len(classList)),2) return crossEntropy def chooseBestFeature(self, dataSet): &#x27;&#x27;&#x27; 从不同特征中选择交叉熵差值最低的作为分离特征 return bestFeature下标 &#x27;&#x27;&#x27; bestInfoGain=-1 baseCrossEntropy=self.calcCrossEntropy(dataSet) numFeature=len(dataSet[0])-1 for i in range(numFeature): # 根据不同特征分开，并重新计算根据每个特征得到的交叉熵的和 featureList=set([example[i] for example in dataSet]) newCrossEntropy=0 for value in featureList: subDataSet=self.splitDataSet(dataSet,i,value) newCrossEntropy+=len(subDataSet)/len(dataSet)*self.calcCrossEntropy(subDataSet) infoGain=baseCrossEntropy-newCrossEntropy if infoGain&gt;bestInfoGain: bestInfoGain=infoGain bestFeature=i return bestFeature def splitDataSet(self, dataSet, index,value): &#x27;&#x27;&#x27; 根据最佳的特征分离数据集，形成新的子集 &#x27;&#x27;&#x27; subDataSet=[] for example in dataSet: if example[index]==value: temp=example[:index] temp.extend(example[index+1:]) subDataSet.append(temp) return subDataSet def ifNodeFeatureIsSame(self,dataSet): featureMat = [example[:(len(dataSet[0])-1)] for example in dataSet] uniqueFeatureMat=np.unique(featureMat) if len(uniqueFeatureMat) == 1: return True else: return False def majorityCount(self,classList): className,counts=np.unique(np.array(classList)) return className[np.argmax(counts)] def createTree(self,dataSet,labels): # 生成结点node classList=[example[-1] for example in dataSet] # 情况1：当前分支中全部都为同一个属性不需要分类 # 情况2：当前分支为1集合不需要分类 # 情况3：最优化划分 if classList.count(classList[0])==len(classList): return classList[0] if len(labels)==0 or self.ifNodeFeatureIsSame(dataSet): return self.majorityCount(classList) bestFeature=self.chooseBestFeature(dataSet) bestFeatureLabel=labels[bestFeature] myTree=&#123;bestFeatureLabel:&#123;&#125;&#125; #删除区分的属性 del(labels[bestFeature]) featureValues=[example[bestFeature] for example in dataSet] uniqueValues=set(featureValues) for value in uniqueValues: sublabels=labels[:] myTree[bestFeatureLabel][value]= \\ self.createTree(self.splitDataSet(dataSet, bestFeature, value), sublabels) return myTreeif __name__==&#x27;__main__&#x27;: newTree=decisionTree() filename=&#x27;datasets/watermelon.txt&#x27; dataSet,labels=newTree.dataLoader(filename) #或者直接根据例子来 #dataSet,labels=newTree.createExampleDataset() print(newTree.createTree(dataSet,labels)) txt文件 123456789101112131415161718编号,色泽,根蒂,敲声,纹理,脐部,触感,好瓜1,青绿,蜷缩,浊响,清晰,凹陷,硬滑,是2,乌黑,蜷缩,沉闷,清晰,凹陷,硬滑,是3,乌黑,蜷缩,浊响,清晰,凹陷,硬滑,是4,青绿,蜷缩,沉闷,清晰,凹陷,硬滑,是5,浅白,蜷缩,浊响,清晰,凹陷,硬滑,是6,青绿,稍蜷,浊响,清晰,稍凹,软粘,是7,乌黑,稍蜷,浊响,稍糊,稍凹,软粘,是8,乌黑,稍蜷,浊响,清晰,稍凹,硬滑,是9,乌黑,稍蜷,沉闷,稍糊,稍凹,硬滑,否10,青绿,硬挺,清脆,清晰,平坦,软粘,否11,浅白,硬挺,清脆,模糊,平坦,硬滑,否12,浅白,蜷缩,浊响,模糊,平坦,软粘,否13,青绿,稍蜷,浊响,稍糊,凹陷,硬滑,否14,浅白,稍蜷,沉闷,稍糊,凹陷,硬滑,否15,乌黑,稍蜷,浊响,清晰,稍凹,软粘,否16,浅白,蜷缩,浊响,模糊,平坦,硬滑,否17,青绿,蜷缩,沉闷,稍糊,稍凹,硬滑,否 0x02 剪枝处理 先剪枝（prepruning）：基于过少实例决策树导致较大方差，进而导致较大的泛化误差，eg：在到达一个节点的训练实例树小于训练集的某个百分比（5%），则无论是否不纯或者有错误都不近一步分裂 后剪枝（postpruning）：回溯其他的选择（留个坑，回溯法还没看），我们让树完全增长知道所有的树叶都是纯的并具有零训练误差，然后找出导致过分拟合的子树并剪掉。eg：我们从最初的被标记的数据集中保留一个剪枝集，在训练阶段不适用，对于每颗子树，我们用一个被该子树覆盖的训练实例标记的树叶节点替代它，如果该树叶在剪枝集合上的性能不必该子树茶，则剪掉该子树并保留树叶节点可因为子树的附加的复杂性是不必要的 0x03 连续与缺失值处理 暂时不重要 0x04 额外的东西 集成学习（ ensemble learning）：利用弱学习器组合来形成一个强的学习器，包括bagging、stacking、boosting 由bagging得到的随机森林（random forest）、由boosting得到的GBDT（gradient boosting decision tree）并XGBOOST和lightGBM","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"CS229-05-参数方法和非参数方法","slug":"CS229-05--参数方法和非参数方法","date":"2022-02-13T09:23:12.000Z","updated":"2023-05-13T13:47:27.764Z","comments":true,"path":"posts/f3d9a90.html","link":"","permalink":"https://blog.tjdata.site/posts/f3d9a90.html","excerpt":"在初步了解了线性模型之后，总结一下算法的一些规则 （材料来自网络，可能会侵权）","text":"在初步了解了线性模型之后，总结一下算法的一些规则 （材料来自网络，可能会侵权） 0X00 引言 （实验讨论如何在使用概率对不确定性建模，留个坑之后再说，如何作出最优决策）现在考虑如何从给定的训练集中估计这些概率，从分类和回归的参数方法开始 参数方法，这里假设样本取自服从已知模型的某个分布（eg.高斯分布），模型定义在有效统计量（eg. 方差和均值），一旦从样本中估计参数就知道了整个分布，方法主要分为最大似然估计（maximum likelihood estimation）、贝叶斯估计（Bayes‘ estimator）等 参数方法的优点：将估计概率密度、判别式或者回归函数问题归结成为少量参数值 参数方法的缺点：假设并不是总是整理的，并且不成立会导致较大的误差 非参数方法（nonparametric estimation）：算法使用合适的距离度量，从训练集中找出相似的实例，并且由他们插值得到正确的输出（assumption：世界是平稳的，并且无论是密度、判别式还是回归函数都能缓慢变化，相似的例子意味这相似的事物） 基本概念 密度估计（density estimation） 密度估计是估计p(x)p(x)p(x)的一般情况，在分类中，其中估计密度是能够计算后验概率P(Ci/x)P(C_i/x)P(C​i​​/x)并做决策的类密度P(x/Ci)andP(Ci)P(x/C_i) and P(C_i)P(x/C​i​​)andP(C​i​​)；在回归中，估计的密度是 :P(y∣x)P(y|x)P(y∣x) 0X01 参数方法 01-1 method—最大似然估计（MLE，maximum likelihood estimation） 已知 样本参数，多个独立同分布（i.i.d）的样本集：{xt}t=1m\\{x^t\\}_{t=1}^m{x​t​​}​t=1​m​​，同时假设样本都是某个定义在参数θ\\thetaθ的已知概率密度族中抽取的实例： xi∈p(x∣θ)x^i\\in p(x|\\theta) x​i​​∈p(x∣θ) 求 最感兴趣是找到参数θ\\thetaθ 解答： 因为每个样本是独立分布的，所以给定参数θ\\thetaθ,样本的似然likelihood是单点似然的乘积： l(θ∣X)=∏t=1Mp(xt∣θ)l(\\theta|X)=\\prod_{t=1}^Mp(x^t|\\theta) l(θ∣X)=​t=1​∏​M​​p(x​t​​∣θ) 为了简化计算，将乘积转换为求和，并且假设某种密度族（eg. 之前的exp family）进一步简化计算量 L(θ∣X)=Σt=1Mlog[p(xt∣θ)]L(\\theta|X)=\\Sigma_{t=1}^Mlog[p(x^t|\\theta)] L(θ∣X)=Σ​t=1​M​​log[p(x​t​​∣θ)] 常见的似然函数是convex的，所以直接求导就行了 ∂L(θ∣X)∂θ=0\\frac{\\partial L(\\theta|X)}{\\partial \\theta}=0 ​∂θ​​∂L(θ∣X)​​=0 eg： 关于指数族的推导 01-2 method—最大后验估计（MAP，maximum A posterior） 已知 在MLE的likelihood基础上，我们又知道了参数θ\\thetaθ的先验prior分布 p(θ)p(\\theta) p(θ) 求 在此基础上我们依旧希望得到最佳的参数θ\\thetaθ 解 根据贝叶斯规则，后验密度posterior density,告诉我们在看到样本之后θ\\thetaθ的可能取值： p(θ∣X)=p(X∣θ)p(θ)P(X)=p(X∣θ)p(θ)∫p(X∣θ)p(θ)dθp(\\theta|X)=\\frac{p(X|\\theta)p(\\theta)}{P(X)}=\\frac{p(X|\\theta)p(\\theta)}{\\int p(X|\\theta)p(\\theta)d\\theta} p(θ∣X)=​P(X)​​p(X∣θ)p(θ)​​=​∫p(X∣θ)p(θ)dθ​​p(X∣θ)p(θ)​​ 在正常情况下，知道了p(θ∣X)p(\\theta|X)p(θ∣X)，之后想要估计x则： p(x|X)=\\int p(x,\\theta|X)d \\theta\\\\=\\int p(x|\\theta,X)p(\\theta|X)d\\theta\\\\=\\int p(x|\\theta)p(\\theta|X)d \\theta 所以知道了p(θ∣X)p(\\theta|X)p(θ∣X)就知道了关于分布的一切，但是这个积分比较困难，因此为了用简便，我们希望将p(θ∣X)p(\\theta|X)p(θ∣X)看成一个常数： θMAP=argmaxθp(θ∣X)\\theta_{MAP}=argmax_{\\theta}p(\\theta|X) θ​MAP​​=argmax​θ​​p(θ∣X) 01-3 method—贝叶斯估计（Bayesian estimation） 和MAP相似，但是对于θ\\thetaθ 处理并不是最大值，而是均值 θbayes=E(θ∣X)\\theta_{bayes}=E(\\theta|X) θ​bayes​​=E(θ∣X) 01-4 example—参数估计 我们假设 x^t=N(\\theta,\\sigma^2)\\\\ \\theta=N(\\mu_0,\\sigma_0^2)\\\\ 其中\\mu_0,\\sigma_0^2,\\sigma^2已知 由此知道了 似然函数p(X∣θ)=∏i=1m1(2∗π)∗σ∗exp(−(xt−θ)22σ2)p(X|\\theta)=\\prod_{i=1}^m\\frac{1}{\\sqrt(2*\\pi)*\\sigma}*exp(-\\frac{(x^t-\\theta)^2}{2\\sigma^2})p(X∣θ)=∏​i=1​m​​​√​(​​​2∗π)∗σ​​1​​∗exp(−​2σ​2​​​​(x​t​​−θ)​2​​​​)、 先验参数p(θ)=1(2∗π)∗σ0∗exp(−(θ−μ0)22σ02)p(\\theta)=\\frac{1}{\\sqrt(2*\\pi)*\\sigma_0}*exp(-\\frac{(\\theta-\\mu_0)^2}{2\\sigma_0^2})p(θ)=​√​(​​​2∗π)∗σ​0​​​​1​​∗exp(−​2σ​0​2​​​​(θ−μ​0​​)​2​​​​) 由此得到E(θ∣X) or argmaxP(θ∣X)E(\\theta|X)\\ or\\ argmaxP(\\theta|X)E(θ∣X) or argmaxP(θ∣X) 01-5 discussion —讨论 MAP和贝叶斯估计都将整个后验密度归约到单个点且损失信息，除非后验单峰的且这些点周围有一个窄峰，但是随着计算能力的提高蛮可以使用蒙特卡洛或者近似方法来计算整个积分 （bias｜variance dilemma），常见的解决方法 交叉验证 cross-validation训练看损失函数的“拐点” 正则化regularization：E=数据上误差+a*模型复杂度 正则化另外一个角度：E=训练误差+a*偏差的乐观项，利用AIC（Akaike‘s information criterion）和BIC（Bayesian information criterion） 结构风险最小化（SRM，structural risk minimization）将模型集合按照复杂程度（随机变量的个数，或者VC维）排序一次训练 最小描述长度（minimum description length，MDL），利用信息论中的kolmogorov复杂度度量 0X02 半参数方法 待定 0X03 非参数方法 不同的非参数方法会定义不同相似性 or 或者不同的定义插值的方法，在非参数模型中不存在单个全局模型，需要时需要有局部模型只收到邻近训练实例的影响 常见的机器学习中非参数方法又被称为instance-based或者memory-based方法 03-1 密度估计 直方图估计 histogram 质朴估计 naive estimator 核估计 kernel estimator k最近邻估计 k-nearest neighbor，k-nn K-NN算法 1 计算测试对象到训练集中每个对象的距离 2 按照距离的远近排序 3 选取与当前测试对象最近的k的训练对象，作为该测试对象的邻居 4 统计这k邻居的类别频率 5 选择k个邻居中频率最高的类别，作为测试对象的类别 12345678910111213141516171819202122232425262728293031323334353637383940import matplotlib.pyplot as pltimport seaborn as snsimport numpy as npclass knn: def loadDataset(self,filename): # 借用SVM的数据集，但是这里使用numpy返回np.array数据 dataMat = []; labelMat = [] fr = open(filename) for line in fr.readlines(): # 逐行读取，滤除空格等 lineArr = line.strip().split(&#x27;\\t&#x27;) dataMat.append([float(lineArr[0]), float(lineArr[1])]) # 添加数据 labelMat.append(float(lineArr[2])) # 添加标签 dataMat=np.array(dataMat) self.dataMat=dataMat self.labelMat=labelMat def visualDataset(self): sns.scatterplot(self.dataMat[:, 0],self.dataMat[:, 1],hue=self.labelMat) plt.show() def predict(self,input,k): def distance(point): points=np.tile(point,(self.dataMat.shape[0],1)) dis=np.linalg.norm(points - self.dataMat,axis=1) return dis dis=distance(input) target=np.array(self.labelMat)[np.argsort(dis)&lt;k] if sum(target)&gt;0: return 1 else: return -1if __name__ == &#x27;__main__&#x27;: model=knn() model.loadDataset(&#x27;CS229_2018autumn/ProblemSet(课后作业）/codeByhand/datasets/testSet.txt&#x27;) model.visualDataset() example=[0,0] print(model.predict(example,6)) 03-2 分类 上次的SVM算法 优点： 解决高维特征的分类问题和回归问题很有效,在特征维度大于样本数时依然有很好的效果。 仅仅使用一部分支持向量来做超平面的决策，无需依赖全部数据。 有大量的核函数可以使用，从而可以很灵活的来解决各种非线性的分类回归问题。 样本量不是海量数据的时候，分类准确率高，泛化能力强。 缺点： 如果特征维度远远大于样本数，则SVM表现一般。 SVM在样本量非常大，核函数映射维度非常高时，计算量过大，不太适合使用。 非线性问题的核函数的选择没有通用标准，难以选择一个合适的核函数。 SVM对缺失数据敏感。","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"CS229-02--支持向量机SVM","slug":"CS229-02--支持向量机SVM","date":"2022-02-05T08:15:13.000Z","updated":"2023-05-13T13:47:15.871Z","comments":true,"path":"posts/1b530e1a.html","link":"","permalink":"https://blog.tjdata.site/posts/1b530e1a.html","excerpt":"讨论一种不同的线性分类和回归方法，每种学习算法都具有不同的归纳偏倚，做不同的假设，定义不同的目标函数，因此可能找到不同的模型 Support Vector Machine","text":"讨论一种不同的线性分类和回归方法，每种学习算法都具有不同的归纳偏倚，做不同的假设，定义不同的目标函数，因此可能找到不同的模型 Support Vector Machine 0x01 引言 支持向量机使用Vapnik原则 不要在解决实际问题之前把解决一个更复杂的问题作为第一步（vapnik，1995） 训练后，线性模型的参数（权重向量）可以用训练集的一个子集表示，这个子集称为支持向量support vector。对于分类这些是靠近边界的实例，因此知道它们可以提取知识：这些事两个类之间的边界附近、不确定或有错误的实例，它们的个数给我们提供了范化误差的一个估计，并且正如我们将在下面看到的，能够用实例集表示模型参数进行核化 其总体框架：是一种分类算法，主要应用于二分类算法，通过定位两类数据在集合空间中的margin，来确定分类起，主要步骤分为： （建立模型）将二分类问题转换成为一个优化问题 （求解模型）利用SMO算法、拉格朗日对偶、KKT条件来求解简化优化问题 （分类讨论）之后利用松弛变量、核函数、惩罚因子等对不同情况下的优化问题进行求解 它的优点和缺点是什么？ 优点：参数非常少，不像logistic regression还具有超参数，虽然比神经网络效果差，但是很简单 缺点： 0x02 建立模型 符号说明（notation） input: X=(x_1,...,x_n)\\\\ labels：y \\in \\{-1,1\\}\\\\ hyperplane:\\omega^T*X+b(等价于之前的\\theta^T*X)\\\\ g(Z)= \\begin {cases}1 \\ if\\ Z>=0\\\\ -1\\ if\\ otherwise \\end{cases} 数据集和超平面的距离 定义边缘（margin） geo- margin 从单个实例来看，就是向量到一个平面的距离，根据向量的推导知识可以看出： geomargini=y(i)∗(ωTXi+b)geo_{margin}^{i}=y^{(i)}*(\\omega^TX^i+b) geo​margin​i​​=y​(i)​​∗(ω​T​​X​i​​+b) 从整个数据集来看，就是一群点到一个平面中距离的最小值，定义为 geomargin=mini=1mgeomarginigeo_{margin}=min_{i=1}^m geo_{margin}^i geo​margin​​=min​i=1​m​​geo​margin​i​​ fun- margin 上述的几何边缘的定义中，最终出现的结果可能会出现结果会随着不同的w的取值而出现不同的情况，因此需要从归一化的角度来更新边缘 funmargin(i)=y(i)∗(ωTX(i)+b)∣∣w∣∣fun_{margin}^{(i)}=\\frac{y^{(i)}*(\\omega^TX^{(i)}+b)}{||w||} fun​margin​(i)​​=​∣∣w∣∣​​y​(i)​​∗(ω​T​​X​(i)​​+b)​​ 同样定义数据集的fun margin funmargin=mini=1m funmarginifun_{margin}=min_{i=1}^m\\ fun_{margin}^{i} fun​margin​​=min​i=1​m​​ fun​margin​i​​ 得到模型（model） 最直观的，我们希望所有点的margin可以都以大于零，在这个约束的基础上，数据集的margin可以越大越好 target:max[min_{i=1}^m y^{(i)}*(\\omega^TX^i+b)]\\\\ s.t.:y^{(i)}*(\\omega^TX^i+b)>=0\\\\ ||w||=1 在上述直觉的基础上，需要对模型进行进一步的调整 我们希望所有的margin都可以大于零，也可以说是希望所有的margin都大于最小margin（目标函数）的值 max\\ \\hat\\gamma\\\\ s.t.:y^{(i)}(w^Tx^{(i)}+b)>=\\hat\\gamma\\\\ ||w||=1 可以将||w||=1的假设调整到目标函数上 max\\ \\hat\\gamma/||w||\\\\ s.t.:y^{(i)}(w^Tx^{(i)}+b)>=\\hat\\gamma 同样的跟进一步，我们假设之间的距离为1 γ^=1\\hat \\gamma=1 ​γ​^​​=1 那么模型等价于 max\\ \\frac{1}{||w||}\\\\ s.t.:y^{(i)}(w^Tx^{(i)}+b)>=\\hat\\gamma 为了方便后续计算 min12∣∣w∣∣2min \\frac{1}{2}||w||^2 min​2​​1​​∣∣w∣∣​2​​ 由此转换为一个凸优化问题 min \\frac{1}{2}||w||^2\\\\ s.t.:1-y^{(i)}(w^Tx^{(i)}+b)=0 之后利用SMO算法来求解得到 aia_i a​i​​ 之后得到hyperplane为： Σ(aiy(i)xiTxj+b)\\Sigma (a_iy^{(i)}x_i^Tx_j+b) Σ(a​i​​y​(i)​​x​i​T​​x​j​​+b) 0x04 分类讨论 在线性可分的情况下可以顺利的求解出 a_i 加入松弛变量和惩罚因子来找到相对更好的hyperplane 使用kernel trick来将低维映射到高纬的空间，使得在高纬空间中数据是线性可分的 详细介绍kernel trick： 本来是在低维中直接内积 xiTxjx_i^Tx_j x​i​T​​x​j​​ 之后希望都从地维转换到高纬，在计算内积 ϕ(xi)Tϕ(xj)\\phi(x_i)^T\\phi(x_j) ϕ(x​i​​)​T​​ϕ(x​j​​) 跟进一步，希望直接在低维空间计算高维内积 线性核：x_i^Tx_j\\\\ 多项式核：（x_i^Tx_j+1）^q\\\\ 高斯核：exp(-\\frac{(||x_i-x_j||^2))}{2}\\\\ sigmoid:tanh(x_i^Tx_j+1) 0x05 SVM code [github](https://github.com/chenxia31/code_Study_Practice/tree/main/CS229_2018autumn/ProblemSet(课后作业）/课后习题02) 借鉴别人的，留一个坑自己写 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189import matplotlib.pyplot as pltimport numpy as npimport random&quot;&quot;&quot;函数说明:读取数据Parameters: fileName - 文件名Returns: dataMat - 数据矩阵 labelMat - 数据标签&quot;&quot;&quot;def loadDataSet(fileName): dataMat = []; labelMat = [] fr = open(fileName) for line in fr.readlines(): #逐行读取，滤除空格等 lineArr = line.strip().split(&#x27;\\t&#x27;) dataMat.append([float(lineArr[0]), float(lineArr[1])]) #添加数据 labelMat.append(float(lineArr[2])) #添加标签 return dataMat,labelMat&quot;&quot;&quot;函数说明:随机选择alphaParameters: i - alpha m - alpha参数个数Returns: j -&quot;&quot;&quot;def selectJrand(i, m): j = i #选择一个不等于i的j while (j == i): j = int(random.uniform(0, m)) return j&quot;&quot;&quot;函数说明:修剪alphaParameters: aj - alpha值 H - alpha上限 L - alpha下限Returns: aj - alpah值&quot;&quot;&quot;def clipAlpha(aj,H,L): if aj &gt; H: aj = H if L &gt; aj: aj = L return aj&quot;&quot;&quot;函数说明:简化版SMO算法Parameters: dataMatIn - 数据矩阵 classLabels - 数据标签 C - 松弛变量 toler - 容错率 maxIter - 最大迭代次数Returns: 无&quot;&quot;&quot;# 参数分别为 数据集、类别标签、常数C、容错率、最大循环次数def smoSimple(dataMatIn, classLabels, C, toler, maxIter):# #转换为numpy的mat存储 dataMatrix = np.mat(dataMatIn); labelMat = np.mat(classLabels).transpose()#转置成列向量 #初始化b参数，统计dataMatrix的维度 b = 0; m,n = np.shape(dataMatrix)# m=100,n=2 #初始化alpha参数，设为0 alphas = np.mat(np.zeros((m,1)))# 100个alpha #初始化迭代次数 iter_num = 0 #最多迭代matIter次 while (iter_num &lt; maxIter): alphaPairsChanged = 0 #用于记录alpha是否已经进行优化 for i in range(m): #步骤1：计算误差Ei #此公式为分类决策公式 fXi = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b #print(&quot;fXi:&quot;,fXi) Ei = fXi - float(labelMat[i])#误差 #优化alpha，更设定一定的容错率。 if ((labelMat[i]*Ei &lt; -toler) and (alphas[i] &lt; C)) or ((labelMat[i]*Ei &gt; toler) and (alphas[i] &gt; 0)): #随机选择另一个与alpha_i成对优化的alpha_j j = selectJrand(i,m) #步骤1：计算误差Ej fXj = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b Ej = fXj - float(labelMat[j]) #保存更新前的aplpha值，使用深拷贝 alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy(); #步骤2：计算上下界L和H if (labelMat[i] != labelMat[j]): L = max(0, alphas[j] - alphas[i]) H = min(C, C + alphas[j] - alphas[i]) else: L = max(0, alphas[j] + alphas[i] - C) H = min(C, alphas[j] + alphas[i]) if L==H: print(&quot;L==H&quot;); continue #步骤3：计算eta，即η。 eta = dataMatrix[i,:]*dataMatrix[i,:].T +dataMatrix[j,:]*dataMatrix[j,:].T-2.0 * dataMatrix[i,:]*dataMatrix[j,:].T if eta == 0: print(&quot;eta=0&quot;); continue #步骤4：更新alpha_j alphas[j] += labelMat[j]*(Ei - Ej)/eta #步骤5：修剪alpha_j alphas[j] = clipAlpha(alphas[j],H,L) #abs 函数 返回数字的绝对值 if (abs(alphas[j] - alphaJold) &lt; 0.00001): print(&quot;alpha_j变化太小&quot;); continue #步骤6：更新alpha_i alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j]) #步骤7：更新b_1和b_2 b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T #步骤8：根据b_1和b_2更新b if (0 &lt; alphas[i]) and (C &gt; alphas[i]): b = b1 elif (0 &lt; alphas[j]) and (C &gt; alphas[j]): b = b2 else: b = (b1 + b2)/2.0 #统计优化次数 alphaPairsChanged += 1 #打印统计信息 print(&quot;第%d次迭代 样本:%d, alpha优化次数:%d&quot; % (iter_num,i,alphaPairsChanged)) #更新迭代次数 if (alphaPairsChanged == 0): iter_num += 1 else: iter_num = 0 print(&quot;迭代次数: %d&quot; % iter_num) return b,alphas&quot;&quot;&quot;函数说明:分类结果可视化Parameters: dataMat - 数据矩阵 w - 直线法向量 b - 直线解决Returns: 无&quot;&quot;&quot;def showClassifer(dataMat, w, b): #绘制样本点 data_plus = [] #正样本 data_minus = [] #负样本 for i in range(len(dataMat)): if labelMat[i] &gt; 0: data_plus.append(dataMat[i]) else: data_minus.append(dataMat[i]) data_plus_np = np.array(data_plus) #转换为numpy矩阵 data_minus_np = np.array(data_minus) #转换为numpy矩阵 plt.scatter(np.transpose(data_plus_np)[0], np.transpose(data_plus_np)[1], s=30, alpha=0.7) #正样本散点图 plt.scatter(np.transpose(data_minus_np)[0], np.transpose(data_minus_np)[1], s=30, alpha=0.7) #负样本散点图 #绘制直线 x1 = max(dataMat)[0] x2 = min(dataMat)[0] a1, a2 = w b = float(b) a1 = float(a1[0]) a2 = float(a2[0]) y1, y2 = (-b- a1*x1)/a2, (-b - a1*x2)/a2 plt.plot([x1, x2], [y1, y2]) #找出支持向量点 for i, alpha in enumerate(alphas): if abs(alpha) &gt; 0:#如果alpha&gt;0,表示 alpha所在的不等式条件起作用了 x, y = dataMat[i] plt.scatter([x], [y], s=150, c=&#x27;none&#x27;, alpha=0.7, linewidth=1.5, edgecolor=&#x27;red&#x27;) plt.show()&quot;&quot;&quot;函数说明:计算wParameters: dataMat - 数据矩阵 labelMat - 数据标签 alphas - alphas值Returns: w&quot;&quot;&quot;def get_w(dataMat, labelMat, alphas): alphas, dataMat, labelMat = np.array(alphas), np.array(dataMat), np.array(labelMat) w = np.dot((np.tile(labelMat.reshape(1, -1).T, (1, 2)) * dataMat).T, alphas) return w.tolist()if __name__ == &#x27;__main__&#x27;: dataMat, labelMat = loadDataSet(&#x27;datasets/testSet.txt&#x27;) b,alphas = smoSimple(dataMat, labelMat, 0.6, 0.001, 40) # print(&quot;b,alphas&quot;,b,alphas) w = get_w(dataMat, labelMat, alphas) print(&quot;w:&quot;,w) showClassifer(dataMat, w, b) /datasets/testSet.txt 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991003.542485 1.977398 -13.018896 2.556416 -17.551510 -1.580030 12.114999 -0.004466 -18.127113 1.274372 17.108772 -0.986906 18.610639 2.046708 12.326297 0.265213 -13.634009 1.730537 -10.341367 -0.894998 -13.125951 0.293251 -12.123252 -0.783563 -10.887835 -2.797792 -17.139979 -2.329896 11.696414 -1.212496 -18.117032 0.623493 18.497162 -0.266649 14.658191 3.507396 -18.197181 1.545132 11.208047 0.213100 -11.928486 -0.321870 -12.175808 -0.014527 -17.886608 0.461755 13.223038 -0.552392 -13.628502 2.190585 -17.407860 -0.121961 17.286357 0.251077 12.301095 -0.533988 -1-0.232542 -0.547690 -13.457096 -0.082216 -13.023938 -0.057392 -18.015003 0.885325 18.991748 0.923154 17.916831 -1.781735 17.616862 -0.217958 12.450939 0.744967 -17.270337 -2.507834 11.749721 -0.961902 -11.803111 -0.176349 -18.804461 3.044301 11.231257 -0.568573 -12.074915 1.410550 -1-0.743036 -1.736103 -13.536555 3.964960 -18.410143 0.025606 17.382988 -0.478764 16.960661 -0.245353 18.234460 0.701868 18.168618 -0.903835 11.534187 -0.622492 -19.229518 2.066088 17.886242 0.191813 12.893743 -1.643468 -11.870457 -1.040420 -15.286862 -2.358286 16.080573 0.418886 12.544314 1.714165 -16.016004 -3.753712 10.926310 -0.564359 -10.870296 -0.109952 -12.369345 1.375695 -11.363782 -0.254082 -17.279460 -0.189572 11.896005 0.515080 -18.102154 -0.603875 12.529893 0.662657 -11.963874 -0.365233 -18.132048 0.785914 18.245938 0.372366 16.543888 0.433164 1-0.236713 -5.766721 -18.112593 0.295839 19.803425 1.495167 11.497407 -0.552916 -11.336267 -1.632889 -19.205805 -0.586480 11.966279 -1.840439 -18.398012 1.584918 17.239953 -1.764292 17.556201 0.241185 19.015509 0.345019 18.266085 -0.230977 18.545620 2.788799 19.295969 1.346332 12.404234 0.570278 -12.037772 0.021919 -11.727631 -0.453143 -11.979395 -0.050773 -18.092288 -1.372433 11.667645 0.239204 -19.854303 1.365116 17.921057 -1.327587 18.500757 1.492372 11.339746 -0.291183 -13.107511 0.758367 -12.609525 0.902979 -13.263585 1.367898 -12.912122 -0.202359 -11.731786 0.589096 -12.387003 1.573131 -1","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"}]},{"title":"CS229-01--线性模型","slug":"CS229-01--线性模型","date":"2022-01-29T09:48:44.000Z","updated":"2023-05-13T13:47:12.926Z","comments":true,"path":"posts/7a22647b.html","link":"","permalink":"https://blog.tjdata.site/posts/7a22647b.html","excerpt":"根据Andrew wu 机器学习的监督学习的第一部分所总结的关于：linear regression、logistic regression、gradient decent、Newton、locally weighted linear regression、generalized linear model","text":"根据Andrew wu 机器学习的监督学习的第一部分所总结的关于：linear regression、logistic regression、gradient decent、Newton、locally weighted linear regression、generalized linear model 0x01 引言 机器学习的定义： 对于某类任务task和性能度量performance，如果一个计算机程序在task上以performance衡量的性能随着经验experience而自我完善，那么我们称这个计算机程序在从experience中学习 机器学习的方法在不同领域中以不同的方式逐渐发展到共通的状态，从统计学习中从特殊到一般的inference、从工程学中的模式识别，以及结合神经网络、信号处理、自动控制、人工智能以及数据挖掘等不同领域来综合方法，从数据中induction，从训练的模型deduction 在区分中机器学习常见分为监督学习supervised learning、非监督学习unsupervised learning和强化学习reinforcement learning 监督学习，给定dataset，包括输入x和输出y，由此来构建一个算法得到x和y的映射关系 非监督学习：给定dataset，包括输入x，由此来构建一些算法 机器学习算法的过程包括： 首先构建一个假设函数（hypothesis），其中包含一个模型中需要的参数（parameter） 之后构建目标函数（target），来让包含参数的模型更加贴合实际，这里需要一定的目标函数来刻画 转换成为一个优化问题（optimization），可以利用一些算法来进去求解 对模型进行指标的评价 0x02 线性回归 linear regression 数据集 输入变量：X^i=[x^i_1,x^i_2,...,x^i_n]\\\\ 输出变量：y^i\\\\ 单个实例：\\{X^i,y^i\\}\\\\ 完整数据集：\\{(X^i,y^i),i=1,...,m\\} 假设 线性回归中比较强的假设为 \\hat{y}=h_\\theta(X)=\\theta^T*X \\theta:[1,(n+1)]\\\\ X:=[x^0,x^1,...,x^n],x^0=1 目标函数 直观的方法，目标函数是预测值predict和真实值ground- truth之间的某种不相似的关系，我们希望的是两者尽可能的相似，所以这里可以使用欧氏距离来刻画： loss\\ function= 1/2*\\Sigma_{i=1}^{m}[h_\\theta(X^i)-y^i]^2\\\\ （这里的1/2只是为了方便后续求导的方便） 我们希望这个越小越好 概率解释的方法，在预测中总会有着各种各样的误差，所以 \\hat{y^i}=h_\\theta(X^i)+\\epsilon^i \\\\ 这样解释其实是将预测值 y 看成是一个分布，这个分布首先具有一个概率分布函数，之后我们在预测中希望的是所有预测值的分布在取真实值的时候概率最大，这时候求解出来的参数就是模型想要的参数 根据中心极限定理这个推导得出误差项分布是一种高斯分布，则得到预测值的分布 \\epsilon^i \\in N(0,\\sigma^2)\\\\ \\hat {y^i}=\\frac{1}{\\sigma*\\sqrt(2*\\pi)}*exp(-\\frac{(\\hat y^i-h_\\theta(X))^2}{2*\\sigma^2}) 得到最大似然函数（likelihood function） L=∏i=1mP(y^∣X,θ)L=\\prod_{i=1}^m P(\\hat y|X,\\theta) L=​i=1​∏​m​​P(​y​^​​∣X,θ) 然后对其取对数后求导 In（L）=\\Sigma_{i=1}^{m}P(\\hat{y})\\\\ \\frac{\\partial(In (L))}{\\partial \\theta}=\\Sigma_{i=1}^m[Ln(\\frac{1}{\\sigma*\\sqrt(2*\\pi)})+-\\frac{(\\hat y^i-h_\\theta(X))^2}{2*\\sigma^2}] 如果希望上式最小，等价 Max−(y^i−hθ(X))22Max -\\frac{(\\hat y^i-h_\\theta(X))^2}{2} Max−​2​​(​y​^​​​i​​−h​θ​​(X))​2​​​​ 或者等价于 Min (y^i−hθ(X))22Min\\ \\frac{(\\hat y^i-h_\\theta(X))^2}{2} Min ​2​​(​y​^​​​i​​−h​θ​​(X))​2​​​​ 非常amazing的看出两个方法居然得到相同的结论！但其实深思我们会发现第一种方法我们是根据经验来得到，我们主观的认识用在线性回归中利用欧式距离会好一点，第二种方法我们带着一个假设（误差满足高斯分布）出发，来得到概率分布，通过maximum likelihood estimation（MLE）得到损失函数,两者只是解释的方法不同 优化算法 这种优化算法的常见是使用梯度下降的方式进行计算： init\\ \\ \\theta=zeros(1,n+1)\\\\ update:\\theta_j:=\\theta_j-lr*\\frac{\\partial J}{\\partial \\theta}\\\\ lr:learning\\ rate 由上述推导看出我们的目标函数的梯度 J(\\theta)=\\frac{(\\hat y^i-h_\\theta (X^i))^2}{2}\\\\ \\frac{\\partial J}{\\partial \\theta }=\\Sigma_{i=1}^m(h_\\theta(X^i)-y^i)*\\frac{\\partial h_\\theta(X^i)}{\\partial \\theta}\\\\ 这里的: X^i:(1,n+1)=\\{x_0,x_1,...,x_j,...,x_n\\}\\\\ 则： \\frac{\\partial J}{\\partial \\theta }=\\Sigma_{i=1}^m(h_\\theta(X^i)-y^i)*X^i 这样就可以每次运行下去了，但是我们会发现在优化的过程每次梯度下降的过程都需要对所有数据进行计算，所以通常被称为batch gradient descent（BGD），但是这样速度通常会变的很慢，因此需要尝试**stochastic gradient descent（SGD）**下降的梯度只使用一个点而不是所有点的梯度相加，由此得到最终解 0x03 逻辑回归 logistics regression 数据集 输入变量：X^i=[x^i_1,x^i_2,...,x^i_n]\\\\ 输出变量：y^i\\in{0,1}\\\\ 单个实例：\\{X^i,y^i\\}\\\\ 完整数据集：\\{(X^i,y^i),i=1,...,m\\} 与之前不同的是，这里的输出变量或者说是label，仅为0或者1 假设 我们仍然假设为线性模型： h_\\theta(X)=g(\\theta^T*X)\\\\ g(z)=\\frac{1}{1+exp(-z)}\\\\ 由此得到的预测值输出：\\\\ \\hat y = \\begin{cases} 0 & \\theta^T X=0 \\end{cases} 损失函数 这里我们从概率分布的角度出发，利用MLE的方式来寻找最佳的损失函数 首先确定预测值 y 的分布 P(\\hat{y}=0)=h_\\theta(X)\\\\ P(\\hat{y}=1)=1-h_\\theta(X)\\\\ 由此我们可以出预测值正确的概率分布函数为： P(yi^)=hθ(X)1−yi∗(1−hθ(X)yi)P(\\hat{y^i})=h_\\theta(X)^{1-y^i}*(1-h_\\theta(X)^{y^i}) P(​y​i​​​^​​)=h​θ​​(X)​1−y​i​​​​∗(1−h​θ​​(X)​y​i​​​​) 我们希望针对所有的分布函数可以最大化 L=\\prod_{i=1}^m(h_\\theta(X)^{1-y^i}*(1-h_\\theta(X)^{y^i}))\\\\ 优化算法 GD 梯度下降的方法 首先计算梯度、然后更新 \\frac{\\partial(InJ)}{\\partial\\theta}=\\Sigma_{i=1}^m[(1-y)*1/h_\\theta(X)-y*/(1-h_\\theta(X))]*\\frac{\\partial h_\\theta(X)}{\\partial\\theta}\\\\ 同时\\\\ \\frac{\\partial h_\\theta(X)}{\\partial \\theta}=X*\\frac{\\partial g(\\theta^TX)}{\\partial \\theta}\\\\ 可得到\\\\ \\frac{\\partial(InJ)}{\\partial\\theta}=(y-h_\\theta(X))*X 更新梯度 θ:=θ+lr∗∂(InJ)∂θ\\theta:=\\theta+lr*\\frac{\\partial(InJ)}{\\partial\\theta} θ:=θ+lr∗​∂θ​​∂(InJ)​​ Newton法 推导过程没有看，但是更新参数的过程为 \\theta:=\\theta-H^{-1}\\bigtriangledown_\\theta L(\\theta)\\\\ Hessian\\ matrix:H_{ij}=\\frac{\\partial^2 L(\\theta)}{\\partial \\theta_i\\partial\\theta_j} 番外-- logistic code 根据机器学习课后习题来的： 建立一个线性模型的class： 12345678910111213141516171819202122232425262728293031323334353637383940class LinearModel(object): &quot;&quot;&quot;Base class for linear models.&quot;&quot;&quot; def __init__(self, step_size=0.2, max_iter=100, eps=1e-2, theta_0=None, learning_rate=0.01,verbose=True): &quot;&quot;&quot; Args: step_size: Step size for iterative solvers only. max_iter: Maximum number of iterations for the solver. eps: Threshold for determining convergence. theta_0: Initial guess for theta. If None, use the zero vector. verbose: Print loss values during training. &quot;&quot;&quot; self.theta = theta_0 self.step_size = step_size self.max_iter = max_iter self.eps = eps self.verbose = verbose self.learning_rate=learning_rate def fit(self, x, y): &quot;&quot;&quot;Run solver to fit linear model. Args: x: Training example inputs. Shape (m, n). y: Training example labels. Shape (m,). &quot;&quot;&quot; raise NotImplementedError(&#x27;Subclass of LinearModel must implement fit method.&#x27;) def predict(self, x): &quot;&quot;&quot;Make a prediction given new inputs x. Args: x: Inputs of shape (m, n). Returns: Outputs of shape (m,). &quot;&quot;&quot; raise NotImplementedError(&#x27;Subclass of LinearModel must implement predict method.&#x27;) 之后对其进行更改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115import numpy as npimport utilfrom linear_model import LinearModelimport numpy as npdef main(train_path, eval_path, pred_path): &quot;&quot;&quot;Problem 1(b): Logistic regression with Newton&#x27;s Method. Args: train_path: Path to CSV file containing dataset for training. eval_path: Path to CSV file containing dataset for evaluation. pred_path: Path to save predictions. &quot;&quot;&quot; x_train, y_train = util.load_dataset(train_path, add_intercept=True) x_eval, y_eval = util.load_dataset(eval_path, add_intercept=True) # *** START CODE HERE *** model = LogisticRegression() model.fit(x_train, y_train) # *** END CODE HERE ***class LogisticRegression(LinearModel): &quot;&quot;&quot;Logistic regression with Newton&#x27;s Method as the solver. Example usage: &gt; clf = LogisticRegression() &gt; clf.fit(x_train, y_train) &gt; clf.predict(x_eval) &quot;&quot;&quot; def fit(self, x, y): &quot;&quot;&quot;Run Newton&#x27;s Method to minimize J(theta) for logistic regression. Args: x: Training example inputs. Shape (m, n). y: Training example labels. Shape (m,). &quot;&quot;&quot; # *** START CODE HERE *** def h(theta, x): &#x27;&#x27;&#x27; logistic的假设 参数： theta：超参数 x：输入变量，或者是特征值 &#x27;&#x27;&#x27; return 1 / (1 + np.exp(-np.dot(x, theta))) # *** END CODE HERE *** def gradient(theta, x, y): &#x27;&#x27;&#x27; 计算梯度 参数： theta：超参数 x：输入变量 y：验证变量 &#x27;&#x27;&#x27; m, _ = x.shape return -1 / m * np.dot(x.T, (y - h(theta, x))) def hessian(theta, x): &quot;&quot;&quot; 计算Hessian公式 &quot;&quot;&quot; m, _ = x.shape h_theta_x = np.reshape(h(theta, x), (-1, 1)) return 1 / m * np.dot(x.T, h_theta_x * (1 - h_theta_x) * x) def next_theta(theta, x, y): &quot;&quot;&quot;通过Newton法来更新theta :param theta: Shape (n,). :return: The updated theta of shape (n,). &quot;&quot;&quot; return theta - np.dot(np.linalg.inv(hessian(theta, x)), gradient(theta, x, y)) m, n = x.shape # m是训练集的大小，n是特征的多少 # 初始化theta if self.theta is None: self.theta = np.zeros(n) # 更新theta old_theta = self.theta new_theta = next_theta(self.theta, x, y) # 合适的时候停止 while np.linalg.norm(new_theta - old_theta, 1) &gt;= self.eps: old_theta = new_theta new_theta = next_theta(old_theta, x, y) self.theta = new_theta def predict(self, x): &quot;&quot;&quot;Make a prediction given new inputs x. Args: x: Inputs of shape (m, n). Returns: Outputs of shape (m,). &quot;&quot;&quot; # *** START CODE HERE *** return x @ self.theta &gt;= 0 # *** END CODE HERE ***train_path = &#x27;../data/ds1_train.csv&#x27;valid_path = &#x27;../data/ds1_valid.csv&#x27;prad_path = &#x27;../data/ds1_valid.csv&#x27;main(train_path, valid_path, prad_path) 0x04 广义线性模型 Generative linear model 三个最基本的假设 预测值y的分布是指数族，～Exponential Family（n）其中n为超参数 对于给定的x，我们得到一个关于预测值y的概率分布函数，这个分布函数的期望我们将其作为我们最终的预测值，则满足 h(X)=E(y∣X,θ)h(X)=E(y|X,\\theta) h(X)=E(y∣X,θ) （限制性最大的假设）假设自然参数n和输入变量x之前的关系是线性的 η=θTX\\eta=\\theta^TX η=θ​T​​X 关于什么是指数族 指数族分布并不是一个具体的概率分布，指的是一类分布，这类分布具有一些共同的特性，所以形成一个概率分布族family，常见的指数族分布包括高斯分布、二项分布、多项式分布、泊松分布、gamma分布、beta分布等 P(y,\\eta)=b(y)*exp(\\eta^TT(y)-a(\\eta))\\\\ 这里的\\eta 为自然参数\\\\ T(y)是充分统计量\\\\ a(\\eta)是对数分割函数，来帮助\\int p(y,\\eta)dy=1 常见的指数族和对应分类算法的： 实数～高斯分布 0-1分布～伯努利分布 计数分布～泊松分布 非零实数～Gamma正参数分布 由GLM构建线性模型的过程 linear regression hθ(X)=E(y)=u=η=θTXh_\\theta(X)=E(y)=u=\\eta=\\theta^TX h​θ​​(X)=E(y)=u=η=θ​T​​X logistic regression h_\\theta(x)=E(y)=\\phi\\\\ =\\frac{1}{1+e^{-\\eta}}\\\\ =\\frac{1}{1+e^{-\\theta^Tx}} 0x05 高斯判别式算法 Gauss discriminant analysis 判别式算法：希望找到一个分别的算法 生成式算法：希望针对数据本身建模 （判别式算法意味着一个找到一个线来区分两者，生成算法意味着找到数据本身的性质） 或许一个是频率学派、一个是贝叶斯学派…","categories":[{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"}],"tags":[{"name":"AndrewWu","slug":"AndrewWu","permalink":"https://blog.tjdata.site/tags/AndrewWu/"}]},{"title":"HELLO WORLD","slug":"HELLO-WORLD","date":"2022-01-28T01:02:58.000Z","updated":"2023-05-13T13:49:40.299Z","comments":true,"path":"posts/87e5865b.html","link":"","permalink":"https://blog.tjdata.site/posts/87e5865b.html","excerpt":"关于为什么我希望拥有一个自己的博客？并承诺会将这份博客写下去","text":"关于为什么我希望拥有一个自己的博客？并承诺会将这份博客写下去 0x01 关于blog 博客本身便有着其自身作为互联网的浪漫！（这里不谈web3）互联网作为其诞生之初便是让每个人都平等的链接起来并可以分享和发表自己的观点，但是随着商业和政府的融入，互联网逐渐显示出其工具性的特点，个人在其中的作用逐渐被垄断性的互联网公司所抹除，仿佛互联网公司便是互联网中的实际执法者。但回顾在互联网最开始的愿景中，是希望每个人可以通过互联网连接在一起，博客有着一台服务器、一个域名便可以发不出自己的生活点滴、自由思想等，可以让自己的声音在互联网的一角中的留有回响 0x02 关于自己 本人的专业是交通运输行业中的交通信息方向的大四学生（2022年），作为一名综合性的应用学科，交通本科中学习的方向很多，但是同样也有学的不精细的特点 （基础类）高等数学、线性代数、概率论、复变函数、理论力学、C++ （专业基础类）模电数电、电路分析、交通信号基础、自动控制原理、信号与系统、信息传输原理 （专业进阶）嵌入式系统、交通信息检测与处理、交通数据分析、车站与区间信号控制、列车运行控制系统 在计算机技术加持在传统行业中，以数据来说话的思想推动着数据化、信息化、智能化、自动化的发展，这可能也是本人研究生之后的方向。所以作为一个非计算机科学、非数学科学出生的人来说，交通行业对于数据处理的方式可能最多是在于模型应用场景的人为区分，但是本人还是希望可以学习一些计算机、数学、编程等比较有趣的知识来武装自己，并在接触新鲜事物中保持着自己的前进的动力。 正如Jobs所述：stay hungry，stay foolish！ 0x03 关于自己的blog 对于一个系统的设计自然要从需求的角度出发，自己的blog体系也不意外，因此建立自己博客的目的是我希望将自己的学习知识用比较个性化的语言总结出来发布到网上 记录：并总结自己的所学，可能会走弯路，但是要尝试去做 督促：自己学习，同样是为了自己后续的进步 因此希望从大四开始，从今天开始，至少保证一个月一篇，正常尽可能的保持一个星期一篇来认真写出一份文章。 同时post的分类可能会有： base，比如Linux的简单使用、python环境的配置等 lives，自己杂谈的所思所想 CS，比如web开发、数据结构之类的知识 DS，比如一些数据的笔记、算法的推导 0x04 搭建过程 利用GitHub pages+ Hexo，选取一个好看的主题 之后购买域名来解析到对应位置，同时也需要在GitHub中配置 利用typora管理post文件夹、利用gitee来管理图床 一些常见的命令： 1234hexo clean 用于清除混存与静态文件hexo new post [文章标题] 可以新建文章hexo generate 用于生成静态文件hexo deploy 用于部署网站 在编写文章的时候，可以选择一个 1234使用cover：[图片url]来为添加封面&lt;!--more--&gt;之前的是摘要的部分 祝看到的人生活学习愉快！","categories":[{"name":"Memo","slug":"Memo","permalink":"https://blog.tjdata.site/categories/Memo/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"https://blog.tjdata.site/tags/%E6%9D%82%E8%B0%88/"}]},{"title":"算法设计","slug":"算法设计","date":"2021-08-08T06:17:05.000Z","updated":"2023-05-13T13:53:11.612Z","comments":true,"path":"posts/95085cd8.html","link":"","permalink":"https://blog.tjdata.site/posts/95085cd8.html","excerpt":"divide and conquer In section 2.3.1 we can saw how merge sort serves as an example of the divide-and conquer paradigm. Recalling that in divide-and-conquer, we solve a problem recursively, applying three step at each level of the recursion:","text":"divide and conquer In section 2.3.1 we can saw how merge sort serves as an example of the divide-and conquer paradigm. Recalling that in divide-and-conquer, we solve a problem recursively, applying three step at each level of the recursion: Divide the problem into a number of subproblems that are smaller instances of the same problem Conquer the subproblems by solving them recurisvely. If the problem sizes are small enough, however,just solve the subproblems in a straightforward manner. Combine the solutions to the subpoblems into the solution for the original problem (1)对于一个规模为N 的问题，若该问题可以容易地解决，则直接解决,否则执行下面的步骤。 (2)将该问题分解成若干个规模较小的子问题，这些子问题互相独立，并且原问题形式相同。 (3)递归recursively地解子问题。 (4)然后，将各子问题的解合并得到原问题的解 example： merge sort 对于一个长数组的排序问题，其排序可以分为左半边、右半边的排序手段 这样独立分配的子任务最终排序为可以分为最小的两个元素 排序之后再合并 12345678910111213141516171819202122232425262728293031323334353637from math import floordef merge_sort(A, p, r): if p &lt; r: q = floor((p + r) / 2) merge_sort(A, p, q) merge_sort(A, q + 1, r) merge(A, p, q, r) return Adef merge(A, p, q, r): n1 = q - p + 1 n2 = r - q L = [] R = [] ceiling = 10000 for i in range(0, n1): L.append(A[p + i - 1]) for j in range(0, n2): R.append(A[q + j]) L.append(ceiling) R.append(ceiling) i = 0 j = 0 for k in range(p - 1, r): if L[i] &lt;= R[j]: A[k] = L[i] i = i + 1 else: A[k] = R[j] j = j + 1 return Aprint(merge_sort([1, 3, 4, 2, 3, 1], 1, 6)) Dymanic programming dynamic programming, like the divide-and-conquer method ，solves problems by combineing the solutions to subproblems.(“programming in this context refers to a tabular method,not ato wirting computer code”). As we saw in cahpter 2 and 4, divide -and -conquer algorithm partition the problem into disjoint subproblems, solve the subproblems recursively, and then combine their solutions to solve the orignal problem. In contrast, ddynamic programming applies when the subproblems overlap—that is, when subproblems share subsubproblems. In this context, a divide-and-conquer algotirhm does more work than necessary , reaped solving the common subsubproblems. A dynamic-programming algorithm solves each subsubproblems juest once and then saves its answei in the table, thereby avoiding the work of recomputing the answer every time it solves each subsubproblem. We typically apply dynamic programming to optimization problems. Such problems can have many possible solutions. Each solution has a value, and we wish to find a solution with optimal value. characterizethe structure of an optimal solution Recursively defin ethe value of an opitmal solution Compute the value of an optimal solution, typically in a bottom-up fashion. Construst an optimal solution from computed information 确定dynamic programming的数组以及具体的下标定义 确定递推公式 dynamic programming数组的初始化 具体举例来使得计算进行下去 Example: 三角形最小和 123456789101112131415triangle=[[2], [3, 4], [6, 5, 7], [4, 1, 8, 3]]DP=[]DP.append(triangle[0])if len(triangle)&gt;=1: for story in range(1, len(triangle)): temp=[] for i in range(0, len(triangle[story])): if i==0: temp.append(DP[story-1][0] + triangle[story][0]) elif i==(len(triangle[story]) - 1): temp.append(DP[story-1][i-1] + triangle[story][i]) else: temp.append(min(triangle[story][i] + DP[story - 1][i - 1], triangle[story][i] + DP[story - 1][i])) DP.append(temp)min(DP[-1]) Greedy programming –remain to studying– back tracking –remain to studying– branch and bound –remain to studying–","categories":[{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"}],"tags":[{"name":"study","slug":"study","permalink":"https://blog.tjdata.site/tags/study/"}]},{"title":"","slug":"《matrix》影评","date":"2021-08-07T14:56:28.000Z","updated":"2023-04-29T09:30:29.299Z","comments":true,"path":"posts/0.html","link":"","permalink":"https://blog.tjdata.site/posts/0.html","excerpt":"1999-《黑客帝国》 就个人最近看到的资料，主要从20世纪计算机的发展、以及从哲学意义上的存在来观看这个电影（当然neo的the one思想也很贴合圣经，最后感悟的思想也很想事人始终得不到的圣杯，当然得有一个女性角色再危机关头利用“love“来拯救主角，这都不是不重要的细节）","text":"1999-《黑客帝国》 就个人最近看到的资料，主要从20世纪计算机的发展、以及从哲学意义上的存在来观看这个电影（当然neo的the one思想也很贴合圣经，最后感悟的思想也很想事人始终得不到的圣杯，当然得有一个女性角色再危机关头利用“love“来拯救主角，这都不是不重要的细节） — 哲学的角度philosophy 就像是最基本的问题，matrix主要带给我们的问题是： Matrix塑造的世界和真实世界之间的差别是什么？ 面临matrix的时间，作为human的我们和the one有什么区别 依旧每个人信仰的作用 关于世界的构成可以在第二部分中详细阐述，其最核心的思想便是：matrix的世界是模拟的，‘There is no spoon（这里没有汤勺）’ 为什么neo可以称为the one，我想是由于他具有know生活在一个模拟的世界，然后believe生活在模拟的世界中自己可以做出一些超乎寻常规律的行为，最后才能real地将这个运用在matrix这个世界中，之后real的运用中又回反哺backup地重新巩固自己的believe这个行为，⚠️仅仅believe是没有对可能ow行为的反馈的。 头头某菲尔思达到了believe的信念，所以他可以将这些人（real man）聚集起来，才能了解到matrix是虚伪的世界，才可以在层次上激发这些人，才会相信有neo这样的the one，但是他自己本身不是the one，因为❕❕他相信不代表他能去做出来这件事❕❕，所以他无法更近一步的了解到这个世界是虚拟的本质 Neo在believe这个事实之后，在和黑衣人的决斗中也做到了这一点，并更清晰的认识到所谓的模拟世界无非是代码的本质，这样又给他本身的believe带来反馈，这样变成坚强的the one！！ 二 计算机历史发展的角度 计算一直是人类希望做到的，比如在一个饭店中的对账，银行中的流水的计算，这些可能用算盘就能解决，但是到工业革命，各种企业蓬勃发展，体量不断增大，以及军事、科学方面对于计算的需求不断增大，逐渐出现了机械电动装置的计算机器，这些机器一般较为复杂，难以维修，机械装置一般不可靠，在逐渐的发展中，计数装置从继电器、到真空管、到电子管、再到半导体，存储装置从最初的纸条到声压、到磁带、到磁盘、再到现在的硬盘。 计算能力不断增加，最初的二战时期的计算可能用于导弹计算、密码破解，等仅仅用于计算的场景，但在50年代～70年代，在这个辉煌的时代，计算机器开始进入民用环节，计算机可用于简单的计算，但是更有趣的加上显示屏和打印机之后，以及互联网，人们可以惊讶的发现计算机可以做许多之前难以想象的事情：比如下象棋、利用图形界面来实现CAD（computer aided design）、利用互联网来实现图书音乐视频等信息的传输。 这个时候计算机不再仅仅是个‘compute’计算的设备，而变成一个多功能的‘电脑’，到80年代～2000年，计算机硬件在摩尔定律下一直蓬勃发展，以及各种操作系统的不但发展，加上二战之后人们文化的发展，这个时代的科幻开始发展，三个理念：机器人、人工智能、计算机对于人类的威胁始终是主题。 《太空漫游2001》电影中的经典 《神经漫游者》书籍中的经典 黑客帝国《matrix》便是提出一个疑问：“如果我们的世界是由程序编制好的？如何” 各种物理规律不过是一行代码，人类本身的各种冲动不过是模拟的电脉冲，世界中的各种美好事物不过是模拟的，其中最好奇的一点便是，人们利用精神进入一个虚拟的世界，在虚拟的世界受到冲击，虚拟世界中自己以为自己被攻击，大脑做出反应，那么物理世界中的大脑会做出对应的反应吗？同样虚拟世界中的精神体死亡了，本人的肉体还会或者吗，可以🔗yale university中 Can my body survive f my deaths of spirit 那么这样的世界的‘真real’在哪里呢？ 所以know yourself","categories":[],"tags":[]},{"title":"chenxia,hello world","slug":"chenxia-hello-world","date":"2021-08-07T13:28:33.000Z","updated":"2022-10-17T08:18:08.947Z","comments":true,"path":"posts/3f0d2081.html","link":"","permalink":"https://blog.tjdata.site/posts/3f0d2081.html","excerpt":"Welcome to chenxia‘s site ! This is my very first post.","text":"Welcome to chenxia‘s site ! This is my very first post. 终于搞好了博客 GitHub中以.github.io建立自己的仓库来当作网站的仓库 之后利用hexo来搭建自己本地的网站 利用ssh和git来将本地的网站和GitHub的仓库连接 主题太难选了！！ 相关基本的操作 12345hexo generatehexo newhexo deployhexo severhexo publish","categories":[],"tags":[{"name":"lives","slug":"lives","permalink":"https://blog.tjdata.site/tags/lives/"}]}],"categories":[{"name":"baseline","slug":"baseline","permalink":"https://blog.tjdata.site/categories/baseline/"},{"name":"RL","slug":"RL","permalink":"https://blog.tjdata.site/categories/RL/"},{"name":"memo","slug":"memo","permalink":"https://blog.tjdata.site/categories/memo/"},{"name":"ML&DL","slug":"ML-DL","permalink":"https://blog.tjdata.site/categories/ML-DL/"},{"name":"Memo","slug":"Memo","permalink":"https://blog.tjdata.site/categories/Memo/"},{"name":"Baseline","slug":"Baseline","permalink":"https://blog.tjdata.site/categories/Baseline/"},{"name":"CS","slug":"CS","permalink":"https://blog.tjdata.site/categories/CS/"},{"name":"homework","slug":"homework","permalink":"https://blog.tjdata.site/categories/homework/"},{"name":"Trans","slug":"Trans","permalink":"https://blog.tjdata.site/categories/Trans/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://blog.tjdata.site/tags/wiki/"},{"name":"CS188","slug":"CS188","permalink":"https://blog.tjdata.site/tags/CS188/"},{"name":"datawhale","slug":"datawhale","permalink":"https://blog.tjdata.site/tags/datawhale/"},{"name":"Mac","slug":"Mac","permalink":"https://blog.tjdata.site/tags/Mac/"},{"name":"torch","slug":"torch","permalink":"https://blog.tjdata.site/tags/torch/"},{"name":"Kaggle","slug":"Kaggle","permalink":"https://blog.tjdata.site/tags/Kaggle/"},{"name":"LSR","slug":"LSR","permalink":"https://blog.tjdata.site/tags/LSR/"},{"name":"proxyApp","slug":"proxyApp","permalink":"https://blog.tjdata.site/tags/proxyApp/"},{"name":"document","slug":"document","permalink":"https://blog.tjdata.site/tags/document/"},{"name":"知识管理","slug":"知识管理","permalink":"https://blog.tjdata.site/tags/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86/"},{"name":"chart","slug":"chart","permalink":"https://blog.tjdata.site/tags/chart/"},{"name":"git","slug":"git","permalink":"https://blog.tjdata.site/tags/git/"},{"name":"pandas","slug":"pandas","permalink":"https://blog.tjdata.site/tags/pandas/"},{"name":"使用技巧","slug":"使用技巧","permalink":"https://blog.tjdata.site/tags/%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"},{"name":"CS229","slug":"CS229","permalink":"https://blog.tjdata.site/tags/CS229/"},{"name":"paper","slug":"paper","permalink":"https://blog.tjdata.site/tags/paper/"},{"name":"CS285","slug":"CS285","permalink":"https://blog.tjdata.site/tags/CS285/"},{"name":"D2L","slug":"D2L","permalink":"https://blog.tjdata.site/tags/D2L/"},{"name":"蘑菇书","slug":"蘑菇书","permalink":"https://blog.tjdata.site/tags/%E8%98%91%E8%8F%87%E4%B9%A6/"},{"name":"Review","slug":"Review","permalink":"https://blog.tjdata.site/tags/Review/"},{"name":"paper_reading","slug":"paper-reading","permalink":"https://blog.tjdata.site/tags/paper-reading/"},{"name":"nothing","slug":"nothing","permalink":"https://blog.tjdata.site/tags/nothing/"},{"name":"Translation","slug":"Translation","permalink":"https://blog.tjdata.site/tags/Translation/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://blog.tjdata.site/tags/Leetcode/"},{"name":"network","slug":"network","permalink":"https://blog.tjdata.site/tags/network/"},{"name":"PersonPost","slug":"PersonPost","permalink":"https://blog.tjdata.site/tags/PersonPost/"},{"name":"netowrk","slug":"netowrk","permalink":"https://blog.tjdata.site/tags/netowrk/"},{"name":"Single","slug":"Single","permalink":"https://blog.tjdata.site/tags/Single/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://blog.tjdata.site/tags/LeetCode/"},{"name":"TsinghuaBook","slug":"TsinghuaBook","permalink":"https://blog.tjdata.site/tags/TsinghuaBook/"},{"name":"Pyomo","slug":"Pyomo","permalink":"https://blog.tjdata.site/tags/Pyomo/"},{"name":"Django","slug":"Django","permalink":"https://blog.tjdata.site/tags/Django/"},{"name":"Experiment","slug":"Experiment","permalink":"https://blog.tjdata.site/tags/Experiment/"},{"name":"AndrewWu","slug":"AndrewWu","permalink":"https://blog.tjdata.site/tags/AndrewWu/"},{"name":"杂谈","slug":"杂谈","permalink":"https://blog.tjdata.site/tags/%E6%9D%82%E8%B0%88/"},{"name":"study","slug":"study","permalink":"https://blog.tjdata.site/tags/study/"},{"name":"lives","slug":"lives","permalink":"https://blog.tjdata.site/tags/lives/"}]}